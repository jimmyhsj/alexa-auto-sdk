{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Alexa Auto SDK \u00b6 What is Auto SDK? \u00b6 The Alexa Auto SDK contains essential client-side software required to integrate Alexa into the automobile. The Auto SDK provides libraries that connect to Alexa and expose interfaces for your vehicle software to implement the platform-specific behavior for audio input, media streaming, calling through a connected phone, turn-by-turn navigation, controlling vehicle features such as heaters and lights, and more. You can use the included sample application to learn about the Auto SDK interfaces and to test interactions before integration. Product guidelines \u00b6 The Product Requirements and Guidelines docs describe requirements and principals to follow when designing and implementing an Auto SDK client integration for your vehicle. Your integration must follow the product requirements and pass Amazon's automotive certification process. What's new in Auto SDK? \u00b6 Auto SDK is always improving. See the Auto SDK release notes to learn about the latest features and enhancements. Developer resources \u00b6 Follow the Get Started with Auto SDK guide to set up the Auto SDK development prerequisites. Read the Explore Auto SDK Concepts docs to learn how Auto SDK works and understand its core APIs. Read the Explore Auto SDK Features docs to learn about all the different features Auto SDK provides. Follow the developer docs for Android or Native C++ to guide you through integrating Auto SDK into your vehicle. Use the Auto SDK Migration Guide to ease your upgrade to the latest Auto SDK version.","title":"Alexa Auto SDK"},{"location":"#alexa-auto-sdk","text":"","title":"Alexa Auto SDK"},{"location":"#what-is-auto-sdk","text":"The Alexa Auto SDK contains essential client-side software required to integrate Alexa into the automobile. The Auto SDK provides libraries that connect to Alexa and expose interfaces for your vehicle software to implement the platform-specific behavior for audio input, media streaming, calling through a connected phone, turn-by-turn navigation, controlling vehicle features such as heaters and lights, and more. You can use the included sample application to learn about the Auto SDK interfaces and to test interactions before integration.","title":"What is Auto SDK?"},{"location":"#product-guidelines","text":"The Product Requirements and Guidelines docs describe requirements and principals to follow when designing and implementing an Auto SDK client integration for your vehicle. Your integration must follow the product requirements and pass Amazon's automotive certification process.","title":"Product guidelines"},{"location":"#whats-new-in-auto-sdk","text":"Auto SDK is always improving. See the Auto SDK release notes to learn about the latest features and enhancements.","title":"What's new in Auto SDK?"},{"location":"#developer-resources","text":"Follow the Get Started with Auto SDK guide to set up the Auto SDK development prerequisites. Read the Explore Auto SDK Concepts docs to learn how Auto SDK works and understand its core APIs. Read the Explore Auto SDK Features docs to learn about all the different features Auto SDK provides. Follow the developer docs for Android or Native C++ to guide you through integrating Auto SDK into your vehicle. Use the Auto SDK Migration Guide to ease your upgrade to the latest Auto SDK version.","title":"Developer resources"},{"location":"CONTRIBUTING/","text":"Contribution Guidelines \u00b6 Thank you for your interest in contributing to Alexa Auto SDK. Whether it's a bug report, new feature request, documentation request, or a correction, we greatly value feedback and contributions from the developer community. Read the following guidelines before submitting any issues to ensure we have all the necessary information to respond to your request or contribution. Report a bug or request a feature \u00b6 We do not use the GitHub issue tracker. See the Need Help? page of Auto SDK documentation for details about reporting issues. Pull requests \u00b6 At this time, we do not accept pull requests. If you want to contribute a code change, follow the same process used to report bugs and request features. Report security issues \u00b6 If you discover a potential security issue in this project, we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public Github issue. License \u00b6 See the LICENSE file for Auto SDK licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"CONTRIBUTING/#contribution-guidelines","text":"Thank you for your interest in contributing to Alexa Auto SDK. Whether it's a bug report, new feature request, documentation request, or a correction, we greatly value feedback and contributions from the developer community. Read the following guidelines before submitting any issues to ensure we have all the necessary information to respond to your request or contribution.","title":"Contribution Guidelines"},{"location":"CONTRIBUTING/#report-a-bug-or-request-a-feature","text":"We do not use the GitHub issue tracker. See the Need Help? page of Auto SDK documentation for details about reporting issues.","title":"Report a bug or request a feature"},{"location":"CONTRIBUTING/#pull-requests","text":"At this time, we do not accept pull requests. If you want to contribute a code change, follow the same process used to report bugs and request features.","title":"Pull requests"},{"location":"CONTRIBUTING/#report-security-issues","text":"If you discover a potential security issue in this project, we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public Github issue.","title":"Report security issues"},{"location":"CONTRIBUTING/#license","text":"See the LICENSE file for Auto SDK licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"License"},{"location":"get-started/","text":"Get Started with Auto SDK \u00b6 This guide outlines the one-time steps required to get started building an Auto SDK integration for your vehicle. Register an AVS product \u00b6 The Alexa features enabled by Auto SDK are built upon the Alexa Voice Service (AVS) . Prior to using Auto SDK, follow the Register a Product with AVS guide to set up an Amazon developer account, register a product for your vehicle, and create a security profile. For the Please select your product type option, select Device with Alexa built-in . For the Product category option, select Automotive . In the product details page of your new AVS product, take note of the following fields for later use: The Amazon ID from the top of the page The Client ID from the Other devices and platforms tab Clone the Auto SDK source code \u00b6 Auto SDK is open source. Clone the alexa-auto-sdk project from Github on your development machine: git clone https://github.com/alexa/alexa-auto-sdk.git Auto SDK documentation refers to the root directory of the cloned project as AUTO_SDK_HOME . Install prerequisites \u00b6 Prior to building Auto SDK, install the build prerequisites outlined the Auto SDK build system documentation. Note: If you are an Android developer, you will build the Alexa Auto Client Service (AACS) with Gradle rather than using the Auto SDK Builder Tool directly. However, you still need to install the build system prerequisites described in the build system documentation because the AACS Gradle build depends on the Auto SDK build system. Read the overview documentation \u00b6 To get a high-level understanding of how to use Auto SDK, read the concepts documentation . After understanding the API concepts, read the feature overview documentation to get a sense of which Auto SDK features you will use in your integration and to identify which Auto SDK extensions you want to download. (Optional) Download extensions \u00b6 If you want to use any of the optional features provided by Auto SDK extensions, request your Amazon Solutions Architect (SA) or Partner Manager to grant Alexa developer console access to the extensions you need. Download the extension archives and follow the documentation in each extension archive to move the extension source code and dependencies into your Auto SDK source tree. Some extensions, such as Local Voice Control (LVC), have additional resources to use, so ensure you thoroughly read the extension documentation for any more setup steps. Follow a developer guide \u00b6 Use the developer guides for Android or Native C++ to guide you through the next steps to develop your Auto SDK integration.","title":"Get Started"},{"location":"get-started/#get-started-with-auto-sdk","text":"This guide outlines the one-time steps required to get started building an Auto SDK integration for your vehicle.","title":"Get Started with Auto SDK"},{"location":"get-started/#register-an-avs-product","text":"The Alexa features enabled by Auto SDK are built upon the Alexa Voice Service (AVS) . Prior to using Auto SDK, follow the Register a Product with AVS guide to set up an Amazon developer account, register a product for your vehicle, and create a security profile. For the Please select your product type option, select Device with Alexa built-in . For the Product category option, select Automotive . In the product details page of your new AVS product, take note of the following fields for later use: The Amazon ID from the top of the page The Client ID from the Other devices and platforms tab","title":"Register an AVS product"},{"location":"get-started/#clone-the-auto-sdk-source-code","text":"Auto SDK is open source. Clone the alexa-auto-sdk project from Github on your development machine: git clone https://github.com/alexa/alexa-auto-sdk.git Auto SDK documentation refers to the root directory of the cloned project as AUTO_SDK_HOME .","title":"Clone the Auto SDK source code"},{"location":"get-started/#install-prerequisites","text":"Prior to building Auto SDK, install the build prerequisites outlined the Auto SDK build system documentation. Note: If you are an Android developer, you will build the Alexa Auto Client Service (AACS) with Gradle rather than using the Auto SDK Builder Tool directly. However, you still need to install the build system prerequisites described in the build system documentation because the AACS Gradle build depends on the Auto SDK build system.","title":"Install prerequisites"},{"location":"get-started/#read-the-overview-documentation","text":"To get a high-level understanding of how to use Auto SDK, read the concepts documentation . After understanding the API concepts, read the feature overview documentation to get a sense of which Auto SDK features you will use in your integration and to identify which Auto SDK extensions you want to download.","title":"Read the overview documentation"},{"location":"get-started/#optional-download-extensions","text":"If you want to use any of the optional features provided by Auto SDK extensions, request your Amazon Solutions Architect (SA) or Partner Manager to grant Alexa developer console access to the extensions you need. Download the extension archives and follow the documentation in each extension archive to move the extension source code and dependencies into your Auto SDK source tree. Some extensions, such as Local Voice Control (LVC), have additional resources to use, so ensure you thoroughly read the extension documentation for any more setup steps.","title":"(Optional) Download extensions"},{"location":"get-started/#follow-a-developer-guide","text":"Use the developer guides for Android or Native C++ to guide you through the next steps to develop your Auto SDK integration.","title":"Follow a developer guide"},{"location":"help/","text":"Need Help? \u00b6 Request additional functionality \u00b6 The following functionality is available with help from your designated Amazon Solutions Architect (SA) or Partner Manager: Address Book contact and navigation favorites uploading Amazon Music and other music service providers Wake Word support Alexa Communication Local Voice Control Device Client Metrics Voice Chrome for Android Alexa Presentation Language (APL) component required for APL rendering on the Android Sample App To use this functionality, your product must be placed on an allow list by Amazon. Contact your SA or Partner Manager, provide the Amazon ID of your development device, and request the functionality you want to add. Note: If you would like to request additional functionality but don't have a designated SA or Partner Manager, please reach out using the \"Request More Information\" form at the end of the Alexa Auto Software Development Kit page on the developer console. To find the Amazon ID for your development device: Log in to the AVS developer console . Click PRODUCTS . Take note of the Amazon ID for your device. Report an issue \u00b6 Existing Alexa Auto SDK users \u00b6 Please reach out to the designated Amazon Solutions Architect (SA) or Partner Manager for your company, and include the following information: Overview - provide a brief overview of the issue Steps to reproduce - provide details of how to reproduce the issue Logs - include relevant logs Platform and environment - provide details about your hardware platform, operating system, compiler, API level, etc. New Alexa Auto SDK users \u00b6 Please fill out the form \"Request more information\" at the bottom of the Alexa Auto Software Development Kit page on the developer console. Once you have submitted your request, someone from Amazon will contact you.","title":"Need Help?"},{"location":"help/#need-help","text":"","title":"Need Help?"},{"location":"help/#request-additional-functionality","text":"The following functionality is available with help from your designated Amazon Solutions Architect (SA) or Partner Manager: Address Book contact and navigation favorites uploading Amazon Music and other music service providers Wake Word support Alexa Communication Local Voice Control Device Client Metrics Voice Chrome for Android Alexa Presentation Language (APL) component required for APL rendering on the Android Sample App To use this functionality, your product must be placed on an allow list by Amazon. Contact your SA or Partner Manager, provide the Amazon ID of your development device, and request the functionality you want to add. Note: If you would like to request additional functionality but don't have a designated SA or Partner Manager, please reach out using the \"Request More Information\" form at the end of the Alexa Auto Software Development Kit page on the developer console. To find the Amazon ID for your development device: Log in to the AVS developer console . Click PRODUCTS . Take note of the Amazon ID for your device.","title":"Request additional functionality"},{"location":"help/#report-an-issue","text":"","title":"Report an issue"},{"location":"help/#existing-alexa-auto-sdk-users","text":"Please reach out to the designated Amazon Solutions Architect (SA) or Partner Manager for your company, and include the following information: Overview - provide a brief overview of the issue Steps to reproduce - provide details of how to reproduce the issue Logs - include relevant logs Platform and environment - provide details about your hardware platform, operating system, compiler, API level, etc.","title":"Existing Alexa Auto SDK users"},{"location":"help/#new-alexa-auto-sdk-users","text":"Please fill out the form \"Request more information\" at the bottom of the Alexa Auto Software Development Kit page on the developer console. Once you have submitted your request, someone from Amazon will contact you.","title":"New Alexa Auto SDK users"},{"location":"product-guidelines/","text":"Product Requirements and Guidelines \u00b6 Amazon provides requirements you must follow when integrating Alexa Auto SDK into your vehicle. To verify your integration meets the requirements, passing Amazon's automotive certification process is a prerequisite to launch your Alexa in-vehicle experience. Refer to the guidelines below when designing and developing your integration, and contact your Amazon Solutions Architect (SA) or Partner Manager to guide you through the certification process. Customer experience requirements \u00b6 The Alexa Automotive customer experience requirements define product requirements your integration must meet in order to provide a customer experience that passes Amazon's certification process. Product and UX guidelines \u00b6 The Alexa Automotive design guidelines define principles, user interface patterns, and multi-modal best practices for Alexa automotive experiences. Security best practices \u00b6 All Alexa products are required to follow the Security Best Practices for Alexa . When building an Alexa experience using the Auto SDK, additionally adhere to the following security principles: Protect configuration files for Auto SDK from tampering and inspection. Protect configuration parameters, such as those found in Auto SDK configuration files, from tampering and inspection, including but not limited to the following: SQLite database files, Unix Domain Sockets, wake word models, and metrics sink files. Protect components used for the Local Voice Control (LVC) extension, including associated LVC language model packages (Linux) and APKs (Android), from tampering and inspection, including but not limited to the following: Unix Domain Sockets, model directories, skill and service executables, prompts and assets JSON files, and all files configuring these components. Your implementation of Auto SDK interfaces must not retain locks, crash, hang, or throw uncaught exceptions. Use exploit mitigation flags and memory randomization techniques when you compile your source code to prevent vulnerabilities from exploiting buffer overflows and memory corruptions.","title":"Product Requirements and Guidelines"},{"location":"product-guidelines/#product-requirements-and-guidelines","text":"Amazon provides requirements you must follow when integrating Alexa Auto SDK into your vehicle. To verify your integration meets the requirements, passing Amazon's automotive certification process is a prerequisite to launch your Alexa in-vehicle experience. Refer to the guidelines below when designing and developing your integration, and contact your Amazon Solutions Architect (SA) or Partner Manager to guide you through the certification process.","title":"Product Requirements and Guidelines"},{"location":"product-guidelines/#customer-experience-requirements","text":"The Alexa Automotive customer experience requirements define product requirements your integration must meet in order to provide a customer experience that passes Amazon's certification process.","title":"Customer experience requirements"},{"location":"product-guidelines/#product-and-ux-guidelines","text":"The Alexa Automotive design guidelines define principles, user interface patterns, and multi-modal best practices for Alexa automotive experiences.","title":"Product and UX guidelines"},{"location":"product-guidelines/#security-best-practices","text":"All Alexa products are required to follow the Security Best Practices for Alexa . When building an Alexa experience using the Auto SDK, additionally adhere to the following security principles: Protect configuration files for Auto SDK from tampering and inspection. Protect configuration parameters, such as those found in Auto SDK configuration files, from tampering and inspection, including but not limited to the following: SQLite database files, Unix Domain Sockets, wake word models, and metrics sink files. Protect components used for the Local Voice Control (LVC) extension, including associated LVC language model packages (Linux) and APKs (Android), from tampering and inspection, including but not limited to the following: Unix Domain Sockets, model directories, skill and service executables, prompts and assets JSON files, and all files configuring these components. Your implementation of Auto SDK interfaces must not retain locks, crash, hang, or throw uncaught exceptions. Use exploit mitigation flags and memory randomization techniques when you compile your source code to prevent vulnerabilities from exploiting buffer overflows and memory corruptions.","title":"Security best practices"},{"location":"aasb/","text":"AASB Message Reference \u00b6 Use the AASB message interfaces to provide platform-specific deep integration to the Auto SDK Engine. The AASB message reference is organized by module and interface name.","title":"AASB Message Reference"},{"location":"aasb/#aasb-message-reference","text":"Use the AASB message interfaces to provide platform-specific deep integration to the Auto SDK Engine. The AASB message reference is organized by module and interface name.","title":"AASB Message Reference"},{"location":"aasb/aasb/AASB/","text":"AASB \u00b6 Outgoing Messages \u00b6 StartService \u00b6 Notifies the platform that the AASB service has started. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StartService\" } } } StopService \u00b6 Notifies the platform that the AASB service is about to stop. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StopService\" } } }","title":"AASB"},{"location":"aasb/aasb/AASB/#aasb","text":"","title":"AASB"},{"location":"aasb/aasb/AASB/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/aasb/AASB/#startservice","text":"Notifies the platform that the AASB service has started.","title":"StartService"},{"location":"aasb/aasb/AASB/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StartService\" } } }","title":"JSON Structure"},{"location":"aasb/aasb/AASB/#stopservice","text":"Notifies the platform that the AASB service is about to stop.","title":"StopService"},{"location":"aasb/aasb/AASB/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StopService\" } } }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/","text":"AddressBook \u00b6 Outgoing Messages \u00b6 AddAddressBookReply \u00b6 Reply for AddAddressBook message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example success Bool Yes False if address book was already added or some internal error, otherwise true on successful. RemoveAddressBookReply \u00b6 Reply for RemoveAddressBook message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example success Bool Yes False if address book is not already added or some internal error, otherwise true on successful. Incoming Messages \u00b6 AddAddressBook \u00b6 Notifies the engine on an availability of an address book. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}}, \"name\": {{String}}, \"type\": {{AddressBookType}}, \"addressBookData\": {{AddressBook}} } } Payload \u00b6 Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. name String Yes Friendly name of the address book, or an empty string if not available. type AddressBookType Yes Type of the address book AddressBookType. addressBookData AddressBook Yes A filled out AddressBook object. RemoveAddressBook \u00b6 Notifies the engine on a non-availability of an already available address book. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}} } } Payload \u00b6 Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. Set this to empty string for engine to remove all uploaded address books. Type Definitions \u00b6 AddressBook \u00b6 JSON Structure \u00b6 { \"navigationNames\": [{{NavigationName}}], \"contactNames\": [{{ContactName}}], \"phoneData\": [{{PhoneData}}], \"postalAddresses\": [{{PostalAddress}}] } Properties \u00b6 Property Type Required Description Example navigationNames NavigationName [] Yes List of NavigationName. contactNames ContactName [] Yes List of ContactName. phoneData PhoneData [] Yes List of PhoneData. postalAddresses PostalAddress [] Yes List of PostalAddresses. NavigationName \u00b6 JSON Structure \u00b6 { \"entryId\": {{String}}, \"name\": {{String}}, \"phoneticName\": {{String}} } Properties \u00b6 Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. name String Yes Name of the entry, or an empty string if not available. If the name field contains Kanji characters, you must also provide the corresponding phoneticName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". phoneticName String No Phonetic name of the entry if available. ContactName \u00b6 JSON Structure \u00b6 { \"entryId\": {{String}}, \"firstName\": {{String}}, \"lastName\": {{String}}, \"nickname\": {{String}}, \"phoneticFirstName\": {{String}}, \"phoneticLastName\": {{String}} } Properties \u00b6 Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. firstName String Yes First name of the entry, or an empty string if not available. If the firstName field contains Kanji characters, you must also provide the corresponding phoneticFirstName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". lastName String Yes Last name of the entry, or an empty string if not available. If the lastName field contains Kanji characters, you must also provide the corresponding phoneticLastName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". nickname String Yes Name of the entry, or an empty string if not available. phoneticFirstName String No Phonetic first name of entry if available. phoneticLastName String No Phonetic last name of entry if available. PhoneData \u00b6 JSON Structure \u00b6 { \"entryId\": {{String}}, \"label\": {{String}}, \"number\": {{String}} } Properties \u00b6 Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. If multiple numbers are associated with a contact, Alexa will verbally ask the customer to confirm which number they want. If labels are assigned to the numbers and Alexa recognizes the types Alexa asks for confirmation; otherwise, Alexa says the last four digits of each number for the customer to select the one to call. number String Yes Numeric phone number, or an empty string if not available. PostalAddress \u00b6 JSON Structure \u00b6 { \"entryId\": {{String}}, \"label\": {{String}}, \"addressLine1\": {{String}}, \"addressLine2\": {{String}}, \"addressLine3\": {{String}}, \"city\": {{String}}, \"stateOrRegion\": {{String}}, \"districtOrCounty\": {{String}}, \"postalCode\": {{String}}, \"country\": {{String}}, \"latitudeInDegrees\": {{Float}}, \"longitudeInDegrees\": {{Float}}, \"accuracyInMeters\": {{Float}} } Properties \u00b6 Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. addressLine1 String Yes First line of the postal address, or an empty string if not available. addressLine2 String Yes Second line of the postal address, or an empty string if not available. addressLine3 String Yes addressLine3 Third line of the postal address, or an empty string if not available. city String Yes City name, or an empty string if not available. stateOrRegion String Yes State or Region name, or an empty string if not available. districtOrCounty String Yes District or County name, or an empty string if not available. postalCode String Yes Postal code or Zip code, or an empty string if not available. country String Yes Country name, or an empty string if not available. latitudeInDegrees Float Yes Geo latitude in degrees. longitudeInDegrees Float Yes Geo longitude in degrees. accuracyInMeters Float Yes Accuracy in meters, or zero if not available. Enums \u00b6 AddressBookType \u00b6 Values \u00b6 Value Description \"CONTACT\" Contacts. \"NAVIGATION\" Navigation Address.","title":"AddressBook"},{"location":"aasb/address-book/AddressBook/#addressbook","text":"","title":"AddressBook"},{"location":"aasb/address-book/AddressBook/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/address-book/AddressBook/#addaddressbookreply","text":"Reply for AddAddressBook message.","title":"AddAddressBookReply"},{"location":"aasb/address-book/AddressBook/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#payload","text":"Property Type Required Description Example success Bool Yes False if address book was already added or some internal error, otherwise true on successful.","title":"Payload"},{"location":"aasb/address-book/AddressBook/#removeaddressbookreply","text":"Reply for RemoveAddressBook message.","title":"RemoveAddressBookReply"},{"location":"aasb/address-book/AddressBook/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#payload_1","text":"Property Type Required Description Example success Bool Yes False if address book is not already added or some internal error, otherwise true on successful.","title":"Payload"},{"location":"aasb/address-book/AddressBook/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/address-book/AddressBook/#addaddressbook","text":"Notifies the engine on an availability of an address book.","title":"AddAddressBook"},{"location":"aasb/address-book/AddressBook/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}}, \"name\": {{String}}, \"type\": {{AddressBookType}}, \"addressBookData\": {{AddressBook}} } }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#payload_2","text":"Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. name String Yes Friendly name of the address book, or an empty string if not available. type AddressBookType Yes Type of the address book AddressBookType. addressBookData AddressBook Yes A filled out AddressBook object.","title":"Payload"},{"location":"aasb/address-book/AddressBook/#removeaddressbook","text":"Notifies the engine on a non-availability of an already available address book.","title":"RemoveAddressBook"},{"location":"aasb/address-book/AddressBook/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#payload_3","text":"Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. Set this to empty string for engine to remove all uploaded address books.","title":"Payload"},{"location":"aasb/address-book/AddressBook/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/address-book/AddressBook/#addressbook_1","text":"","title":"AddressBook"},{"location":"aasb/address-book/AddressBook/#json-structure_4","text":"{ \"navigationNames\": [{{NavigationName}}], \"contactNames\": [{{ContactName}}], \"phoneData\": [{{PhoneData}}], \"postalAddresses\": [{{PostalAddress}}] }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#properties","text":"Property Type Required Description Example navigationNames NavigationName [] Yes List of NavigationName. contactNames ContactName [] Yes List of ContactName. phoneData PhoneData [] Yes List of PhoneData. postalAddresses PostalAddress [] Yes List of PostalAddresses.","title":"Properties"},{"location":"aasb/address-book/AddressBook/#navigationname","text":"","title":"NavigationName"},{"location":"aasb/address-book/AddressBook/#json-structure_5","text":"{ \"entryId\": {{String}}, \"name\": {{String}}, \"phoneticName\": {{String}} }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#properties_1","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. name String Yes Name of the entry, or an empty string if not available. If the name field contains Kanji characters, you must also provide the corresponding phoneticName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". phoneticName String No Phonetic name of the entry if available.","title":"Properties"},{"location":"aasb/address-book/AddressBook/#contactname","text":"","title":"ContactName"},{"location":"aasb/address-book/AddressBook/#json-structure_6","text":"{ \"entryId\": {{String}}, \"firstName\": {{String}}, \"lastName\": {{String}}, \"nickname\": {{String}}, \"phoneticFirstName\": {{String}}, \"phoneticLastName\": {{String}} }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#properties_2","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. firstName String Yes First name of the entry, or an empty string if not available. If the firstName field contains Kanji characters, you must also provide the corresponding phoneticFirstName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". lastName String Yes Last name of the entry, or an empty string if not available. If the lastName field contains Kanji characters, you must also provide the corresponding phoneticLastName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". nickname String Yes Name of the entry, or an empty string if not available. phoneticFirstName String No Phonetic first name of entry if available. phoneticLastName String No Phonetic last name of entry if available.","title":"Properties"},{"location":"aasb/address-book/AddressBook/#phonedata","text":"","title":"PhoneData"},{"location":"aasb/address-book/AddressBook/#json-structure_7","text":"{ \"entryId\": {{String}}, \"label\": {{String}}, \"number\": {{String}} }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#properties_3","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. If multiple numbers are associated with a contact, Alexa will verbally ask the customer to confirm which number they want. If labels are assigned to the numbers and Alexa recognizes the types Alexa asks for confirmation; otherwise, Alexa says the last four digits of each number for the customer to select the one to call. number String Yes Numeric phone number, or an empty string if not available.","title":"Properties"},{"location":"aasb/address-book/AddressBook/#postaladdress","text":"","title":"PostalAddress"},{"location":"aasb/address-book/AddressBook/#json-structure_8","text":"{ \"entryId\": {{String}}, \"label\": {{String}}, \"addressLine1\": {{String}}, \"addressLine2\": {{String}}, \"addressLine3\": {{String}}, \"city\": {{String}}, \"stateOrRegion\": {{String}}, \"districtOrCounty\": {{String}}, \"postalCode\": {{String}}, \"country\": {{String}}, \"latitudeInDegrees\": {{Float}}, \"longitudeInDegrees\": {{Float}}, \"accuracyInMeters\": {{Float}} }","title":"JSON Structure"},{"location":"aasb/address-book/AddressBook/#properties_4","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. addressLine1 String Yes First line of the postal address, or an empty string if not available. addressLine2 String Yes Second line of the postal address, or an empty string if not available. addressLine3 String Yes addressLine3 Third line of the postal address, or an empty string if not available. city String Yes City name, or an empty string if not available. stateOrRegion String Yes State or Region name, or an empty string if not available. districtOrCounty String Yes District or County name, or an empty string if not available. postalCode String Yes Postal code or Zip code, or an empty string if not available. country String Yes Country name, or an empty string if not available. latitudeInDegrees Float Yes Geo latitude in degrees. longitudeInDegrees Float Yes Geo longitude in degrees. accuracyInMeters Float Yes Accuracy in meters, or zero if not available.","title":"Properties"},{"location":"aasb/address-book/AddressBook/#enums","text":"","title":"Enums"},{"location":"aasb/address-book/AddressBook/#addressbooktype","text":"","title":"AddressBookType"},{"location":"aasb/address-book/AddressBook/#values","text":"Value Description \"CONTACT\" Contacts. \"NAVIGATION\" Navigation Address.","title":"Values"},{"location":"aasb/alexa/Alerts/","text":"Alerts \u00b6 Outgoing Messages \u00b6 AlertCreated \u00b6 Notifies the platform implementation of an alert created, with detailed alert info. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertCreated\" } }, \"payload\": { \"alertToken\": {{String}}, \"detailedInfo\": {{String}} } } Payload \u00b6 Property Type Required Description Example alertToken String Yes The AVS token of the alert. detailedInfo String Yes The alert info payload. AlertDeleted \u00b6 Notifies the platform implementation of an alert deleted, with the alertToken. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertDeleted\" } }, \"payload\": { \"alertToken\": {{String}} } } Payload \u00b6 Property Type Required Description Example alertToken String Yes The AVS token of the alert. AlertStateChanged \u00b6 Notifies the platform implementation of an alert state change. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertStateChanged\" } }, \"payload\": { \"alertToken\": {{String}}, \"state\": {{AlertState}}, \"reason\": {{String}} } } Payload \u00b6 Property Type Required Description Example alertToken String Yes The opaque token that uniquely identifies the alert. state AlertState Yes The new alert state. reason String Yes The reason for the state change. Incoming Messages \u00b6 RemoveAllAlerts \u00b6 Notifies the Engine of a platform request to clear the user's pending alerts from storage. This may be useful for a scenario in which a user's pending alerts should not go off after he logs out of the application. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"RemoveAllAlerts\" } } } LocalStop \u00b6 Notifies the Engine of a platform request to stop any active alert, such as when a user presses a physical 'stop' button. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"LocalStop\" } } } Enums \u00b6 AlertState \u00b6 Values \u00b6 Value Description \"READY\" The alert is ready to activate and is waiting for channel focus. \"STARTED\" The alert is activated, and rendering is perceivable by the user. \"STOPPED\" The alert has stopped due to user or system intervention. \"SNOOZED\" The alert is active but has been snoozed. \"COMPLETED\" The alert has completed on its own, without user interaction. \"PAST_DUE\" The alert has expired and will not be rendered. \"FOCUS_ENTERED_FOREGROUND\" The alert has entered the foreground. \"FOCUS_ENTERED_BACKGROUND\" The alert has entered the background. \"ERROR\" The alert has encountered an error. \"DELETED\" The alert has been deleted. \"SCHEDULED_FOR_LATER\" The alert has been scheduled to trigger at a future time.","title":"Alerts"},{"location":"aasb/alexa/Alerts/#alerts","text":"","title":"Alerts"},{"location":"aasb/alexa/Alerts/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/Alerts/#alertcreated","text":"Notifies the platform implementation of an alert created, with detailed alert info.","title":"AlertCreated"},{"location":"aasb/alexa/Alerts/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertCreated\" } }, \"payload\": { \"alertToken\": {{String}}, \"detailedInfo\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/Alerts/#payload","text":"Property Type Required Description Example alertToken String Yes The AVS token of the alert. detailedInfo String Yes The alert info payload.","title":"Payload"},{"location":"aasb/alexa/Alerts/#alertdeleted","text":"Notifies the platform implementation of an alert deleted, with the alertToken.","title":"AlertDeleted"},{"location":"aasb/alexa/Alerts/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertDeleted\" } }, \"payload\": { \"alertToken\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/Alerts/#payload_1","text":"Property Type Required Description Example alertToken String Yes The AVS token of the alert.","title":"Payload"},{"location":"aasb/alexa/Alerts/#alertstatechanged","text":"Notifies the platform implementation of an alert state change.","title":"AlertStateChanged"},{"location":"aasb/alexa/Alerts/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertStateChanged\" } }, \"payload\": { \"alertToken\": {{String}}, \"state\": {{AlertState}}, \"reason\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/Alerts/#payload_2","text":"Property Type Required Description Example alertToken String Yes The opaque token that uniquely identifies the alert. state AlertState Yes The new alert state. reason String Yes The reason for the state change.","title":"Payload"},{"location":"aasb/alexa/Alerts/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/Alerts/#removeallalerts","text":"Notifies the Engine of a platform request to clear the user's pending alerts from storage. This may be useful for a scenario in which a user's pending alerts should not go off after he logs out of the application.","title":"RemoveAllAlerts"},{"location":"aasb/alexa/Alerts/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"RemoveAllAlerts\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/Alerts/#localstop","text":"Notifies the Engine of a platform request to stop any active alert, such as when a user presses a physical 'stop' button.","title":"LocalStop"},{"location":"aasb/alexa/Alerts/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"LocalStop\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/Alerts/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/Alerts/#alertstate","text":"","title":"AlertState"},{"location":"aasb/alexa/Alerts/#values","text":"Value Description \"READY\" The alert is ready to activate and is waiting for channel focus. \"STARTED\" The alert is activated, and rendering is perceivable by the user. \"STOPPED\" The alert has stopped due to user or system intervention. \"SNOOZED\" The alert is active but has been snoozed. \"COMPLETED\" The alert has completed on its own, without user interaction. \"PAST_DUE\" The alert has expired and will not be rendered. \"FOCUS_ENTERED_FOREGROUND\" The alert has entered the foreground. \"FOCUS_ENTERED_BACKGROUND\" The alert has entered the background. \"ERROR\" The alert has encountered an error. \"DELETED\" The alert has been deleted. \"SCHEDULED_FOR_LATER\" The alert has been scheduled to trigger at a future time.","title":"Values"},{"location":"aasb/alexa/AlexaClient/","text":"AlexaClient \u00b6 Outgoing Messages \u00b6 ConnectionStatusChanged \u00b6 Notifies the platform implementation of an AVS connection status change. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"ConnectionStatusChanged\" } }, \"payload\": { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}} } } Payload \u00b6 Property Type Required Description Example status ConnectionStatus Yes The new AVS connection status. reason ConnectionChangedReason Yes The reason for the status change. ConnectionStatusChanged \u00b6 Notifies a listener about changes in connection status for multiple Alexa endpoints. There are multiple connections when using Local Voice Control. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"ConnectionStatusChanged\" } }, \"payload\": { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}}, \"detailed\": {{ConnectionStatusDetails}} } } Payload \u00b6 Property Type Required Description Example status ConnectionStatus Yes The Alexa connection status. This is an aggregated status for the multiple connections. reason ConnectionChangedReason Yes The reason for the status change. detailed ConnectionStatusDetails Yes A detailed breakdown of connection status info per connection type. DialogStateChanged \u00b6 Notifies the platform implementation of an Alexa dialog state change. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"DialogStateChanged\" } }, \"payload\": { \"state\": {{DialogState}} } } Payload \u00b6 Property Type Required Description Example state DialogState Yes The new Alexa dialog state. AuthStateChanged \u00b6 Notifies the platform implementation of an AVS authorization state change. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"state\": {{AuthState}}, \"error\": {{AuthError}} } } Payload \u00b6 Property Type Required Description Example state AuthState Yes The new authorization state. error AuthError Yes The error state of the authorization attempt. Incoming Messages \u00b6 StopForegroundActivity \u00b6 Notifies the Engine to stop foreground activity. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"StopForegroundActivity\" } } } Type Definitions \u00b6 ConnectionStatusInfo \u00b6 JSON Structure \u00b6 { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}} } Properties \u00b6 Property Type Required Description Example status ConnectionStatus No (default: ConnectionStatus::DISCONNECTED ) The connection status. reason ConnectionChangedReason No (default: ConnectionChangedReason::NONE ) The reason for the connection status change. ConnectionStatusDetails \u00b6 JSON Structure \u00b6 { \"avs\": {{ConnectionStatusInfo}}, \"local\": {{ConnectionStatusInfo}} } Properties \u00b6 Property Type Required Description Example avs ConnectionStatusInfo Yes Describes the connection to the Alexa Voice Service. local ConnectionStatusInfo Yes Describes the connection to the local endpoint. Enums \u00b6 DialogState \u00b6 Values \u00b6 Value Description \"IDLE\" Alexa is idle and ready for an interaction. \"LISTENING\" Alexa is currently listening. \"EXPECTING\" Alexa is currently expecting a response from the user. \"THINKING\" A user request has completed, and no more user input is being accepted. Alexa is waiting for a response from AVS. \"SPEAKING\" Alexa is responding to a request with speech. ConnectionStatus \u00b6 Values \u00b6 Value Description \"DISCONNECTED\" Not connected to AVS. \"PENDING\" Attempting to establish a connection to AVS. \"CONNECTED\" Connected to AVS. ConnectionChangedReason \u00b6 Values \u00b6 Value Description \"NONE\" No reason specified. \"SUCCESS\" The connection status changed due to a successful operation. \"UNRECOVERABLE_ERROR\" The connection status changed due to an error from which there is no recovery. \"ACL_CLIENT_REQUEST\" The connection status changed due to a client request. \"ACL_DISABLED\" The connection attempt failed because connection was disabled. \"DNS_TIMEDOUT\" The connection attempt failed due to a DNS resolution timeout. \"CONNECTION_TIMEDOUT\" The connection attempt failed due to a connection timeout. \"CONNECTION_THROTTLED\" The connection attempt failed due to excessive load on the server. \"INVALID_AUTH\" The provided access credentials were invalid. \"PING_TIMEDOUT\" There was a timeout sending a ping request. \"WRITE_TIMEDOUT\" There was a timeout writing to AVS. \"READ_TIMEDOUT\" There was a timeout reading from AVS. \"FAILURE_PROTOCOL_ERROR\" There was an underlying protocol error. \"INTERNAL_ERROR\" There was an internal error. \"SERVER_INTERNAL_ERROR\" There was an internal error on the server. \"SERVER_SIDE_DISCONNECT\" The server asked the client to reconnect. \"SERVER_ENDPOINT_CHANGED\" The server endpoint has changed.","title":"AlexaClient"},{"location":"aasb/alexa/AlexaClient/#alexaclient","text":"","title":"AlexaClient"},{"location":"aasb/alexa/AlexaClient/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/AlexaClient/#connectionstatuschanged","text":"Notifies the platform implementation of an AVS connection status change.","title":"ConnectionStatusChanged"},{"location":"aasb/alexa/AlexaClient/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"ConnectionStatusChanged\" } }, \"payload\": { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#payload","text":"Property Type Required Description Example status ConnectionStatus Yes The new AVS connection status. reason ConnectionChangedReason Yes The reason for the status change.","title":"Payload"},{"location":"aasb/alexa/AlexaClient/#connectionstatuschanged_1","text":"Notifies a listener about changes in connection status for multiple Alexa endpoints. There are multiple connections when using Local Voice Control.","title":"ConnectionStatusChanged"},{"location":"aasb/alexa/AlexaClient/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"ConnectionStatusChanged\" } }, \"payload\": { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}}, \"detailed\": {{ConnectionStatusDetails}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#payload_1","text":"Property Type Required Description Example status ConnectionStatus Yes The Alexa connection status. This is an aggregated status for the multiple connections. reason ConnectionChangedReason Yes The reason for the status change. detailed ConnectionStatusDetails Yes A detailed breakdown of connection status info per connection type.","title":"Payload"},{"location":"aasb/alexa/AlexaClient/#dialogstatechanged","text":"Notifies the platform implementation of an Alexa dialog state change.","title":"DialogStateChanged"},{"location":"aasb/alexa/AlexaClient/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"DialogStateChanged\" } }, \"payload\": { \"state\": {{DialogState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#payload_2","text":"Property Type Required Description Example state DialogState Yes The new Alexa dialog state.","title":"Payload"},{"location":"aasb/alexa/AlexaClient/#authstatechanged","text":"Notifies the platform implementation of an AVS authorization state change.","title":"AuthStateChanged"},{"location":"aasb/alexa/AlexaClient/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"state\": {{AuthState}}, \"error\": {{AuthError}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#payload_3","text":"Property Type Required Description Example state AuthState Yes The new authorization state. error AuthError Yes The error state of the authorization attempt.","title":"Payload"},{"location":"aasb/alexa/AlexaClient/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/AlexaClient/#stopforegroundactivity","text":"Notifies the Engine to stop foreground activity.","title":"StopForegroundActivity"},{"location":"aasb/alexa/AlexaClient/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"StopForegroundActivity\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/alexa/AlexaClient/#connectionstatusinfo","text":"","title":"ConnectionStatusInfo"},{"location":"aasb/alexa/AlexaClient/#json-structure_5","text":"{ \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}} }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#properties","text":"Property Type Required Description Example status ConnectionStatus No (default: ConnectionStatus::DISCONNECTED ) The connection status. reason ConnectionChangedReason No (default: ConnectionChangedReason::NONE ) The reason for the connection status change.","title":"Properties"},{"location":"aasb/alexa/AlexaClient/#connectionstatusdetails","text":"","title":"ConnectionStatusDetails"},{"location":"aasb/alexa/AlexaClient/#json-structure_6","text":"{ \"avs\": {{ConnectionStatusInfo}}, \"local\": {{ConnectionStatusInfo}} }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaClient/#properties_1","text":"Property Type Required Description Example avs ConnectionStatusInfo Yes Describes the connection to the Alexa Voice Service. local ConnectionStatusInfo Yes Describes the connection to the local endpoint.","title":"Properties"},{"location":"aasb/alexa/AlexaClient/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/AlexaClient/#dialogstate","text":"","title":"DialogState"},{"location":"aasb/alexa/AlexaClient/#values","text":"Value Description \"IDLE\" Alexa is idle and ready for an interaction. \"LISTENING\" Alexa is currently listening. \"EXPECTING\" Alexa is currently expecting a response from the user. \"THINKING\" A user request has completed, and no more user input is being accepted. Alexa is waiting for a response from AVS. \"SPEAKING\" Alexa is responding to a request with speech.","title":"Values"},{"location":"aasb/alexa/AlexaClient/#connectionstatus","text":"","title":"ConnectionStatus"},{"location":"aasb/alexa/AlexaClient/#values_1","text":"Value Description \"DISCONNECTED\" Not connected to AVS. \"PENDING\" Attempting to establish a connection to AVS. \"CONNECTED\" Connected to AVS.","title":"Values"},{"location":"aasb/alexa/AlexaClient/#connectionchangedreason","text":"","title":"ConnectionChangedReason"},{"location":"aasb/alexa/AlexaClient/#values_2","text":"Value Description \"NONE\" No reason specified. \"SUCCESS\" The connection status changed due to a successful operation. \"UNRECOVERABLE_ERROR\" The connection status changed due to an error from which there is no recovery. \"ACL_CLIENT_REQUEST\" The connection status changed due to a client request. \"ACL_DISABLED\" The connection attempt failed because connection was disabled. \"DNS_TIMEDOUT\" The connection attempt failed due to a DNS resolution timeout. \"CONNECTION_TIMEDOUT\" The connection attempt failed due to a connection timeout. \"CONNECTION_THROTTLED\" The connection attempt failed due to excessive load on the server. \"INVALID_AUTH\" The provided access credentials were invalid. \"PING_TIMEDOUT\" There was a timeout sending a ping request. \"WRITE_TIMEDOUT\" There was a timeout writing to AVS. \"READ_TIMEDOUT\" There was a timeout reading from AVS. \"FAILURE_PROTOCOL_ERROR\" There was an underlying protocol error. \"INTERNAL_ERROR\" There was an internal error. \"SERVER_INTERNAL_ERROR\" There was an internal error on the server. \"SERVER_SIDE_DISCONNECT\" The server asked the client to reconnect. \"SERVER_ENDPOINT_CHANGED\" The server endpoint has changed.","title":"Values"},{"location":"aasb/alexa/AlexaSpeaker/","text":"AlexaSpeaker \u00b6 Outgoing Messages \u00b6 SpeakerSettingsChanged \u00b6 Notifies the platform implementation that the speaker settings have changed for a specific speaker type. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"SpeakerSettingsChanged\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"local\": {{Bool}}, \"volume\": {{Int}}, \"mute\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. local Bool Yes True if the change originated from calling localSetVolume(). volume Int Yes he new volume setting of the Speaker. mute Bool Yes The mute setting of the Speaker. Incoming Messages \u00b6 LocalAdjustVolume \u00b6 Notifies the Engine of a relative adjustment to the volume setting of the Speaker, originating on the platform. The delta value is relative to the current volume setting and is positive to increase volume or negative to reduce volume. The volume delta value should be scaled to fit the needs of the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalAdjustVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"delta\": {{Int}} } } Payload \u00b6 Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. delta Int Yes The volume adjustment to apply to the Speaker. LocalSetVolume \u00b6 Notifies the Engine of a volume change event originating on the platform, such as a user pressing a \"volume up\" or \"volume down\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setVolume() on each AVS-synced Speaker. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"volume\": {{Int}} } } Payload \u00b6 Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. volume Int Yes The new volume setting of the Speaker. LocalSetMute \u00b6 Notifies the Engine of a mute setting change event originating on the platform, such as a user pressing a \"mute\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setMute() on each AVS-synced Speaker. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetMute\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"mute\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. mute Bool Yes The new mute setting of the Speaker. Enums \u00b6 SpeakerType \u00b6 Values \u00b6 Value Description \"ALEXA_VOLUME\" The Speaker type that is controlled by AVS. \"ALERTS_VOLUME\" The Speaker type that is controlled locally by the platform.","title":"AlexaSpeaker"},{"location":"aasb/alexa/AlexaSpeaker/#alexaspeaker","text":"","title":"AlexaSpeaker"},{"location":"aasb/alexa/AlexaSpeaker/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/AlexaSpeaker/#speakersettingschanged","text":"Notifies the platform implementation that the speaker settings have changed for a specific speaker type.","title":"SpeakerSettingsChanged"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"SpeakerSettingsChanged\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"local\": {{Bool}}, \"volume\": {{Int}}, \"mute\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaSpeaker/#payload","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. local Bool Yes True if the change originated from calling localSetVolume(). volume Int Yes he new volume setting of the Speaker. mute Bool Yes The mute setting of the Speaker.","title":"Payload"},{"location":"aasb/alexa/AlexaSpeaker/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/AlexaSpeaker/#localadjustvolume","text":"Notifies the Engine of a relative adjustment to the volume setting of the Speaker, originating on the platform. The delta value is relative to the current volume setting and is positive to increase volume or negative to reduce volume. The volume delta value should be scaled to fit the needs of the platform.","title":"LocalAdjustVolume"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalAdjustVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"delta\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaSpeaker/#payload_1","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. delta Int Yes The volume adjustment to apply to the Speaker.","title":"Payload"},{"location":"aasb/alexa/AlexaSpeaker/#localsetvolume","text":"Notifies the Engine of a volume change event originating on the platform, such as a user pressing a \"volume up\" or \"volume down\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setVolume() on each AVS-synced Speaker.","title":"LocalSetVolume"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"volume\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaSpeaker/#payload_2","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. volume Int Yes The new volume setting of the Speaker.","title":"Payload"},{"location":"aasb/alexa/AlexaSpeaker/#localsetmute","text":"Notifies the Engine of a mute setting change event originating on the platform, such as a user pressing a \"mute\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setMute() on each AVS-synced Speaker.","title":"LocalSetMute"},{"location":"aasb/alexa/AlexaSpeaker/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetMute\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"mute\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AlexaSpeaker/#payload_3","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. mute Bool Yes The new mute setting of the Speaker.","title":"Payload"},{"location":"aasb/alexa/AlexaSpeaker/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/AlexaSpeaker/#speakertype","text":"","title":"SpeakerType"},{"location":"aasb/alexa/AlexaSpeaker/#values","text":"Value Description \"ALEXA_VOLUME\" The Speaker type that is controlled by AVS. \"ALERTS_VOLUME\" The Speaker type that is controlled locally by the platform.","title":"Values"},{"location":"aasb/alexa/AudioPlayer/","text":"AudioPlayer \u00b6 Outgoing Messages \u00b6 PlayerActivityChanged \u00b6 Notifies the platform implementation of a change in audio playback state. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"PlayerActivityChanged\" } }, \"payload\": { \"state\": {{PlayerActivity}} } } Payload \u00b6 Property Type Required Description Example state PlayerActivity Yes The new playback state. GetPlayerPositionReply \u00b6 Reply for GetPlayerPosition message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackPosition\": {{Int}} } } Payload \u00b6 Property Type Required Description Example playbackPosition Int Yes The audio player's playback position in milliseconds. GetPlayerDurationReply \u00b6 Reply for GetPlayerDuration message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackDuration\": {{Int}} } } Payload \u00b6 Property Type Required Description Example playbackDuration Int Yes The audio player's playback duration in milliseconds. Incoming Messages \u00b6 GetPlayerPosition \u00b6 Returns the current playback position of the audio player. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\" } } } GetPlayerDuration \u00b6 Returns the playback duration of the audio player. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\" } } } Enums \u00b6 PlayerActivity \u00b6 Values \u00b6 Value Description \"IDLE\" Audio playback has not yet begun. \"PLAYING\" Audio is currently playing. \"STOPPED\" Audio playback is stopped, either from a stop directive or playback error. \"PAUSED\" Audio playback is paused. \"BUFFER_UNDERRUN\" Audio playback is stalled because a buffer underrun has occurred. \"FINISHED\" Audio playback is finished.","title":"AudioPlayer"},{"location":"aasb/alexa/AudioPlayer/#audioplayer","text":"","title":"AudioPlayer"},{"location":"aasb/alexa/AudioPlayer/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/AudioPlayer/#playeractivitychanged","text":"Notifies the platform implementation of a change in audio playback state.","title":"PlayerActivityChanged"},{"location":"aasb/alexa/AudioPlayer/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"PlayerActivityChanged\" } }, \"payload\": { \"state\": {{PlayerActivity}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AudioPlayer/#payload","text":"Property Type Required Description Example state PlayerActivity Yes The new playback state.","title":"Payload"},{"location":"aasb/alexa/AudioPlayer/#getplayerpositionreply","text":"Reply for GetPlayerPosition message.","title":"GetPlayerPositionReply"},{"location":"aasb/alexa/AudioPlayer/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackPosition\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AudioPlayer/#payload_1","text":"Property Type Required Description Example playbackPosition Int Yes The audio player's playback position in milliseconds.","title":"Payload"},{"location":"aasb/alexa/AudioPlayer/#getplayerdurationreply","text":"Reply for GetPlayerDuration message.","title":"GetPlayerDurationReply"},{"location":"aasb/alexa/AudioPlayer/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackDuration\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AudioPlayer/#payload_2","text":"Property Type Required Description Example playbackDuration Int Yes The audio player's playback duration in milliseconds.","title":"Payload"},{"location":"aasb/alexa/AudioPlayer/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/AudioPlayer/#getplayerposition","text":"Returns the current playback position of the audio player.","title":"GetPlayerPosition"},{"location":"aasb/alexa/AudioPlayer/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/AudioPlayer/#getplayerduration","text":"Returns the playback duration of the audio player.","title":"GetPlayerDuration"},{"location":"aasb/alexa/AudioPlayer/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/AudioPlayer/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/AudioPlayer/#playeractivity","text":"","title":"PlayerActivity"},{"location":"aasb/alexa/AudioPlayer/#values","text":"Value Description \"IDLE\" Audio playback has not yet begun. \"PLAYING\" Audio is currently playing. \"STOPPED\" Audio playback is stopped, either from a stop directive or playback error. \"PAUSED\" Audio playback is paused. \"BUFFER_UNDERRUN\" Audio playback is stalled because a buffer underrun has occurred. \"FINISHED\" Audio playback is finished.","title":"Values"},{"location":"aasb/alexa/AuthProvider/","text":"AuthProvider \u00b6 Outgoing Messages \u00b6 GetAuthToken \u00b6 Returns the token used by the platform implementation for authorization with AVS. The platform implementation should retrieve an auth token if it does not have one. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\" } } } GetAuthState \u00b6 Returns the AVS authorization state of the platform implementation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\" } } } Incoming Messages \u00b6 AuthStateChanged \u00b6 Notifies the Engine of a change in AVS authorization state in the platform implementation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"authState\": {{AuthState}}, \"authError\": {{AuthError}} } } Payload \u00b6 Property Type Required Description Example authState AuthState Yes The new authorization state. authError AuthError Yes The error state of the authorization attempt. GetAuthTokenReply \u00b6 Reply for GetAuthToken message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\", \"replyToId\": {{String}} } }, \"payload\": { \"authToken\": {{String}} } } Payload \u00b6 Property Type Required Description Example authToken String Yes The token used to authorize with AVS. GetAuthStateReply \u00b6 Reply for GetAuthState message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{AuthState}} } } Payload \u00b6 Property Type Required Description Example state AuthState Yes The AVS authorization state. Enums \u00b6 AuthError \u00b6 Values \u00b6 Value Description \"NO_ERROR\" No error encountered. \"UNKNOWN_ERROR\" An error was encountered, but no error description can be determined. \"AUTHORIZATION_FAILED\" The client authorization failed. \"UNAUTHORIZED_CLIENT\" The client is not authorized to use authorization codes. \"SERVER_ERROR\" The server encountered a runtime error. \"INVALID_REQUEST\" The request is missing a required parameter, has an invalid value, or is otherwise malformed. \"INVALID_VALUE\" One of the values in the request was invalid. \"AUTHORIZATION_EXPIRED\" The authorization code is invalid, expired, revoked, or was issued to a different client. \"UNSUPPORTED_GRANT_TYPE\" The client specified the wrong token type. \"INVALID_CODE_PAIR\" Invalid code pair provided in Code-based linking token request. \"AUTHORIZATION_PENDING\" Waiting for user to authorize the specified code pair. \"SLOW_DOWN\" Client should slow down in the rate of requests polling for an access token. \"INTERNAL_ERROR\" Internal error in client code. \"INVALID_CBL_CLIENT_ID\" Client ID not valid for use with code based linking. AuthState \u00b6 Values \u00b6 Value Description \"UNINITIALIZED\" Authorization has not yet been acquired. \"REFRESHED\" Authorization has been refreshed. \"EXPIRED\" Authorization has expired. \"UNRECOVERABLE_ERROR\" Authorization has failed in a manner that cannot be corrected by retrying.","title":"AuthProvider"},{"location":"aasb/alexa/AuthProvider/#authprovider","text":"","title":"AuthProvider"},{"location":"aasb/alexa/AuthProvider/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/AuthProvider/#getauthtoken","text":"Returns the token used by the platform implementation for authorization with AVS. The platform implementation should retrieve an auth token if it does not have one.","title":"GetAuthToken"},{"location":"aasb/alexa/AuthProvider/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/AuthProvider/#getauthstate","text":"Returns the AVS authorization state of the platform implementation.","title":"GetAuthState"},{"location":"aasb/alexa/AuthProvider/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/AuthProvider/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/AuthProvider/#authstatechanged","text":"Notifies the Engine of a change in AVS authorization state in the platform implementation.","title":"AuthStateChanged"},{"location":"aasb/alexa/AuthProvider/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"authState\": {{AuthState}}, \"authError\": {{AuthError}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AuthProvider/#payload","text":"Property Type Required Description Example authState AuthState Yes The new authorization state. authError AuthError Yes The error state of the authorization attempt.","title":"Payload"},{"location":"aasb/alexa/AuthProvider/#getauthtokenreply","text":"Reply for GetAuthToken message.","title":"GetAuthTokenReply"},{"location":"aasb/alexa/AuthProvider/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\", \"replyToId\": {{String}} } }, \"payload\": { \"authToken\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AuthProvider/#payload_1","text":"Property Type Required Description Example authToken String Yes The token used to authorize with AVS.","title":"Payload"},{"location":"aasb/alexa/AuthProvider/#getauthstatereply","text":"Reply for GetAuthState message.","title":"GetAuthStateReply"},{"location":"aasb/alexa/AuthProvider/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{AuthState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/AuthProvider/#payload_2","text":"Property Type Required Description Example state AuthState Yes The AVS authorization state.","title":"Payload"},{"location":"aasb/alexa/AuthProvider/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/AuthProvider/#autherror","text":"","title":"AuthError"},{"location":"aasb/alexa/AuthProvider/#values","text":"Value Description \"NO_ERROR\" No error encountered. \"UNKNOWN_ERROR\" An error was encountered, but no error description can be determined. \"AUTHORIZATION_FAILED\" The client authorization failed. \"UNAUTHORIZED_CLIENT\" The client is not authorized to use authorization codes. \"SERVER_ERROR\" The server encountered a runtime error. \"INVALID_REQUEST\" The request is missing a required parameter, has an invalid value, or is otherwise malformed. \"INVALID_VALUE\" One of the values in the request was invalid. \"AUTHORIZATION_EXPIRED\" The authorization code is invalid, expired, revoked, or was issued to a different client. \"UNSUPPORTED_GRANT_TYPE\" The client specified the wrong token type. \"INVALID_CODE_PAIR\" Invalid code pair provided in Code-based linking token request. \"AUTHORIZATION_PENDING\" Waiting for user to authorize the specified code pair. \"SLOW_DOWN\" Client should slow down in the rate of requests polling for an access token. \"INTERNAL_ERROR\" Internal error in client code. \"INVALID_CBL_CLIENT_ID\" Client ID not valid for use with code based linking.","title":"Values"},{"location":"aasb/alexa/AuthProvider/#authstate","text":"","title":"AuthState"},{"location":"aasb/alexa/AuthProvider/#values_1","text":"Value Description \"UNINITIALIZED\" Authorization has not yet been acquired. \"REFRESHED\" Authorization has been refreshed. \"EXPIRED\" Authorization has expired. \"UNRECOVERABLE_ERROR\" Authorization has failed in a manner that cannot be corrected by retrying.","title":"Values"},{"location":"aasb/alexa/DeviceSetup/","text":"DeviceSetup \u00b6 Outgoing Messages \u00b6 SetupCompletedResponse \u00b6 SetupCompletedResponse description JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompletedResponse\" } }, \"payload\": { \"statusCode\": {{StatusCode}} } } Payload \u00b6 Property Type Required Description Example statusCode StatusCode Yes Status description. Incoming Messages \u00b6 SetupCompleted \u00b6 SetupCompleted description. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompleted\" } } } Enums \u00b6 StatusCode \u00b6 Values \u00b6 Value Description \"SUCCESS\" Successful description. \"FAIL\" Failure description.","title":"DeviceSetup"},{"location":"aasb/alexa/DeviceSetup/#devicesetup","text":"","title":"DeviceSetup"},{"location":"aasb/alexa/DeviceSetup/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/DeviceSetup/#setupcompletedresponse","text":"SetupCompletedResponse description","title":"SetupCompletedResponse"},{"location":"aasb/alexa/DeviceSetup/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompletedResponse\" } }, \"payload\": { \"statusCode\": {{StatusCode}} } }","title":"JSON Structure"},{"location":"aasb/alexa/DeviceSetup/#payload","text":"Property Type Required Description Example statusCode StatusCode Yes Status description.","title":"Payload"},{"location":"aasb/alexa/DeviceSetup/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/DeviceSetup/#setupcompleted","text":"SetupCompleted description.","title":"SetupCompleted"},{"location":"aasb/alexa/DeviceSetup/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompleted\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/DeviceSetup/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/DeviceSetup/#statuscode","text":"","title":"StatusCode"},{"location":"aasb/alexa/DeviceSetup/#values","text":"Value Description \"SUCCESS\" Successful description. \"FAIL\" Failure description.","title":"Values"},{"location":"aasb/alexa/DoNotDisturb/","text":"DoNotDisturb \u00b6 Outgoing Messages \u00b6 SetDoNotDisturb \u00b6 Handle setting of DND directive. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"SetDoNotDisturb\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example doNotDisturb Bool Yes setting state. Incoming Messages \u00b6 DoNotDisturbChanged \u00b6 Notifies the Engine of a platform request to set the DND State. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"DoNotDisturbChanged\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example doNotDisturb Bool Yes setting state.","title":"DoNotDisturb"},{"location":"aasb/alexa/DoNotDisturb/#donotdisturb","text":"","title":"DoNotDisturb"},{"location":"aasb/alexa/DoNotDisturb/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/DoNotDisturb/#setdonotdisturb","text":"Handle setting of DND directive.","title":"SetDoNotDisturb"},{"location":"aasb/alexa/DoNotDisturb/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"SetDoNotDisturb\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/alexa/DoNotDisturb/#payload","text":"Property Type Required Description Example doNotDisturb Bool Yes setting state.","title":"Payload"},{"location":"aasb/alexa/DoNotDisturb/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/DoNotDisturb/#donotdisturbchanged","text":"Notifies the Engine of a platform request to set the DND State.","title":"DoNotDisturbChanged"},{"location":"aasb/alexa/DoNotDisturb/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"DoNotDisturbChanged\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/alexa/DoNotDisturb/#payload_1","text":"Property Type Required Description Example doNotDisturb Bool Yes setting state.","title":"Payload"},{"location":"aasb/alexa/EqualizerController/","text":"EqualizerController \u00b6 Outgoing Messages \u00b6 GetBandLevels \u00b6 Retrieves the current equalizer gain settings on the device for each supported band. If unsupported band levels are provided, the Engine will truncate levels to the configured range. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\" } } } SetBandLevels \u00b6 Notifies the platform implementation to apply the provided gain settings to the corresponding equalizer bands. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"SetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } } Payload \u00b6 Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands and their gain settings to apply as integer dB values. Incoming Messages \u00b6 LocalResetBands \u00b6 Notifies the Engine that the gain levels for the equalizer bands are being reset to their defaults. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalResetBands\" } }, \"payload\": { \"bands\": [{{EqualizerBand}}] } } Payload \u00b6 Property Type Required Description Example bands EqualizerBand [] No The equalizer bands to reset. Empty @a bands resets all supported equalizer bands. LocalSetBandLevels \u00b6 Notifies the Engine that gain levels for one or more equalizer bands are being set directly on the device. If unsupported levels are provided, the Engine will truncate the settings to the configured range. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalSetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } } Payload \u00b6 Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands to change and their gain settings as integer dB values. LocalAdjustBandLevels \u00b6 Notifies the Engine that relative adjustments to equalizer band gain levels are being made directly on the device. If adjustments put the band level settings beyond the configured dB range, the Engine will truncate the settings to the configured range. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalAdjustBandLevels\" } }, \"payload\": { \"bandAdjustments\": [{{EqualizerBandLevel}}] } } Payload \u00b6 Property Type Required Description Example bandAdjustments EqualizerBandLevel [] Yes he equalizer bands to adjust and their relative gain adjustments as integer dB values. GetBandLevelsReply \u00b6 Reply for GetBandLevels message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\", \"replyToId\": {{String}} } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } } Payload \u00b6 Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The supported equalizer bands and their current gain settings as integer dB values. Type Definitions \u00b6 EqualizerBandLevel \u00b6 JSON Structure \u00b6 { \"band\": {{EqualizerBand}}, \"level\": {{Int}} } Properties \u00b6 Property Type Required Description Example band EqualizerBand Yes Describes the equalizer bands supported by Alexa. The platform implementation may support a subset of these. level Int Yes Describes the level of gain of a particular equalizer band as an integer dB value. Enums \u00b6 EqualizerBand \u00b6 Values \u00b6 Value Description \"BASS\" Bass equalizer band. \"MIDRANGE\" Mid-range equalizer band. \"TREBLE\" Treble equalizer band.","title":"EqualizerController"},{"location":"aasb/alexa/EqualizerController/#equalizercontroller","text":"","title":"EqualizerController"},{"location":"aasb/alexa/EqualizerController/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/EqualizerController/#getbandlevels","text":"Retrieves the current equalizer gain settings on the device for each supported band. If unsupported band levels are provided, the Engine will truncate levels to the configured range.","title":"GetBandLevels"},{"location":"aasb/alexa/EqualizerController/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#setbandlevels","text":"Notifies the platform implementation to apply the provided gain settings to the corresponding equalizer bands.","title":"SetBandLevels"},{"location":"aasb/alexa/EqualizerController/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"SetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#payload","text":"Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands and their gain settings to apply as integer dB values.","title":"Payload"},{"location":"aasb/alexa/EqualizerController/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/EqualizerController/#localresetbands","text":"Notifies the Engine that the gain levels for the equalizer bands are being reset to their defaults.","title":"LocalResetBands"},{"location":"aasb/alexa/EqualizerController/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalResetBands\" } }, \"payload\": { \"bands\": [{{EqualizerBand}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#payload_1","text":"Property Type Required Description Example bands EqualizerBand [] No The equalizer bands to reset. Empty @a bands resets all supported equalizer bands.","title":"Payload"},{"location":"aasb/alexa/EqualizerController/#localsetbandlevels","text":"Notifies the Engine that gain levels for one or more equalizer bands are being set directly on the device. If unsupported levels are provided, the Engine will truncate the settings to the configured range.","title":"LocalSetBandLevels"},{"location":"aasb/alexa/EqualizerController/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalSetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#payload_2","text":"Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands to change and their gain settings as integer dB values.","title":"Payload"},{"location":"aasb/alexa/EqualizerController/#localadjustbandlevels","text":"Notifies the Engine that relative adjustments to equalizer band gain levels are being made directly on the device. If adjustments put the band level settings beyond the configured dB range, the Engine will truncate the settings to the configured range.","title":"LocalAdjustBandLevels"},{"location":"aasb/alexa/EqualizerController/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalAdjustBandLevels\" } }, \"payload\": { \"bandAdjustments\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#payload_3","text":"Property Type Required Description Example bandAdjustments EqualizerBandLevel [] Yes he equalizer bands to adjust and their relative gain adjustments as integer dB values.","title":"Payload"},{"location":"aasb/alexa/EqualizerController/#getbandlevelsreply","text":"Reply for GetBandLevels message.","title":"GetBandLevelsReply"},{"location":"aasb/alexa/EqualizerController/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\", \"replyToId\": {{String}} } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#payload_4","text":"Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The supported equalizer bands and their current gain settings as integer dB values.","title":"Payload"},{"location":"aasb/alexa/EqualizerController/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/alexa/EqualizerController/#equalizerbandlevel","text":"","title":"EqualizerBandLevel"},{"location":"aasb/alexa/EqualizerController/#json-structure_6","text":"{ \"band\": {{EqualizerBand}}, \"level\": {{Int}} }","title":"JSON Structure"},{"location":"aasb/alexa/EqualizerController/#properties","text":"Property Type Required Description Example band EqualizerBand Yes Describes the equalizer bands supported by Alexa. The platform implementation may support a subset of these. level Int Yes Describes the level of gain of a particular equalizer band as an integer dB value.","title":"Properties"},{"location":"aasb/alexa/EqualizerController/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/EqualizerController/#equalizerband","text":"","title":"EqualizerBand"},{"location":"aasb/alexa/EqualizerController/#values","text":"Value Description \"BASS\" Bass equalizer band. \"MIDRANGE\" Mid-range equalizer band. \"TREBLE\" Treble equalizer band.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/","text":"ExternalMediaAdapter \u00b6 Outgoing Messages \u00b6 PlayControl \u00b6 Occurs during playback control via voice interaction or PlaybackController interface. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayControl\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"controlType\": {{PlayControlType}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. controlType PlayControlType Yes Playback control type being invoked. Seek \u00b6 Called when the user invokes media seek via speech. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Seek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"offset\": {{Int}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. offset Int Yes Offset position within media item, in milliseconds. Logout \u00b6 Directive called after a discovered player initiates the logoutComplete event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Logout\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. Play \u00b6 Called when the user first calls play for the external media via voice control. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Play\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"playContextToken\": {{String}}, \"index\": {{Int}}, \"offset\": {{Int}}, \"preload\": {{Bool}}, \"navigation\": {{Navigation}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. playContextToken String Yes Track/playlist/album/artist/station/podcast context identifier. index Int Yes If the playback context is an indexable container like a playlist, the index of the media item in the container. offset Int Yes Offset position within media item, in milliseconds. preload Bool Yes Whether the media item should preload or not. navigation Navigation Yes The app transition behavior. GetState \u00b6 Must provide the local external media player apps @PlaybackStateExternal, and @SessionStateExternal information to maintain cloud sync. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"GetState\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"state\": {{ExternalMediaAdapterState}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. state ExternalMediaAdapterState Yes The ExternalMediaAdapterState to be initialized by the platform. Login \u00b6 Directive called after a discovered player initiates the loginComplete event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Login\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"accessToken\": {{String}}, \"userName\": {{String}}, \"forceLogin\": {{Bool}}, \"tokenRefreshInterval\": {{Int}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. accessToken String Yes The handshake token between AVS, and the external media player app session. userName String Yes The username provided by the external media player app, if available. forceLogin Bool Yes True if no handshake is needed, and login is simply assumed. tokenRefreshInterval Int Yes refresh interval of the accessToken, if available. AdjustSeek \u00b6 Called when the user invokes media seek adjustment via speech. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"deltaOffset\": {{Int}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. deltaOffset Int Yes Change in offset position within media item, in milliseconds. MutedStateChanged \u00b6 Notifies the platform implementation to apply a mute state change to the output channel. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"state\": {{MutedState}} } } Payload \u00b6 Property Type Required Description Example state MutedState Yes The muted state to apply to the output channel. MUTED when the output channel be muted, UNMUTED when unmuted. VolumeChanged \u00b6 Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"volume\": {{Float}} } } Payload \u00b6 Property Type Required Description Example volume Float Yes The volume to set on the output channel. volume is in the range [0,1]. Authorize \u00b6 Called after discovered media players have been reported. Returns a list of reported players and whether they have been authorized for use with Alexa. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Authorize\" } }, \"payload\": { \"authorizedPlayers\": [{{AuthorizedPlayerInfo}}] } } Payload \u00b6 Property Type Required Description Example authorizedPlayers AuthorizedPlayerInfo [] Yes A list of discovered players with their status of authorization for use with Alexa. Incoming Messages \u00b6 PlayerEvent \u00b6 Should be called on a local external media player event. This will sync the context with AVS. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"eventName\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. eventName String Yes Canonical event name. LogoutComplete \u00b6 Should be called on a local external media player logout. This will unset authorization of the app with AVS. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LogoutComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. LoginComplete \u00b6 Should be called on a local external media player login. This will set authorization of the app with AVS. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LoginComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes Should be called on a local external media player login. This will set authorization of the app with AVS. SetFocus \u00b6 Should be called on local external media player events. This will switch the media focus to that context. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"SetFocus\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. ReportDiscoveredPlayers \u00b6 Should be called on startup in order to notify AVS of the local external media players. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"ReportDiscoveredPlayers\" } }, \"payload\": { \"discoveredPlayers\": [{{DiscoveredPlayerInfo}}] } } Payload \u00b6 Property Type Required Description Example discoveredPlayers DiscoveredPlayerInfo [] Yes The List of discovered players. RemoveDiscoveredPlayer \u00b6 RemoveDiscoveredPlayer description. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RemoveDiscoveredPlayer\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes localPlayerId description. RequestToken \u00b6 The device is responsible for requesting an access token when needed. This is typically done immediately upon connection to AVS. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RequestToken\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. PlayerError \u00b6 Should be called on a player error. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerError\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. Type Definitions \u00b6 ExternalMediaAdapterState \u00b6 JSON Structure \u00b6 { \"sessionState\": {{SessionStateExternal}}, \"playbackState\": {{PlaybackStateExternal}} } Properties \u00b6 Property Type Required Description Example sessionState SessionStateExternal Yes Variable to hold the session state. playbackState PlaybackStateExternal Yes Variable to hold the playback state. SessionStateExternal \u00b6 JSON Structure \u00b6 { \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"playerCookie\": {{String}}, \"spiVersion\": {{String}} } Properties \u00b6 Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. playerCookie String Yes A player may declare arbitrary information for itself. spiVersion String Yes The only spiVersion that currently exists is \"1.0\". PlaybackStateExternal \u00b6 JSON Structure \u00b6 { \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} } Properties \u00b6 Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PLAYING. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled or not. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled or not. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource. smallURL String Yes The URL for small cover art image resource. mediumURL String Yes The URL for medium cover art image resource. largeURL String Yes The URL for large cover art image resource. coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds. AuthorizedPlayerInfo \u00b6 JSON Structure \u00b6 { \"localPlayerId\": {{String}}, \"authorized\": {{Bool}} } Properties \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. authorized Bool Yes Authorization status. ValidationData \u00b6 JSON Structure \u00b6 { \"certificate\": {{String}} } Properties \u00b6 Property Type Required Description Example certificate String Yes Validation data. DiscoveredPlayerInfo \u00b6 JSON Structure \u00b6 { \"localPlayerId\": {{String}}, \"spiVersion\": {{String}}, \"validationMethod\": {{ValidationMethod}}, \"validationData\": [{{ValidationData}}] } Properties \u00b6 Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. spiVersion String Yes The only spiVersion that currently exists is '1.0'. validationMethod ValidationMethod Yes Validation methods. validationData ValidationData [] Yes Validation data: 1. Device platform issued app signing certificate. A List of certificates may be attached. 2. In some cases validation is performed locally. The certificate is trasmitted as validationData during discovery to announce the activated app's identity in order to allow app activation to be revoked. 3. empty. Enums \u00b6 SupportedPlaybackOperation \u00b6 Values \u00b6 Value Description \"PLAY\" Play is supported (voice only). \"PAUSE\" Pause is supported. \"STOP\" Stop is supported. \"NEXT\" Next is supported. \"PREVIOUS\" Previous is supported. \"START_OVER\" Start Over is supported. \"FAST_FORWARD\" Fast Forward is supported. \"REWIND\" Rewind is supported. \"ENABLE_REPEAT\" Enable Repeat is supported. \"ENABLE_REPEAT_ONE\" Enable Repeat One is supported. \"DISABLE_REPEAT\" Disbale Repeat is supported. \"ENABLE_SHUFFLE\" Enable Shuffle is supported. \"DISABLE_SHUFFLE\" Disable Shuffle is supported. \"FAVORITE\" Favorite is supported. \"UNFAVORITE\" Unfavorite is supported. \"SEEK\" Seek is supported. \"ADJUST_SEEK\" Adjust Seek is supported. PlayControlType \u00b6 Values \u00b6 Value Description \"PAUSE\" pause playback. \"RESUME\" resume playback. \"STOP\" stop playback. \"NEXT\" next song. \"PREVIOUS\" previous playback. \"START_OVER\" start playback over. \"FAST_FORWARD\" fast forward external media described time. \"REWIND\" rewind external media described time. \"ENABLE_REPEAT_ONE\" enable repeat current song. \"ENABLE_REPEAT\" enable playlist looping. \"DISABLE_REPEAT\" disable playlist looping. \"ENABLE_SHUFFLE\" enable playlist shuffling. \"DISABLE_SHUFFLE\" disable playlist shuffling. \"FAVORITE\" favorite song. \"UNFAVORITE\" unfavorite song. ValidationMethod \u00b6 Values \u00b6 Value Description \"SIGNING_CERTIFICATE\" description for SIGNING_CERTIFICATE. \"GENERATED_CERTIFICATE\" description for GENERATED_CERTIFICATE. \"NONE\" description for NONE. Favorites \u00b6 Values \u00b6 Value Description \"FAVORITED\" song is favorited. \"UNFAVORITED\" song is unfavorited. \"NOT_RATED\" song is not rated. MutedState \u00b6 Values \u00b6 Value Description \"MUTED\" The audio channel state id muted. \"UNMUTED\" The audio channel state id unmuted. Navigation \u00b6 Values \u00b6 Value Description \"DEFAULT\" Source dependant behavior. \"NONE\" No navigation should occur. \"FOREGROUND\" External app should take foreground. MediaType \u00b6 Values \u00b6 Value Description \"TRACK\" A single song source. \"PODCAST\" A podcast source. \"STATION\" A station source. \"AD\" An advertisement source. \"SAMPLE\" A sample source. \"OTHER\" A miscellaneous source.","title":"ExternalMediaAdapter"},{"location":"aasb/alexa/ExternalMediaAdapter/#externalmediaadapter","text":"","title":"ExternalMediaAdapter"},{"location":"aasb/alexa/ExternalMediaAdapter/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/ExternalMediaAdapter/#playcontrol","text":"Occurs during playback control via voice interaction or PlaybackController interface.","title":"PlayControl"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayControl\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"controlType\": {{PlayControlType}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. controlType PlayControlType Yes Playback control type being invoked.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#seek","text":"Called when the user invokes media seek via speech.","title":"Seek"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Seek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"offset\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_1","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. offset Int Yes Offset position within media item, in milliseconds.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#logout","text":"Directive called after a discovered player initiates the logoutComplete event.","title":"Logout"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Logout\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_2","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#play","text":"Called when the user first calls play for the external media via voice control.","title":"Play"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Play\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"playContextToken\": {{String}}, \"index\": {{Int}}, \"offset\": {{Int}}, \"preload\": {{Bool}}, \"navigation\": {{Navigation}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_3","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. playContextToken String Yes Track/playlist/album/artist/station/podcast context identifier. index Int Yes If the playback context is an indexable container like a playlist, the index of the media item in the container. offset Int Yes Offset position within media item, in milliseconds. preload Bool Yes Whether the media item should preload or not. navigation Navigation Yes The app transition behavior.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#getstate","text":"Must provide the local external media player apps @PlaybackStateExternal, and @SessionStateExternal information to maintain cloud sync.","title":"GetState"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"GetState\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"state\": {{ExternalMediaAdapterState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_4","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. state ExternalMediaAdapterState Yes The ExternalMediaAdapterState to be initialized by the platform.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#login","text":"Directive called after a discovered player initiates the loginComplete event.","title":"Login"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Login\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"accessToken\": {{String}}, \"userName\": {{String}}, \"forceLogin\": {{Bool}}, \"tokenRefreshInterval\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_5","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. accessToken String Yes The handshake token between AVS, and the external media player app session. userName String Yes The username provided by the external media player app, if available. forceLogin Bool Yes True if no handshake is needed, and login is simply assumed. tokenRefreshInterval Int Yes refresh interval of the accessToken, if available.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#adjustseek","text":"Called when the user invokes media seek adjustment via speech.","title":"AdjustSeek"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"deltaOffset\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_6","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. deltaOffset Int Yes Change in offset position within media item, in milliseconds.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#mutedstatechanged","text":"Notifies the platform implementation to apply a mute state change to the output channel.","title":"MutedStateChanged"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"state\": {{MutedState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_7","text":"Property Type Required Description Example state MutedState Yes The muted state to apply to the output channel. MUTED when the output channel be muted, UNMUTED when unmuted.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#volumechanged","text":"Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform.","title":"VolumeChanged"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"volume\": {{Float}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_8","text":"Property Type Required Description Example volume Float Yes The volume to set on the output channel. volume is in the range [0,1].","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#authorize","text":"Called after discovered media players have been reported. Returns a list of reported players and whether they have been authorized for use with Alexa.","title":"Authorize"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Authorize\" } }, \"payload\": { \"authorizedPlayers\": [{{AuthorizedPlayerInfo}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_9","text":"Property Type Required Description Example authorizedPlayers AuthorizedPlayerInfo [] Yes A list of discovered players with their status of authorization for use with Alexa.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/ExternalMediaAdapter/#playerevent","text":"Should be called on a local external media player event. This will sync the context with AVS.","title":"PlayerEvent"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"eventName\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_10","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. eventName String Yes Canonical event name.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#logoutcomplete","text":"Should be called on a local external media player logout. This will unset authorization of the app with AVS.","title":"LogoutComplete"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LogoutComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_11","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#logincomplete","text":"Should be called on a local external media player login. This will set authorization of the app with AVS.","title":"LoginComplete"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LoginComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_12","text":"Property Type Required Description Example localPlayerId String Yes Should be called on a local external media player login. This will set authorization of the app with AVS.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#setfocus","text":"Should be called on local external media player events. This will switch the media focus to that context.","title":"SetFocus"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"SetFocus\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_13","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#reportdiscoveredplayers","text":"Should be called on startup in order to notify AVS of the local external media players.","title":"ReportDiscoveredPlayers"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_14","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"ReportDiscoveredPlayers\" } }, \"payload\": { \"discoveredPlayers\": [{{DiscoveredPlayerInfo}}] } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_14","text":"Property Type Required Description Example discoveredPlayers DiscoveredPlayerInfo [] Yes The List of discovered players.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#removediscoveredplayer","text":"RemoveDiscoveredPlayer description.","title":"RemoveDiscoveredPlayer"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_15","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RemoveDiscoveredPlayer\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_15","text":"Property Type Required Description Example localPlayerId String Yes localPlayerId description.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#requesttoken","text":"The device is responsible for requesting an access token when needed. This is typically done immediately upon connection to AVS.","title":"RequestToken"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_16","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RequestToken\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_16","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#playererror","text":"Should be called on a player error.","title":"PlayerError"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_17","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerError\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#payload_17","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal.","title":"Payload"},{"location":"aasb/alexa/ExternalMediaAdapter/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/alexa/ExternalMediaAdapter/#externalmediaadapterstate","text":"","title":"ExternalMediaAdapterState"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_18","text":"{ \"sessionState\": {{SessionStateExternal}}, \"playbackState\": {{PlaybackStateExternal}} }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties","text":"Property Type Required Description Example sessionState SessionStateExternal Yes Variable to hold the session state. playbackState PlaybackStateExternal Yes Variable to hold the playback state.","title":"Properties"},{"location":"aasb/alexa/ExternalMediaAdapter/#sessionstateexternal","text":"","title":"SessionStateExternal"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_19","text":"{ \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"playerCookie\": {{String}}, \"spiVersion\": {{String}} }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_1","text":"Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. playerCookie String Yes A player may declare arbitrary information for itself. spiVersion String Yes The only spiVersion that currently exists is \"1.0\".","title":"Properties"},{"location":"aasb/alexa/ExternalMediaAdapter/#playbackstateexternal","text":"","title":"PlaybackStateExternal"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_20","text":"{ \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_2","text":"Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PLAYING. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled or not. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled or not. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource. smallURL String Yes The URL for small cover art image resource. mediumURL String Yes The URL for medium cover art image resource. largeURL String Yes The URL for large cover art image resource. coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds.","title":"Properties"},{"location":"aasb/alexa/ExternalMediaAdapter/#authorizedplayerinfo","text":"","title":"AuthorizedPlayerInfo"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_21","text":"{ \"localPlayerId\": {{String}}, \"authorized\": {{Bool}} }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_3","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. authorized Bool Yes Authorization status.","title":"Properties"},{"location":"aasb/alexa/ExternalMediaAdapter/#validationdata","text":"","title":"ValidationData"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_22","text":"{ \"certificate\": {{String}} }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_4","text":"Property Type Required Description Example certificate String Yes Validation data.","title":"Properties"},{"location":"aasb/alexa/ExternalMediaAdapter/#discoveredplayerinfo","text":"","title":"DiscoveredPlayerInfo"},{"location":"aasb/alexa/ExternalMediaAdapter/#json-structure_23","text":"{ \"localPlayerId\": {{String}}, \"spiVersion\": {{String}}, \"validationMethod\": {{ValidationMethod}}, \"validationData\": [{{ValidationData}}] }","title":"JSON Structure"},{"location":"aasb/alexa/ExternalMediaAdapter/#properties_5","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. spiVersion String Yes The only spiVersion that currently exists is '1.0'. validationMethod ValidationMethod Yes Validation methods. validationData ValidationData [] Yes Validation data: 1. Device platform issued app signing certificate. A List of certificates may be attached. 2. In some cases validation is performed locally. The certificate is trasmitted as validationData during discovery to announce the activated app's identity in order to allow app activation to be revoked. 3. empty.","title":"Properties"},{"location":"aasb/alexa/ExternalMediaAdapter/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/ExternalMediaAdapter/#supportedplaybackoperation","text":"","title":"SupportedPlaybackOperation"},{"location":"aasb/alexa/ExternalMediaAdapter/#values","text":"Value Description \"PLAY\" Play is supported (voice only). \"PAUSE\" Pause is supported. \"STOP\" Stop is supported. \"NEXT\" Next is supported. \"PREVIOUS\" Previous is supported. \"START_OVER\" Start Over is supported. \"FAST_FORWARD\" Fast Forward is supported. \"REWIND\" Rewind is supported. \"ENABLE_REPEAT\" Enable Repeat is supported. \"ENABLE_REPEAT_ONE\" Enable Repeat One is supported. \"DISABLE_REPEAT\" Disbale Repeat is supported. \"ENABLE_SHUFFLE\" Enable Shuffle is supported. \"DISABLE_SHUFFLE\" Disable Shuffle is supported. \"FAVORITE\" Favorite is supported. \"UNFAVORITE\" Unfavorite is supported. \"SEEK\" Seek is supported. \"ADJUST_SEEK\" Adjust Seek is supported.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/#playcontroltype","text":"","title":"PlayControlType"},{"location":"aasb/alexa/ExternalMediaAdapter/#values_1","text":"Value Description \"PAUSE\" pause playback. \"RESUME\" resume playback. \"STOP\" stop playback. \"NEXT\" next song. \"PREVIOUS\" previous playback. \"START_OVER\" start playback over. \"FAST_FORWARD\" fast forward external media described time. \"REWIND\" rewind external media described time. \"ENABLE_REPEAT_ONE\" enable repeat current song. \"ENABLE_REPEAT\" enable playlist looping. \"DISABLE_REPEAT\" disable playlist looping. \"ENABLE_SHUFFLE\" enable playlist shuffling. \"DISABLE_SHUFFLE\" disable playlist shuffling. \"FAVORITE\" favorite song. \"UNFAVORITE\" unfavorite song.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/#validationmethod","text":"","title":"ValidationMethod"},{"location":"aasb/alexa/ExternalMediaAdapter/#values_2","text":"Value Description \"SIGNING_CERTIFICATE\" description for SIGNING_CERTIFICATE. \"GENERATED_CERTIFICATE\" description for GENERATED_CERTIFICATE. \"NONE\" description for NONE.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/#favorites","text":"","title":"Favorites"},{"location":"aasb/alexa/ExternalMediaAdapter/#values_3","text":"Value Description \"FAVORITED\" song is favorited. \"UNFAVORITED\" song is unfavorited. \"NOT_RATED\" song is not rated.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/#mutedstate","text":"","title":"MutedState"},{"location":"aasb/alexa/ExternalMediaAdapter/#values_4","text":"Value Description \"MUTED\" The audio channel state id muted. \"UNMUTED\" The audio channel state id unmuted.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/#navigation","text":"","title":"Navigation"},{"location":"aasb/alexa/ExternalMediaAdapter/#values_5","text":"Value Description \"DEFAULT\" Source dependant behavior. \"NONE\" No navigation should occur. \"FOREGROUND\" External app should take foreground.","title":"Values"},{"location":"aasb/alexa/ExternalMediaAdapter/#mediatype","text":"","title":"MediaType"},{"location":"aasb/alexa/ExternalMediaAdapter/#values_6","text":"Value Description \"TRACK\" A single song source. \"PODCAST\" A podcast source. \"STATION\" A station source. \"AD\" An advertisement source. \"SAMPLE\" A sample source. \"OTHER\" A miscellaneous source.","title":"Values"},{"location":"aasb/alexa/FeatureDiscovery/","text":"FeatureDiscovery \u00b6 Outgoing Messages \u00b6 GetFeaturesReply \u00b6 Reply for GetFeatures message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"FeatureDiscovery\", \"action\": \"GetFeatures\", \"replyToId\": {{String}} } }, \"payload\": { \"discoveryResponses\": {{String}} } } Payload \u00b6 Property Type Required Description Example discoveryResponses String Yes An escaped JSON string containing the discovery responses. See the Alexa module documentation for complete details of the schema. Incoming Messages \u00b6 GetFeatures \u00b6 Get a list of Alexa features based on the domain, eventType, locale and limit. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"FeatureDiscovery\", \"action\": \"GetFeatures\" } }, \"payload\": { \"discoveryRequests\": {{String}} } } Payload \u00b6 Property Type Required Description Example discoveryRequests String Yes An escaped JSON string containing the discovery requests. See the Alexa module documentation for complete details of the schema.","title":"FeatureDiscovery"},{"location":"aasb/alexa/FeatureDiscovery/#featurediscovery","text":"","title":"FeatureDiscovery"},{"location":"aasb/alexa/FeatureDiscovery/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/FeatureDiscovery/#getfeaturesreply","text":"Reply for GetFeatures message.","title":"GetFeaturesReply"},{"location":"aasb/alexa/FeatureDiscovery/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"FeatureDiscovery\", \"action\": \"GetFeatures\", \"replyToId\": {{String}} } }, \"payload\": { \"discoveryResponses\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/FeatureDiscovery/#payload","text":"Property Type Required Description Example discoveryResponses String Yes An escaped JSON string containing the discovery responses. See the Alexa module documentation for complete details of the schema.","title":"Payload"},{"location":"aasb/alexa/FeatureDiscovery/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/FeatureDiscovery/#getfeatures","text":"Get a list of Alexa features based on the domain, eventType, locale and limit.","title":"GetFeatures"},{"location":"aasb/alexa/FeatureDiscovery/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"FeatureDiscovery\", \"action\": \"GetFeatures\" } }, \"payload\": { \"discoveryRequests\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/FeatureDiscovery/#payload_1","text":"Property Type Required Description Example discoveryRequests String Yes An escaped JSON string containing the discovery requests. See the Alexa module documentation for complete details of the schema.","title":"Payload"},{"location":"aasb/alexa/GlobalPreset/","text":"GlobalPreset \u00b6 Outgoing Messages \u00b6 SetGlobalPreset \u00b6 Called after receiving a global preset play directive. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"GlobalPreset\", \"action\": \"SetGlobalPreset\" } }, \"payload\": { \"preset\": {{Int}} } } Payload \u00b6 Property Type Required Description Example preset Int Yes The preset integer from the playbackContextToken.","title":"GlobalPreset"},{"location":"aasb/alexa/GlobalPreset/#globalpreset","text":"","title":"GlobalPreset"},{"location":"aasb/alexa/GlobalPreset/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/GlobalPreset/#setglobalpreset","text":"Called after receiving a global preset play directive.","title":"SetGlobalPreset"},{"location":"aasb/alexa/GlobalPreset/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"GlobalPreset\", \"action\": \"SetGlobalPreset\" } }, \"payload\": { \"preset\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/GlobalPreset/#payload","text":"Property Type Required Description Example preset Int Yes The preset integer from the playbackContextToken.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/","text":"LocalMediaSource \u00b6 Outgoing Messages \u00b6 PlayControl \u00b6 Occurs during playback control via voice interaction or PlaybackController interface. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayControl\" } }, \"payload\": { \"source\": {{Source}}, \"controlType\": {{PlayControlType}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. controlType PlayControlType Yes Playback control type being invoked. Seek \u00b6 Called when the user invokes media seek via speech. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Seek\" } }, \"payload\": { \"source\": {{Source}}, \"offset\": {{Int}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. offset Int Yes Offset position within media item, in milliseconds. Play \u00b6 Called when the user calls play with a content selection type. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Play\" } }, \"payload\": { \"source\": {{Source}}, \"contentSelectorType\": {{ContentSelector}}, \"payload\": {{String}}, \"sessionId\": {{String}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. contentSelectorType ContentSelector Yes Content selection type. payload String Yes Content selector payload. sessionId String Yes Universally unique identifier (UUID) generated according to the RFC 4122 specification. Since Alexa is starting the session here, use this session Id for further events and errors. GetState \u00b6 Must provide the local media source @PlaybackStateLocal, and @SessionStateLocal information to maintain cloud sync. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\" } }, \"payload\": { \"source\": {{Source}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. AdjustSeek \u00b6 Called when the user invokes media seek adjustment via speech. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"source\": {{Source}}, \"deltaOffset\": {{Int}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. deltaOffset Int Yes Change in offset position within media item, in milliseconds. MutedStateChanged \u00b6 Notifies the platform implementation to apply a muted state has changed for the output channel. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"source\": {{Source}}, \"state\": {{MutedState}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. state MutedState Yes The muted state to apply to the output channel. VolumeChanged \u00b6 Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"source\": {{Source}}, \"volume\": {{Float}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. volume Float Yes The volume to set on the output channel. Incoming Messages \u00b6 PlayerEvent \u00b6 Should be called on a local media source player event. This will sync the context with AVS. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"source\": {{Source}}, \"eventName\": {{String}}, \"sessionId\": {{String}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. eventName String Yes Canonical event name. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended. SetFocus \u00b6 Should be called on local media source player events. This will switch the media focus to that context. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"SetFocus\" } }, \"payload\": { \"source\": {{Source}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. PlayerError \u00b6 Should be called on a local media source player error. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerError\" } }, \"payload\": { \"source\": {{Source}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}}, \"sessionId\": {{String}} } } Payload \u00b6 Property Type Required Description Example source Source Yes LocalMediaSource source type. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended. GetStateReply \u00b6 Reply for GetState message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{LocalMediaSourceState}} } } Payload \u00b6 Property Type Required Description Example state LocalMediaSourceState Yes state description. Type Definitions \u00b6 LocalMediaSourceState \u00b6 JSON Structure \u00b6 { \"sessionState\": {{SessionState}}, \"playbackState\": {{PlaybackState}} } Properties \u00b6 Property Type Required Description Example sessionState SessionState Yes Variable to hold the session state. playbackState PlaybackState Yes Variable to hold the playback state. PlaybackState \u00b6 JSON Structure \u00b6 { \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} } Properties \u00b6 Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PAUSED/PLAYING/FINISHED/FAST_FORWARDING/REWINDING/BUFFER_UNDERRUN. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource} . smallURL String Yes The URL for small cover art image resource} . mediumURL String Yes The URL for medium cover art image resource} . largeURL String Yes The URL for large cover art image resource} . coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds. SessionState \u00b6 JSON Structure \u00b6 { \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"supportedContentSelectors\": [{{ContentSelector}}], \"spiVersion\": {{String}} } Properties \u00b6 Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. supportedContentSelectors ContentSelector [] Yes Array of content selector types supported by the player. spiVersion String Yes The only spiVersion that currently exists is '1.0'. Enums \u00b6 Source \u00b6 Values \u00b6 Value Description \"BLUETOOTH\" bluetooth source. \"USB\" USB source. \"FM_RADIO\" FM radio source. \"AM_RADIO\" AM radio source. \"SATELLITE_RADIO\" satellite radio source. \"LINE_IN\" audio line source. \"COMPACT_DISC\" CD player source. \"SIRIUS_XM\" SIRIUS XM source. \"DAB\" DAB source. \"DEFAULT\" DEFAULT source. ContentSelector \u00b6 Values \u00b6 Value Description \"FREQUENCY\" radio station selection. \"CHANNEL\" radio channel selection. \"PRESET\" preset selection.","title":"LocalMediaSource"},{"location":"aasb/alexa/LocalMediaSource/#localmediasource","text":"","title":"LocalMediaSource"},{"location":"aasb/alexa/LocalMediaSource/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/LocalMediaSource/#playcontrol","text":"Occurs during playback control via voice interaction or PlaybackController interface.","title":"PlayControl"},{"location":"aasb/alexa/LocalMediaSource/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayControl\" } }, \"payload\": { \"source\": {{Source}}, \"controlType\": {{PlayControlType}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. controlType PlayControlType Yes Playback control type being invoked.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#seek","text":"Called when the user invokes media seek via speech.","title":"Seek"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Seek\" } }, \"payload\": { \"source\": {{Source}}, \"offset\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_1","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. offset Int Yes Offset position within media item, in milliseconds.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#play","text":"Called when the user calls play with a content selection type.","title":"Play"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Play\" } }, \"payload\": { \"source\": {{Source}}, \"contentSelectorType\": {{ContentSelector}}, \"payload\": {{String}}, \"sessionId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_2","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. contentSelectorType ContentSelector Yes Content selection type. payload String Yes Content selector payload. sessionId String Yes Universally unique identifier (UUID) generated according to the RFC 4122 specification. Since Alexa is starting the session here, use this session Id for further events and errors.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#getstate","text":"Must provide the local media source @PlaybackStateLocal, and @SessionStateLocal information to maintain cloud sync.","title":"GetState"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\" } }, \"payload\": { \"source\": {{Source}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_3","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#adjustseek","text":"Called when the user invokes media seek adjustment via speech.","title":"AdjustSeek"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"source\": {{Source}}, \"deltaOffset\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_4","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. deltaOffset Int Yes Change in offset position within media item, in milliseconds.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#mutedstatechanged","text":"Notifies the platform implementation to apply a muted state has changed for the output channel.","title":"MutedStateChanged"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"source\": {{Source}}, \"state\": {{MutedState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_5","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. state MutedState Yes The muted state to apply to the output channel.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#volumechanged","text":"Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform.","title":"VolumeChanged"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"source\": {{Source}}, \"volume\": {{Float}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_6","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. volume Float Yes The volume to set on the output channel.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/LocalMediaSource/#playerevent","text":"Should be called on a local media source player event. This will sync the context with AVS.","title":"PlayerEvent"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"source\": {{Source}}, \"eventName\": {{String}}, \"sessionId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_7","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. eventName String Yes Canonical event name. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#setfocus","text":"Should be called on local media source player events. This will switch the media focus to that context.","title":"SetFocus"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"SetFocus\" } }, \"payload\": { \"source\": {{Source}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_8","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#playererror","text":"Should be called on a local media source player error.","title":"PlayerError"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerError\" } }, \"payload\": { \"source\": {{Source}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}}, \"sessionId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_9","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#getstatereply","text":"Reply for GetState message.","title":"GetStateReply"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{LocalMediaSourceState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#payload_10","text":"Property Type Required Description Example state LocalMediaSourceState Yes state description.","title":"Payload"},{"location":"aasb/alexa/LocalMediaSource/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/alexa/LocalMediaSource/#localmediasourcestate","text":"","title":"LocalMediaSourceState"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_11","text":"{ \"sessionState\": {{SessionState}}, \"playbackState\": {{PlaybackState}} }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#properties","text":"Property Type Required Description Example sessionState SessionState Yes Variable to hold the session state. playbackState PlaybackState Yes Variable to hold the playback state.","title":"Properties"},{"location":"aasb/alexa/LocalMediaSource/#playbackstate","text":"","title":"PlaybackState"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_12","text":"{ \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#properties_1","text":"Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PAUSED/PLAYING/FINISHED/FAST_FORWARDING/REWINDING/BUFFER_UNDERRUN. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource} . smallURL String Yes The URL for small cover art image resource} . mediumURL String Yes The URL for medium cover art image resource} . largeURL String Yes The URL for large cover art image resource} . coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds.","title":"Properties"},{"location":"aasb/alexa/LocalMediaSource/#sessionstate","text":"","title":"SessionState"},{"location":"aasb/alexa/LocalMediaSource/#json-structure_13","text":"{ \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"supportedContentSelectors\": [{{ContentSelector}}], \"spiVersion\": {{String}} }","title":"JSON Structure"},{"location":"aasb/alexa/LocalMediaSource/#properties_2","text":"Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. supportedContentSelectors ContentSelector [] Yes Array of content selector types supported by the player. spiVersion String Yes The only spiVersion that currently exists is '1.0'.","title":"Properties"},{"location":"aasb/alexa/LocalMediaSource/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/LocalMediaSource/#source","text":"","title":"Source"},{"location":"aasb/alexa/LocalMediaSource/#values","text":"Value Description \"BLUETOOTH\" bluetooth source. \"USB\" USB source. \"FM_RADIO\" FM radio source. \"AM_RADIO\" AM radio source. \"SATELLITE_RADIO\" satellite radio source. \"LINE_IN\" audio line source. \"COMPACT_DISC\" CD player source. \"SIRIUS_XM\" SIRIUS XM source. \"DAB\" DAB source. \"DEFAULT\" DEFAULT source.","title":"Values"},{"location":"aasb/alexa/LocalMediaSource/#contentselector","text":"","title":"ContentSelector"},{"location":"aasb/alexa/LocalMediaSource/#values_1","text":"Value Description \"FREQUENCY\" radio station selection. \"CHANNEL\" radio channel selection. \"PRESET\" preset selection.","title":"Values"},{"location":"aasb/alexa/MediaPlaybackRequestor/","text":"MediaPlaybackRequestor \u00b6 Outgoing Messages \u00b6 MediaPlaybackResponse \u00b6 Result of the RequestMediaPlayback request. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"MediaPlaybackResponse\" } }, \"payload\": { \"mediaPlaybackRequestStatus\": {{MediaPlaybackRequestStatus}} } } Payload \u00b6 Property Type Required Description Example mediaPlaybackRequestStatus MediaPlaybackRequestStatus Yes Enum value representing the response of the RequestMediaPlaybackMessage request. Incoming Messages \u00b6 RequestMediaPlayback \u00b6 OEM Developers are expected to call this method whenever Alexa is the right candidate for the media resume. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"RequestMediaPlayback\" } }, \"payload\": { \"invocationReason\": {{InvocationReason}}, \"elapsedBootTime\": {{int64}} } } Payload \u00b6 Property Type Required Description Example invocationReason InvocationReason Yes Reason for calling this API. elapsedBootTime int64 Yes Provide the elapsed boot time in mili seconds if your platform does not provide a right value using https://developer.android.com/reference/android/os/SystemClock#elapsedRealtime() or https://man7.org/linux/man-pages/man2/sysinfo.2.html uptime. Enums \u00b6 MediaPlaybackRequestStatus \u00b6 Values \u00b6 Value Description \"SUCCESS\" Successful description. \"FAILED_CAN_RETRY\" Failure description. \"FAILED_TIMEOUT\" Too late to send RequestMediaPlaybackMessage, Failed to deliver. \"ERROR\" Event call is failed because of an error. InvocationReason \u00b6 Values \u00b6 Value Description \"AUTOMOTIVE_STARTUP\" System call for the automatic media resume. \"EXPLICIT_USER_ACTION\" Driver action for the media resume.","title":"MediaPlaybackRequestor"},{"location":"aasb/alexa/MediaPlaybackRequestor/#mediaplaybackrequestor","text":"","title":"MediaPlaybackRequestor"},{"location":"aasb/alexa/MediaPlaybackRequestor/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/MediaPlaybackRequestor/#mediaplaybackresponse","text":"Result of the RequestMediaPlayback request.","title":"MediaPlaybackResponse"},{"location":"aasb/alexa/MediaPlaybackRequestor/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"MediaPlaybackResponse\" } }, \"payload\": { \"mediaPlaybackRequestStatus\": {{MediaPlaybackRequestStatus}} } }","title":"JSON Structure"},{"location":"aasb/alexa/MediaPlaybackRequestor/#payload","text":"Property Type Required Description Example mediaPlaybackRequestStatus MediaPlaybackRequestStatus Yes Enum value representing the response of the RequestMediaPlaybackMessage request.","title":"Payload"},{"location":"aasb/alexa/MediaPlaybackRequestor/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/MediaPlaybackRequestor/#requestmediaplayback","text":"OEM Developers are expected to call this method whenever Alexa is the right candidate for the media resume.","title":"RequestMediaPlayback"},{"location":"aasb/alexa/MediaPlaybackRequestor/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"RequestMediaPlayback\" } }, \"payload\": { \"invocationReason\": {{InvocationReason}}, \"elapsedBootTime\": {{int64}} } }","title":"JSON Structure"},{"location":"aasb/alexa/MediaPlaybackRequestor/#payload_1","text":"Property Type Required Description Example invocationReason InvocationReason Yes Reason for calling this API. elapsedBootTime int64 Yes Provide the elapsed boot time in mili seconds if your platform does not provide a right value using https://developer.android.com/reference/android/os/SystemClock#elapsedRealtime() or https://man7.org/linux/man-pages/man2/sysinfo.2.html uptime.","title":"Payload"},{"location":"aasb/alexa/MediaPlaybackRequestor/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/MediaPlaybackRequestor/#mediaplaybackrequeststatus","text":"","title":"MediaPlaybackRequestStatus"},{"location":"aasb/alexa/MediaPlaybackRequestor/#values","text":"Value Description \"SUCCESS\" Successful description. \"FAILED_CAN_RETRY\" Failure description. \"FAILED_TIMEOUT\" Too late to send RequestMediaPlaybackMessage, Failed to deliver. \"ERROR\" Event call is failed because of an error.","title":"Values"},{"location":"aasb/alexa/MediaPlaybackRequestor/#invocationreason","text":"","title":"InvocationReason"},{"location":"aasb/alexa/MediaPlaybackRequestor/#values_1","text":"Value Description \"AUTOMOTIVE_STARTUP\" System call for the automatic media resume. \"EXPLICIT_USER_ACTION\" Driver action for the media resume.","title":"Values"},{"location":"aasb/alexa/Notifications/","text":"Notifications \u00b6 Outgoing Messages \u00b6 SetIndicator \u00b6 Notifies the platform implementation of whether a notification indicator should be rendered. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"SetIndicator\" } }, \"payload\": { \"state\": {{IndicatorState}} } } Payload \u00b6 Property Type Required Description Example state IndicatorState Yes The new notification indicator state. OnNotificationReceived \u00b6 Notifies the platform implementation of notification received. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"OnNotificationReceived\" } } } Enums \u00b6 IndicatorState \u00b6 Values \u00b6 Value Description \"OFF\" The notification indicator should be turned off. \"ON\" The notification indicator should be turned on. \"UNKNOWN\" The notification indicator state is unknown.","title":"Notifications"},{"location":"aasb/alexa/Notifications/#notifications","text":"","title":"Notifications"},{"location":"aasb/alexa/Notifications/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/Notifications/#setindicator","text":"Notifies the platform implementation of whether a notification indicator should be rendered.","title":"SetIndicator"},{"location":"aasb/alexa/Notifications/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"SetIndicator\" } }, \"payload\": { \"state\": {{IndicatorState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/Notifications/#payload","text":"Property Type Required Description Example state IndicatorState Yes The new notification indicator state.","title":"Payload"},{"location":"aasb/alexa/Notifications/#onnotificationreceived","text":"Notifies the platform implementation of notification received.","title":"OnNotificationReceived"},{"location":"aasb/alexa/Notifications/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"OnNotificationReceived\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/Notifications/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/Notifications/#indicatorstate","text":"","title":"IndicatorState"},{"location":"aasb/alexa/Notifications/#values","text":"Value Description \"OFF\" The notification indicator should be turned off. \"ON\" The notification indicator should be turned on. \"UNKNOWN\" The notification indicator state is unknown.","title":"Values"},{"location":"aasb/alexa/PlaybackController/","text":"PlaybackController \u00b6 Incoming Messages \u00b6 ButtonPressed \u00b6 Notifies the Engine of a platform button request (i.e. Play/Pause/Next/Previous/Skip Forward/Skip Backward) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer to control playback on the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"ButtonPressed\" } }, \"payload\": { \"button\": {{PlaybackButton}} } } Payload \u00b6 Property Type Required Description Example button PlaybackButton Yes The playback button type. TogglePressed \u00b6 Notifies the Engine of a platform toggle request (i.e. Shuffle/Loop/Repeat/Thumbs Up/Thumbs Down) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"TogglePressed\" } }, \"payload\": { \"toggle\": {{PlaybackToggle}}, \"action\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example toggle PlaybackToggle Yes The playback toggle type. action Bool Yes The toggle action. Enums \u00b6 PlaybackButton \u00b6 Values \u00b6 Value Description \"PLAY\" Play button. \"PAUSE\" Pause button. \"NEXT\" Next button. \"PREVIOUS\" Previous button. \"SKIP_FORWARD\" Skip Forward button. \"SKIP_BACKWARD\" Skip Backward button. PlaybackToggle \u00b6 Values \u00b6 Value Description \"SHUFFLE\" Shuffle toggle. \"LOOP\" Loop toggle. \"REPEAT\" Repeat toggle. \"THUMBS_UP\" Thumbs Up toggle. \"THUMBS_DOWN\" Thumbs Down toggle.","title":"PlaybackController"},{"location":"aasb/alexa/PlaybackController/#playbackcontroller","text":"","title":"PlaybackController"},{"location":"aasb/alexa/PlaybackController/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/PlaybackController/#buttonpressed","text":"Notifies the Engine of a platform button request (i.e. Play/Pause/Next/Previous/Skip Forward/Skip Backward) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer to control playback on the platform.","title":"ButtonPressed"},{"location":"aasb/alexa/PlaybackController/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"ButtonPressed\" } }, \"payload\": { \"button\": {{PlaybackButton}} } }","title":"JSON Structure"},{"location":"aasb/alexa/PlaybackController/#payload","text":"Property Type Required Description Example button PlaybackButton Yes The playback button type.","title":"Payload"},{"location":"aasb/alexa/PlaybackController/#togglepressed","text":"Notifies the Engine of a platform toggle request (i.e. Shuffle/Loop/Repeat/Thumbs Up/Thumbs Down) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer.","title":"TogglePressed"},{"location":"aasb/alexa/PlaybackController/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"TogglePressed\" } }, \"payload\": { \"toggle\": {{PlaybackToggle}}, \"action\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/alexa/PlaybackController/#payload_1","text":"Property Type Required Description Example toggle PlaybackToggle Yes The playback toggle type. action Bool Yes The toggle action.","title":"Payload"},{"location":"aasb/alexa/PlaybackController/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/PlaybackController/#playbackbutton","text":"","title":"PlaybackButton"},{"location":"aasb/alexa/PlaybackController/#values","text":"Value Description \"PLAY\" Play button. \"PAUSE\" Pause button. \"NEXT\" Next button. \"PREVIOUS\" Previous button. \"SKIP_FORWARD\" Skip Forward button. \"SKIP_BACKWARD\" Skip Backward button.","title":"Values"},{"location":"aasb/alexa/PlaybackController/#playbacktoggle","text":"","title":"PlaybackToggle"},{"location":"aasb/alexa/PlaybackController/#values_1","text":"Value Description \"SHUFFLE\" Shuffle toggle. \"LOOP\" Loop toggle. \"REPEAT\" Repeat toggle. \"THUMBS_UP\" Thumbs Up toggle. \"THUMBS_DOWN\" Thumbs Down toggle.","title":"Values"},{"location":"aasb/alexa/SpeechRecognizer/","text":"SpeechRecognizer \u00b6 Outgoing Messages \u00b6 WakewordDetected \u00b6 Notifies the platform implementation when a wake word is detected. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"WakewordDetected\" } }, \"payload\": { \"wakeword\": {{String}} } } Payload \u00b6 Property Type Required Description Example wakeword String Yes The wake word that was detected. EndOfSpeechDetected \u00b6 Notifies the platform implementation when end of speech is detected for the current recognize event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"EndOfSpeechDetected\" } } } Incoming Messages \u00b6 StopCapture \u00b6 Notifies the Engine to terminate the current recognize event. The Engine will call stopAudioInput() to notify the platform implementation when to stop writing audio samples. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StopCapture\" } } } StartCapture \u00b6 Notifies the Engine of a speech recognition event. The Engine will call startAudioInput() to notify the platform implementation when to start writing audio samples. If the initator type is HOLD_TO_TALK, then the platform implementation should call stopCapture() to terminate speech recognition on release of the press-and-hold action. Otherwise, the Engine will terminate the recognize event when end of speech is detected. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StartCapture\" } }, \"payload\": { \"initiator\": {{Initiator}}, \"keywordBegin\": {{Int}}, \"keywordEnd\": {{Int}}, \"keyword\": {{String}} } } Payload \u00b6 Property Type Required Description Example initiator Initiator Yes Initiator type for the speech recognition event. keywordBegin Int No (default: -1 ) The sample index where the keyword begins. Must be provided when initiator type is WAKEWORD. keywordEnd Int No (default: -1 ) The sample index where the keyword ends. Must be provided when initiator type is WAKEWORD. keyword String No The keyword being recognized, e.g. alexa. Must be provided when initiator type is WAKEWORD. Enums \u00b6 Initiator \u00b6 Values \u00b6 Value Description \"HOLD_TO_TALK\" Hold-to-talk speech initiator type. \"TAP_TO_TALK\" Tap-to-talk speech initiator type. \"WAKEWORD\" Wakeword speech initiator type.","title":"SpeechRecognizer"},{"location":"aasb/alexa/SpeechRecognizer/#speechrecognizer","text":"","title":"SpeechRecognizer"},{"location":"aasb/alexa/SpeechRecognizer/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/SpeechRecognizer/#wakeworddetected","text":"Notifies the platform implementation when a wake word is detected.","title":"WakewordDetected"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"WakewordDetected\" } }, \"payload\": { \"wakeword\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/SpeechRecognizer/#payload","text":"Property Type Required Description Example wakeword String Yes The wake word that was detected.","title":"Payload"},{"location":"aasb/alexa/SpeechRecognizer/#endofspeechdetected","text":"Notifies the platform implementation when end of speech is detected for the current recognize event.","title":"EndOfSpeechDetected"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"EndOfSpeechDetected\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/SpeechRecognizer/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/SpeechRecognizer/#stopcapture","text":"Notifies the Engine to terminate the current recognize event. The Engine will call stopAudioInput() to notify the platform implementation when to stop writing audio samples.","title":"StopCapture"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StopCapture\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/SpeechRecognizer/#startcapture","text":"Notifies the Engine of a speech recognition event. The Engine will call startAudioInput() to notify the platform implementation when to start writing audio samples. If the initator type is HOLD_TO_TALK, then the platform implementation should call stopCapture() to terminate speech recognition on release of the press-and-hold action. Otherwise, the Engine will terminate the recognize event when end of speech is detected.","title":"StartCapture"},{"location":"aasb/alexa/SpeechRecognizer/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StartCapture\" } }, \"payload\": { \"initiator\": {{Initiator}}, \"keywordBegin\": {{Int}}, \"keywordEnd\": {{Int}}, \"keyword\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/alexa/SpeechRecognizer/#payload_1","text":"Property Type Required Description Example initiator Initiator Yes Initiator type for the speech recognition event. keywordBegin Int No (default: -1 ) The sample index where the keyword begins. Must be provided when initiator type is WAKEWORD. keywordEnd Int No (default: -1 ) The sample index where the keyword ends. Must be provided when initiator type is WAKEWORD. keyword String No The keyword being recognized, e.g. alexa. Must be provided when initiator type is WAKEWORD.","title":"Payload"},{"location":"aasb/alexa/SpeechRecognizer/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/SpeechRecognizer/#initiator","text":"","title":"Initiator"},{"location":"aasb/alexa/SpeechRecognizer/#values","text":"Value Description \"HOLD_TO_TALK\" Hold-to-talk speech initiator type. \"TAP_TO_TALK\" Tap-to-talk speech initiator type. \"WAKEWORD\" Wakeword speech initiator type.","title":"Values"},{"location":"aasb/alexa/TemplateRuntime/","text":"TemplateRuntime \u00b6 Outgoing Messages \u00b6 RenderTemplate \u00b6 Provides visual metadata associated with a user request to Alexa. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderTemplate\" } }, \"payload\": { \"payload\": {{String}}, \"focusState\": {{FocusState}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Renderable template metadata in structured JSON format. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface. ClearPlayerInfo \u00b6 Notifies the platform implementation to dismiss the player info display card. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearPlayerInfo\" } } } ClearTemplate \u00b6 Notifies the platform implementation to dismiss the template display card. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearTemplate\" } } } RenderPlayerInfo \u00b6 Provides visual metadata associated with a user request to Alexa for audio playback. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderPlayerInfo\" } }, \"payload\": { \"payload\": {{String}}, \"audioPlayerState\": {{PlayerActivity}}, \"offset\": {{Int}}, \"focusState\": {{FocusState}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Renderable player info metadata in structured JSON format. audioPlayerState PlayerActivity Yes The state of the AudioPlayer. offset Int Yes The offset in millisecond of the media that AudioPlayer is handling. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface. Incoming Messages \u00b6 DisplayCardCleared \u00b6 Notifies the Engine that a display card has been cleared from the screen. Upon getting this notification, the TemplateRuntime will release the visual channel. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"DisplayCardCleared\" } } } Enums \u00b6 FocusState \u00b6 Values \u00b6 Value Description \"FOREGROUND\" Represents the highest focus a Channel can have. \"BACKGROUND\" Represents the intermediate level focus a Channel can have. \"NONE\" This focus is used to represent when a Channel is not being used.","title":"TemplateRuntime"},{"location":"aasb/alexa/TemplateRuntime/#templateruntime","text":"","title":"TemplateRuntime"},{"location":"aasb/alexa/TemplateRuntime/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/alexa/TemplateRuntime/#rendertemplate","text":"Provides visual metadata associated with a user request to Alexa.","title":"RenderTemplate"},{"location":"aasb/alexa/TemplateRuntime/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderTemplate\" } }, \"payload\": { \"payload\": {{String}}, \"focusState\": {{FocusState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/TemplateRuntime/#payload","text":"Property Type Required Description Example payload String Yes Renderable template metadata in structured JSON format. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface.","title":"Payload"},{"location":"aasb/alexa/TemplateRuntime/#clearplayerinfo","text":"Notifies the platform implementation to dismiss the player info display card.","title":"ClearPlayerInfo"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearPlayerInfo\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/TemplateRuntime/#cleartemplate","text":"Notifies the platform implementation to dismiss the template display card.","title":"ClearTemplate"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearTemplate\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/TemplateRuntime/#renderplayerinfo","text":"Provides visual metadata associated with a user request to Alexa for audio playback.","title":"RenderPlayerInfo"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderPlayerInfo\" } }, \"payload\": { \"payload\": {{String}}, \"audioPlayerState\": {{PlayerActivity}}, \"offset\": {{Int}}, \"focusState\": {{FocusState}} } }","title":"JSON Structure"},{"location":"aasb/alexa/TemplateRuntime/#payload_1","text":"Property Type Required Description Example payload String Yes Renderable player info metadata in structured JSON format. audioPlayerState PlayerActivity Yes The state of the AudioPlayer. offset Int Yes The offset in millisecond of the media that AudioPlayer is handling. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface.","title":"Payload"},{"location":"aasb/alexa/TemplateRuntime/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/alexa/TemplateRuntime/#displaycardcleared","text":"Notifies the Engine that a display card has been cleared from the screen. Upon getting this notification, the TemplateRuntime will release the visual channel.","title":"DisplayCardCleared"},{"location":"aasb/alexa/TemplateRuntime/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"DisplayCardCleared\" } } }","title":"JSON Structure"},{"location":"aasb/alexa/TemplateRuntime/#enums","text":"","title":"Enums"},{"location":"aasb/alexa/TemplateRuntime/#focusstate","text":"","title":"FocusState"},{"location":"aasb/alexa/TemplateRuntime/#values","text":"Value Description \"FOREGROUND\" Represents the highest focus a Channel can have. \"BACKGROUND\" Represents the intermediate level focus a Channel can have. \"NONE\" This focus is used to represent when a Channel is not being used.","title":"Values"},{"location":"aasb/apl/APL/","text":"APL \u00b6 Outgoing Messages \u00b6 DataSourceUpdate \u00b6 Notifies the platform implementation of a dynamic data source update. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"DataSourceUpdate\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example type String Yes The type of data source update received. payload String Yes The data source update payload in JSON format. token String Yes The presentation token associated with the APL document. InterruptCommandSequence \u00b6 Notifies the platform implementation to clear the APL document rendering. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"InterruptCommandSequence\" } }, \"payload\": { \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes The presentation token associated with the APL document. UpdateAPLRuntimeProperties \u00b6 Notifies the platform implementation of APL runtime properties to be used during rendering. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"UpdateAPLRuntimeProperties\" } }, \"payload\": { \"properties\": {{String}} } } Payload \u00b6 Property Type Required Description Example properties String Yes String in JSON format containing updated APL runtime properties. RenderDocument \u00b6 Notifies the platform implementation that an APL document needs rendering. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocument\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}}, \"windowId\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes The APL document to be rendered represented as a JSON string. token String Yes The presentation token associated with the APL document. windowId String Yes The window ID where the APL document will be rendered or empty string for default window. ExecuteCommands \u00b6 Notifies the platform implementation that an APL document needs rendering. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommands\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes The APL commands to be executed represented as a JSON string. token String Yes The presentation token associated with the APL document. ClearDocument \u00b6 Notifies the platform implementation to clear the APL document rendering. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearDocument\" } }, \"payload\": { \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes The presentation token associated with the APL document. Incoming Messages \u00b6 ProcessActivityEvent \u00b6 Notifies the Engine of an activity event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ProcessActivityEvent\" } }, \"payload\": { \"source\": {{String}}, \"event\": {{ActivityEvent}} } } Payload \u00b6 Property Type Required Description Example source String Yes The source value for the activity event. event ActivityEvent Yes The activity event type. SetAPLMaxVersion \u00b6 Notifies the Engine of the maximum APL version supported. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetAPLMaxVersion\" } }, \"payload\": { \"version\": {{String}} } } Payload \u00b6 Property Type Required Description Example version String Yes The maximum APL version supported. SendUserEvent \u00b6 Notifies the Engine that user generated an event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendUserEvent\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes The APL user event represented as a JSON string. SendDataSourceFetchRequestEvent \u00b6 Notifies the Engine of a data source fetch request. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDataSourceFetchRequestEvent\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example type String Yes The type of data source fetch request. payload String Yes The APL user event represented as a JSON string. SendDeviceWindowState \u00b6 Notifies the Engine of the current window state. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDeviceWindowState\" } }, \"payload\": { \"state\": {{String}} } } Payload \u00b6 Property Type Required Description Example state String Yes JSON string representing the payload of the window state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/display-window.html#windowstate-context-object. SendDocumentState \u00b6 Notifies the Engine that APL runtime generated visual document state. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDocumentState\" } }, \"payload\": { \"state\": {{String}} } } Payload \u00b6 Property Type Required Description Example state String Yes JSON string representing the payload of the rendered document state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/presentation-apl.html#rendereddocumentstate. SendRuntimeErrorEvent \u00b6 Notifies the Engine that an APL runtime error occurred. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendRuntimeErrorEvent\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes The APL runtime error event represented as a JSON string. ClearAllExecuteCommands \u00b6 Notifies the Engine that APL render finished clearing all commands. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearAllExecuteCommands\" } } } SetPlatformProperty \u00b6 Notifies the Engine of properties such as vehicle driving state, day/night mode, and custom theme id. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetPlatformProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes The name of the property to be set. value String Yes The value that the property will be set to. ExecuteCommandsResult \u00b6 Notifies the Engine of the command execution result. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommandsResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes The token associated with the commands. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty. SetDocumentIdleTimeout \u00b6 Notifies the Engine of the idle timeout value. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetDocumentIdleTimeout\" } }, \"payload\": { \"timeout\": {{int64}} } } Payload \u00b6 Property Type Required Description Example timeout int64 Yes Idle timeout value in milliseconds. RenderDocumentResult \u00b6 Notifies the Engine of command execution result. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocumentResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes The token associated with the APL document. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty. ClearCard \u00b6 Notifies the Engine that APL render finished clearing document. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearCard\" } } } Enums \u00b6 ActivityEvent \u00b6 Values \u00b6 Value Description \"ACTIVATED\" GUI switched to active state. \"DEACTIVATED\" GUI become inactive. \"ONE_TIME\" GUI processed one-time event (touch/scroll/etc). \"INTERRUPT\" Interrupt event (touch). \"UNKNOWN\" Guard option for unknown received state.","title":"APL"},{"location":"aasb/apl/APL/#apl","text":"","title":"APL"},{"location":"aasb/apl/APL/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/apl/APL/#datasourceupdate","text":"Notifies the platform implementation of a dynamic data source update.","title":"DataSourceUpdate"},{"location":"aasb/apl/APL/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"DataSourceUpdate\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload","text":"Property Type Required Description Example type String Yes The type of data source update received. payload String Yes The data source update payload in JSON format. token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"aasb/apl/APL/#interruptcommandsequence","text":"Notifies the platform implementation to clear the APL document rendering.","title":"InterruptCommandSequence"},{"location":"aasb/apl/APL/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"InterruptCommandSequence\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_1","text":"Property Type Required Description Example token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"aasb/apl/APL/#updateaplruntimeproperties","text":"Notifies the platform implementation of APL runtime properties to be used during rendering.","title":"UpdateAPLRuntimeProperties"},{"location":"aasb/apl/APL/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"UpdateAPLRuntimeProperties\" } }, \"payload\": { \"properties\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_2","text":"Property Type Required Description Example properties String Yes String in JSON format containing updated APL runtime properties.","title":"Payload"},{"location":"aasb/apl/APL/#renderdocument","text":"Notifies the platform implementation that an APL document needs rendering.","title":"RenderDocument"},{"location":"aasb/apl/APL/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocument\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}}, \"windowId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_3","text":"Property Type Required Description Example payload String Yes The APL document to be rendered represented as a JSON string. token String Yes The presentation token associated with the APL document. windowId String Yes The window ID where the APL document will be rendered or empty string for default window.","title":"Payload"},{"location":"aasb/apl/APL/#executecommands","text":"Notifies the platform implementation that an APL document needs rendering.","title":"ExecuteCommands"},{"location":"aasb/apl/APL/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommands\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_4","text":"Property Type Required Description Example payload String Yes The APL commands to be executed represented as a JSON string. token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"aasb/apl/APL/#cleardocument","text":"Notifies the platform implementation to clear the APL document rendering.","title":"ClearDocument"},{"location":"aasb/apl/APL/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearDocument\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_5","text":"Property Type Required Description Example token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"aasb/apl/APL/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/apl/APL/#processactivityevent","text":"Notifies the Engine of an activity event.","title":"ProcessActivityEvent"},{"location":"aasb/apl/APL/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ProcessActivityEvent\" } }, \"payload\": { \"source\": {{String}}, \"event\": {{ActivityEvent}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_6","text":"Property Type Required Description Example source String Yes The source value for the activity event. event ActivityEvent Yes The activity event type.","title":"Payload"},{"location":"aasb/apl/APL/#setaplmaxversion","text":"Notifies the Engine of the maximum APL version supported.","title":"SetAPLMaxVersion"},{"location":"aasb/apl/APL/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetAPLMaxVersion\" } }, \"payload\": { \"version\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_7","text":"Property Type Required Description Example version String Yes The maximum APL version supported.","title":"Payload"},{"location":"aasb/apl/APL/#senduserevent","text":"Notifies the Engine that user generated an event.","title":"SendUserEvent"},{"location":"aasb/apl/APL/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendUserEvent\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_8","text":"Property Type Required Description Example payload String Yes The APL user event represented as a JSON string.","title":"Payload"},{"location":"aasb/apl/APL/#senddatasourcefetchrequestevent","text":"Notifies the Engine of a data source fetch request.","title":"SendDataSourceFetchRequestEvent"},{"location":"aasb/apl/APL/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDataSourceFetchRequestEvent\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_9","text":"Property Type Required Description Example type String Yes The type of data source fetch request. payload String Yes The APL user event represented as a JSON string.","title":"Payload"},{"location":"aasb/apl/APL/#senddevicewindowstate","text":"Notifies the Engine of the current window state.","title":"SendDeviceWindowState"},{"location":"aasb/apl/APL/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDeviceWindowState\" } }, \"payload\": { \"state\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_10","text":"Property Type Required Description Example state String Yes JSON string representing the payload of the window state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/display-window.html#windowstate-context-object.","title":"Payload"},{"location":"aasb/apl/APL/#senddocumentstate","text":"Notifies the Engine that APL runtime generated visual document state.","title":"SendDocumentState"},{"location":"aasb/apl/APL/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDocumentState\" } }, \"payload\": { \"state\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_11","text":"Property Type Required Description Example state String Yes JSON string representing the payload of the rendered document state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/presentation-apl.html#rendereddocumentstate.","title":"Payload"},{"location":"aasb/apl/APL/#sendruntimeerrorevent","text":"Notifies the Engine that an APL runtime error occurred.","title":"SendRuntimeErrorEvent"},{"location":"aasb/apl/APL/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendRuntimeErrorEvent\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_12","text":"Property Type Required Description Example payload String Yes The APL runtime error event represented as a JSON string.","title":"Payload"},{"location":"aasb/apl/APL/#clearallexecutecommands","text":"Notifies the Engine that APL render finished clearing all commands.","title":"ClearAllExecuteCommands"},{"location":"aasb/apl/APL/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearAllExecuteCommands\" } } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#setplatformproperty","text":"Notifies the Engine of properties such as vehicle driving state, day/night mode, and custom theme id.","title":"SetPlatformProperty"},{"location":"aasb/apl/APL/#json-structure_14","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetPlatformProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_13","text":"Property Type Required Description Example name String Yes The name of the property to be set. value String Yes The value that the property will be set to.","title":"Payload"},{"location":"aasb/apl/APL/#executecommandsresult","text":"Notifies the Engine of the command execution result.","title":"ExecuteCommandsResult"},{"location":"aasb/apl/APL/#json-structure_15","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommandsResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_14","text":"Property Type Required Description Example token String Yes The token associated with the commands. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty.","title":"Payload"},{"location":"aasb/apl/APL/#setdocumentidletimeout","text":"Notifies the Engine of the idle timeout value.","title":"SetDocumentIdleTimeout"},{"location":"aasb/apl/APL/#json-structure_16","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetDocumentIdleTimeout\" } }, \"payload\": { \"timeout\": {{int64}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_15","text":"Property Type Required Description Example timeout int64 Yes Idle timeout value in milliseconds.","title":"Payload"},{"location":"aasb/apl/APL/#renderdocumentresult","text":"Notifies the Engine of command execution result.","title":"RenderDocumentResult"},{"location":"aasb/apl/APL/#json-structure_17","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocumentResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#payload_16","text":"Property Type Required Description Example token String Yes The token associated with the APL document. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty.","title":"Payload"},{"location":"aasb/apl/APL/#clearcard","text":"Notifies the Engine that APL render finished clearing document.","title":"ClearCard"},{"location":"aasb/apl/APL/#json-structure_18","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearCard\" } } }","title":"JSON Structure"},{"location":"aasb/apl/APL/#enums","text":"","title":"Enums"},{"location":"aasb/apl/APL/#activityevent","text":"","title":"ActivityEvent"},{"location":"aasb/apl/APL/#values","text":"Value Description \"ACTIVATED\" GUI switched to active state. \"DEACTIVATED\" GUI become inactive. \"ONE_TIME\" GUI processed one-time event (touch/scroll/etc). \"INTERRUPT\" Interrupt event (touch). \"UNKNOWN\" Guard option for unknown received state.","title":"Values"},{"location":"aasb/car-control/CarControl/","text":"CarControl \u00b6 Outgoing Messages \u00b6 AdjustControllerValue \u00b6 Adjusts the range setting identified by endpointId and instanceId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": \"RANGE\", \"capabilityType\": \"RANGE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{double}} } } Payload \u00b6 Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta double Yes The delta by which to adjust the range setting. AdjustControllerValue \u00b6 Adjusts the mode of the setting identified by endpointId and instanceId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": \"MODE\", \"capabilityType\": \"MODE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{Int}} } } Payload \u00b6 Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta Int Yes The delta by which to adjust the mode. AdjustControllerValue \u00b6 JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } } } SetControllerValue \u00b6 Sets the power state of the endpoint identified by endpointId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"POWER\", \"capabilityType\": \"POWER\", \"endpointId\": {{String}}, \"turnOn\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. turnOn Bool Yes The power setting. True to turn on the endpoint or False to turn off. SetControllerValue \u00b6 Sets the range setting identified by endpointId and instanceId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"RANGE\", \"capabilityType\": \"RANGE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{double}} } } Payload \u00b6 Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value double Yes The new range setting. SetControllerValue \u00b6 Sets the toggle state of the setting identified by endpointId and instanceId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"TOGGLE\", \"capabilityType\": \"TOGGLE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"turnOn\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. turnOn Bool Yes The power state of the setting. True to turn on the setting or False to turn off. SetControllerValue \u00b6 Sets the mode of the setting identified by endpointId and instanceId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"MODE\", \"capabilityType\": \"MODE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{String}} } } Payload \u00b6 Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value String Yes The new mode to set. SetControllerValue \u00b6 JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } } } Incoming Messages \u00b6 AdjustControllerValueReply \u00b6 Reply for AdjustControllerValue message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted. Failure to send the asynchronous reply message within 5 seconds results in a timeout. SetControllerValueReply \u00b6 Reply for SetControllerValue message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"CarControl"},{"location":"aasb/car-control/CarControl/#carcontrol","text":"","title":"CarControl"},{"location":"aasb/car-control/CarControl/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/car-control/CarControl/#adjustcontrollervalue","text":"Adjusts the range setting identified by endpointId and instanceId.","title":"AdjustControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": \"RANGE\", \"capabilityType\": \"RANGE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{double}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta double Yes The delta by which to adjust the range setting.","title":"Payload"},{"location":"aasb/car-control/CarControl/#adjustcontrollervalue_1","text":"Adjusts the mode of the setting identified by endpointId and instanceId.","title":"AdjustControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": \"MODE\", \"capabilityType\": \"MODE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_1","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta Int Yes The delta by which to adjust the mode.","title":"Payload"},{"location":"aasb/car-control/CarControl/#adjustcontrollervalue_2","text":"","title":"AdjustControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#setcontrollervalue","text":"Sets the power state of the endpoint identified by endpointId.","title":"SetControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"POWER\", \"capabilityType\": \"POWER\", \"endpointId\": {{String}}, \"turnOn\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_2","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. turnOn Bool Yes The power setting. True to turn on the endpoint or False to turn off.","title":"Payload"},{"location":"aasb/car-control/CarControl/#setcontrollervalue_1","text":"Sets the range setting identified by endpointId and instanceId.","title":"SetControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"RANGE\", \"capabilityType\": \"RANGE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{double}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_3","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value double Yes The new range setting.","title":"Payload"},{"location":"aasb/car-control/CarControl/#setcontrollervalue_2","text":"Sets the toggle state of the setting identified by endpointId and instanceId.","title":"SetControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"TOGGLE\", \"capabilityType\": \"TOGGLE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"turnOn\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_4","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. turnOn Bool Yes The power state of the setting. True to turn on the setting or False to turn off.","title":"Payload"},{"location":"aasb/car-control/CarControl/#setcontrollervalue_3","text":"Sets the mode of the setting identified by endpointId and instanceId.","title":"SetControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": \"MODE\", \"capabilityType\": \"MODE\", \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_5","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value String Yes The new mode to set.","title":"Payload"},{"location":"aasb/car-control/CarControl/#setcontrollervalue_4","text":"","title":"SetControllerValue"},{"location":"aasb/car-control/CarControl/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/car-control/CarControl/#adjustcontrollervaluereply","text":"Reply for AdjustControllerValue message.","title":"AdjustControllerValueReply"},{"location":"aasb/car-control/CarControl/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_6","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"Payload"},{"location":"aasb/car-control/CarControl/#setcontrollervaluereply","text":"Reply for SetControllerValue message.","title":"SetControllerValueReply"},{"location":"aasb/car-control/CarControl/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/car-control/CarControl/#payload_7","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"Payload"},{"location":"aasb/cbl/CBL/","text":"CBL \u00b6 Outgoing Messages \u00b6 CBLStateChanged \u00b6 (Deprecated) Notifies the platform implementation of an authorization flow state change. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"CBLStateChanged\" } }, \"payload\": { \"state\": {{CBLState}}, \"reason\": {{CBLStateChangedReason}}, \"url\": {{String}}, \"code\": {{String}} } } Payload \u00b6 Property Type Required Description Example state CBLState Yes State of the CBL Authorization flow. reason CBLStateChangedReason Yes The state change reason. url String Yes The localeized url to enter the CBL code. code String Yes The CBL code. ClearRefreshToken \u00b6 (Deprecated) Notifies the platform implementation to clear the refresh token. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"ClearRefreshToken\" } } } SetRefreshToken \u00b6 (Deprecated) Notifies the platform implemnentation to set the refresh token. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetRefreshToken\" } }, \"payload\": { \"refreshToken\": {{String}} } } Payload \u00b6 Property Type Required Description Example refreshToken String Yes The refresh token. GetRefreshToken \u00b6 (Deprecated) Returns the refresh token stored by the platform implementation, otherwise return an empty string. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\" } } } SetUserProfile \u00b6 (Deprecated) Notifies the platform implementation about the user profile. This is notified only when requestUserProfile is enabled in the configuration. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetUserProfile\" } }, \"payload\": { \"name\": {{String}}, \"email\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes The logged in user name. email String Yes The logged in user email. Incoming Messages \u00b6 Start \u00b6 (Deprecated) Notifies the Engine to cancel the authorization process. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Start\" } } } Cancel \u00b6 (Deprecated) Notifies the Engine to cancel the authorization process. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Cancel\" } } } Reset \u00b6 (Deprecated) Notifies the Engine to reset the authorization state. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Reset\" } } } GetRefreshTokenReply \u00b6 Reply for GetRefreshToken message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\", \"replyToId\": {{String}} } }, \"payload\": { \"refreshToken\": {{String}} } } Payload \u00b6 Property Type Required Description Example refreshToken String Yes The refresh token. Enums \u00b6 CBLState \u00b6 Specifies the state of the authorization flow. Values \u00b6 Value Description \"STARTING\" CBL process is starting. \"REQUESTING_CODE_PAIR\" Initiating the process to request a code pair. \"CODE_PAIR_RECEIVED\" Code pair is received and is waiting on user to authenticate. \"REFRESHING_TOKEN\" Refreshing token stage has begun. \"REQUESTING_TOKEN\" Requesting for authorization token. \"STOPPING\" CBL process is ending. CBLStateChangedReason \u00b6 Specifies the reason for the state change. Values \u00b6 Value Description \"SUCCESS\" The CBL state changed successfully. \"ERROR\" Error occurred in the CBL process. \"TIMEOUT\" Request timed out. \"CODE_PAIR_EXPIRED\" Code pair has expired and user will need to initiate the authentication process again. \"AUTHORIZATION_EXPIRED\" The refresh token is invalid, revoked, or was issued to a different client. \"NONE\" No reason specified.","title":"CBL"},{"location":"aasb/cbl/CBL/#cbl","text":"","title":"CBL"},{"location":"aasb/cbl/CBL/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/cbl/CBL/#cblstatechanged","text":"(Deprecated) Notifies the platform implementation of an authorization flow state change.","title":"CBLStateChanged"},{"location":"aasb/cbl/CBL/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"CBLStateChanged\" } }, \"payload\": { \"state\": {{CBLState}}, \"reason\": {{CBLStateChangedReason}}, \"url\": {{String}}, \"code\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#payload","text":"Property Type Required Description Example state CBLState Yes State of the CBL Authorization flow. reason CBLStateChangedReason Yes The state change reason. url String Yes The localeized url to enter the CBL code. code String Yes The CBL code.","title":"Payload"},{"location":"aasb/cbl/CBL/#clearrefreshtoken","text":"(Deprecated) Notifies the platform implementation to clear the refresh token.","title":"ClearRefreshToken"},{"location":"aasb/cbl/CBL/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"ClearRefreshToken\" } } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#setrefreshtoken","text":"(Deprecated) Notifies the platform implemnentation to set the refresh token.","title":"SetRefreshToken"},{"location":"aasb/cbl/CBL/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetRefreshToken\" } }, \"payload\": { \"refreshToken\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#payload_1","text":"Property Type Required Description Example refreshToken String Yes The refresh token.","title":"Payload"},{"location":"aasb/cbl/CBL/#getrefreshtoken","text":"(Deprecated) Returns the refresh token stored by the platform implementation, otherwise return an empty string.","title":"GetRefreshToken"},{"location":"aasb/cbl/CBL/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\" } } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#setuserprofile","text":"(Deprecated) Notifies the platform implementation about the user profile. This is notified only when requestUserProfile is enabled in the configuration.","title":"SetUserProfile"},{"location":"aasb/cbl/CBL/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetUserProfile\" } }, \"payload\": { \"name\": {{String}}, \"email\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#payload_2","text":"Property Type Required Description Example name String Yes The logged in user name. email String Yes The logged in user email.","title":"Payload"},{"location":"aasb/cbl/CBL/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/cbl/CBL/#start","text":"(Deprecated) Notifies the Engine to cancel the authorization process.","title":"Start"},{"location":"aasb/cbl/CBL/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Start\" } } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#cancel","text":"(Deprecated) Notifies the Engine to cancel the authorization process.","title":"Cancel"},{"location":"aasb/cbl/CBL/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Cancel\" } } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#reset","text":"(Deprecated) Notifies the Engine to reset the authorization state.","title":"Reset"},{"location":"aasb/cbl/CBL/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Reset\" } } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#getrefreshtokenreply","text":"Reply for GetRefreshToken message.","title":"GetRefreshTokenReply"},{"location":"aasb/cbl/CBL/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\", \"replyToId\": {{String}} } }, \"payload\": { \"refreshToken\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/cbl/CBL/#payload_3","text":"Property Type Required Description Example refreshToken String Yes The refresh token.","title":"Payload"},{"location":"aasb/cbl/CBL/#enums","text":"","title":"Enums"},{"location":"aasb/cbl/CBL/#cblstate","text":"Specifies the state of the authorization flow.","title":"CBLState"},{"location":"aasb/cbl/CBL/#values","text":"Value Description \"STARTING\" CBL process is starting. \"REQUESTING_CODE_PAIR\" Initiating the process to request a code pair. \"CODE_PAIR_RECEIVED\" Code pair is received and is waiting on user to authenticate. \"REFRESHING_TOKEN\" Refreshing token stage has begun. \"REQUESTING_TOKEN\" Requesting for authorization token. \"STOPPING\" CBL process is ending.","title":"Values"},{"location":"aasb/cbl/CBL/#cblstatechangedreason","text":"Specifies the reason for the state change.","title":"CBLStateChangedReason"},{"location":"aasb/cbl/CBL/#values_1","text":"Value Description \"SUCCESS\" The CBL state changed successfully. \"ERROR\" Error occurred in the CBL process. \"TIMEOUT\" Request timed out. \"CODE_PAIR_EXPIRED\" Code pair has expired and user will need to initiate the authentication process again. \"AUTHORIZATION_EXPIRED\" The refresh token is invalid, revoked, or was issued to a different client. \"NONE\" No reason specified.","title":"Values"},{"location":"aasb/connectivity/AlexaConnectivity/","text":"AlexaConnectivity \u00b6 Outgoing Messages \u00b6 GetConnectivityState \u00b6 Retrieve the connectivity state from the platform implementation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\" } } } GetIdentifier \u00b6 Retrieve the identifier from the platform implementation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\" } } } ConnectivityStateChangeReply \u00b6 Reply for ConnectivityStateChange message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example success Bool Yes Returns true if connectivity state was processed successfully, false otherwise. SendConnectivityEventReply \u00b6 Reply for SendConnectivityEvent message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\", \"replyToId\": {{String}} } }, \"payload\": { \"statusCode\": {{StatusCode}} } } Payload \u00b6 Property Type Required Description Example statusCode StatusCode Yes Represents the delivery status of event. Incoming Messages \u00b6 ConnectivityStateChange \u00b6 Notifies the Engine of a change in the connectivity state. The Engine calls getConnectivityState to retrieve the the connectivity state and communicate any changes to Alexa. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\" } } } SendConnectivityEvent \u00b6 Notifies an event in the connectivity to the Engine. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\" } }, \"payload\": { \"event\": {{String}} } } Payload \u00b6 Property Type Required Description Example event String Yes The stringified JSON containing the event. GetConnectivityStateReply \u00b6 Reply for GetConnectivityState message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\", \"replyToId\": {{String}} } }, \"payload\": { \"connectivityState\": {{String}} } } Payload \u00b6 Property Type Required Description Example connectivityState String Yes A string representing the connectivity state in structured JSON format. GetIdentifierReply \u00b6 Reply for GetIdentifier message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\", \"replyToId\": {{String}} } }, \"payload\": { \"identifier\": {{String}} } } Payload \u00b6 Property Type Required Description Example identifier String Yes A string representing the identifier. Enums \u00b6 StatusCode \u00b6 Values \u00b6 Value Description \"SUCCESS\" The event was sent to AVS successfully. \"FAIL\" The event was not sent to AVS successfully.","title":"AlexaConnectivity"},{"location":"aasb/connectivity/AlexaConnectivity/#alexaconnectivity","text":"","title":"AlexaConnectivity"},{"location":"aasb/connectivity/AlexaConnectivity/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/connectivity/AlexaConnectivity/#getconnectivitystate","text":"Retrieve the connectivity state from the platform implementation.","title":"GetConnectivityState"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\" } } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#getidentifier","text":"Retrieve the identifier from the platform implementation.","title":"GetIdentifier"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\" } } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#connectivitystatechangereply","text":"Reply for ConnectivityStateChange message.","title":"ConnectivityStateChangeReply"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#payload","text":"Property Type Required Description Example success Bool Yes Returns true if connectivity state was processed successfully, false otherwise.","title":"Payload"},{"location":"aasb/connectivity/AlexaConnectivity/#sendconnectivityeventreply","text":"Reply for SendConnectivityEvent message.","title":"SendConnectivityEventReply"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\", \"replyToId\": {{String}} } }, \"payload\": { \"statusCode\": {{StatusCode}} } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_1","text":"Property Type Required Description Example statusCode StatusCode Yes Represents the delivery status of event.","title":"Payload"},{"location":"aasb/connectivity/AlexaConnectivity/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/connectivity/AlexaConnectivity/#connectivitystatechange","text":"Notifies the Engine of a change in the connectivity state. The Engine calls getConnectivityState to retrieve the the connectivity state and communicate any changes to Alexa.","title":"ConnectivityStateChange"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\" } } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#sendconnectivityevent","text":"Notifies an event in the connectivity to the Engine.","title":"SendConnectivityEvent"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\" } }, \"payload\": { \"event\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_2","text":"Property Type Required Description Example event String Yes The stringified JSON containing the event.","title":"Payload"},{"location":"aasb/connectivity/AlexaConnectivity/#getconnectivitystatereply","text":"Reply for GetConnectivityState message.","title":"GetConnectivityStateReply"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\", \"replyToId\": {{String}} } }, \"payload\": { \"connectivityState\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_3","text":"Property Type Required Description Example connectivityState String Yes A string representing the connectivity state in structured JSON format.","title":"Payload"},{"location":"aasb/connectivity/AlexaConnectivity/#getidentifierreply","text":"Reply for GetIdentifier message.","title":"GetIdentifierReply"},{"location":"aasb/connectivity/AlexaConnectivity/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\", \"replyToId\": {{String}} } }, \"payload\": { \"identifier\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/connectivity/AlexaConnectivity/#payload_4","text":"Property Type Required Description Example identifier String Yes A string representing the identifier.","title":"Payload"},{"location":"aasb/connectivity/AlexaConnectivity/#enums","text":"","title":"Enums"},{"location":"aasb/connectivity/AlexaConnectivity/#statuscode","text":"","title":"StatusCode"},{"location":"aasb/connectivity/AlexaConnectivity/#values","text":"Value Description \"SUCCESS\" The event was sent to AVS successfully. \"FAIL\" The event was not sent to AVS successfully.","title":"Values"},{"location":"aasb/core/AudioInput/","text":"AudioInput \u00b6 Outgoing Messages \u00b6 StopAudioInput \u00b6 Notifies the platform implementation to stop writing audio samples to the Engine. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StopAudioInput\" } }, \"payload\": { \"streamId\": {{String}} } } Payload \u00b6 Property Type Required Description Example streamId String Yes Stream ID that is used to write audio data to. 4f52d5a6-2b36-4723-93d5-4e569be99961 StartAudioInput \u00b6 Notifies the platform implementation to start writing audio samples to the Engine. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StartAudioInput\" } }, \"payload\": { \"name\": {{String}}, \"audioType\": {{AudioInputAudioType}}, \"streamId\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes Name of the Engine component that is requesting audio. audioType AudioInputAudioType Yes The type of audio data being requested. streamId String Yes Stream ID that is used to write audio data to. Enums \u00b6 AudioInputAudioType \u00b6 Values \u00b6 Value Description \"VOICE\" Voice audio type. \"COMMUNICATION\" Communication audio type. \"LOOPBACK\" Loopback audio type.","title":"AudioInput"},{"location":"aasb/core/AudioInput/#audioinput","text":"","title":"AudioInput"},{"location":"aasb/core/AudioInput/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/core/AudioInput/#stopaudioinput","text":"Notifies the platform implementation to stop writing audio samples to the Engine.","title":"StopAudioInput"},{"location":"aasb/core/AudioInput/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StopAudioInput\" } }, \"payload\": { \"streamId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioInput/#payload","text":"Property Type Required Description Example streamId String Yes Stream ID that is used to write audio data to. 4f52d5a6-2b36-4723-93d5-4e569be99961","title":"Payload"},{"location":"aasb/core/AudioInput/#startaudioinput","text":"Notifies the platform implementation to start writing audio samples to the Engine.","title":"StartAudioInput"},{"location":"aasb/core/AudioInput/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StartAudioInput\" } }, \"payload\": { \"name\": {{String}}, \"audioType\": {{AudioInputAudioType}}, \"streamId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioInput/#payload_1","text":"Property Type Required Description Example name String Yes Name of the Engine component that is requesting audio. audioType AudioInputAudioType Yes The type of audio data being requested. streamId String Yes Stream ID that is used to write audio data to.","title":"Payload"},{"location":"aasb/core/AudioInput/#enums","text":"","title":"Enums"},{"location":"aasb/core/AudioInput/#audioinputaudiotype","text":"","title":"AudioInputAudioType"},{"location":"aasb/core/AudioInput/#values","text":"Value Description \"VOICE\" Voice audio type. \"COMMUNICATION\" Communication audio type. \"LOOPBACK\" Loopback audio type.","title":"Values"},{"location":"aasb/core/AudioOutput/","text":"AudioOutput \u00b6 Outgoing Messages \u00b6 GetNumBytesBuffered \u00b6 Returns the amount of audio data buffered. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Resume \u00b6 Notifies the platform implementation to resume an audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Resume\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Play \u00b6 Notifies the platform implementation to play an audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Play\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being played. SetPosition \u00b6 Notifies the platform implementation to set the playback position of the current audio source in the platform media player. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"SetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"position\": {{Int}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. position Int Yes The playback position in milliseconds to set in the platform media player. Prepare \u00b6 Notifies the platform implementation to prepare an audio URL for playback. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": \"URL\", \"url\": {{String}}, \"repeating\": {{Bool}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio source. source String Yes Stream source description. url String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. GetPosition \u00b6 Returns the current playback position of the platform media player. If the audio source is not playing, the most recent position played should be returned. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Pause \u00b6 Notifies the platform implementation to pause an audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Pause\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being paused. GetDuration \u00b6 Request the duration of the current audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Stop \u00b6 Notifies the platform implementation to stop an audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Stop\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Prepare \u00b6 Notifies the platform implementation to prepare an audio stream for playback. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": \"STREAM\", \"streamId\": {{String}}, \"repeating\": {{Bool}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio stream. source String Yes Stream source description. streamId String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. MutedStateChanged \u00b6 Notifies the platform implementation that the muted state has changed for an audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"state\": {{MutedState}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. state MutedState Yes The muted state to apply to the audio source. VolumeChanged \u00b6 Notifies the platform implementation that the volume has changed for an audio source. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"channel\": {{String}}, \"volume\": {{Float}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. volume Float Yes The volume to set on the audio source. The volume is in the range [0,1]. MayDuck \u00b6 Notifies the platform implementation only if prepared media may duck the volume. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MayDuck\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. StartDucking \u00b6 Notifies the platform implementation to move the playback in background. If platform implementation supports audio ducking, reduce the media player volume according to platform guidelines. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StartDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. StopDucking \u00b6 Notifies the platform implementation to move the playback in foreground. If platform implementation supports audio ducking, restore the media player volume to original value. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StopDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Incoming Messages \u00b6 MediaError \u00b6 Notifies the Engine of an error during audio playback. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaError\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"error\": {{MediaError}}, \"description\": {{String}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. error MediaError Yes The error encountered by the platform media player during playback. description String No A description of the error. MediaStateChanged \u00b6 Notifies the Engine of an audio playback state change in the platform implementation. Must be called when the platform media player transitions between stopped and playing states. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"state\": {{MediaState}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. state MediaState Yes The new playback state of the platform media player. AudioFocusEvent \u00b6 Report the engine about the Audio Focus action. Request engine to perform the action mentioned in the parameter. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"AudioFocusEvent\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"focusAction\": {{FocusAction}} } } Payload \u00b6 Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. focusAction FocusAction Yes Report the engine what focus action client has taken due to the external audio focus event. GetNumBytesBufferedReply \u00b6 Reply for GetNumBytesBuffered message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\", \"replyToId\": {{String}} } }, \"payload\": { \"bufferedBytes\": {{Int}} } } Payload \u00b6 Property Type Required Description Example bufferedBytes Int Yes The number of bytes of the audio data buffered, or 0 if it's unknown. GetPositionReply \u00b6 Reply for GetPosition message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"position\": {{Int}} } } Payload \u00b6 Property Type Required Description Example position Int Yes The platform media player's playback position in milliseconds. GetDurationReply \u00b6 Reply for GetDuration message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"duration\": {{Int}} } } Payload \u00b6 Property Type Required Description Example duration Int Yes The duration of the current audio source. If the duration is unknown, then -1 should be returned. Type Definitions \u00b6 AudioStreamProperty \u00b6 JSON Structure \u00b6 { \"name\": {{String}}, \"value\": {{String}} } Properties \u00b6 Property Type Required Description Example name String Yes Stream property name. value String Yes Stream property value. Enums \u00b6 MediaState \u00b6 Values \u00b6 Value Description \"STOPPED\" The audio source is not currently playing. It may have paused, stopped, or finished. \"PLAYING\" The audio source is currently playing. \"BUFFERING\" The audio source is currently buffering data. MediaError \u00b6 Values \u00b6 Value Description \"MEDIA_ERROR_UNKNOWN\" An unknown error occurred. \"MEDIA_ERROR_INVALID_REQUEST\" The server recognized the request as malformed (e.g. bad request, unauthorized, forbidden, not found, etc). \"MEDIA_ERROR_SERVICE_UNAVAILABLE\" The client was unable to reach the service. \"MEDIA_ERROR_INTERNAL_SERVER_ERROR\" The server accepted the request but was unable to process it as expected. \"MEDIA_ERROR_INTERNAL_DEVICE_ERROR\" There was an internal error on the client. AudioOutputAudioType \u00b6 Values \u00b6 Value Description \"TTS\" Text-to-Speech audio type. \"MUSIC\" Music audio type. \"NOTIFICATION\" Notification audio type. \"ALARM\" Alarm audio type. \"EARCON\" Earcon audio type. \"COMMUNICATION\" Communication audio type. \"RINGTONE\" Ringtone audio type. AudioStreamEncoding \u00b6 Values \u00b6 Value Description \"UNKNOWN\" Unknown encoding type. \"LPCM\" LPCM encoding type. \"MP3\" MP3 encoding type. \"OPUS\" Opus encoding type. MutedState \u00b6 Values \u00b6 Value Description \"MUTED\" Muted audio state. \"UNMUTED\" Unmuted audio state. AudioOutputSourceType \u00b6 Values \u00b6 Value Description \"URI\" URI source type. \"STREAM\" Stream audio type. FocusAction \u00b6 Values \u00b6 Value Description \"REPORT_DUCKING_STARTED\" This action informs Alexa engine that ducking is initiated by platform interface. Highly recommended to provide information so that engine would not override the action. \"REPORT_DUCKING_STOPPED\" This action informs Alexa engine that ducking is stopped by platform interface. Highly recommended to provide information so that engine can duck if required.","title":"AudioOutput"},{"location":"aasb/core/AudioOutput/#audiooutput","text":"","title":"AudioOutput"},{"location":"aasb/core/AudioOutput/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/core/AudioOutput/#getnumbytesbuffered","text":"Returns the amount of audio data buffered.","title":"GetNumBytesBuffered"},{"location":"aasb/core/AudioOutput/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#resume","text":"Notifies the platform implementation to resume an audio source.","title":"Resume"},{"location":"aasb/core/AudioOutput/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Resume\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_1","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#play","text":"Notifies the platform implementation to play an audio source.","title":"Play"},{"location":"aasb/core/AudioOutput/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Play\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_2","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being played.","title":"Payload"},{"location":"aasb/core/AudioOutput/#setposition","text":"Notifies the platform implementation to set the playback position of the current audio source in the platform media player.","title":"SetPosition"},{"location":"aasb/core/AudioOutput/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"SetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"position\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_3","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. position Int Yes The playback position in milliseconds to set in the platform media player.","title":"Payload"},{"location":"aasb/core/AudioOutput/#prepare","text":"Notifies the platform implementation to prepare an audio URL for playback.","title":"Prepare"},{"location":"aasb/core/AudioOutput/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": \"URL\", \"url\": {{String}}, \"repeating\": {{Bool}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_4","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio source. source String Yes Stream source description. url String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing.","title":"Payload"},{"location":"aasb/core/AudioOutput/#getposition","text":"Returns the current playback position of the platform media player. If the audio source is not playing, the most recent position played should be returned.","title":"GetPosition"},{"location":"aasb/core/AudioOutput/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_5","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#pause","text":"Notifies the platform implementation to pause an audio source.","title":"Pause"},{"location":"aasb/core/AudioOutput/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Pause\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_6","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being paused.","title":"Payload"},{"location":"aasb/core/AudioOutput/#getduration","text":"Request the duration of the current audio source.","title":"GetDuration"},{"location":"aasb/core/AudioOutput/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_7","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#stop","text":"Notifies the platform implementation to stop an audio source.","title":"Stop"},{"location":"aasb/core/AudioOutput/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Stop\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_8","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#prepare_1","text":"Notifies the platform implementation to prepare an audio stream for playback.","title":"Prepare"},{"location":"aasb/core/AudioOutput/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": \"STREAM\", \"streamId\": {{String}}, \"repeating\": {{Bool}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_9","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio stream. source String Yes Stream source description. streamId String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream.","title":"Payload"},{"location":"aasb/core/AudioOutput/#mutedstatechanged","text":"Notifies the platform implementation that the muted state has changed for an audio source.","title":"MutedStateChanged"},{"location":"aasb/core/AudioOutput/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"state\": {{MutedState}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_10","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. state MutedState Yes The muted state to apply to the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#volumechanged","text":"Notifies the platform implementation that the volume has changed for an audio source.","title":"VolumeChanged"},{"location":"aasb/core/AudioOutput/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"channel\": {{String}}, \"volume\": {{Float}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_11","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. volume Float Yes The volume to set on the audio source. The volume is in the range [0,1].","title":"Payload"},{"location":"aasb/core/AudioOutput/#mayduck","text":"Notifies the platform implementation only if prepared media may duck the volume.","title":"MayDuck"},{"location":"aasb/core/AudioOutput/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MayDuck\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_12","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#startducking","text":"Notifies the platform implementation to move the playback in background. If platform implementation supports audio ducking, reduce the media player volume according to platform guidelines.","title":"StartDucking"},{"location":"aasb/core/AudioOutput/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StartDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_13","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#stopducking","text":"Notifies the platform implementation to move the playback in foreground. If platform implementation supports audio ducking, restore the media player volume to original value.","title":"StopDucking"},{"location":"aasb/core/AudioOutput/#json-structure_14","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StopDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_14","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"aasb/core/AudioOutput/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/core/AudioOutput/#mediaerror","text":"Notifies the Engine of an error during audio playback.","title":"MediaError"},{"location":"aasb/core/AudioOutput/#json-structure_15","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaError\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"error\": {{MediaError}}, \"description\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_15","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. error MediaError Yes The error encountered by the platform media player during playback. description String No A description of the error.","title":"Payload"},{"location":"aasb/core/AudioOutput/#mediastatechanged","text":"Notifies the Engine of an audio playback state change in the platform implementation. Must be called when the platform media player transitions between stopped and playing states.","title":"MediaStateChanged"},{"location":"aasb/core/AudioOutput/#json-structure_16","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"state\": {{MediaState}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_16","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. state MediaState Yes The new playback state of the platform media player.","title":"Payload"},{"location":"aasb/core/AudioOutput/#audiofocusevent","text":"Report the engine about the Audio Focus action. Request engine to perform the action mentioned in the parameter.","title":"AudioFocusEvent"},{"location":"aasb/core/AudioOutput/#json-structure_17","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"AudioFocusEvent\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"focusAction\": {{FocusAction}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_17","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. focusAction FocusAction Yes Report the engine what focus action client has taken due to the external audio focus event.","title":"Payload"},{"location":"aasb/core/AudioOutput/#getnumbytesbufferedreply","text":"Reply for GetNumBytesBuffered message.","title":"GetNumBytesBufferedReply"},{"location":"aasb/core/AudioOutput/#json-structure_18","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\", \"replyToId\": {{String}} } }, \"payload\": { \"bufferedBytes\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_18","text":"Property Type Required Description Example bufferedBytes Int Yes The number of bytes of the audio data buffered, or 0 if it's unknown.","title":"Payload"},{"location":"aasb/core/AudioOutput/#getpositionreply","text":"Reply for GetPosition message.","title":"GetPositionReply"},{"location":"aasb/core/AudioOutput/#json-structure_19","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"position\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_19","text":"Property Type Required Description Example position Int Yes The platform media player's playback position in milliseconds.","title":"Payload"},{"location":"aasb/core/AudioOutput/#getdurationreply","text":"Reply for GetDuration message.","title":"GetDurationReply"},{"location":"aasb/core/AudioOutput/#json-structure_20","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"duration\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#payload_20","text":"Property Type Required Description Example duration Int Yes The duration of the current audio source. If the duration is unknown, then -1 should be returned.","title":"Payload"},{"location":"aasb/core/AudioOutput/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/core/AudioOutput/#audiostreamproperty","text":"","title":"AudioStreamProperty"},{"location":"aasb/core/AudioOutput/#json-structure_21","text":"{ \"name\": {{String}}, \"value\": {{String}} }","title":"JSON Structure"},{"location":"aasb/core/AudioOutput/#properties","text":"Property Type Required Description Example name String Yes Stream property name. value String Yes Stream property value.","title":"Properties"},{"location":"aasb/core/AudioOutput/#enums","text":"","title":"Enums"},{"location":"aasb/core/AudioOutput/#mediastate","text":"","title":"MediaState"},{"location":"aasb/core/AudioOutput/#values","text":"Value Description \"STOPPED\" The audio source is not currently playing. It may have paused, stopped, or finished. \"PLAYING\" The audio source is currently playing. \"BUFFERING\" The audio source is currently buffering data.","title":"Values"},{"location":"aasb/core/AudioOutput/#mediaerror_1","text":"","title":"MediaError"},{"location":"aasb/core/AudioOutput/#values_1","text":"Value Description \"MEDIA_ERROR_UNKNOWN\" An unknown error occurred. \"MEDIA_ERROR_INVALID_REQUEST\" The server recognized the request as malformed (e.g. bad request, unauthorized, forbidden, not found, etc). \"MEDIA_ERROR_SERVICE_UNAVAILABLE\" The client was unable to reach the service. \"MEDIA_ERROR_INTERNAL_SERVER_ERROR\" The server accepted the request but was unable to process it as expected. \"MEDIA_ERROR_INTERNAL_DEVICE_ERROR\" There was an internal error on the client.","title":"Values"},{"location":"aasb/core/AudioOutput/#audiooutputaudiotype","text":"","title":"AudioOutputAudioType"},{"location":"aasb/core/AudioOutput/#values_2","text":"Value Description \"TTS\" Text-to-Speech audio type. \"MUSIC\" Music audio type. \"NOTIFICATION\" Notification audio type. \"ALARM\" Alarm audio type. \"EARCON\" Earcon audio type. \"COMMUNICATION\" Communication audio type. \"RINGTONE\" Ringtone audio type.","title":"Values"},{"location":"aasb/core/AudioOutput/#audiostreamencoding","text":"","title":"AudioStreamEncoding"},{"location":"aasb/core/AudioOutput/#values_3","text":"Value Description \"UNKNOWN\" Unknown encoding type. \"LPCM\" LPCM encoding type. \"MP3\" MP3 encoding type. \"OPUS\" Opus encoding type.","title":"Values"},{"location":"aasb/core/AudioOutput/#mutedstate","text":"","title":"MutedState"},{"location":"aasb/core/AudioOutput/#values_4","text":"Value Description \"MUTED\" Muted audio state. \"UNMUTED\" Unmuted audio state.","title":"Values"},{"location":"aasb/core/AudioOutput/#audiooutputsourcetype","text":"","title":"AudioOutputSourceType"},{"location":"aasb/core/AudioOutput/#values_5","text":"Value Description \"URI\" URI source type. \"STREAM\" Stream audio type.","title":"Values"},{"location":"aasb/core/AudioOutput/#focusaction","text":"","title":"FocusAction"},{"location":"aasb/core/AudioOutput/#values_6","text":"Value Description \"REPORT_DUCKING_STARTED\" This action informs Alexa engine that ducking is initiated by platform interface. Highly recommended to provide information so that engine would not override the action. \"REPORT_DUCKING_STOPPED\" This action informs Alexa engine that ducking is stopped by platform interface. Highly recommended to provide information so that engine can duck if required.","title":"Values"},{"location":"aasb/core/Authorization/","text":"Authorization \u00b6 Outgoing Messages \u00b6 GetAuthorizationData \u00b6 Get the authorization data from the platform implementation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. AuthorizationError \u00b6 Notifies the platform implementation of an authorization error. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationError\" } }, \"payload\": { \"service\": {{String}}, \"error\": {{String}}, \"message\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. error String Yes The authorization error that occurred. message String Yes The message describing the authorization error. SetAuthorizationData \u00b6 Notifies the platform implementation to store authorization data. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}}, \"data\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. data String Yes The value of the data. EventReceived \u00b6 Notifies the platform implementation of a received authorization event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"EventReceived\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the received event. AuthorizationStateChanged \u00b6 Notifies the platform implementation that the authorization state changed. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" } }, \"payload\": { \"service\": {{String}}, \"state\": {{AuthorizationState}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. state AuthorizationState Yes The new authorization state. Incoming Messages \u00b6 SendEvent \u00b6 Notifies the Engine of an authorization event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SendEvent\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the payload of the event. CancelAuthorization \u00b6 Notifies the Engine to cancel the authorization process. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"CancelAuthorization\" } }, \"payload\": { \"service\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. Logout \u00b6 Notifies the Engine that device has been logged out. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"Logout\" } }, \"payload\": { \"service\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. StartAuthorization \u00b6 Notifies the Engine to start the authorization process. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"StartAuthorization\" } }, \"payload\": { \"service\": {{String}}, \"data\": {{String}} } } Payload \u00b6 Property Type Required Description Example service String Yes The service used for authorization. data String Yes The value of the data. GetAuthorizationDataReply \u00b6 Reply for GetAuthorizationData message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\", \"replyToId\": {{String}} } }, \"payload\": { \"data\": {{String}} } } Payload \u00b6 Property Type Required Description Example data String Yes The data associated with the key if available, otherwise an empty string. Enums \u00b6 AuthorizationState \u00b6 Values \u00b6 Value Description \"UNAUTHORIZED\" Device is unauthorized. \"AUTHORIZING\" Device authorization is in progress. \"AUTHORIZED\" Device is authorized.","title":"Authorization"},{"location":"aasb/core/Authorization/#authorization","text":"","title":"Authorization"},{"location":"aasb/core/Authorization/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/core/Authorization/#getauthorizationdata","text":"Get the authorization data from the platform implementation.","title":"GetAuthorizationData"},{"location":"aasb/core/Authorization/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload","text":"Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data.","title":"Payload"},{"location":"aasb/core/Authorization/#authorizationerror","text":"Notifies the platform implementation of an authorization error.","title":"AuthorizationError"},{"location":"aasb/core/Authorization/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationError\" } }, \"payload\": { \"service\": {{String}}, \"error\": {{String}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_1","text":"Property Type Required Description Example service String Yes The service used for authorization. error String Yes The authorization error that occurred. message String Yes The message describing the authorization error.","title":"Payload"},{"location":"aasb/core/Authorization/#setauthorizationdata","text":"Notifies the platform implementation to store authorization data.","title":"SetAuthorizationData"},{"location":"aasb/core/Authorization/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}}, \"data\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_2","text":"Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. data String Yes The value of the data.","title":"Payload"},{"location":"aasb/core/Authorization/#eventreceived","text":"Notifies the platform implementation of a received authorization event.","title":"EventReceived"},{"location":"aasb/core/Authorization/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"EventReceived\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_3","text":"Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the received event.","title":"Payload"},{"location":"aasb/core/Authorization/#authorizationstatechanged","text":"Notifies the platform implementation that the authorization state changed.","title":"AuthorizationStateChanged"},{"location":"aasb/core/Authorization/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" } }, \"payload\": { \"service\": {{String}}, \"state\": {{AuthorizationState}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_4","text":"Property Type Required Description Example service String Yes The service used for authorization. state AuthorizationState Yes The new authorization state.","title":"Payload"},{"location":"aasb/core/Authorization/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/core/Authorization/#sendevent","text":"Notifies the Engine of an authorization event.","title":"SendEvent"},{"location":"aasb/core/Authorization/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SendEvent\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_5","text":"Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the payload of the event.","title":"Payload"},{"location":"aasb/core/Authorization/#cancelauthorization","text":"Notifies the Engine to cancel the authorization process.","title":"CancelAuthorization"},{"location":"aasb/core/Authorization/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"CancelAuthorization\" } }, \"payload\": { \"service\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_6","text":"Property Type Required Description Example service String Yes The service used for authorization.","title":"Payload"},{"location":"aasb/core/Authorization/#logout","text":"Notifies the Engine that device has been logged out.","title":"Logout"},{"location":"aasb/core/Authorization/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"Logout\" } }, \"payload\": { \"service\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_7","text":"Property Type Required Description Example service String Yes The service used for authorization.","title":"Payload"},{"location":"aasb/core/Authorization/#startauthorization","text":"Notifies the Engine to start the authorization process.","title":"StartAuthorization"},{"location":"aasb/core/Authorization/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"StartAuthorization\" } }, \"payload\": { \"service\": {{String}}, \"data\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_8","text":"Property Type Required Description Example service String Yes The service used for authorization. data String Yes The value of the data.","title":"Payload"},{"location":"aasb/core/Authorization/#getauthorizationdatareply","text":"Reply for GetAuthorizationData message.","title":"GetAuthorizationDataReply"},{"location":"aasb/core/Authorization/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\", \"replyToId\": {{String}} } }, \"payload\": { \"data\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/Authorization/#payload_9","text":"Property Type Required Description Example data String Yes The data associated with the key if available, otherwise an empty string.","title":"Payload"},{"location":"aasb/core/Authorization/#enums","text":"","title":"Enums"},{"location":"aasb/core/Authorization/#authorizationstate","text":"","title":"AuthorizationState"},{"location":"aasb/core/Authorization/#values","text":"Value Description \"UNAUTHORIZED\" Device is unauthorized. \"AUTHORIZING\" Device authorization is in progress. \"AUTHORIZED\" Device is authorized.","title":"Values"},{"location":"aasb/core/DeviceUsage/","text":"DeviceUsage \u00b6 Incoming Messages \u00b6 ReportNetworkDataUsage \u00b6 Report network usage data to the Engine. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceUsage\", \"action\": \"ReportNetworkDataUsage\" } }, \"payload\": { \"usage\": {{String}} } } Payload \u00b6 Property Type Required Description Example usage String Yes A JSON String representation of the network usage data of the application. See the Core module documentation for complete details of the schema.","title":"DeviceUsage"},{"location":"aasb/core/DeviceUsage/#deviceusage","text":"","title":"DeviceUsage"},{"location":"aasb/core/DeviceUsage/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/core/DeviceUsage/#reportnetworkdatausage","text":"Report network usage data to the Engine.","title":"ReportNetworkDataUsage"},{"location":"aasb/core/DeviceUsage/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceUsage\", \"action\": \"ReportNetworkDataUsage\" } }, \"payload\": { \"usage\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/DeviceUsage/#payload","text":"Property Type Required Description Example usage String Yes A JSON String representation of the network usage data of the application. See the Core module documentation for complete details of the schema.","title":"Payload"},{"location":"aasb/core/LocationProvider/","text":"LocationProvider \u00b6 Outgoing Messages \u00b6 GetCountry \u00b6 Requests the ISO country code for the current geolocation of the device. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\" } } } GetLocation \u00b6 Requests the current geolocation of the device. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\" } } } Incoming Messages \u00b6 LocationServiceAccessChanged \u00b6 Notifies the Engine of a change in location service access. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"LocationServiceAccessChanged\" } }, \"payload\": { \"access\": {{LocationServiceAccess}} } } Payload \u00b6 Property Type Required Description Example access LocationServiceAccess Yes Describes the access to the geolocation service on the device. GetCountryReply \u00b6 Reply for GetCountry message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\", \"replyToId\": {{String}} } }, \"payload\": { \"country\": {{String}} } } Payload \u00b6 Property Type Required Description Example country String Yes The current country. GetLocationReply \u00b6 Reply for GetLocation message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\", \"replyToId\": {{String}} } }, \"payload\": { \"location\": {{Location}} } } Payload \u00b6 Property Type Required Description Example location Location Yes The current location. Type Definitions \u00b6 Location \u00b6 JSON Structure \u00b6 { \"latitude\": {{Float}}, \"longitude\": {{Float}}, \"altitude\": {{Float}}, \"accuracy\": {{Float}} } Properties \u00b6 Property Type Required Description Example latitude Float Yes Location latitude. Use -1 if the location is not available. longitude Float Yes Location longitude. Use -1 if the location is not available. altitude Float No (default: -1 ) A location altitude in meters. accuracy Float No (default: -1 ) A location accuracy in meters. Enums \u00b6 LocationServiceAccess \u00b6 Values \u00b6 Value Description \"DISABLED\" The location service on the device is disabled (e.g., GPS is turned off). \"ENABLED\" The location service on the device is enabled (e.g., GPS is turned on).","title":"LocationProvider"},{"location":"aasb/core/LocationProvider/#locationprovider","text":"","title":"LocationProvider"},{"location":"aasb/core/LocationProvider/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/core/LocationProvider/#getcountry","text":"Requests the ISO country code for the current geolocation of the device.","title":"GetCountry"},{"location":"aasb/core/LocationProvider/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\" } } }","title":"JSON Structure"},{"location":"aasb/core/LocationProvider/#getlocation","text":"Requests the current geolocation of the device.","title":"GetLocation"},{"location":"aasb/core/LocationProvider/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\" } } }","title":"JSON Structure"},{"location":"aasb/core/LocationProvider/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/core/LocationProvider/#locationserviceaccesschanged","text":"Notifies the Engine of a change in location service access.","title":"LocationServiceAccessChanged"},{"location":"aasb/core/LocationProvider/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"LocationServiceAccessChanged\" } }, \"payload\": { \"access\": {{LocationServiceAccess}} } }","title":"JSON Structure"},{"location":"aasb/core/LocationProvider/#payload","text":"Property Type Required Description Example access LocationServiceAccess Yes Describes the access to the geolocation service on the device.","title":"Payload"},{"location":"aasb/core/LocationProvider/#getcountryreply","text":"Reply for GetCountry message.","title":"GetCountryReply"},{"location":"aasb/core/LocationProvider/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\", \"replyToId\": {{String}} } }, \"payload\": { \"country\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/LocationProvider/#payload_1","text":"Property Type Required Description Example country String Yes The current country.","title":"Payload"},{"location":"aasb/core/LocationProvider/#getlocationreply","text":"Reply for GetLocation message.","title":"GetLocationReply"},{"location":"aasb/core/LocationProvider/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\", \"replyToId\": {{String}} } }, \"payload\": { \"location\": {{Location}} } }","title":"JSON Structure"},{"location":"aasb/core/LocationProvider/#payload_2","text":"Property Type Required Description Example location Location Yes The current location.","title":"Payload"},{"location":"aasb/core/LocationProvider/#type-definitions","text":"","title":"Type Definitions"},{"location":"aasb/core/LocationProvider/#location","text":"","title":"Location"},{"location":"aasb/core/LocationProvider/#json-structure_5","text":"{ \"latitude\": {{Float}}, \"longitude\": {{Float}}, \"altitude\": {{Float}}, \"accuracy\": {{Float}} }","title":"JSON Structure"},{"location":"aasb/core/LocationProvider/#properties","text":"Property Type Required Description Example latitude Float Yes Location latitude. Use -1 if the location is not available. longitude Float Yes Location longitude. Use -1 if the location is not available. altitude Float No (default: -1 ) A location altitude in meters. accuracy Float No (default: -1 ) A location accuracy in meters.","title":"Properties"},{"location":"aasb/core/LocationProvider/#enums","text":"","title":"Enums"},{"location":"aasb/core/LocationProvider/#locationserviceaccess","text":"","title":"LocationServiceAccess"},{"location":"aasb/core/LocationProvider/#values","text":"Value Description \"DISABLED\" The location service on the device is disabled (e.g., GPS is turned off). \"ENABLED\" The location service on the device is enabled (e.g., GPS is turned on).","title":"Values"},{"location":"aasb/core/NetworkInfoProvider/","text":"NetworkInfoProvider \u00b6 Outgoing Messages \u00b6 GetWifiSignalStrength \u00b6 Requests the signal strength (RSSI) of the WiFi connection on the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\" } } } GetNetworkStatus \u00b6 Requests the network connection status on the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\" } } } Incoming Messages \u00b6 NetworkStatusChanged \u00b6 Notifies the Engine of a network status change on the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"NetworkStatusChanged\" } }, \"payload\": { \"status\": {{NetworkStatus}}, \"wifiSignalStrength\": {{Int}} } } Payload \u00b6 Property Type Required Description Example status NetworkStatus Yes The connection status CONNECTED wifiSignalStrength Int Yes The RSSI of the WiFi connection. GetWifiSignalStrengthReply \u00b6 Reply for GetWifiSignalStrength message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\", \"replyToId\": {{String}} } }, \"payload\": { \"wifiSignalStrength\": {{Int}} } } Payload \u00b6 Property Type Required Description Example wifiSignalStrength Int Yes The RSSI of the WiFi connection. GetNetworkStatusReply \u00b6 Reply for GetNetworkStatus message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\", \"replyToId\": {{String}} } }, \"payload\": { \"status\": {{NetworkStatus}} } } Payload \u00b6 Property Type Required Description Example status NetworkStatus Yes The network connection status Enums \u00b6 NetworkStatus \u00b6 Values \u00b6 Value Description \"UNKNOWN\" The network status is unknown \"DISCONNECTED\" The network is disconnected. \"DISCONNECTING\" The network is disconnecting \"CONNECTED\" The network is connected \"CONNECTING\" The network is connecting","title":"NetworkInfoProvider"},{"location":"aasb/core/NetworkInfoProvider/#networkinfoprovider","text":"","title":"NetworkInfoProvider"},{"location":"aasb/core/NetworkInfoProvider/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/core/NetworkInfoProvider/#getwifisignalstrength","text":"Requests the signal strength (RSSI) of the WiFi connection on the platform.","title":"GetWifiSignalStrength"},{"location":"aasb/core/NetworkInfoProvider/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\" } } }","title":"JSON Structure"},{"location":"aasb/core/NetworkInfoProvider/#getnetworkstatus","text":"Requests the network connection status on the platform.","title":"GetNetworkStatus"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\" } } }","title":"JSON Structure"},{"location":"aasb/core/NetworkInfoProvider/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/core/NetworkInfoProvider/#networkstatuschanged","text":"Notifies the Engine of a network status change on the platform.","title":"NetworkStatusChanged"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"NetworkStatusChanged\" } }, \"payload\": { \"status\": {{NetworkStatus}}, \"wifiSignalStrength\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/core/NetworkInfoProvider/#payload","text":"Property Type Required Description Example status NetworkStatus Yes The connection status CONNECTED wifiSignalStrength Int Yes The RSSI of the WiFi connection.","title":"Payload"},{"location":"aasb/core/NetworkInfoProvider/#getwifisignalstrengthreply","text":"Reply for GetWifiSignalStrength message.","title":"GetWifiSignalStrengthReply"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\", \"replyToId\": {{String}} } }, \"payload\": { \"wifiSignalStrength\": {{Int}} } }","title":"JSON Structure"},{"location":"aasb/core/NetworkInfoProvider/#payload_1","text":"Property Type Required Description Example wifiSignalStrength Int Yes The RSSI of the WiFi connection.","title":"Payload"},{"location":"aasb/core/NetworkInfoProvider/#getnetworkstatusreply","text":"Reply for GetNetworkStatus message.","title":"GetNetworkStatusReply"},{"location":"aasb/core/NetworkInfoProvider/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\", \"replyToId\": {{String}} } }, \"payload\": { \"status\": {{NetworkStatus}} } }","title":"JSON Structure"},{"location":"aasb/core/NetworkInfoProvider/#payload_2","text":"Property Type Required Description Example status NetworkStatus Yes The network connection status","title":"Payload"},{"location":"aasb/core/NetworkInfoProvider/#enums","text":"","title":"Enums"},{"location":"aasb/core/NetworkInfoProvider/#networkstatus","text":"","title":"NetworkStatus"},{"location":"aasb/core/NetworkInfoProvider/#values","text":"Value Description \"UNKNOWN\" The network status is unknown \"DISCONNECTED\" The network is disconnected. \"DISCONNECTING\" The network is disconnecting \"CONNECTED\" The network is connected \"CONNECTING\" The network is connecting","title":"Values"},{"location":"aasb/core/PropertyManager/","text":"PropertyManager \u00b6 Outgoing Messages \u00b6 PropertyChanged \u00b6 Notifies the platform implementation about a change in a property value in the Engine that is not initiated by the platform implementation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyChanged\" } }, \"payload\": { \"name\": {{String}}, \"newValue\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes Name of the property. newValue String Yes The new value of the property. PropertyStateChanged \u00b6 Notifies the platform implementation of the status of a property change after a call to setProperty(). JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyStateChanged\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}}, \"state\": {{PropertyState}} } } Payload \u00b6 Property Type Required Description Example name String Yes Name of the property. value String Yes The value of the property. state PropertyState Yes The property state. GetPropertyReply \u00b6 Reply for GetProperty message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\", \"replyToId\": {{String}} } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes The property name. value String Yes The property value. Incoming Messages \u00b6 GetProperty \u00b6 Retrieves the property setting from the Engine. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\" } }, \"payload\": { \"name\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes The property name. SetProperty \u00b6 Sets the property setting in the Engine. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"SetProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } } Payload \u00b6 Property Type Required Description Example name String Yes The property name. value String Yes The property value. Enums \u00b6 PropertyState \u00b6 Values \u00b6 Value Description \"SUCCEEDED\" The property change was successful. \"FAILED\" The property change failed.","title":"PropertyManager"},{"location":"aasb/core/PropertyManager/#propertymanager","text":"","title":"PropertyManager"},{"location":"aasb/core/PropertyManager/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/core/PropertyManager/#propertychanged","text":"Notifies the platform implementation about a change in a property value in the Engine that is not initiated by the platform implementation.","title":"PropertyChanged"},{"location":"aasb/core/PropertyManager/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyChanged\" } }, \"payload\": { \"name\": {{String}}, \"newValue\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/PropertyManager/#payload","text":"Property Type Required Description Example name String Yes Name of the property. newValue String Yes The new value of the property.","title":"Payload"},{"location":"aasb/core/PropertyManager/#propertystatechanged","text":"Notifies the platform implementation of the status of a property change after a call to setProperty().","title":"PropertyStateChanged"},{"location":"aasb/core/PropertyManager/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyStateChanged\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}}, \"state\": {{PropertyState}} } }","title":"JSON Structure"},{"location":"aasb/core/PropertyManager/#payload_1","text":"Property Type Required Description Example name String Yes Name of the property. value String Yes The value of the property. state PropertyState Yes The property state.","title":"Payload"},{"location":"aasb/core/PropertyManager/#getpropertyreply","text":"Reply for GetProperty message.","title":"GetPropertyReply"},{"location":"aasb/core/PropertyManager/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\", \"replyToId\": {{String}} } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/PropertyManager/#payload_2","text":"Property Type Required Description Example name String Yes The property name. value String Yes The property value.","title":"Payload"},{"location":"aasb/core/PropertyManager/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/core/PropertyManager/#getproperty","text":"Retrieves the property setting from the Engine.","title":"GetProperty"},{"location":"aasb/core/PropertyManager/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\" } }, \"payload\": { \"name\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/PropertyManager/#payload_3","text":"Property Type Required Description Example name String Yes The property name.","title":"Payload"},{"location":"aasb/core/PropertyManager/#setproperty","text":"Sets the property setting in the Engine.","title":"SetProperty"},{"location":"aasb/core/PropertyManager/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"SetProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/core/PropertyManager/#payload_4","text":"Property Type Required Description Example name String Yes The property name. value String Yes The property value.","title":"Payload"},{"location":"aasb/core/PropertyManager/#enums","text":"","title":"Enums"},{"location":"aasb/core/PropertyManager/#propertystate","text":"","title":"PropertyState"},{"location":"aasb/core/PropertyManager/#values","text":"Value Description \"SUCCEEDED\" The property change was successful. \"FAILED\" The property change failed.","title":"Values"},{"location":"aasb/custom-domain/CustomDomain/","text":"CustomDomain \u00b6 Outgoing Messages \u00b6 HandleDirective \u00b6 Notifies the platform on a new custom directive. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"HandleDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"directivePayload\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } } Payload \u00b6 Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive to be handled. directiveName String Yes The name of the custom directive. directivePayload String Yes An opaque JSON payload sent to the device. correlationToken String Yes An opaque token that must be included in any events responding to this directive. messageId String Yes A unique ID used to identify a specific directive. Used to report directive handling result. CancelDirective \u00b6 Notifies the platform to cancel the specific directive with given messageId. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"CancelDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } } Payload \u00b6 Property Type Required Description Example directiveNamespace String Yes The namespace of the cancelled directive. directiveName String Yes The name of the cancelled directive. correlationToken String Yes The correlationToken of the cancelled directive. messageId String Yes A unique ID used to identify a specific directive. GetContext \u00b6 Called to query the current custom states under given namespace from the device. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\" } }, \"payload\": { \"contextNamespace\": {{String}} } } Payload \u00b6 Property Type Required Description Example contextNamespace String Yes The namespace of the queried context. Incoming Messages \u00b6 ReportDirectiveHandlingResult \u00b6 Notifies the engine about the result of a directive handling. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"ReportDirectiveHandlingResult\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"messageId\": {{String}}, \"result\": {{ResultType}} } } Payload \u00b6 Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive. messageId String Yes The messageId that uniquely identifies which directive this report is for. result ResultType Yes The result of the handling. SendEvent \u00b6 Notifes the engine to send a custom event. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"SendEvent\" } }, \"payload\": { \"eventNamespace\": {{String}}, \"eventName\": {{String}}, \"eventPayload\": {{String}}, \"requiresContext\": {{Bool}}, \"correlationToken\": {{String}}, \"customContext\": {{String}} } } Payload \u00b6 Property Type Required Description Example eventNamespace String Yes The namespace of the custom event to be sent. eventName String Yes The name of the event. eventPayload String Yes An opaque JSON payload in the format of escaped JSON string sent to the cloud with the event. requiresContext Bool Yes A boolean indicating if this event must be sent with context. correlationToken String No The token correlating this event to a directive. Required only if this event is sent as a response to a directive. customContext String No The context corresponding to eventNamespace in a String representation of a valid JSON object (escaped). It's optional but recommended to provide the context with the event to reduce the amount of AASB message transactions. You can find the defined structure of context JSON in Custom Domain Platform Interface. GetContextReply \u00b6 Reply for GetContext message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\", \"replyToId\": {{String}} } }, \"payload\": { \"customContext\": {{String}} } } Payload \u00b6 Property Type Required Description Example customContext String Yes The context for the queried namespace in a String representation of a valid JSON object (escaped). You can find the defined structure of context JSON in Custom Domain Platform Interface. Enums \u00b6 ResultType \u00b6 Values \u00b6 Value Description \"UNEXPECTED_INFORMATION_RECEIVED\" The directive sent to your client was malformed or the payload does not conform to the directive specification. \"UNSUPPORTED_OPERATION\" The operation specified by the namespace/name in the directive's header are not supported by the client. \"INTERNAL_ERROR\" An error occurred while the device was handling the directive and the error does not fall into the specified categories. \"SUCCESS\" The directive handling is successful.","title":"CustomDomain"},{"location":"aasb/custom-domain/CustomDomain/#customdomain","text":"","title":"CustomDomain"},{"location":"aasb/custom-domain/CustomDomain/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/custom-domain/CustomDomain/#handledirective","text":"Notifies the platform on a new custom directive.","title":"HandleDirective"},{"location":"aasb/custom-domain/CustomDomain/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"HandleDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"directivePayload\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/custom-domain/CustomDomain/#payload","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive to be handled. directiveName String Yes The name of the custom directive. directivePayload String Yes An opaque JSON payload sent to the device. correlationToken String Yes An opaque token that must be included in any events responding to this directive. messageId String Yes A unique ID used to identify a specific directive. Used to report directive handling result.","title":"Payload"},{"location":"aasb/custom-domain/CustomDomain/#canceldirective","text":"Notifies the platform to cancel the specific directive with given messageId.","title":"CancelDirective"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"CancelDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/custom-domain/CustomDomain/#payload_1","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the cancelled directive. directiveName String Yes The name of the cancelled directive. correlationToken String Yes The correlationToken of the cancelled directive. messageId String Yes A unique ID used to identify a specific directive.","title":"Payload"},{"location":"aasb/custom-domain/CustomDomain/#getcontext","text":"Called to query the current custom states under given namespace from the device.","title":"GetContext"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\" } }, \"payload\": { \"contextNamespace\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/custom-domain/CustomDomain/#payload_2","text":"Property Type Required Description Example contextNamespace String Yes The namespace of the queried context.","title":"Payload"},{"location":"aasb/custom-domain/CustomDomain/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/custom-domain/CustomDomain/#reportdirectivehandlingresult","text":"Notifies the engine about the result of a directive handling.","title":"ReportDirectiveHandlingResult"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"ReportDirectiveHandlingResult\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"messageId\": {{String}}, \"result\": {{ResultType}} } }","title":"JSON Structure"},{"location":"aasb/custom-domain/CustomDomain/#payload_3","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive. messageId String Yes The messageId that uniquely identifies which directive this report is for. result ResultType Yes The result of the handling.","title":"Payload"},{"location":"aasb/custom-domain/CustomDomain/#sendevent","text":"Notifes the engine to send a custom event.","title":"SendEvent"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"SendEvent\" } }, \"payload\": { \"eventNamespace\": {{String}}, \"eventName\": {{String}}, \"eventPayload\": {{String}}, \"requiresContext\": {{Bool}}, \"correlationToken\": {{String}}, \"customContext\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/custom-domain/CustomDomain/#payload_4","text":"Property Type Required Description Example eventNamespace String Yes The namespace of the custom event to be sent. eventName String Yes The name of the event. eventPayload String Yes An opaque JSON payload in the format of escaped JSON string sent to the cloud with the event. requiresContext Bool Yes A boolean indicating if this event must be sent with context. correlationToken String No The token correlating this event to a directive. Required only if this event is sent as a response to a directive. customContext String No The context corresponding to eventNamespace in a String representation of a valid JSON object (escaped). It's optional but recommended to provide the context with the event to reduce the amount of AASB message transactions. You can find the defined structure of context JSON in Custom Domain Platform Interface.","title":"Payload"},{"location":"aasb/custom-domain/CustomDomain/#getcontextreply","text":"Reply for GetContext message.","title":"GetContextReply"},{"location":"aasb/custom-domain/CustomDomain/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\", \"replyToId\": {{String}} } }, \"payload\": { \"customContext\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/custom-domain/CustomDomain/#payload_5","text":"Property Type Required Description Example customContext String Yes The context for the queried namespace in a String representation of a valid JSON object (escaped). You can find the defined structure of context JSON in Custom Domain Platform Interface.","title":"Payload"},{"location":"aasb/custom-domain/CustomDomain/#enums","text":"","title":"Enums"},{"location":"aasb/custom-domain/CustomDomain/#resulttype","text":"","title":"ResultType"},{"location":"aasb/custom-domain/CustomDomain/#values","text":"Value Description \"UNEXPECTED_INFORMATION_RECEIVED\" The directive sent to your client was malformed or the payload does not conform to the directive specification. \"UNSUPPORTED_OPERATION\" The operation specified by the namespace/name in the directive's header are not supported by the client. \"INTERNAL_ERROR\" An error occurred while the device was handling the directive and the error does not fall into the specified categories. \"SUCCESS\" The directive handling is successful.","title":"Values"},{"location":"aasb/messaging/Messaging/","text":"Messaging \u00b6 Outgoing Messages \u00b6 SendMessage \u00b6 Send SMS message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessage\" } }, \"payload\": { \"token\": {{String}}, \"message\": {{String}}, \"recipients\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. message String Yes Body of the SMS text message to be sent. recipients String Yes String in JSON format containing the recipient of the SMS message. UpdateMessagesStatus \u00b6 Update status of SMS messages. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatus\" } }, \"payload\": { \"token\": {{String}}, \"conversationId\": {{String}}, \"status\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. conversationId String Yes The id of the conversation whose messages need to be updated. status String Yes String in JSON format representing the message ids and status to be updated. UploadConversations \u00b6 Upload SMS unread messages message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UploadConversations\" } }, \"payload\": { \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. Incoming Messages \u00b6 UpdateMessagesStatusFailed \u00b6 Notifies the Engine the message status update failed. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error. UpdateMessagingEndpointState \u00b6 Notifies the Engine of updates to the messaging endpoint state. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagingEndpointState\" } }, \"payload\": { \"connectionState\": {{ConnectionState}}, \"sendPermission\": {{PermissionState}}, \"readPermission\": {{PermissionState}} } } Payload \u00b6 Property Type Required Description Example connectionState ConnectionState Yes The value for the connection state. sendPermission PermissionState Yes The value for the send permission. readPermission PermissionState Yes The value for the read permission. SendMessageSucceeded \u00b6 Notifies the Engine that message send was successful. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageSucceeded\" } }, \"payload\": { \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. SendMessageFailed \u00b6 Notifies the Engine the message send failed. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error. ConversationsReport \u00b6 Notifies the Engine to upload conversations report to the cloud. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"ConversationsReport\" } }, \"payload\": { \"token\": {{String}}, \"conversations\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. conversations String Yes String in JSON format representing all conversations with unread SMS messages. UpdateMessagesStatusSucceeded \u00b6 Notifies the Engine that message status was successful. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusSucceeded\" } }, \"payload\": { \"token\": {{String}} } } Payload \u00b6 Property Type Required Description Example token String Yes Token id for send message request. Enums \u00b6 ConnectionState \u00b6 Values \u00b6 Value Description \"DISCONNECTED\" Messaging device is disconnected. \"CONNECTED\" Messaging device is connected. PermissionState \u00b6 Values \u00b6 Value Description \"OFF\" Permission is not granted. \"ON\" Permission is granted. ErrorCode \u00b6 Values \u00b6 Value Description \"GENERIC_FAILURE\" Generic error handling SMS request. \"NO_CONNECTIVITY\" Messaging device is not connected. \"NO_PERMISSION\" Permission denied.","title":"Messaging"},{"location":"aasb/messaging/Messaging/#messaging","text":"","title":"Messaging"},{"location":"aasb/messaging/Messaging/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/messaging/Messaging/#sendmessage","text":"Send SMS message.","title":"SendMessage"},{"location":"aasb/messaging/Messaging/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessage\" } }, \"payload\": { \"token\": {{String}}, \"message\": {{String}}, \"recipients\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload","text":"Property Type Required Description Example token String Yes Token id for send message request. message String Yes Body of the SMS text message to be sent. recipients String Yes String in JSON format containing the recipient of the SMS message.","title":"Payload"},{"location":"aasb/messaging/Messaging/#updatemessagesstatus","text":"Update status of SMS messages.","title":"UpdateMessagesStatus"},{"location":"aasb/messaging/Messaging/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatus\" } }, \"payload\": { \"token\": {{String}}, \"conversationId\": {{String}}, \"status\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_1","text":"Property Type Required Description Example token String Yes Token id for send message request. conversationId String Yes The id of the conversation whose messages need to be updated. status String Yes String in JSON format representing the message ids and status to be updated.","title":"Payload"},{"location":"aasb/messaging/Messaging/#uploadconversations","text":"Upload SMS unread messages message.","title":"UploadConversations"},{"location":"aasb/messaging/Messaging/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UploadConversations\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_2","text":"Property Type Required Description Example token String Yes Token id for send message request.","title":"Payload"},{"location":"aasb/messaging/Messaging/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/messaging/Messaging/#updatemessagesstatusfailed","text":"Notifies the Engine the message status update failed.","title":"UpdateMessagesStatusFailed"},{"location":"aasb/messaging/Messaging/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_3","text":"Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error.","title":"Payload"},{"location":"aasb/messaging/Messaging/#updatemessagingendpointstate","text":"Notifies the Engine of updates to the messaging endpoint state.","title":"UpdateMessagingEndpointState"},{"location":"aasb/messaging/Messaging/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagingEndpointState\" } }, \"payload\": { \"connectionState\": {{ConnectionState}}, \"sendPermission\": {{PermissionState}}, \"readPermission\": {{PermissionState}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_4","text":"Property Type Required Description Example connectionState ConnectionState Yes The value for the connection state. sendPermission PermissionState Yes The value for the send permission. readPermission PermissionState Yes The value for the read permission.","title":"Payload"},{"location":"aasb/messaging/Messaging/#sendmessagesucceeded","text":"Notifies the Engine that message send was successful.","title":"SendMessageSucceeded"},{"location":"aasb/messaging/Messaging/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageSucceeded\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_5","text":"Property Type Required Description Example token String Yes Token id for send message request.","title":"Payload"},{"location":"aasb/messaging/Messaging/#sendmessagefailed","text":"Notifies the Engine the message send failed.","title":"SendMessageFailed"},{"location":"aasb/messaging/Messaging/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_6","text":"Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error.","title":"Payload"},{"location":"aasb/messaging/Messaging/#conversationsreport","text":"Notifies the Engine to upload conversations report to the cloud.","title":"ConversationsReport"},{"location":"aasb/messaging/Messaging/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"ConversationsReport\" } }, \"payload\": { \"token\": {{String}}, \"conversations\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_7","text":"Property Type Required Description Example token String Yes Token id for send message request. conversations String Yes String in JSON format representing all conversations with unread SMS messages.","title":"Payload"},{"location":"aasb/messaging/Messaging/#updatemessagesstatussucceeded","text":"Notifies the Engine that message status was successful.","title":"UpdateMessagesStatusSucceeded"},{"location":"aasb/messaging/Messaging/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusSucceeded\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/messaging/Messaging/#payload_8","text":"Property Type Required Description Example token String Yes Token id for send message request.","title":"Payload"},{"location":"aasb/messaging/Messaging/#enums","text":"","title":"Enums"},{"location":"aasb/messaging/Messaging/#connectionstate","text":"","title":"ConnectionState"},{"location":"aasb/messaging/Messaging/#values","text":"Value Description \"DISCONNECTED\" Messaging device is disconnected. \"CONNECTED\" Messaging device is connected.","title":"Values"},{"location":"aasb/messaging/Messaging/#permissionstate","text":"","title":"PermissionState"},{"location":"aasb/messaging/Messaging/#values_1","text":"Value Description \"OFF\" Permission is not granted. \"ON\" Permission is granted.","title":"Values"},{"location":"aasb/messaging/Messaging/#errorcode","text":"","title":"ErrorCode"},{"location":"aasb/messaging/Messaging/#values_2","text":"Value Description \"GENERIC_FAILURE\" Generic error handling SMS request. \"NO_CONNECTIVITY\" Messaging device is not connected. \"NO_PERMISSION\" Permission denied.","title":"Values"},{"location":"aasb/navigation/Navigation/","text":"Navigation \u00b6 Outgoing Messages \u00b6 ShowAlternativeRoutes \u00b6 Notifies the platform implementation to show alternative routes. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutes\" } }, \"payload\": { \"alternateRouteType\": {{AlternateRouteType}} } } Payload \u00b6 Property Type Required Description Example alternateRouteType AlternateRouteType Yes alternateRouteType The type of alternate route requested. ShowPreviousWaypoints \u00b6 Notifies the platform implementation to display list of previous waypoints. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowPreviousWaypoints\" } } } ControlDisplay \u00b6 Notifies the platform implementation to perform user interaction with the onscreen map application. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ControlDisplay\" } }, \"payload\": { \"controlDisplay\": {{ControlDisplay}} } } Payload \u00b6 Property Type Required Description Example controlDisplay ControlDisplay Yes the user requested map control. AnnounceRoadRegulation \u00b6 Notifies the platform implementation to give details about road regulations about the road segments that the user is on. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceRoadRegulation\" } }, \"payload\": { \"roadRegulation\": {{RoadRegulation}} } } Payload \u00b6 Property Type Required Description Example roadRegulation RoadRegulation Yes Type of road regulation requested. CancelNavigation \u00b6 Notifies the platform implementation to cancel navigation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"CancelNavigation\" } } } AnnounceManeuver \u00b6 Notifies the platform implementation to give details about a maneuver to next waypoint on the route or a completely different waypoint off route. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceManeuver\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes JSON data containing the manueuver information. NavigateToPreviousWaypoint \u00b6 Notifies the platform implementation to start navigation to the previous waypoint. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigateToPreviousWaypoint\" } } } GetNavigationState \u00b6 Retrieve the navigation state from the platform. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\" } } } StartNavigation \u00b6 Notifies the platform implementation to start the navigation. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"StartNavigation\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes JSON data containing the destination information. Incoming Messages \u00b6 ShowAlternativeRoutesSucceeded \u00b6 Notifies AVS of successful showing of alternative routes to the user. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutesSucceeded\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes data containing the alternative route information. NavigationError \u00b6 Notifies the Engine of error in handling a Navigation directive. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationError\" } }, \"payload\": { \"type\": {{ErrorType}}, \"code\": {{ErrorCode}}, \"description\": {{String}} } } Payload \u00b6 Property Type Required Description Example type ErrorType Yes ErrorType describing which operation failed. code ErrorCode Yes ErrorCode describing the type of failure. description String Yes String providing additional information. NavigationEvent \u00b6 Notifies the Engine of successful handling of a Navigation directive. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationEvent\" } }, \"payload\": { \"event\": {{EventName}} } } Payload \u00b6 Property Type Required Description Example event EventName Yes EventName describing which operation was successful. GetNavigationStateReply \u00b6 Reply for GetNavigationState message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\", \"replyToId\": {{String}} } }, \"payload\": { \"navigationState\": {{String}} } } Payload \u00b6 Property Type Required Description Example navigationState String Yes the current NavigationState JSON payload. Enums \u00b6 AlternateRouteType \u00b6 Values \u00b6 Value Description \"DEFAULT\" description for DEFAULT. \"SHORTER_TIME\" description for SHORTER_TIME. \"SHORTER_DISTANCE\" description for SHORTER_DISTANCE. ControlDisplay \u00b6 Values \u00b6 Value Description \"SHOW_ROUTE_OVERVIEW\" description for SHOW_ROUTE_OVERVIEW. \"SHOW_DIRECTIONS_LIST\" description for SHOW_DIRECTIONS_LIST. \"ZOOM_IN\" description for ZOOM_IN. \"ZOOM_OUT\" description for ZOOM_OUT. \"CENTER_MAP_ON_CURRENT_LOCATION\" description for CENTER_MAP_ON_CURRENT_LOCATION. \"ORIENT_NORTH\" description for ORIENT_NORTH. \"SCROLL_NORTH\" description for SCROLL_NORTH. \"SCROLL_UP\" description for SCROLL_UP. \"SCROLL_EAST\" description for SCROLL_EAST. \"SCROLL_RIGHT\" description for SCROLL_RIGHT. \"SCROLL_SOUTH\" description for SCROLL_SOUTH. \"SCROLL_DOWN\" description for SCROLL_DOWN. \"SCROLL_WEST\" description for SCROLL_WEST. \"SCROLL_LEFT\" description for SCROLL_LEFT. \"MUTE_ROUTE_GUIDANCE\" navigation sounds off. \"UNMUTE_ROUTE_GUIDANCE\" navigation sounds on. RoadRegulation \u00b6 Values \u00b6 Value Description \"SPEED_LIMIT\" description for SHOW_ROUTE_OVERVIEW. \"CARPOOL_RULES\" description for SHOW_DIRECTIONS_LIST. ErrorType \u00b6 Values \u00b6 Value Description \"NAVIGATION_START_FAILED\" Navigation failed to start. Send in response to startNavigation() directive. \"SHOW_PREVIOUS_WAYPOINTS_FAILED\" List of previous waypoints failed to display. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_START_FAILED\" The previous navigation route failed to start. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_FAILED\" Overview of route was failed to display. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_FAILED\" List of directions was failed to display. Send in response to controlDisplay() directive. \"ZOOM_IN_FAILED\" Map zoom-in unsuccessful. Send in response to controlDisplay() directive. \"ZOOM_OUT_FAILED\" Map zoom-out unsuccessful. Send in response to controlDisplay() directive. \"CENTER_FAILED\" Map centering unsuccessful. Send in response to controlDisplay() directive. \"ORIENT_NORTH_FAILED\" Map alignment to north unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_NORTH_FAILED\" Moving map North was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_UP_FAILED\" Moving map upwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_EAST_FAILED\" Moving map East was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_RIGHT_FAILED\" Moving map rightwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_SOUTH_FAILED\" Moving map South was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_DOWN_FAILED\" Moving map downwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_WEST_FAILED\" Moving map west was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_LEFT_FAILED\" Moving map leftwards was unsuccessful. Send in response to controlDisplay() directive. \"MUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be muted. Send in response to controlDisplay() directive. \"UNMUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_FAILED\" Displaying default alternate routes was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_FAILED\" Displaying alternate routes with shorter times was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_FAILED\" Displaying alternate routes with shorter distances was unsuccessful. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_FAILED\" Next turn announcement was unsuccessful. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_FAILED\" Next exit announcement was unsuccessful. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_FAILED\" Announcement for entering directions was unsuccessful. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_FAILED\" Announcement for merging directions was unsuccessful. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_FAILED\" Lane guidance announcement was unsuccessful. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_FAILED\" Current speed limit announcement was unsuccessful. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_FAILED\" Carpool status announcement was unsuccessful. Send in response to announceRoadRegulation() directive. ErrorCode \u00b6 Values \u00b6 Value Description \"INTERNAL_SERVICE_ERROR\" Failure caused by an unexpected service or client implementation error. \"ROUTE_NOT_FOUND\" Failed because the route could not be found. \"NO_PREVIOUS_WAYPOINTS\" Failed because there are no previous waypoints available. \"NOT_SUPPORTED\" The requested operation is not supported. \"NOT_ALLOWED\" The requested operation is not allowed right now. \"NOT_NAVIGATING\" The requested operation can't be performed because the vehicle is not navigating. EventName \u00b6 Values \u00b6 Value Description \"NAVIGATION_STARTED\" Navigation was started. Send in response to startNavigation() directive. \"PREVIOUS_WAYPOINTS_SHOWN\" List of previous waypoints was displayed. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_STARTED\" The previous navigation route was started. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_SHOWN\" Overview of route was displayed. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_SHOWN\" List of directions was displayed. Send in response to controlDisplay() directive. \"ZOOMED_IN\" Map successfully zoomed in. Send in response to controlDisplay() directive. \"ZOOMED_OUT\" Map successfully zoomed out. Send in response to controlDisplay() directive. \"MAP_CENTERED\" Map successfully centered. Send in response to controlDisplay() directive. \"ORIENTED_NORTH\" Map successfully aligned with north up. Send in response to controlDisplay() directive. \"SCROLLED_NORTH\" Map successfully moved in North direction. Send in response to controlDisplay() directive. \"SCROLLED_UP\" Map successfully moved upwards. Send in response to controlDisplay() directive. \"SCROLLED_EAST\" Map successfully moved in East direction. Send in response to controlDisplay() directive. \"SCROLLED_RIGHT\" Map successfully moved rightwards. Send in response to controlDisplay() directive. \"SCROLLED_SOUTH\" Map successfully moved in South direction. Send in response to controlDisplay() directive. \"SCROLLED_DOWN\" Map successfully moved downwards. Send in response to controlDisplay() directive. \"SCROLLED_WEST\" Map successfully moved in West direction. Send in response to controlDisplay() directive. \"SCROLLED_LEFT\" Map successfully moved leftwards. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_MUTED\" Map sounds were muted. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_UNMUTED\" Map sounds were unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_SHOWN\" Default alternate routes were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_SHOWN\" Alternate routes with shorter times were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_SHOWN\" Alternate routes with shorter distances were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_ANNOUNCED\" Next turn was successfully announced. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_ANNOUNCED\" Next exit was successfully announced. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_ANNOUNCED\" Directions for entering successfully announced. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_ANNOUNCED\" Directions for merging successfully announced. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_ANNOUNCED\" Lane guidance was successfully announced. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_ANNOUNCED\" Current speed limit successfully announced. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_ANNOUNCED\" Carpool status successfully announced. Send in response to announceRoadRegulation() directive.","title":"Navigation"},{"location":"aasb/navigation/Navigation/#navigation","text":"","title":"Navigation"},{"location":"aasb/navigation/Navigation/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/navigation/Navigation/#showalternativeroutes","text":"Notifies the platform implementation to show alternative routes.","title":"ShowAlternativeRoutes"},{"location":"aasb/navigation/Navigation/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutes\" } }, \"payload\": { \"alternateRouteType\": {{AlternateRouteType}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload","text":"Property Type Required Description Example alternateRouteType AlternateRouteType Yes alternateRouteType The type of alternate route requested.","title":"Payload"},{"location":"aasb/navigation/Navigation/#showpreviouswaypoints","text":"Notifies the platform implementation to display list of previous waypoints.","title":"ShowPreviousWaypoints"},{"location":"aasb/navigation/Navigation/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowPreviousWaypoints\" } } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#controldisplay","text":"Notifies the platform implementation to perform user interaction with the onscreen map application.","title":"ControlDisplay"},{"location":"aasb/navigation/Navigation/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ControlDisplay\" } }, \"payload\": { \"controlDisplay\": {{ControlDisplay}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_1","text":"Property Type Required Description Example controlDisplay ControlDisplay Yes the user requested map control.","title":"Payload"},{"location":"aasb/navigation/Navigation/#announceroadregulation","text":"Notifies the platform implementation to give details about road regulations about the road segments that the user is on.","title":"AnnounceRoadRegulation"},{"location":"aasb/navigation/Navigation/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceRoadRegulation\" } }, \"payload\": { \"roadRegulation\": {{RoadRegulation}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_2","text":"Property Type Required Description Example roadRegulation RoadRegulation Yes Type of road regulation requested.","title":"Payload"},{"location":"aasb/navigation/Navigation/#cancelnavigation","text":"Notifies the platform implementation to cancel navigation.","title":"CancelNavigation"},{"location":"aasb/navigation/Navigation/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"CancelNavigation\" } } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#announcemaneuver","text":"Notifies the platform implementation to give details about a maneuver to next waypoint on the route or a completely different waypoint off route.","title":"AnnounceManeuver"},{"location":"aasb/navigation/Navigation/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceManeuver\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_3","text":"Property Type Required Description Example payload String Yes JSON data containing the manueuver information.","title":"Payload"},{"location":"aasb/navigation/Navigation/#navigatetopreviouswaypoint","text":"Notifies the platform implementation to start navigation to the previous waypoint.","title":"NavigateToPreviousWaypoint"},{"location":"aasb/navigation/Navigation/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigateToPreviousWaypoint\" } } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#getnavigationstate","text":"Retrieve the navigation state from the platform.","title":"GetNavigationState"},{"location":"aasb/navigation/Navigation/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\" } } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#startnavigation","text":"Notifies the platform implementation to start the navigation.","title":"StartNavigation"},{"location":"aasb/navigation/Navigation/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"StartNavigation\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_4","text":"Property Type Required Description Example payload String Yes JSON data containing the destination information.","title":"Payload"},{"location":"aasb/navigation/Navigation/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/navigation/Navigation/#showalternativeroutessucceeded","text":"Notifies AVS of successful showing of alternative routes to the user.","title":"ShowAlternativeRoutesSucceeded"},{"location":"aasb/navigation/Navigation/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutesSucceeded\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_5","text":"Property Type Required Description Example payload String Yes data containing the alternative route information.","title":"Payload"},{"location":"aasb/navigation/Navigation/#navigationerror","text":"Notifies the Engine of error in handling a Navigation directive.","title":"NavigationError"},{"location":"aasb/navigation/Navigation/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationError\" } }, \"payload\": { \"type\": {{ErrorType}}, \"code\": {{ErrorCode}}, \"description\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_6","text":"Property Type Required Description Example type ErrorType Yes ErrorType describing which operation failed. code ErrorCode Yes ErrorCode describing the type of failure. description String Yes String providing additional information.","title":"Payload"},{"location":"aasb/navigation/Navigation/#navigationevent","text":"Notifies the Engine of successful handling of a Navigation directive.","title":"NavigationEvent"},{"location":"aasb/navigation/Navigation/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationEvent\" } }, \"payload\": { \"event\": {{EventName}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_7","text":"Property Type Required Description Example event EventName Yes EventName describing which operation was successful.","title":"Payload"},{"location":"aasb/navigation/Navigation/#getnavigationstatereply","text":"Reply for GetNavigationState message.","title":"GetNavigationStateReply"},{"location":"aasb/navigation/Navigation/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\", \"replyToId\": {{String}} } }, \"payload\": { \"navigationState\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/navigation/Navigation/#payload_8","text":"Property Type Required Description Example navigationState String Yes the current NavigationState JSON payload.","title":"Payload"},{"location":"aasb/navigation/Navigation/#enums","text":"","title":"Enums"},{"location":"aasb/navigation/Navigation/#alternateroutetype","text":"","title":"AlternateRouteType"},{"location":"aasb/navigation/Navigation/#values","text":"Value Description \"DEFAULT\" description for DEFAULT. \"SHORTER_TIME\" description for SHORTER_TIME. \"SHORTER_DISTANCE\" description for SHORTER_DISTANCE.","title":"Values"},{"location":"aasb/navigation/Navigation/#controldisplay_1","text":"","title":"ControlDisplay"},{"location":"aasb/navigation/Navigation/#values_1","text":"Value Description \"SHOW_ROUTE_OVERVIEW\" description for SHOW_ROUTE_OVERVIEW. \"SHOW_DIRECTIONS_LIST\" description for SHOW_DIRECTIONS_LIST. \"ZOOM_IN\" description for ZOOM_IN. \"ZOOM_OUT\" description for ZOOM_OUT. \"CENTER_MAP_ON_CURRENT_LOCATION\" description for CENTER_MAP_ON_CURRENT_LOCATION. \"ORIENT_NORTH\" description for ORIENT_NORTH. \"SCROLL_NORTH\" description for SCROLL_NORTH. \"SCROLL_UP\" description for SCROLL_UP. \"SCROLL_EAST\" description for SCROLL_EAST. \"SCROLL_RIGHT\" description for SCROLL_RIGHT. \"SCROLL_SOUTH\" description for SCROLL_SOUTH. \"SCROLL_DOWN\" description for SCROLL_DOWN. \"SCROLL_WEST\" description for SCROLL_WEST. \"SCROLL_LEFT\" description for SCROLL_LEFT. \"MUTE_ROUTE_GUIDANCE\" navigation sounds off. \"UNMUTE_ROUTE_GUIDANCE\" navigation sounds on.","title":"Values"},{"location":"aasb/navigation/Navigation/#roadregulation","text":"","title":"RoadRegulation"},{"location":"aasb/navigation/Navigation/#values_2","text":"Value Description \"SPEED_LIMIT\" description for SHOW_ROUTE_OVERVIEW. \"CARPOOL_RULES\" description for SHOW_DIRECTIONS_LIST.","title":"Values"},{"location":"aasb/navigation/Navigation/#errortype","text":"","title":"ErrorType"},{"location":"aasb/navigation/Navigation/#values_3","text":"Value Description \"NAVIGATION_START_FAILED\" Navigation failed to start. Send in response to startNavigation() directive. \"SHOW_PREVIOUS_WAYPOINTS_FAILED\" List of previous waypoints failed to display. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_START_FAILED\" The previous navigation route failed to start. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_FAILED\" Overview of route was failed to display. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_FAILED\" List of directions was failed to display. Send in response to controlDisplay() directive. \"ZOOM_IN_FAILED\" Map zoom-in unsuccessful. Send in response to controlDisplay() directive. \"ZOOM_OUT_FAILED\" Map zoom-out unsuccessful. Send in response to controlDisplay() directive. \"CENTER_FAILED\" Map centering unsuccessful. Send in response to controlDisplay() directive. \"ORIENT_NORTH_FAILED\" Map alignment to north unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_NORTH_FAILED\" Moving map North was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_UP_FAILED\" Moving map upwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_EAST_FAILED\" Moving map East was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_RIGHT_FAILED\" Moving map rightwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_SOUTH_FAILED\" Moving map South was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_DOWN_FAILED\" Moving map downwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_WEST_FAILED\" Moving map west was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_LEFT_FAILED\" Moving map leftwards was unsuccessful. Send in response to controlDisplay() directive. \"MUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be muted. Send in response to controlDisplay() directive. \"UNMUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_FAILED\" Displaying default alternate routes was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_FAILED\" Displaying alternate routes with shorter times was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_FAILED\" Displaying alternate routes with shorter distances was unsuccessful. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_FAILED\" Next turn announcement was unsuccessful. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_FAILED\" Next exit announcement was unsuccessful. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_FAILED\" Announcement for entering directions was unsuccessful. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_FAILED\" Announcement for merging directions was unsuccessful. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_FAILED\" Lane guidance announcement was unsuccessful. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_FAILED\" Current speed limit announcement was unsuccessful. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_FAILED\" Carpool status announcement was unsuccessful. Send in response to announceRoadRegulation() directive.","title":"Values"},{"location":"aasb/navigation/Navigation/#errorcode","text":"","title":"ErrorCode"},{"location":"aasb/navigation/Navigation/#values_4","text":"Value Description \"INTERNAL_SERVICE_ERROR\" Failure caused by an unexpected service or client implementation error. \"ROUTE_NOT_FOUND\" Failed because the route could not be found. \"NO_PREVIOUS_WAYPOINTS\" Failed because there are no previous waypoints available. \"NOT_SUPPORTED\" The requested operation is not supported. \"NOT_ALLOWED\" The requested operation is not allowed right now. \"NOT_NAVIGATING\" The requested operation can't be performed because the vehicle is not navigating.","title":"Values"},{"location":"aasb/navigation/Navigation/#eventname","text":"","title":"EventName"},{"location":"aasb/navigation/Navigation/#values_5","text":"Value Description \"NAVIGATION_STARTED\" Navigation was started. Send in response to startNavigation() directive. \"PREVIOUS_WAYPOINTS_SHOWN\" List of previous waypoints was displayed. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_STARTED\" The previous navigation route was started. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_SHOWN\" Overview of route was displayed. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_SHOWN\" List of directions was displayed. Send in response to controlDisplay() directive. \"ZOOMED_IN\" Map successfully zoomed in. Send in response to controlDisplay() directive. \"ZOOMED_OUT\" Map successfully zoomed out. Send in response to controlDisplay() directive. \"MAP_CENTERED\" Map successfully centered. Send in response to controlDisplay() directive. \"ORIENTED_NORTH\" Map successfully aligned with north up. Send in response to controlDisplay() directive. \"SCROLLED_NORTH\" Map successfully moved in North direction. Send in response to controlDisplay() directive. \"SCROLLED_UP\" Map successfully moved upwards. Send in response to controlDisplay() directive. \"SCROLLED_EAST\" Map successfully moved in East direction. Send in response to controlDisplay() directive. \"SCROLLED_RIGHT\" Map successfully moved rightwards. Send in response to controlDisplay() directive. \"SCROLLED_SOUTH\" Map successfully moved in South direction. Send in response to controlDisplay() directive. \"SCROLLED_DOWN\" Map successfully moved downwards. Send in response to controlDisplay() directive. \"SCROLLED_WEST\" Map successfully moved in West direction. Send in response to controlDisplay() directive. \"SCROLLED_LEFT\" Map successfully moved leftwards. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_MUTED\" Map sounds were muted. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_UNMUTED\" Map sounds were unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_SHOWN\" Default alternate routes were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_SHOWN\" Alternate routes with shorter times were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_SHOWN\" Alternate routes with shorter distances were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_ANNOUNCED\" Next turn was successfully announced. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_ANNOUNCED\" Next exit was successfully announced. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_ANNOUNCED\" Directions for entering successfully announced. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_ANNOUNCED\" Directions for merging successfully announced. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_ANNOUNCED\" Lane guidance was successfully announced. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_ANNOUNCED\" Current speed limit successfully announced. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_ANNOUNCED\" Carpool status successfully announced. Send in response to announceRoadRegulation() directive.","title":"Values"},{"location":"aasb/phone-control/PhoneCallController/","text":"PhoneCallController \u00b6 Outgoing Messages \u00b6 SendDTMF \u00b6 Notifies the platform implementation to send a DTMF signal to the calling device. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMF\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Details of the DTMF request in structured JSON format. Dial \u00b6 Notifies the platform implementation to initiate an outgoing phone call to the destination address. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Dial\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Details of the dial request in structured JSON format. Redial \u00b6 Notifies the platform implementation to redial the last called phone number. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Redial\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Details of the redial request in structured JSON format. Stop \u00b6 Notifies the platform implementation to end an ongoing call or stop inbound or outbound call setup. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Stop\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Details of the stop request in structured JSON format. Answer \u00b6 Notifies the platform implementation to answer an inbound call. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Answer\" } }, \"payload\": { \"payload\": {{String}} } } Payload \u00b6 Property Type Required Description Example payload String Yes Details of the answer request in structured JSON format. CreateCallIdReply \u00b6 Reply for CreateCallId message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\", \"replyToId\": {{String}} } }, \"payload\": { \"callId\": {{String}} } } Payload \u00b6 Property Type Required Description Example callId String Yes Unique identifier for a call. Incoming Messages \u00b6 CreateCallId \u00b6 Generates a unique identifier for a call. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\" } } } CallStateChanged \u00b6 Notifies the Engine of a change in the state of an ongoing call. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallStateChanged\" } }, \"payload\": { \"state\": {{CallState}}, \"callId\": {{String}}, \"callerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example state CallState Yes The state of the call. callId String Yes The unique identifier associated with the call. callerId String No The identifier for a contact. SendDTMFSucceeded \u00b6 Notifies the Engine that sending the DTMF signal succeeded. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFSucceeded\" } }, \"payload\": { \"callId\": {{String}} } } Payload \u00b6 Property Type Required Description Example callId String Yes The unique identifier for the associated call. ConnectionStateChanged \u00b6 Notifies the Engine of a change in connection to a calling device. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"ConnectionStateChanged\" } }, \"payload\": { \"state\": {{ConnectionState}} } } Payload \u00b6 Property Type Required Description Example state ConnectionState Yes The state of connection to a calling device. CallFailed \u00b6 Notifies the Engine of an error related to a call. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{CallError}}, \"message\": {{String}} } } Payload \u00b6 Property Type Required Description Example callId String Yes The unique identifier for the call associated with the error. code CallError Yes The error type. message String No A description of the error. CallerIdReceived \u00b6 Notifies the Engine that a caller id was received for an inbound call. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallerIdReceived\" } }, \"payload\": { \"callId\": {{String}}, \"callerId\": {{String}} } } Payload \u00b6 Property Type Required Description Example callId String Yes The unique identifier for the call associated with the callId. callerId String Yes The caller's identifier or phone number. DeviceConfigurationUpdated \u00b6 Notifies the Engine of the calling feature configuration of the connected calling device. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"DeviceConfigurationUpdated\" } }, \"payload\": { \"configurationMap\": {{String}} } } Payload \u00b6 Property Type Required Description Example configurationMap String Yes A map of configuration properties to the boolean state of the properties. SendDTMFFailed \u00b6 Notifies the Engine that the DTMF signal could not be delivered to the remote party. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{DTMFError}}, \"message\": {{String}} } } Payload \u00b6 Property Type Required Description Example callId String Yes callId The unique identifier for the associated call. code DTMFError Yes The error type. message String No A description of the error. Enums \u00b6 CallingDeviceConfigurationProperty \u00b6 Values \u00b6 Value Description \"DTMF_SUPPORTED\" Whether the device supports DTMF signaling. ConnectionState \u00b6 Values \u00b6 Value Description \"CONNECTED\" A calling device is connected. \"DISCONNECTED\" No calling device is connected. DTMFError \u00b6 Values \u00b6 Value Description \"CALL_NOT_IN_PROGRESS\" There is no active call through which a DTMF signal can be sent. \"DTMF_FAILED\" Generic DTMF error. CallError \u00b6 Values \u00b6 Value Description \"NO_CARRIER\" No carrier is available on the calling device. \"BUSY\" The calling device is busy when setting up an outbound call, such as when a call is already in progress. \"NO_ANSWER\" The remote party did not answer the call. \"NO_NUMBER_FOR_REDIAL\" Redial was requested, but there is no previously dialed number available. \"OTHER\" Generic error. CallState \u00b6 Values \u00b6 Value Description \"IDLE\" The call is not in an active state. \"DIALING\" The outbound call is initiated by the user. Call setup is in progress. \"OUTBOUND_RINGING\" The outbound call has been set up, and the remote party is alerted. \"ACTIVE\" The call is active, and media is being transmitted between the caller and remote party. \"CALL_RECEIVED\" An alert for the inbound call has been received. \"INBOUND_RINGING\" The inbound call is ringing.","title":"PhoneCallController"},{"location":"aasb/phone-control/PhoneCallController/#phonecallcontroller","text":"","title":"PhoneCallController"},{"location":"aasb/phone-control/PhoneCallController/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/phone-control/PhoneCallController/#senddtmf","text":"Notifies the platform implementation to send a DTMF signal to the calling device.","title":"SendDTMF"},{"location":"aasb/phone-control/PhoneCallController/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMF\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload","text":"Property Type Required Description Example payload String Yes Details of the DTMF request in structured JSON format.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#dial","text":"Notifies the platform implementation to initiate an outgoing phone call to the destination address.","title":"Dial"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Dial\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_1","text":"Property Type Required Description Example payload String Yes Details of the dial request in structured JSON format.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#redial","text":"Notifies the platform implementation to redial the last called phone number.","title":"Redial"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Redial\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_2","text":"Property Type Required Description Example payload String Yes Details of the redial request in structured JSON format.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#stop","text":"Notifies the platform implementation to end an ongoing call or stop inbound or outbound call setup.","title":"Stop"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Stop\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_3","text":"Property Type Required Description Example payload String Yes Details of the stop request in structured JSON format.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#answer","text":"Notifies the platform implementation to answer an inbound call.","title":"Answer"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Answer\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_4","text":"Property Type Required Description Example payload String Yes Details of the answer request in structured JSON format.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#createcallidreply","text":"Reply for CreateCallId message.","title":"CreateCallIdReply"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\", \"replyToId\": {{String}} } }, \"payload\": { \"callId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_5","text":"Property Type Required Description Example callId String Yes Unique identifier for a call.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/phone-control/PhoneCallController/#createcallid","text":"Generates a unique identifier for a call.","title":"CreateCallId"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\" } } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#callstatechanged","text":"Notifies the Engine of a change in the state of an ongoing call.","title":"CallStateChanged"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallStateChanged\" } }, \"payload\": { \"state\": {{CallState}}, \"callId\": {{String}}, \"callerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_6","text":"Property Type Required Description Example state CallState Yes The state of the call. callId String Yes The unique identifier associated with the call. callerId String No The identifier for a contact.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#senddtmfsucceeded","text":"Notifies the Engine that sending the DTMF signal succeeded.","title":"SendDTMFSucceeded"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFSucceeded\" } }, \"payload\": { \"callId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_7","text":"Property Type Required Description Example callId String Yes The unique identifier for the associated call.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#connectionstatechanged","text":"Notifies the Engine of a change in connection to a calling device.","title":"ConnectionStateChanged"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"ConnectionStateChanged\" } }, \"payload\": { \"state\": {{ConnectionState}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_8","text":"Property Type Required Description Example state ConnectionState Yes The state of connection to a calling device.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#callfailed","text":"Notifies the Engine of an error related to a call.","title":"CallFailed"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{CallError}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_9","text":"Property Type Required Description Example callId String Yes The unique identifier for the call associated with the error. code CallError Yes The error type. message String No A description of the error.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#calleridreceived","text":"Notifies the Engine that a caller id was received for an inbound call.","title":"CallerIdReceived"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallerIdReceived\" } }, \"payload\": { \"callId\": {{String}}, \"callerId\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_10","text":"Property Type Required Description Example callId String Yes The unique identifier for the call associated with the callId. callerId String Yes The caller's identifier or phone number.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#deviceconfigurationupdated","text":"Notifies the Engine of the calling feature configuration of the connected calling device.","title":"DeviceConfigurationUpdated"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"DeviceConfigurationUpdated\" } }, \"payload\": { \"configurationMap\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_11","text":"Property Type Required Description Example configurationMap String Yes A map of configuration properties to the boolean state of the properties.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#senddtmffailed","text":"Notifies the Engine that the DTMF signal could not be delivered to the remote party.","title":"SendDTMFFailed"},{"location":"aasb/phone-control/PhoneCallController/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{DTMFError}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/phone-control/PhoneCallController/#payload_12","text":"Property Type Required Description Example callId String Yes callId The unique identifier for the associated call. code DTMFError Yes The error type. message String No A description of the error.","title":"Payload"},{"location":"aasb/phone-control/PhoneCallController/#enums","text":"","title":"Enums"},{"location":"aasb/phone-control/PhoneCallController/#callingdeviceconfigurationproperty","text":"","title":"CallingDeviceConfigurationProperty"},{"location":"aasb/phone-control/PhoneCallController/#values","text":"Value Description \"DTMF_SUPPORTED\" Whether the device supports DTMF signaling.","title":"Values"},{"location":"aasb/phone-control/PhoneCallController/#connectionstate","text":"","title":"ConnectionState"},{"location":"aasb/phone-control/PhoneCallController/#values_1","text":"Value Description \"CONNECTED\" A calling device is connected. \"DISCONNECTED\" No calling device is connected.","title":"Values"},{"location":"aasb/phone-control/PhoneCallController/#dtmferror","text":"","title":"DTMFError"},{"location":"aasb/phone-control/PhoneCallController/#values_2","text":"Value Description \"CALL_NOT_IN_PROGRESS\" There is no active call through which a DTMF signal can be sent. \"DTMF_FAILED\" Generic DTMF error.","title":"Values"},{"location":"aasb/phone-control/PhoneCallController/#callerror","text":"","title":"CallError"},{"location":"aasb/phone-control/PhoneCallController/#values_3","text":"Value Description \"NO_CARRIER\" No carrier is available on the calling device. \"BUSY\" The calling device is busy when setting up an outbound call, such as when a call is already in progress. \"NO_ANSWER\" The remote party did not answer the call. \"NO_NUMBER_FOR_REDIAL\" Redial was requested, but there is no previously dialed number available. \"OTHER\" Generic error.","title":"Values"},{"location":"aasb/phone-control/PhoneCallController/#callstate","text":"","title":"CallState"},{"location":"aasb/phone-control/PhoneCallController/#values_4","text":"Value Description \"IDLE\" The call is not in an active state. \"DIALING\" The outbound call is initiated by the user. Call setup is in progress. \"OUTBOUND_RINGING\" The outbound call has been set up, and the remote party is alerted. \"ACTIVE\" The call is active, and media is being transmitted between the caller and remote party. \"CALL_RECEIVED\" An alert for the inbound call has been received. \"INBOUND_RINGING\" The inbound call is ringing.","title":"Values"},{"location":"aasb/text-to-speech/TextToSpeech/","text":"TextToSpeech \u00b6 Outgoing Messages \u00b6 PrepareSpeechFailed \u00b6 Notifies the platform implementation about a failed speech synthesis. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechFailed\" } }, \"payload\": { \"speechId\": {{String}}, \"reason\": {{String}} } } Payload \u00b6 Property Type Required Description Example speechId String Yes The speech ID. reason String Yes The failure reason. PrepareSpeechCompleted \u00b6 Notifies the platform implementation about a successful speech synthesis. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechCompleted\" } }, \"payload\": { \"speechId\": {{String}}, \"token\": {{String}}, \"source\": \"STREAM\", \"streamId\": {{String}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}}, \"metadata\": {{String}} } } Payload \u00b6 Property Type Required Description Example speechId String Yes The speech ID. token String Yes A unique token for this audio stream. source String Yes source description. streamId String Yes The URL audio stream being provided. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. metadata String Yes The metadata associated with the speech resource. GetCapabilitiesReply \u00b6 Reply for GetCapabilities message. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\", \"replyToId\": {{String}} } }, \"payload\": { \"capabilities\": {{String}} } } Payload \u00b6 Property Type Required Description Example capabilities String Yes The capabilities of the Text to Speech provider. Incoming Messages \u00b6 PrepareSpeech \u00b6 Prepare Speech from a text/SSML input. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeech\" } }, \"payload\": { \"speechId\": {{String}}, \"text\": {{String}}, \"provider\": {{String}}, \"options\": {{String}} } } Payload \u00b6 Property Type Required Description Example speechId String Yes The speech ID. text String Yes The text/SSML to be used for speech synthesis. provider String Yes The text to speech provider to be used for speech synthesis. options String No The options to be used for speech synthesis. GetCapabilities \u00b6 Get Capabilities of a Text to Speech provider. JSON Structure \u00b6 { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\" } }, \"payload\": { \"provider\": {{String}} } } Payload \u00b6 Property Type Required Description Example provider String Yes The provider string. Use text-to-speech-provider here.","title":"TextToSpeech"},{"location":"aasb/text-to-speech/TextToSpeech/#texttospeech","text":"","title":"TextToSpeech"},{"location":"aasb/text-to-speech/TextToSpeech/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"aasb/text-to-speech/TextToSpeech/#preparespeechfailed","text":"Notifies the platform implementation about a failed speech synthesis.","title":"PrepareSpeechFailed"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechFailed\" } }, \"payload\": { \"speechId\": {{String}}, \"reason\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/text-to-speech/TextToSpeech/#payload","text":"Property Type Required Description Example speechId String Yes The speech ID. reason String Yes The failure reason.","title":"Payload"},{"location":"aasb/text-to-speech/TextToSpeech/#preparespeechcompleted","text":"Notifies the platform implementation about a successful speech synthesis.","title":"PrepareSpeechCompleted"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechCompleted\" } }, \"payload\": { \"speechId\": {{String}}, \"token\": {{String}}, \"source\": \"STREAM\", \"streamId\": {{String}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}}, \"metadata\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_1","text":"Property Type Required Description Example speechId String Yes The speech ID. token String Yes A unique token for this audio stream. source String Yes source description. streamId String Yes The URL audio stream being provided. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. metadata String Yes The metadata associated with the speech resource.","title":"Payload"},{"location":"aasb/text-to-speech/TextToSpeech/#getcapabilitiesreply","text":"Reply for GetCapabilities message.","title":"GetCapabilitiesReply"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\", \"replyToId\": {{String}} } }, \"payload\": { \"capabilities\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_2","text":"Property Type Required Description Example capabilities String Yes The capabilities of the Text to Speech provider.","title":"Payload"},{"location":"aasb/text-to-speech/TextToSpeech/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"aasb/text-to-speech/TextToSpeech/#preparespeech","text":"Prepare Speech from a text/SSML input.","title":"PrepareSpeech"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeech\" } }, \"payload\": { \"speechId\": {{String}}, \"text\": {{String}}, \"provider\": {{String}}, \"options\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_3","text":"Property Type Required Description Example speechId String Yes The speech ID. text String Yes The text/SSML to be used for speech synthesis. provider String Yes The text to speech provider to be used for speech synthesis. options String No The options to be used for speech synthesis.","title":"Payload"},{"location":"aasb/text-to-speech/TextToSpeech/#getcapabilities","text":"Get Capabilities of a Text to Speech provider.","title":"GetCapabilities"},{"location":"aasb/text-to-speech/TextToSpeech/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\" } }, \"payload\": { \"provider\": {{String}} } }","title":"JSON Structure"},{"location":"aasb/text-to-speech/TextToSpeech/#payload_4","text":"Property Type Required Description Example provider String Yes The provider string. Use text-to-speech-provider here.","title":"Payload"},{"location":"android/","text":"Auto SDK Android Developer Guide \u00b6 Overview \u00b6 Use the Android developer documentation to understand how to set up, build, and integrate Auto SDK into your Android application. Get started by reading about Alexa Auto Client Service (AACS) .","title":"Overview"},{"location":"android/#auto-sdk-android-developer-guide","text":"","title":"Auto SDK Android Developer Guide"},{"location":"android/#overview","text":"Use the Android developer documentation to understand how to set up, build, and integrate Auto SDK into your Android application. Get started by reading about Alexa Auto Client Service (AACS) .","title":"Overview"},{"location":"android/aacs/","text":"Alexa Auto Client Service (AACS) \u00b6 Overview \u00b6 Alexa Auto Client Service (AACS) is an Alexa Auto SDK feature packaged in an Android archive library (AAR). By providing a common service framework, AACS simplifies the integration of the Auto SDK with your Android device and supports all the Auto SDK extensions. Your application communicates with AACS through an intent, which is a messaging object on an Android device. AACS provides the platform implementation for certain interfaces, which speeds up Alexa integration for in-vehicle infotainment (IVI). Without AACS, typical integration of the Auto SDK in the IVI involves the implementation of abstract interfaces provided by each Auto SDK module to handle platform-specific functionality. To implement all required platform interfaces, the Auto SDK is integrated to an event-based system that converts from direct method APIs to an event-based architecture. This document assumes that you understand how the Auto SDK works, as described in the Auto SDK concepts documentation . When this document uses the term \"application,\" it refers to the application you develop on the Android platform. Information for your application in this document also applies to your Android service. AACS Architecture \u00b6 The following diagram shows the high-level architecture of AACS on the Android platform. The shaded boxes in the diagram represent components developed by Amazon that are packaged in AACS. The following list describes the components in the AACS service layer, as illustrated in the diagram, and how they interact with one another and with the Auto SDK: AlexaAutoClientService is a persistent service that can start automatically after device boot-up or be manually started by an application through a startService() call. The service performs the following functions: Instantiating the Auto SDK Engine. Creating and registering the AASB message handler with the AASB MessageBroker. Setting the required Engine configuration. Managing the notifications displayed in the system notification area. PhoneControlMessagingImpl and NavigationMessagingImpl are messaging implementations that serialize direct API calls into a standardized message format. The PhoneControlMessagingImpl or NavigationMessagingImpl converts platform interface method parameters into the message payload of the respective messaging implementation. The message is then sent to the service layer by using the AASB MessageBroker with a specific message topic and action. The messaging implementation also subscribes to message topics that are sent from the human-machine interface (HMI) application to the Auto SDK. AudioInputImpl , AudioOutputImpl , ExternalMediaPlayerImpl , and AdditionalPlatformImpl are the direct implementations of Auto SDK platform interfaces. You can enable or disable the implementations in the AACS AAR through the configuration file. If an implementation is disabled, the platform message handler must be provided by a client application. AASB MessageBroker is an abstraction built on top of the Auto SDK core. MessageBroker routes messages between the application and the Auto SDK core. When the application responds to MessageBroker with an event, the event is routed back through the platform interface implementation. AASB MessageHandler implements the platform-specific logic to send and receive AASB messages. Mediaplayer handles the default AudioOutput actions, such as prepare, play, and pause for a TTS channel. IPCLibrary defines the protocol for the communication between the HMI application and AACS. It provides the APIs for sending and receiving AASB Messages over the Android Intent/Binder interface and supports streaming audio data to and from an external application. It builds into an Android archive (AAR) file, which you can include in other apps that need to communicate with AACS. For more information about the IPC, see this README . LVCInteractionProvider implements APIs defined by the ILVCClient Android Interface Definition Language (AIDL) file to connect with ILVCService , which is implemented by the Local Voice Control (LVC) application. This connection also enables the LVC APK to provide the configuration for LVC. The core of the HMI application that holds the business logic need not change with AlexaAutoClientService . However, you must modify the application so that it can interface with the APIs defined by AACS. Obtaining the AACS AAR \u00b6 AACS is packaged as an Android library (AAR). You can obtain the AACS AAR in one of two ways: To obtain the pre-built AACS AAR and the other dependency AARs which are required for using AACS, contact your Amazon Solutions Architect (SA) or Partner Manager for more information. To build the AACS AAR from source code, following the steps below. Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/service Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds AACS core service, as well as all the other needed dependencies (such as Auto SDK) required for AACS to function. It also generates AAR files that are used for communicating with AACS from your application. To install all the generated AARs to your application, add the installDeps task after the build command. Specify the path you want the artifacts to be installed to by using the -PinstallPath option. If -PinstallPath is not specified, the artifacts will be copied to alexa-auto-sdk/aacs/android/service/deploy by default. ./gradlew assembleLocalRelease installDeps -PinstallPath=<path/to/your/application/directory> Using AACS with Your Application \u00b6 This section provides information about how AACS works with your application. To build your application with AACS, you can either include AACS and the other dependencies as local sub-projects, or you can build them as AARs and copy to the libs folder of your application. Using AACS as a local module Include AACS and the other dependency libraries as sub-projects in the settings.gradle file of your project. In the build.gradle file of your application, add the following implementation statements: implementation project(':aacs') implementation project(':aacs-extra') implementation project(':aacs-maccandroid') implementation project(':aacsconstants') implementation project(':aacsipc') implementation project(':aacscommonutils') implementation project(':alexa-auto-tts') // replace the <path/to/Auto/SDK/AARs> placeholder with your path implementation fileTree(include: ['*.aar'], dir: <path/to/Auto/SDK/AARs>) See the ${AUTO_SDK_HOME}/aacs/android/sample-app/settings.gradle and ${AUTO_SDK_HOME}/aacs/android/sample-app/alexa-auto-app/build.gradle files of the AACS Sample App for more information. Using AACS as a local binary Include the AARs in the libs folder of your application. See Obtaining the AACS AAR for instructions of how to obtain the AACS AARs. Add the following implementation statement to the build.gradle file of your application: implementation fileTree(dir: 'libs', include: ['*.aar']) AACS as Foreground Service or System Service \u00b6 AACS runs as a started service on Android. The Initialization section describes how it is started; this section describes what you do to run AACS as a foreground service or a system service. As Foreground Service \u00b6 Typically, AACS is started as a foreground service, which has higher priority and continues running unless it is under memory constraints. In addition, the service displays notifications to alert the user that it is running. AACS is run as a foreground service if your application containg AACS AAR is not a system application. Then your application can use the startForegroundService() function to initialize AACS. If AACS is started properly, a notification is displayed. Since Android 8.0 (API level 26), foreground services have had some changes in how they are initialized. The following code checks the Android version and calls the correct API: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.O) { startForegroundService(intent); } else { startService(intent); } As Persistent System Service \u00b6 If you have root access on the device and your application containing AACS AAR is a system application, then AACS is run as a system service. Your application no longer needs to start AACS in the foreground, and no notifications appear to show that the service is running. The following example shows an application starting AACS as a system service: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); startService(intent); Note: persistentSystemService configuration is deprecated. You no longer need to specify this field to run AACS as a persistent system service. AACS Initialization and Configuration \u00b6 Initializing AACS means getting AACS ready to communicate with other applications. However, Alexa functionality is not available until AACS receives the configuration. Initialization \u00b6 There are two ways to initialize AACS: Start AACS from an application: AACS includes a permission that determines whether an application can start or stop the service. For an application to start or stop AACS, specify the permission name in the application's AndroidManifest.xml file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice\"/> For an example of starting AACS from an application, see example for starting AACS as a system service . Start AACS upon device boot: If you want AACS to start every time the user turns on the device, set startOnDeviceBootEnabled in aacs.general of your configuration to true . Due to this setting, AACS initiates a startService() call on itself when it receives the BOOT_COMPLETED intent, which the device broadcasts when it is finished booting. Important! The device considers AACS inactive until AACS is run at least once. AACS does not start automatically on device boot unless AACS is considered active. Simply run AACS at least once after installation, and AACS will start each time the device is restarted. Whether startOnDeviceBootEnabled is set to true or false , the application can always send a startService() or stopService() call to start or stop AACS. Configuration Schema \u00b6 This section describes the configuration schema, which includes Auto SDK engine configuration, general service behavioral settings, and definitions for how AACS interfaces with applications. For more information about AACS configuration, see Configuration Reference documentation . Important! Some configuration fields may require you to provide filepaths. These filepaths must be absolute paths that are accessible to AACS. AACS will not accept filepaths to public locations (such as SD card) for security reasons. The sample configuration JSON file in this section illustrates the AACS configuration structure. Be sure to fill out the following required sections under deviceInfo of aacs.alexa : clientId productId deviceSerialNumber The following documents provide more information about configuration: Auto SDK module documentation Complete configuration file { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"name\", \"description\": \"description\" }, \"localMediaSource\": { \"types\": [] }, \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 50000 } }, \"aacs.vehicle\": { \"info\": { \"make\": \"Amazon\", \"model\": \"AACE\", \"year\": \"2020\", \"trim\": \"aac\", \"geography\": \"US\", \"version\": \"1.2.3\", \"os\": \"Sample OS 1.0\", \"arch\": \"Sample Arch 1.0\", \"language\": \"en-US\", \"microphone\": \"SingleArray\", \"countries\": \"US,GB,IE,CA,DE,AT,IN,JP,AU,NZ,FR\", \"vehicleIdentifier\": \"Sample Identifier ABC\" }, \"operatingCountry\": \"US\" }, \"aacs.cbl\": { \"enableUserProfile\": false }, \"aacs.carControl\": { \"endpoints\":[], \"zones\":[] }, \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"intentTargets\" : { \"AASB\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, ... (Other topics omitted) } }, \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } } } Sending a Configuration Message \u00b6 Sending the configuration relies on the provided IPC library . This section describes the configuration's basic syntax. The message structure consists of two fields, configFilepaths and configStrings . configFilepaths is a String array containing paths to files which hold full or partial configuration JSON. configStrings is a String array containing full or partial configurations in the form of escaped JSON Strings. All partial configurations (from filepath or String) will be reconstructed by AACS to be a single, full configuration. We recommend using the configStrings option. See the Important note on filepaths in the beginning of the Configuration section. The following code shows an empty configMessage : { \"configFilepaths: [], \"configStrings\": [] } Using an instance of AACSSender , the sendConfigMessageEmbedded() or sendConfigMessageAnySize() method ensures that the configuration message can be sent to AACS. The following example shows how to construct and send the configuration message: try { String config = \"...\"; // configuration read from file JSONObject configJson = new JSONObject(config); JSONArray configStringsArray = new JSONArray(); configStringsArray.put(configJson.toString()); // add escaped JSON string JSONObject configMessage = new JSONObject(); configMessage.put(\"configFilepaths\", new JSONArray()); configMessage.put(\"configStrings\", configStringsArray); aacsSender.sendConfigMessageAnySize(configMessage.toString(), target, getApplicationContext()); } catch (JSONException e) { ... } File Sharing and Permissions \u00b6 Some configurable fields for the Auto SDK require paths to files in your application, which is inaccessible to AACS. To enable the Auto SDK to get the file paths, AACS provides a protocol for applications to grant the Auto SDK URI permissions for these files. AACS then creates a local copy of the file in its internal storage and configures the fields for the Auto SDK, using the file path to the local copy to ensure accessibility. Fields that require file sharing are described in documentation. Currently, only installed extensions have configurable fields that need file sharing. See the AACS README for your extension for more information about file sharing. AACS's file sharing protocol uses Android's FileProvider class to securely receive the URIs of files in applications. See the Android documentation on how to set up FileProvider in your application. Your FileProvider is functional after the application includes a <provider> element in its AndroidManifest and a filepaths.xml file for specifying shareable paths. After FileProvider is set up, AACS expects to receive an intent with action Intent.ACTION_SEND_MULTIPLE to include the URIs of files to be shared. Send the intent after service initialization but before the configuration message is sent. It requires the following structure: Action: Intent.ACTION_SEND_MULTIPLE - The standard Android intent for sharing multiple pieces of content Type: The MIME type of a URI Extra: AACSConstants.CONFIG_MODULE or configModule - A String representing the module to be configured by the shared files ParcelableArrayListExtra: Intent.EXTRA_STREAM - An ArrayList<Uri> containing URIs of files to be shared Before sending the intent, be sure to grant the Intent.FLAG_GRANT_READ_URI_PERMISSION to AACS for each URI being sent. Also, because the intent holds multiple file URIs for a single configuration module at a time, if there are multiple files for separate modules, send multiple intents, as shown in the following example implementation: private void shareFilePermissionsOfSameModule(File parent, String[] filenames, String module) { ArrayList<Uri> fileUris = new ArrayList<>(); for (String name : filenames) { File file = new File(parent, name); Uri fileUri = FileProvider.getUriForFile( MainActivity.this, <your-application's-provider>, file); grantUriPermission(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), fileUri, Intent.FLAG_GRANT_READ_URI_PERMISSION); fileUris.add(fileUri); } Intent shareFileIntent = new Intent(); shareFileIntent.setComponent( new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), AACSConstants.AACS_CLASS_NAME)); shareFileIntent.setAction(Intent.ACTION_SEND_MULTIPLE); shareFileIntent.setType(getContentResolver().getType(fileUris.get(0))); shareFileIntent.putExtra(AACSConstants.CONFIG_MODULE, module); shareFileIntent.putParcelableArrayListExtra(Intent.EXTRA_STREAM, fileUris); startForegroundService(shareFileIntent); } Note: AACSConstants.AACS_PACKAGE_NAME is deprecated and it shall be removed from the future Alexa Auto SDK versions. Use AACSConstants.getAACSPackageName(Context) instead. Initialization Protocol \u00b6 After starting the service, send file sharing intents for any files outside of AACS's access that will be needed for configuration. Then, send the configuration message. If there are no files to be shared, the configuration can be sent immediately after AACS is initialized. The configuration is not part of the initial intent to start the service because intents in Android have size limits, which the configuration might exceed. Using the provided IPC library allows for sending configuration of any size. Because AACS stores the last configuration received, the only requirement is that the configuration is sent the first time AACS is run after installation. At any subsequent start, AACS uses the stored configuration. Similarly for shared files, AACS retains local copies of the files, so file sharing intents do not have to be re-sent in subsequent launches. However, updating the stored configuration (without uninstalling the application containing AACS AAR) requires that the startService intent include an Extras field called newConfig . newConfig holds a boolean value that alerts AACS not to start running with the stored configuration, but wait for a new configuration message. In addition, whenever the newConfig field is set to true , AACS clears all local copies of shared files and expect new file sharing intents, if necessary for the new configuration. Note : The old configuration is overwritten by the new configuration. For your application to start AACS with a new configuration, make sure your intent includes newConfig , as shown in the following example: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); intentStartService.putExtra(\"newConfig\", true); Omitting newConfig is the same as setting it to false , which causes AACS to use the stored configuration. Important : Sending a new configuration is allowed only once per service run. After AACS is configured and running, AACS ignores subsequent attempts to update the configuration, even if the newConfig field is true . To update an existing configuration, you must stop the service and restart it with newConfig set to true . This same rule applies to file sharing intents. Initialization Sequence Diagram \u00b6 The following diagram shows an example of initializing AACS from an app used by a driver. Default Platform Implementation \u00b6 Default platform implementations refer to implementations of Auto SDK platform interfaces that AACS provides to replace the normal protocol of using AASB messages. By enabling a default platform implementation in AACS, you no longer have to handle messages for a particular platform interface and can rely on AACS to provide the necessary functionality. AACS provides a default implementation for these platform interfaces: AudioInput (audioType: VOICE, COMMS) AudioOutput (audioType: TTS, ALARM, NOTIFICATIONS, EARCON, RINGTONE) LocationProvider NetworkInfoProvider ExternalMediaAdapter for Media App Command and Control (MACC) LocalMediaSource PropertyManager The platform implementations for these interfaces are disabled by default; the AASB messages for these interfaces are routed to the client app to be handled . To enable the default platform implementation in AACS, you must set the aacs.defaultPlatformHandlers configuration flags. In the following example, you use aacs.defaultPlatformHandlers in the configuration file to instruct AACS to handle LocationProvider and NetworkInfoProvider , AudioInput for VOICE , and AudioOutput for TTS . Specific apps handle the other messages. \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, ... other audio types } } } Property Content Provider Implementation (Optional) \u00b6 AACS supports the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. Using a content provider offers the following advantages: AACS can consistently provide the properties across multiple launches. Because properties are persistent, your application does not need to reset the properties after each AACS restart. AACS messages are asynchronous, which might cause timeouts and subsequently incorrect or error states. Using a content provider to retrieve state data makes the retrieval process synchronous, thus guaranteeing that the request for state information reaches its destination and a response is received. ContentProvider is the standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. Sequence Diagram and Overview \u00b6 The following sequence diagram illustrates the workflow for the default property manager implementation in AACS. This implementation provides the interface, based on the Android ContentProvider , for OEM apps to get and set Auto SDK properties. aace.alexa.wakewordSupported aace.alexa.system.firmwareVersion aace.alexa.setting.locale aace.alexa.countrySupported aace.alexa.timezone aace.alexa.wakewordEnabled aace.vehicle.operatingCountry aace.core.version aace.network.networkInterface By using the native Android ContentProvider class, you can initiate query and update operations. query retrieves and returns the current String value of an Auto SDK property. update sets an Auto SDK property in the Engine and returns a boolean value based on the success of the operation. Insert and Delete operations are disabled for Auto SDK properties. Implementation Examples \u00b6 Add useDefaultPropertyManager in the config.json file and set it to true , as shown in the following example: ... \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, --> \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { ... Add READ_USER_DICTIONARY permission to AndroidManifest.xml in your application, as shown in the following example: <uses-permission... <uses-permission android:name=\"android.permission.READ_USER_DICTIONARY\" /> <uses-permission... In the application implementation, set the URI for getting the ContentResolver instance as follows: private final Uri uri = Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI); Register ContentObserver for monitoring any Auto SDK property changes that are initiated by the engine. ContentObserver is a native Android class which observes changes to data and will call its onChange() method to perform callbacks when a content change occurs. It includes the changed content Uri when available. To register ContentObserver , first register your application with ContentObserver // PropertyHandler is an example class using ContentProvider API to query and update properties in your application PropertyHandler alexaPropertyHandler = new PropertyHandler(this); // PropertyContentObserver is an example implementation of the callback for property changes PropertyContentObserver propertyObserver = new PropertyContentObserver(alexaPropertyHandler, this); getContentResolver().registerContentObserver(Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI), true, propertyObserver); Then implement the PropertyContentObserver class and add the desired callback behavior in method onChange() : public class PropertyContentObserver extends ContentObserver { private static Activity mActivity; public PropertyContentObserver(Handler handler, Activity activity) { super(handler); mActivity = activity; } @Override public void onChange(boolean changed) { this.onChange(changed, null); } @Override public void onChange(boolean changed, Uri uri) { // Do something when content change occurs } } Perform query() and update() operation within application using the previously set URI: query() Cursor cursor = getContentResolver().query(uri, null, propertyName, null, null); cursor.moveToFirst(); String propertyValue = cursor.getString(1); update() must be called in its own thread, not the main UI thread since update() calls setProperty and receive the result asynchronously. ExecutorService mExecutor; ContentValues cv = new ContentValues(); cv.put(propertyName, propertyValue); if (mExecutor == null ) { mExecutor = Executors.newSingleThreadExecutor(); } else { synchronized (OEMApplication.class) { if (mExecutor.isShutdown()) { // Log warning that Executor has already been shut down for update. Not updating property. } mExecutor.submit(() -> { getContentResolver().update(uri, cv, propertyName, null); }); } } Important Considerations for Using ContentProvider \u00b6 AACS Property Content Provider does not support the insert and delete APIs in Property ContentProvider; You must use AACS with the AmazonLite Wake Word extension if you want to update aace.alexa.wakewordEnabled property; aace.alexa.countrySupported is a deprecated property and cannot be get/set; aace.alexa.wakewordSupported and aace.core.version are read-only properties acquired when building Auto SDK and cannot be set. Valid property value for aace.alexa.wakewordEnabled is true or false . All the other Auto SDK properties will be validated by Auto SDK. Auto SDK will provide value validation for aace.alexa.wakewordEnabled in the future. Enabling AACS to synchronize Alexa's Time Zone and Locale with Device Settings (Optional) \u00b6 AACS supports synchronizing Alexa's time zone and locale properties with the ones in device settings. To enable the functionality, refer to this README for proper configuration. Once enabled, AACS will synchronize the time zone and/or locale properties of Alexa with the device settings in the following conditions: When Auto SDK engine is initialized, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. When the authorization state is refreshed, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. When AACS gets android.intent.action.LOCALE_CHANGED intent as a result of device locale setting change, Alexa locale property will be updated if the locale is supported by Alexa. When AACS gets android.intent.action.TIMEZONE_CHANGED intent as a result of device time zone setting change, Alexa time zone property will be updated. You can also disable the automatic synchronization for specific properties. This is particularly useful when your application wants to disable/enable the synchronization at runtime. For example, after the user manually selects a locale, you may want to disable the synchronization to allow the user's selection to override the system setting changes. To achieve this use case, your application can send intents with the metadata below to AACS: Action: Disable: com.amazon.aacs.syncSystemPropertyChange.disable Enable: com.amazon.aacs.syncSystemPropertyChange.enable Category: com.amazon.aacs.syncSystemPropertyChange Extra: \"property\": <alexa_property_name> If this feature is not enabled, your application can still have the full flexibility in changing the two properties by handling AASB Property Manager messages. Additionally, you can configure AACS to update the system time zone if the user changes the Alexa's time zone for the device (e.g. the user can change the property on their Alexa mobile app). To enable the functionality, refer to this README for proper configuration. Your application with AACS needs to be a system application with android permission android.permission.SET_TIME_ZONE obtained. Note: Always provide the system permission android.permission.SET_TIME_ZONE when AACS AAR is in a system application. Refer to Privileged Permission Allowlisting in Android documentation. Using Custom Domain Module with CustomDomainMessageDispatcher Enabled (Optional) \u00b6 To use Custom Domain module with AACS, you need to explicitly enable it first by adding module enablement configuration. Please refer to AACS Configuration README to enable the Custom Domain module. By default, all the Custom Domain intents share the same com.amazon.aacs.aasb.customDomain intent category. If CustomDomainMessageDispatcher is enabled, the intent category will be the namespace of the custom interface prefixed with com.amazon.aacs.customDomain , which allows AACS to dispatch the Custom Domain AASB messages from the engine to the proper components in your system based on the custom namespace. Below is the intent schema of the intents sent from the dispatcher. All the intents are sent with our IPC library . You can use AACSReceiver to receive and process the AASB Custom Domain messages in the intents. Intent for handling/canceling a custom directive: Action: com.amazon.aacs.customDomain.<custom-directive-name> . Category: com.amazon.aacs.customDomain.<custom-directive-namespace> . Intent for getting the context for a custom namespace: Action: com.amazon.aacs.customDomain.GetContext Category: com.amazon.aacs.customDomain.<custom-context-namespace> . You can define intent filters in the Android Manifest of your applications to subscribe to the specific Custom Domain intents. See Specifying the Intent Targets for Handling Messages Using Android Manifest to learn more about specifying intent targets. Please refer to this README on enabling CustomDomainMessageDispatcher. Note : CustomDomainMessageDispatcher does not process any custom directives. Your application is responsible for handling any custom directives, sending custom events, and providing custom contexts following the Custom Domain AASB Documentation . If the dispatcher is not enabled, your application will be responsible for receiving all the Custom Domain AASB Messages (as intents) at one place. Specifying the Intent Targets for Handling Messages \u00b6 The AASB message intent targets can be ACTIVITY , RECEIVER , or SERVICE . There are two ways to specify the intent targets for AASB message intents from AACS. Using Android Manifest \u00b6 You can define intent filters in your application's Android Manifest. The intent filter must exactly match the intents' categories and actions. In the intent filter for an intent that wraps an AASB message, specify the category as com.amazon.aacs.aasb.<AASB_Message_Topic> and action as com.amazon.aacs.aasb.<AASB_Message_Action> . The following example shows an intent filter of all the CBL message intents for a broadcast receiver target: <intent-filter> <action android:name=\"com.amazon.aacs.aasb.CBLStateChanged\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairReceived\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairExpired\"/> <action android:name=\"com.amazon.aacs.aasb.SetProfileName\"/> <action android:name=\"com.amazon.aacs.aasb.GetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.SetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.ClearRefreshToken\"/> <category android:name=\"com.amazon.aacs.aasb.CBL\" /> </intent-filter> To receive the message specified through the Android Manifest, the application must also have com.amazon.alexaautoclientservice permission in its Android Manifest. <uses-permission android:name=\"com.amazon.alexaautoclientservice\" /> Follow these important guidelines if the intent target is an activity: You must add <category android:name=\"android.intent.category.DEFAULT\" /> to the intent filter as explained here . Be aware that if you start applications with AACS (for example, by specifying Activity as the intent targets from AACS), the target Activity will move to the foreground or become in focus, causing distraction or confusion to the user. AACS does not request SYSTEM_ALERT_WINDOW permission to directly create windows on top of all other apps. Amazon recommends using VIS (VoiceInteractionService) to launch activities, and using Android Services or Broadcast Receivers to receive intents from AACS. Using AACS Configuration File \u00b6 You can use the AACS configuration file to specify the app that can handle AASB messages with a specific \"topic\". This method of specifying intent targets has the highest priority, meaning it can override the ones specified through intent filters in manifests. After you use the AACS configuration to specify the app, intents with all the actions belonging to the topic go to the specified targets. Fill the optional fields in intentTargets in the AACS configuration file as needed. See the Configuration Reference documentation for information about intentTargets . The following sample configuration shows how to populate intentTargets for each topic. The field type accepts RECEIVER , ACTIVITY , and SERVICE , depending on the type of the target that handles the intents with the topic. The targets can be broadcast receiver, application activity, and service. The format for specifying AASB message intent targets for an AASB message topic is as follows: \"<topic>\" : { \"type\": [<target_1_type>, <target_2_type>, ...], \"package\": [\"<target_1_package_name>\", \"<target_2_package_name>\", ...], \"class\": [\"<target_1_class_name>\", \"<target_2_class_name>\", ...] }, The following example shows two topics, which are AASB and APL : \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\": [\"ACTIVITY\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\"com.amazon.aacstestapp.MainActivity\"] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\".IntentReceiver\"] // short version of class name is also accepted. }, // In this case, the class must be in the package specified in \"package\". // ... other topics } } NOTE : If a given \"topic\" is specified both in the configuration file and the Android Manifest, the configuration file takes priority and the targets with intent filters are ignored. Amazon recommends intent filters when possible. Use the configuration approach only if you need to override the existing intent filters. AACS first searches for targets for an intent with a topic in the configuration file. If nothing is found, the package manager scans the intent filters on the device to locate a match. AACS also caches the scan results based on both topic and action. The cache is cleared every time AACS is restarted. Platform Implementation in Your Application \u00b6 Your applications can register for specific AASB messages and provide a platform implementation. For example, an application (\u201cLogin app\") can register for Authorization messages. For information about the Authorization module, see the Core module documentation. Initial Authentication Sequence Diagram \u00b6 The following sequence diagram illustrates how an application (\u201cLogin app\") exchanges messages with AACS over Android Intents to log in the user for Alexa. Wake Word Enabled Sequence Diagram \u00b6 The sequence diagram illustrates the sequence for the user to access Alexa if you use the default implementation of AudioInput in AACS. In this diagram, the driver is logged in and wake word is enabled. The driver initiates the action by uttering the Alexa wake word. Audio is processed locally by the wake word engine in AACS until the wake word is detected. Upon wake word detection, AACS notifies the application that the dialog state has changed to \"listening\" and initiates a Recognize event with Alexa. While in the listening state, audio data is sent to Alexa. When the end of speech is detected, Alexa sends a StopCapture directive to AACS, and the dialog state is changed to \"thinking.\" Alexa then responds with additional directives in response to the speech request. For information about other messages to provide your implementation in the client APK, please refer to the documentation for each Auto SDK module. Client Utility Library \u00b6 AACS also provides an optional library, AACS Common Utils . It contains useful methods to make messaging with AACS easier. You can use it as-is or as a reference to facilitate the integration of the Auto SDK with AACS. For information about the library, see AACS Common Utils README and in-code documentation in the library. Device Settings Required for AACS \u00b6 AACS requires microphone and location permissions when the default implementation is used for AudioInput and Location. If AACS runs in a system application, you can grant these permissions so that the application users do not have to set the permissions. Otherwise, be sure to instruct your users to grant the following permissions on the app info page under Settings on their device: Location: Enable android.permission.ACCESS_FINE_LOCATION to give AACS access the current location. Microphone: Enable android.permission.RECORD_AUDIO to give permission to AACS to record audio. Microphone must be enabled if you configure AudioInput to use the default implementation of AACS. Checking AACS Connection State \u00b6 Your application or service can check the status of AACS by using ping , which returns a response as long as AACS is running. The AACSPinger utility class from the IPC library enables you to use ping . To ping AACS, specify the ping permission name in your application's Android Manifest file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice.ping\"/> The following example shows how to use AACSPinger : AACSPinger aacsPinger = new AACSPinger(getApplicationContext(), \"com.amazon.alexaautoclientservice.ping\"); Future<AACSPinger.AACSPingResponse> fut = aacsPinger.pingAACS(); AACSPinger.AACSPingResponse response = fut.get(); if (response.hasResponse) { // Ping was responded to by AACS String state = response.AACSState; ... } else { // Ping timed out without an AACS response } If AACS responds to the ping request, the AACSPingResponse.AACSState string returned by AACSPinger.pingAACS() has one of the following values: STARTED WAIT_FOR_LVC_CONFIG CONFIGURED ENGINE_INITIALIZED CONNECTED STOPPED If AACS does not respond within the default timeout of 1 second, AACSPingResponse.hasResponse is false . AACS State Notification \u00b6 As an alternative to pinger where the application or service can fetch the AACS State, AACS also broadcast the various state transitions. Your application needs to register a receiver for the following intent action: \"com.amazon.aacs.service.statechanged\" This is defined in AACS Constants as ACTION_STATE_CHANGE The following example shows an intent receiver to receive AACS State transition events: mAACSStateIntentReceiver = new aacsStateIntentReceiver(); IntentFilter filter = new IntentFilter(); filter.addAction(AACSConstants.ACTION_STATE_CHANGE); (context.get()).registerReceiver(mAACSStateIntentReceiver, filter); Request list of extras from AACS \u00b6 Your application can receive the list of AACS extra modules by sending an intent with the action AACSConstants.IntentAction.GET_SERVICE_METADATA and the category AACSConstants.IntentCategory.GET_SERVICE_METADATA , which returns a response by receiving an intent AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . To get the extras list from AACS- Specify the permission name in your application's Android Manifest file as follows: <uses-permission android:name= \"com.amazon.alexaautoclientservice.getservicemetadata\" /> Register a receiver in you application's Android Manifest file as follows: Following block shows an example of requesting list of extras: <receiver android:name= \".<Receiver Class>\" android:enabled= \"true\" android:exported= \"true\" /> Send a request intent to AACS. Following code snippet shows an example Intent intent = new Intent (); intent . setAction ( AACSConstants . IntentAction . GET_SERVICE_METADATA ); intent . addCategory ( AACSConstants . IntentCategory . GET_SERVICE_METADATA ); intent . putExtra ( AACSConstants . REPLY_TO_PACKAGE , getPackageName ()); intent . putExtra ( AACSConstants . REPLY_TO_CLASS , < Receiver_Class_Name > . class . getName ()); intent . putExtra ( AACSConstants . REPLY_TYPE , \"RECEIVER\" ); sendBroadcast ( intent ); Your receiver class will receive an intent with the following payload { \"metaData\" : { \"extrasModuleList\" : [] } } You can get the payload from the received intent with action AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . Following code snippet shows the example: String payload = intent . getStringExtra ( AACSConstants . PAYLOAD ); Using Instrumentation \u00b6 You can use AACS instrumentation to log AASB messages for debugging purposes. For more information about how to use instrumentation, see the AACS Instrumentation README . Note: You can use instrumentation only if you use the debug option when building the Auto SDK with AACS. Including App Components with AACS AAR in your application \u00b6 The Auto SDK provides packages (also called \"app components\") in the $AAC_SDK_HOME/aacs/android/app-components directory. App components could be included in your application along with AACS AAR to speed up the Alexa integration. Note: Some app components implement the handling of AASB messages for certain topics, allowing your applications to interface with AACS by using standard Android APIs. If you include such app components in your application with AACS AAR, your application does not need to handle the AASB messages for those particular AASB topics. AACS Sample App \u00b6 The Auto SDK includes an Android-based application that demonstrates how an application uses AACS. For more information about the AACS Sample App, see the AACS Sample App README .","title":"AACS Overview"},{"location":"android/aacs/#alexa-auto-client-service-aacs","text":"","title":"Alexa Auto Client Service (AACS)"},{"location":"android/aacs/#overview","text":"Alexa Auto Client Service (AACS) is an Alexa Auto SDK feature packaged in an Android archive library (AAR). By providing a common service framework, AACS simplifies the integration of the Auto SDK with your Android device and supports all the Auto SDK extensions. Your application communicates with AACS through an intent, which is a messaging object on an Android device. AACS provides the platform implementation for certain interfaces, which speeds up Alexa integration for in-vehicle infotainment (IVI). Without AACS, typical integration of the Auto SDK in the IVI involves the implementation of abstract interfaces provided by each Auto SDK module to handle platform-specific functionality. To implement all required platform interfaces, the Auto SDK is integrated to an event-based system that converts from direct method APIs to an event-based architecture. This document assumes that you understand how the Auto SDK works, as described in the Auto SDK concepts documentation . When this document uses the term \"application,\" it refers to the application you develop on the Android platform. Information for your application in this document also applies to your Android service.","title":"Overview"},{"location":"android/aacs/#aacs-architecture","text":"The following diagram shows the high-level architecture of AACS on the Android platform. The shaded boxes in the diagram represent components developed by Amazon that are packaged in AACS. The following list describes the components in the AACS service layer, as illustrated in the diagram, and how they interact with one another and with the Auto SDK: AlexaAutoClientService is a persistent service that can start automatically after device boot-up or be manually started by an application through a startService() call. The service performs the following functions: Instantiating the Auto SDK Engine. Creating and registering the AASB message handler with the AASB MessageBroker. Setting the required Engine configuration. Managing the notifications displayed in the system notification area. PhoneControlMessagingImpl and NavigationMessagingImpl are messaging implementations that serialize direct API calls into a standardized message format. The PhoneControlMessagingImpl or NavigationMessagingImpl converts platform interface method parameters into the message payload of the respective messaging implementation. The message is then sent to the service layer by using the AASB MessageBroker with a specific message topic and action. The messaging implementation also subscribes to message topics that are sent from the human-machine interface (HMI) application to the Auto SDK. AudioInputImpl , AudioOutputImpl , ExternalMediaPlayerImpl , and AdditionalPlatformImpl are the direct implementations of Auto SDK platform interfaces. You can enable or disable the implementations in the AACS AAR through the configuration file. If an implementation is disabled, the platform message handler must be provided by a client application. AASB MessageBroker is an abstraction built on top of the Auto SDK core. MessageBroker routes messages between the application and the Auto SDK core. When the application responds to MessageBroker with an event, the event is routed back through the platform interface implementation. AASB MessageHandler implements the platform-specific logic to send and receive AASB messages. Mediaplayer handles the default AudioOutput actions, such as prepare, play, and pause for a TTS channel. IPCLibrary defines the protocol for the communication between the HMI application and AACS. It provides the APIs for sending and receiving AASB Messages over the Android Intent/Binder interface and supports streaming audio data to and from an external application. It builds into an Android archive (AAR) file, which you can include in other apps that need to communicate with AACS. For more information about the IPC, see this README . LVCInteractionProvider implements APIs defined by the ILVCClient Android Interface Definition Language (AIDL) file to connect with ILVCService , which is implemented by the Local Voice Control (LVC) application. This connection also enables the LVC APK to provide the configuration for LVC. The core of the HMI application that holds the business logic need not change with AlexaAutoClientService . However, you must modify the application so that it can interface with the APIs defined by AACS.","title":"AACS Architecture"},{"location":"android/aacs/#obtaining-the-aacs-aar","text":"AACS is packaged as an Android library (AAR). You can obtain the AACS AAR in one of two ways: To obtain the pre-built AACS AAR and the other dependency AARs which are required for using AACS, contact your Amazon Solutions Architect (SA) or Partner Manager for more information. To build the AACS AAR from source code, following the steps below. Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/service Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds AACS core service, as well as all the other needed dependencies (such as Auto SDK) required for AACS to function. It also generates AAR files that are used for communicating with AACS from your application. To install all the generated AARs to your application, add the installDeps task after the build command. Specify the path you want the artifacts to be installed to by using the -PinstallPath option. If -PinstallPath is not specified, the artifacts will be copied to alexa-auto-sdk/aacs/android/service/deploy by default. ./gradlew assembleLocalRelease installDeps -PinstallPath=<path/to/your/application/directory>","title":"Obtaining the AACS AAR"},{"location":"android/aacs/#using-aacs-with-your-application","text":"This section provides information about how AACS works with your application. To build your application with AACS, you can either include AACS and the other dependencies as local sub-projects, or you can build them as AARs and copy to the libs folder of your application. Using AACS as a local module Include AACS and the other dependency libraries as sub-projects in the settings.gradle file of your project. In the build.gradle file of your application, add the following implementation statements: implementation project(':aacs') implementation project(':aacs-extra') implementation project(':aacs-maccandroid') implementation project(':aacsconstants') implementation project(':aacsipc') implementation project(':aacscommonutils') implementation project(':alexa-auto-tts') // replace the <path/to/Auto/SDK/AARs> placeholder with your path implementation fileTree(include: ['*.aar'], dir: <path/to/Auto/SDK/AARs>) See the ${AUTO_SDK_HOME}/aacs/android/sample-app/settings.gradle and ${AUTO_SDK_HOME}/aacs/android/sample-app/alexa-auto-app/build.gradle files of the AACS Sample App for more information. Using AACS as a local binary Include the AARs in the libs folder of your application. See Obtaining the AACS AAR for instructions of how to obtain the AACS AARs. Add the following implementation statement to the build.gradle file of your application: implementation fileTree(dir: 'libs', include: ['*.aar'])","title":"Using AACS with Your Application"},{"location":"android/aacs/#aacs-as-foreground-service-or-system-service","text":"AACS runs as a started service on Android. The Initialization section describes how it is started; this section describes what you do to run AACS as a foreground service or a system service.","title":"AACS as Foreground Service or System Service"},{"location":"android/aacs/#as-foreground-service","text":"Typically, AACS is started as a foreground service, which has higher priority and continues running unless it is under memory constraints. In addition, the service displays notifications to alert the user that it is running. AACS is run as a foreground service if your application containg AACS AAR is not a system application. Then your application can use the startForegroundService() function to initialize AACS. If AACS is started properly, a notification is displayed. Since Android 8.0 (API level 26), foreground services have had some changes in how they are initialized. The following code checks the Android version and calls the correct API: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.O) { startForegroundService(intent); } else { startService(intent); }","title":"As Foreground Service"},{"location":"android/aacs/#as-persistent-system-service","text":"If you have root access on the device and your application containing AACS AAR is a system application, then AACS is run as a system service. Your application no longer needs to start AACS in the foreground, and no notifications appear to show that the service is running. The following example shows an application starting AACS as a system service: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); startService(intent); Note: persistentSystemService configuration is deprecated. You no longer need to specify this field to run AACS as a persistent system service.","title":"As Persistent System Service"},{"location":"android/aacs/#aacs-initialization-and-configuration","text":"Initializing AACS means getting AACS ready to communicate with other applications. However, Alexa functionality is not available until AACS receives the configuration.","title":"AACS Initialization and Configuration"},{"location":"android/aacs/#initialization","text":"There are two ways to initialize AACS: Start AACS from an application: AACS includes a permission that determines whether an application can start or stop the service. For an application to start or stop AACS, specify the permission name in the application's AndroidManifest.xml file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice\"/> For an example of starting AACS from an application, see example for starting AACS as a system service . Start AACS upon device boot: If you want AACS to start every time the user turns on the device, set startOnDeviceBootEnabled in aacs.general of your configuration to true . Due to this setting, AACS initiates a startService() call on itself when it receives the BOOT_COMPLETED intent, which the device broadcasts when it is finished booting. Important! The device considers AACS inactive until AACS is run at least once. AACS does not start automatically on device boot unless AACS is considered active. Simply run AACS at least once after installation, and AACS will start each time the device is restarted. Whether startOnDeviceBootEnabled is set to true or false , the application can always send a startService() or stopService() call to start or stop AACS.","title":"Initialization"},{"location":"android/aacs/#configuration-schema","text":"This section describes the configuration schema, which includes Auto SDK engine configuration, general service behavioral settings, and definitions for how AACS interfaces with applications. For more information about AACS configuration, see Configuration Reference documentation . Important! Some configuration fields may require you to provide filepaths. These filepaths must be absolute paths that are accessible to AACS. AACS will not accept filepaths to public locations (such as SD card) for security reasons. The sample configuration JSON file in this section illustrates the AACS configuration structure. Be sure to fill out the following required sections under deviceInfo of aacs.alexa : clientId productId deviceSerialNumber The following documents provide more information about configuration: Auto SDK module documentation Complete configuration file { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"name\", \"description\": \"description\" }, \"localMediaSource\": { \"types\": [] }, \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 50000 } }, \"aacs.vehicle\": { \"info\": { \"make\": \"Amazon\", \"model\": \"AACE\", \"year\": \"2020\", \"trim\": \"aac\", \"geography\": \"US\", \"version\": \"1.2.3\", \"os\": \"Sample OS 1.0\", \"arch\": \"Sample Arch 1.0\", \"language\": \"en-US\", \"microphone\": \"SingleArray\", \"countries\": \"US,GB,IE,CA,DE,AT,IN,JP,AU,NZ,FR\", \"vehicleIdentifier\": \"Sample Identifier ABC\" }, \"operatingCountry\": \"US\" }, \"aacs.cbl\": { \"enableUserProfile\": false }, \"aacs.carControl\": { \"endpoints\":[], \"zones\":[] }, \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"intentTargets\" : { \"AASB\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, ... (Other topics omitted) } }, \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } } }","title":"Configuration Schema"},{"location":"android/aacs/#sending-a-configuration-message","text":"Sending the configuration relies on the provided IPC library . This section describes the configuration's basic syntax. The message structure consists of two fields, configFilepaths and configStrings . configFilepaths is a String array containing paths to files which hold full or partial configuration JSON. configStrings is a String array containing full or partial configurations in the form of escaped JSON Strings. All partial configurations (from filepath or String) will be reconstructed by AACS to be a single, full configuration. We recommend using the configStrings option. See the Important note on filepaths in the beginning of the Configuration section. The following code shows an empty configMessage : { \"configFilepaths: [], \"configStrings\": [] } Using an instance of AACSSender , the sendConfigMessageEmbedded() or sendConfigMessageAnySize() method ensures that the configuration message can be sent to AACS. The following example shows how to construct and send the configuration message: try { String config = \"...\"; // configuration read from file JSONObject configJson = new JSONObject(config); JSONArray configStringsArray = new JSONArray(); configStringsArray.put(configJson.toString()); // add escaped JSON string JSONObject configMessage = new JSONObject(); configMessage.put(\"configFilepaths\", new JSONArray()); configMessage.put(\"configStrings\", configStringsArray); aacsSender.sendConfigMessageAnySize(configMessage.toString(), target, getApplicationContext()); } catch (JSONException e) { ... }","title":"Sending a Configuration Message"},{"location":"android/aacs/#file-sharing-and-permissions","text":"Some configurable fields for the Auto SDK require paths to files in your application, which is inaccessible to AACS. To enable the Auto SDK to get the file paths, AACS provides a protocol for applications to grant the Auto SDK URI permissions for these files. AACS then creates a local copy of the file in its internal storage and configures the fields for the Auto SDK, using the file path to the local copy to ensure accessibility. Fields that require file sharing are described in documentation. Currently, only installed extensions have configurable fields that need file sharing. See the AACS README for your extension for more information about file sharing. AACS's file sharing protocol uses Android's FileProvider class to securely receive the URIs of files in applications. See the Android documentation on how to set up FileProvider in your application. Your FileProvider is functional after the application includes a <provider> element in its AndroidManifest and a filepaths.xml file for specifying shareable paths. After FileProvider is set up, AACS expects to receive an intent with action Intent.ACTION_SEND_MULTIPLE to include the URIs of files to be shared. Send the intent after service initialization but before the configuration message is sent. It requires the following structure: Action: Intent.ACTION_SEND_MULTIPLE - The standard Android intent for sharing multiple pieces of content Type: The MIME type of a URI Extra: AACSConstants.CONFIG_MODULE or configModule - A String representing the module to be configured by the shared files ParcelableArrayListExtra: Intent.EXTRA_STREAM - An ArrayList<Uri> containing URIs of files to be shared Before sending the intent, be sure to grant the Intent.FLAG_GRANT_READ_URI_PERMISSION to AACS for each URI being sent. Also, because the intent holds multiple file URIs for a single configuration module at a time, if there are multiple files for separate modules, send multiple intents, as shown in the following example implementation: private void shareFilePermissionsOfSameModule(File parent, String[] filenames, String module) { ArrayList<Uri> fileUris = new ArrayList<>(); for (String name : filenames) { File file = new File(parent, name); Uri fileUri = FileProvider.getUriForFile( MainActivity.this, <your-application's-provider>, file); grantUriPermission(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), fileUri, Intent.FLAG_GRANT_READ_URI_PERMISSION); fileUris.add(fileUri); } Intent shareFileIntent = new Intent(); shareFileIntent.setComponent( new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), AACSConstants.AACS_CLASS_NAME)); shareFileIntent.setAction(Intent.ACTION_SEND_MULTIPLE); shareFileIntent.setType(getContentResolver().getType(fileUris.get(0))); shareFileIntent.putExtra(AACSConstants.CONFIG_MODULE, module); shareFileIntent.putParcelableArrayListExtra(Intent.EXTRA_STREAM, fileUris); startForegroundService(shareFileIntent); } Note: AACSConstants.AACS_PACKAGE_NAME is deprecated and it shall be removed from the future Alexa Auto SDK versions. Use AACSConstants.getAACSPackageName(Context) instead.","title":"File Sharing and Permissions"},{"location":"android/aacs/#initialization-protocol","text":"After starting the service, send file sharing intents for any files outside of AACS's access that will be needed for configuration. Then, send the configuration message. If there are no files to be shared, the configuration can be sent immediately after AACS is initialized. The configuration is not part of the initial intent to start the service because intents in Android have size limits, which the configuration might exceed. Using the provided IPC library allows for sending configuration of any size. Because AACS stores the last configuration received, the only requirement is that the configuration is sent the first time AACS is run after installation. At any subsequent start, AACS uses the stored configuration. Similarly for shared files, AACS retains local copies of the files, so file sharing intents do not have to be re-sent in subsequent launches. However, updating the stored configuration (without uninstalling the application containing AACS AAR) requires that the startService intent include an Extras field called newConfig . newConfig holds a boolean value that alerts AACS not to start running with the stored configuration, but wait for a new configuration message. In addition, whenever the newConfig field is set to true , AACS clears all local copies of shared files and expect new file sharing intents, if necessary for the new configuration. Note : The old configuration is overwritten by the new configuration. For your application to start AACS with a new configuration, make sure your intent includes newConfig , as shown in the following example: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); intentStartService.putExtra(\"newConfig\", true); Omitting newConfig is the same as setting it to false , which causes AACS to use the stored configuration. Important : Sending a new configuration is allowed only once per service run. After AACS is configured and running, AACS ignores subsequent attempts to update the configuration, even if the newConfig field is true . To update an existing configuration, you must stop the service and restart it with newConfig set to true . This same rule applies to file sharing intents.","title":"Initialization Protocol"},{"location":"android/aacs/#initialization-sequence-diagram","text":"The following diagram shows an example of initializing AACS from an app used by a driver.","title":"Initialization Sequence Diagram"},{"location":"android/aacs/#default-platform-implementation","text":"Default platform implementations refer to implementations of Auto SDK platform interfaces that AACS provides to replace the normal protocol of using AASB messages. By enabling a default platform implementation in AACS, you no longer have to handle messages for a particular platform interface and can rely on AACS to provide the necessary functionality. AACS provides a default implementation for these platform interfaces: AudioInput (audioType: VOICE, COMMS) AudioOutput (audioType: TTS, ALARM, NOTIFICATIONS, EARCON, RINGTONE) LocationProvider NetworkInfoProvider ExternalMediaAdapter for Media App Command and Control (MACC) LocalMediaSource PropertyManager The platform implementations for these interfaces are disabled by default; the AASB messages for these interfaces are routed to the client app to be handled . To enable the default platform implementation in AACS, you must set the aacs.defaultPlatformHandlers configuration flags. In the following example, you use aacs.defaultPlatformHandlers in the configuration file to instruct AACS to handle LocationProvider and NetworkInfoProvider , AudioInput for VOICE , and AudioOutput for TTS . Specific apps handle the other messages. \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, ... other audio types } } }","title":"Default Platform Implementation"},{"location":"android/aacs/#property-content-provider-implementation-optional","text":"AACS supports the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. Using a content provider offers the following advantages: AACS can consistently provide the properties across multiple launches. Because properties are persistent, your application does not need to reset the properties after each AACS restart. AACS messages are asynchronous, which might cause timeouts and subsequently incorrect or error states. Using a content provider to retrieve state data makes the retrieval process synchronous, thus guaranteeing that the request for state information reaches its destination and a response is received. ContentProvider is the standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data.","title":"Property Content Provider Implementation (Optional)"},{"location":"android/aacs/#sequence-diagram-and-overview","text":"The following sequence diagram illustrates the workflow for the default property manager implementation in AACS. This implementation provides the interface, based on the Android ContentProvider , for OEM apps to get and set Auto SDK properties. aace.alexa.wakewordSupported aace.alexa.system.firmwareVersion aace.alexa.setting.locale aace.alexa.countrySupported aace.alexa.timezone aace.alexa.wakewordEnabled aace.vehicle.operatingCountry aace.core.version aace.network.networkInterface By using the native Android ContentProvider class, you can initiate query and update operations. query retrieves and returns the current String value of an Auto SDK property. update sets an Auto SDK property in the Engine and returns a boolean value based on the success of the operation. Insert and Delete operations are disabled for Auto SDK properties.","title":"Sequence Diagram and Overview"},{"location":"android/aacs/#implementation-examples","text":"Add useDefaultPropertyManager in the config.json file and set it to true , as shown in the following example: ... \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, --> \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { ... Add READ_USER_DICTIONARY permission to AndroidManifest.xml in your application, as shown in the following example: <uses-permission... <uses-permission android:name=\"android.permission.READ_USER_DICTIONARY\" /> <uses-permission... In the application implementation, set the URI for getting the ContentResolver instance as follows: private final Uri uri = Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI); Register ContentObserver for monitoring any Auto SDK property changes that are initiated by the engine. ContentObserver is a native Android class which observes changes to data and will call its onChange() method to perform callbacks when a content change occurs. It includes the changed content Uri when available. To register ContentObserver , first register your application with ContentObserver // PropertyHandler is an example class using ContentProvider API to query and update properties in your application PropertyHandler alexaPropertyHandler = new PropertyHandler(this); // PropertyContentObserver is an example implementation of the callback for property changes PropertyContentObserver propertyObserver = new PropertyContentObserver(alexaPropertyHandler, this); getContentResolver().registerContentObserver(Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI), true, propertyObserver); Then implement the PropertyContentObserver class and add the desired callback behavior in method onChange() : public class PropertyContentObserver extends ContentObserver { private static Activity mActivity; public PropertyContentObserver(Handler handler, Activity activity) { super(handler); mActivity = activity; } @Override public void onChange(boolean changed) { this.onChange(changed, null); } @Override public void onChange(boolean changed, Uri uri) { // Do something when content change occurs } } Perform query() and update() operation within application using the previously set URI: query() Cursor cursor = getContentResolver().query(uri, null, propertyName, null, null); cursor.moveToFirst(); String propertyValue = cursor.getString(1); update() must be called in its own thread, not the main UI thread since update() calls setProperty and receive the result asynchronously. ExecutorService mExecutor; ContentValues cv = new ContentValues(); cv.put(propertyName, propertyValue); if (mExecutor == null ) { mExecutor = Executors.newSingleThreadExecutor(); } else { synchronized (OEMApplication.class) { if (mExecutor.isShutdown()) { // Log warning that Executor has already been shut down for update. Not updating property. } mExecutor.submit(() -> { getContentResolver().update(uri, cv, propertyName, null); }); } }","title":"Implementation Examples"},{"location":"android/aacs/#important-considerations-for-using-contentprovider","text":"AACS Property Content Provider does not support the insert and delete APIs in Property ContentProvider; You must use AACS with the AmazonLite Wake Word extension if you want to update aace.alexa.wakewordEnabled property; aace.alexa.countrySupported is a deprecated property and cannot be get/set; aace.alexa.wakewordSupported and aace.core.version are read-only properties acquired when building Auto SDK and cannot be set. Valid property value for aace.alexa.wakewordEnabled is true or false . All the other Auto SDK properties will be validated by Auto SDK. Auto SDK will provide value validation for aace.alexa.wakewordEnabled in the future.","title":"Important Considerations for Using ContentProvider"},{"location":"android/aacs/#enabling-aacs-to-synchronize-alexas-time-zone-and-locale-with-device-settings-optional","text":"AACS supports synchronizing Alexa's time zone and locale properties with the ones in device settings. To enable the functionality, refer to this README for proper configuration. Once enabled, AACS will synchronize the time zone and/or locale properties of Alexa with the device settings in the following conditions: When Auto SDK engine is initialized, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. When the authorization state is refreshed, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. When AACS gets android.intent.action.LOCALE_CHANGED intent as a result of device locale setting change, Alexa locale property will be updated if the locale is supported by Alexa. When AACS gets android.intent.action.TIMEZONE_CHANGED intent as a result of device time zone setting change, Alexa time zone property will be updated. You can also disable the automatic synchronization for specific properties. This is particularly useful when your application wants to disable/enable the synchronization at runtime. For example, after the user manually selects a locale, you may want to disable the synchronization to allow the user's selection to override the system setting changes. To achieve this use case, your application can send intents with the metadata below to AACS: Action: Disable: com.amazon.aacs.syncSystemPropertyChange.disable Enable: com.amazon.aacs.syncSystemPropertyChange.enable Category: com.amazon.aacs.syncSystemPropertyChange Extra: \"property\": <alexa_property_name> If this feature is not enabled, your application can still have the full flexibility in changing the two properties by handling AASB Property Manager messages. Additionally, you can configure AACS to update the system time zone if the user changes the Alexa's time zone for the device (e.g. the user can change the property on their Alexa mobile app). To enable the functionality, refer to this README for proper configuration. Your application with AACS needs to be a system application with android permission android.permission.SET_TIME_ZONE obtained. Note: Always provide the system permission android.permission.SET_TIME_ZONE when AACS AAR is in a system application. Refer to Privileged Permission Allowlisting in Android documentation.","title":"Enabling AACS to synchronize Alexa's Time Zone and Locale with Device Settings (Optional)"},{"location":"android/aacs/#using-custom-domain-module-with-customdomainmessagedispatcher-enabled-optional","text":"To use Custom Domain module with AACS, you need to explicitly enable it first by adding module enablement configuration. Please refer to AACS Configuration README to enable the Custom Domain module. By default, all the Custom Domain intents share the same com.amazon.aacs.aasb.customDomain intent category. If CustomDomainMessageDispatcher is enabled, the intent category will be the namespace of the custom interface prefixed with com.amazon.aacs.customDomain , which allows AACS to dispatch the Custom Domain AASB messages from the engine to the proper components in your system based on the custom namespace. Below is the intent schema of the intents sent from the dispatcher. All the intents are sent with our IPC library . You can use AACSReceiver to receive and process the AASB Custom Domain messages in the intents. Intent for handling/canceling a custom directive: Action: com.amazon.aacs.customDomain.<custom-directive-name> . Category: com.amazon.aacs.customDomain.<custom-directive-namespace> . Intent for getting the context for a custom namespace: Action: com.amazon.aacs.customDomain.GetContext Category: com.amazon.aacs.customDomain.<custom-context-namespace> . You can define intent filters in the Android Manifest of your applications to subscribe to the specific Custom Domain intents. See Specifying the Intent Targets for Handling Messages Using Android Manifest to learn more about specifying intent targets. Please refer to this README on enabling CustomDomainMessageDispatcher. Note : CustomDomainMessageDispatcher does not process any custom directives. Your application is responsible for handling any custom directives, sending custom events, and providing custom contexts following the Custom Domain AASB Documentation . If the dispatcher is not enabled, your application will be responsible for receiving all the Custom Domain AASB Messages (as intents) at one place.","title":"Using Custom Domain Module with CustomDomainMessageDispatcher Enabled (Optional)"},{"location":"android/aacs/#specifying-the-intent-targets-for-handling-messages","text":"The AASB message intent targets can be ACTIVITY , RECEIVER , or SERVICE . There are two ways to specify the intent targets for AASB message intents from AACS.","title":"Specifying the Intent Targets for Handling Messages"},{"location":"android/aacs/#using-android-manifest","text":"You can define intent filters in your application's Android Manifest. The intent filter must exactly match the intents' categories and actions. In the intent filter for an intent that wraps an AASB message, specify the category as com.amazon.aacs.aasb.<AASB_Message_Topic> and action as com.amazon.aacs.aasb.<AASB_Message_Action> . The following example shows an intent filter of all the CBL message intents for a broadcast receiver target: <intent-filter> <action android:name=\"com.amazon.aacs.aasb.CBLStateChanged\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairReceived\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairExpired\"/> <action android:name=\"com.amazon.aacs.aasb.SetProfileName\"/> <action android:name=\"com.amazon.aacs.aasb.GetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.SetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.ClearRefreshToken\"/> <category android:name=\"com.amazon.aacs.aasb.CBL\" /> </intent-filter> To receive the message specified through the Android Manifest, the application must also have com.amazon.alexaautoclientservice permission in its Android Manifest. <uses-permission android:name=\"com.amazon.alexaautoclientservice\" /> Follow these important guidelines if the intent target is an activity: You must add <category android:name=\"android.intent.category.DEFAULT\" /> to the intent filter as explained here . Be aware that if you start applications with AACS (for example, by specifying Activity as the intent targets from AACS), the target Activity will move to the foreground or become in focus, causing distraction or confusion to the user. AACS does not request SYSTEM_ALERT_WINDOW permission to directly create windows on top of all other apps. Amazon recommends using VIS (VoiceInteractionService) to launch activities, and using Android Services or Broadcast Receivers to receive intents from AACS.","title":"Using Android Manifest"},{"location":"android/aacs/#using-aacs-configuration-file","text":"You can use the AACS configuration file to specify the app that can handle AASB messages with a specific \"topic\". This method of specifying intent targets has the highest priority, meaning it can override the ones specified through intent filters in manifests. After you use the AACS configuration to specify the app, intents with all the actions belonging to the topic go to the specified targets. Fill the optional fields in intentTargets in the AACS configuration file as needed. See the Configuration Reference documentation for information about intentTargets . The following sample configuration shows how to populate intentTargets for each topic. The field type accepts RECEIVER , ACTIVITY , and SERVICE , depending on the type of the target that handles the intents with the topic. The targets can be broadcast receiver, application activity, and service. The format for specifying AASB message intent targets for an AASB message topic is as follows: \"<topic>\" : { \"type\": [<target_1_type>, <target_2_type>, ...], \"package\": [\"<target_1_package_name>\", \"<target_2_package_name>\", ...], \"class\": [\"<target_1_class_name>\", \"<target_2_class_name>\", ...] }, The following example shows two topics, which are AASB and APL : \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\": [\"ACTIVITY\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\"com.amazon.aacstestapp.MainActivity\"] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\".IntentReceiver\"] // short version of class name is also accepted. }, // In this case, the class must be in the package specified in \"package\". // ... other topics } } NOTE : If a given \"topic\" is specified both in the configuration file and the Android Manifest, the configuration file takes priority and the targets with intent filters are ignored. Amazon recommends intent filters when possible. Use the configuration approach only if you need to override the existing intent filters. AACS first searches for targets for an intent with a topic in the configuration file. If nothing is found, the package manager scans the intent filters on the device to locate a match. AACS also caches the scan results based on both topic and action. The cache is cleared every time AACS is restarted.","title":"Using AACS Configuration File"},{"location":"android/aacs/#platform-implementation-in-your-application","text":"Your applications can register for specific AASB messages and provide a platform implementation. For example, an application (\u201cLogin app\") can register for Authorization messages. For information about the Authorization module, see the Core module documentation.","title":"Platform Implementation in Your Application"},{"location":"android/aacs/#initial-authentication-sequence-diagram","text":"The following sequence diagram illustrates how an application (\u201cLogin app\") exchanges messages with AACS over Android Intents to log in the user for Alexa.","title":"Initial Authentication Sequence Diagram"},{"location":"android/aacs/#wake-word-enabled-sequence-diagram","text":"The sequence diagram illustrates the sequence for the user to access Alexa if you use the default implementation of AudioInput in AACS. In this diagram, the driver is logged in and wake word is enabled. The driver initiates the action by uttering the Alexa wake word. Audio is processed locally by the wake word engine in AACS until the wake word is detected. Upon wake word detection, AACS notifies the application that the dialog state has changed to \"listening\" and initiates a Recognize event with Alexa. While in the listening state, audio data is sent to Alexa. When the end of speech is detected, Alexa sends a StopCapture directive to AACS, and the dialog state is changed to \"thinking.\" Alexa then responds with additional directives in response to the speech request. For information about other messages to provide your implementation in the client APK, please refer to the documentation for each Auto SDK module.","title":"Wake Word Enabled Sequence Diagram"},{"location":"android/aacs/#client-utility-library","text":"AACS also provides an optional library, AACS Common Utils . It contains useful methods to make messaging with AACS easier. You can use it as-is or as a reference to facilitate the integration of the Auto SDK with AACS. For information about the library, see AACS Common Utils README and in-code documentation in the library.","title":"Client Utility Library"},{"location":"android/aacs/#device-settings-required-for-aacs","text":"AACS requires microphone and location permissions when the default implementation is used for AudioInput and Location. If AACS runs in a system application, you can grant these permissions so that the application users do not have to set the permissions. Otherwise, be sure to instruct your users to grant the following permissions on the app info page under Settings on their device: Location: Enable android.permission.ACCESS_FINE_LOCATION to give AACS access the current location. Microphone: Enable android.permission.RECORD_AUDIO to give permission to AACS to record audio. Microphone must be enabled if you configure AudioInput to use the default implementation of AACS.","title":"Device Settings Required for AACS"},{"location":"android/aacs/#checking-aacs-connection-state","text":"Your application or service can check the status of AACS by using ping , which returns a response as long as AACS is running. The AACSPinger utility class from the IPC library enables you to use ping . To ping AACS, specify the ping permission name in your application's Android Manifest file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice.ping\"/> The following example shows how to use AACSPinger : AACSPinger aacsPinger = new AACSPinger(getApplicationContext(), \"com.amazon.alexaautoclientservice.ping\"); Future<AACSPinger.AACSPingResponse> fut = aacsPinger.pingAACS(); AACSPinger.AACSPingResponse response = fut.get(); if (response.hasResponse) { // Ping was responded to by AACS String state = response.AACSState; ... } else { // Ping timed out without an AACS response } If AACS responds to the ping request, the AACSPingResponse.AACSState string returned by AACSPinger.pingAACS() has one of the following values: STARTED WAIT_FOR_LVC_CONFIG CONFIGURED ENGINE_INITIALIZED CONNECTED STOPPED If AACS does not respond within the default timeout of 1 second, AACSPingResponse.hasResponse is false .","title":"Checking AACS Connection State"},{"location":"android/aacs/#aacs-state-notification","text":"As an alternative to pinger where the application or service can fetch the AACS State, AACS also broadcast the various state transitions. Your application needs to register a receiver for the following intent action: \"com.amazon.aacs.service.statechanged\" This is defined in AACS Constants as ACTION_STATE_CHANGE The following example shows an intent receiver to receive AACS State transition events: mAACSStateIntentReceiver = new aacsStateIntentReceiver(); IntentFilter filter = new IntentFilter(); filter.addAction(AACSConstants.ACTION_STATE_CHANGE); (context.get()).registerReceiver(mAACSStateIntentReceiver, filter);","title":"AACS State Notification"},{"location":"android/aacs/#request-list-of-extras-from-aacs","text":"Your application can receive the list of AACS extra modules by sending an intent with the action AACSConstants.IntentAction.GET_SERVICE_METADATA and the category AACSConstants.IntentCategory.GET_SERVICE_METADATA , which returns a response by receiving an intent AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . To get the extras list from AACS- Specify the permission name in your application's Android Manifest file as follows: <uses-permission android:name= \"com.amazon.alexaautoclientservice.getservicemetadata\" /> Register a receiver in you application's Android Manifest file as follows: Following block shows an example of requesting list of extras: <receiver android:name= \".<Receiver Class>\" android:enabled= \"true\" android:exported= \"true\" /> Send a request intent to AACS. Following code snippet shows an example Intent intent = new Intent (); intent . setAction ( AACSConstants . IntentAction . GET_SERVICE_METADATA ); intent . addCategory ( AACSConstants . IntentCategory . GET_SERVICE_METADATA ); intent . putExtra ( AACSConstants . REPLY_TO_PACKAGE , getPackageName ()); intent . putExtra ( AACSConstants . REPLY_TO_CLASS , < Receiver_Class_Name > . class . getName ()); intent . putExtra ( AACSConstants . REPLY_TYPE , \"RECEIVER\" ); sendBroadcast ( intent ); Your receiver class will receive an intent with the following payload { \"metaData\" : { \"extrasModuleList\" : [] } } You can get the payload from the received intent with action AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . Following code snippet shows the example: String payload = intent . getStringExtra ( AACSConstants . PAYLOAD );","title":"Request list of extras from AACS"},{"location":"android/aacs/#using-instrumentation","text":"You can use AACS instrumentation to log AASB messages for debugging purposes. For more information about how to use instrumentation, see the AACS Instrumentation README . Note: You can use instrumentation only if you use the debug option when building the Auto SDK with AACS.","title":"Using Instrumentation"},{"location":"android/aacs/#including-app-components-with-aacs-aar-in-your-application","text":"The Auto SDK provides packages (also called \"app components\") in the $AAC_SDK_HOME/aacs/android/app-components directory. App components could be included in your application along with AACS AAR to speed up the Alexa integration. Note: Some app components implement the handling of AASB messages for certain topics, allowing your applications to interface with AACS by using standard Android APIs. If you include such app components in your application with AACS AAR, your application does not need to handle the AASB messages for those particular AASB topics.","title":"Including App Components with AACS AAR in your application"},{"location":"android/aacs/#aacs-sample-app","text":"The Auto SDK includes an Android-based application that demonstrates how an application uses AACS. For more information about the AACS Sample App, see the AACS Sample App README .","title":"AACS Sample App"},{"location":"android/aacs/app-components/","text":"AACS App Components \u00b6 The AACS App Components are modularized, pre-made Android implementation libraries for Auto SDK features. The AACS Sample App uses the AACS App Components, but they are decoupled from the sample app and build independently into standalone AARs for use in any AACS client application. You can speed up your integration by reusing the App Components in your own application. See the documentation of each App Component library for its respective build and usage instructions.","title":"AACS App Components"},{"location":"android/aacs/app-components/#aacs-app-components","text":"The AACS App Components are modularized, pre-made Android implementation libraries for Auto SDK features. The AACS Sample App uses the AACS App Components, but they are decoupled from the sample app and build independently into standalone AARs for use in any AACS client application. You can speed up your integration by reusing the App Components in your own application. See the documentation of each App Component library for its respective build and usage instructions.","title":"AACS App Components"},{"location":"android/aacs/app-components/alexa-auto-apis/","text":"Alexa Auto API \u00b6 This Alexa Auto API package provides: Types that are used across multiple Java packages. A Java package is a collection of related types, which is created to avoid type name collisions. Interfaces that allow packages to communicate with each other by using standard Java, as long as the consumer and provider of the interface meet these requirements: They are in the same Android Package (APK). They are loaded and used in the same process. Component Registry (Service Locator) \u00b6 To enable a package to locate the implementation of an API, the Alexa Auto API Package defines the component registry interfaces and the mechanism to obtain the component registry (also called the service locator). Consuming Implementations from Other Packages \u00b6 The following list explains the component registry interfaces: AlexaAppRootComponent is a component registry interface with an application scope. It provides interfaces that are in scope for the lifetime of the app. This interface provides access to AlexaAppScopedComponents , among other interfaces. AlexaAppScopedComponents provides interfaces that are available for a limited scope. For example, when an app is in logged-off state, AlexaAppLoggedOutScopedComponent can be queried by using AlexaAppScopedComponents . Any library or application class can obtain AlexaAppRootComponent as long as it has the Android context. The following code example illustrates how an app obtains AlexaAppRootComponent : class MyActivity extends AppCompatActivity { public void onStart() { AlexaApp app = AlexaApp.from(this); AlexaAppRootComponent componentRegistry = app.getRootComponent(); componentRegistry.getXYZ().doSomethingUseful(); } } Publishing Implementations for Other Packages \u00b6 How a package publishes the implementation of an API for another package to use depends on the scope, as explained in the following list: App lifecycle implementation: If an object's lifecycle is bound to the lifecycle of an app, then the main Alexa app APK creates an instance of the object and makes it available through the implementation of AlexaAppRootComponent . Limited scoped implementations: A package can publish scoped components into the component registry to be discovered by other packages. To publish a scoped component, the package can obtain AlexaAppScopedComponentsActivator from AlexaAppRootComponent .","title":"Alexa Auto API"},{"location":"android/aacs/app-components/alexa-auto-apis/#alexa-auto-api","text":"This Alexa Auto API package provides: Types that are used across multiple Java packages. A Java package is a collection of related types, which is created to avoid type name collisions. Interfaces that allow packages to communicate with each other by using standard Java, as long as the consumer and provider of the interface meet these requirements: They are in the same Android Package (APK). They are loaded and used in the same process.","title":"Alexa Auto API"},{"location":"android/aacs/app-components/alexa-auto-apis/#component-registry-service-locator","text":"To enable a package to locate the implementation of an API, the Alexa Auto API Package defines the component registry interfaces and the mechanism to obtain the component registry (also called the service locator).","title":"Component Registry (Service Locator)"},{"location":"android/aacs/app-components/alexa-auto-apis/#consuming-implementations-from-other-packages","text":"The following list explains the component registry interfaces: AlexaAppRootComponent is a component registry interface with an application scope. It provides interfaces that are in scope for the lifetime of the app. This interface provides access to AlexaAppScopedComponents , among other interfaces. AlexaAppScopedComponents provides interfaces that are available for a limited scope. For example, when an app is in logged-off state, AlexaAppLoggedOutScopedComponent can be queried by using AlexaAppScopedComponents . Any library or application class can obtain AlexaAppRootComponent as long as it has the Android context. The following code example illustrates how an app obtains AlexaAppRootComponent : class MyActivity extends AppCompatActivity { public void onStart() { AlexaApp app = AlexaApp.from(this); AlexaAppRootComponent componentRegistry = app.getRootComponent(); componentRegistry.getXYZ().doSomethingUseful(); } }","title":"Consuming Implementations from Other Packages"},{"location":"android/aacs/app-components/alexa-auto-apis/#publishing-implementations-for-other-packages","text":"How a package publishes the implementation of an API for another package to use depends on the scope, as explained in the following list: App lifecycle implementation: If an object's lifecycle is bound to the lifecycle of an app, then the main Alexa app APK creates an instance of the object and makes it available through the implementation of AlexaAppRootComponent . Limited scoped implementations: A package can publish scoped components into the component registry to be discovered by other packages. To publish a scoped component, the package can obtain AlexaAppScopedComponentsActivator from AlexaAppRootComponent .","title":"Publishing Implementations for Other Packages"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/","text":"Alexa Auto APL Renderer \u00b6 The Alexa Auto APL Renderer library enables the AACS Sample App to render Amazon Presentation Language (APL) documents on the user's device. The library consists of the following components: APLReceiver : This class receives the APL intents. After receiving an APL RenderDocument intent, it starts adding APLFragment to VoiceActivity or sends the APLDirective event to APLFragment . APLHandler : This class initializes APLPresenter , set APLLayout in APLPresenter when the layout is inflated. This class also handles APL intents, such as those for rendering or clearing APL documents. It also executes APL commands and implements an event interface named IAPLEventSender , which reports events to Alexa or the capability agent. APLFragment : This class inflates the APL layout to render the APL document. The APLLayout object in fragment_apl.xml defines the layout. This class also calls the APLhandler methods to handle APL intents. Prerequisites for Using the Alexa Auto APL Renderer Library \u00b6 The APL Renderer library for the AACS Sample App depends on the capabilities provided by an Auto SDK module called APL Render module. For example, the APL Render module provides the APLPresenter class implementation. The Alexa Auto APL Renderer library initializes this class to provide the orchestration logic in the APL rendering process. For information about how to build the APL Render module, see the APL Render documentation . Using Alexa Auto APL Renderer Library with AACS Sample App \u00b6 To use the Alexa Auto APL Renderer Library with the AACS Sample App, include the appropriate build dependency, fonts package and configure APL in the AACS Sample App. Including Build Dependency (AAR) \u00b6 The Alexa Auto APL Renderer library requires a prebuilt Android view host, which is available as an AAR on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To include the build dependency, you must place the Android view host AAR in the modules/apl-render/src/main/libs/ folder of the APL Render module. Including Fonts Package \u00b6 The Alexa Auto APL Renderer library requires fonts package, which is available as a zip file on the developer portal. To download the fonts package, contact your Solutions Architect (SA) or Partner Manager. Note: To include the fonts package, you must create res/font/ folder in the modules/apl-render/src/main/ folder, unzip the fonts package, and copy all the files into res/font/ folder. Configuring APL in AACS Sample App \u00b6 The AACS Sample App passes aacs_config.json to AACS for configuring the Auto SDK. Follow these steps to enable APL and specify the display format: Enable APL in aacs_config.json : \"aacs.modules\" : { \"aacs.apl\" : { \"APL\" : { \"enabled\" : true } } } Add the gui configuration node in aacs.alexa , as shown in the following example: { \"aacs.alexa\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 900 , \"height\" : 1200 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } } ] } } } For descriptions of the visual characteristic parameters, see the Alexa Smart Screen SDK documentation . APL viewport can be adjusted by changing the width and height pixel values in Alexa.Display.Window configuration. Building AACS Sample App with Alexa Auto APL Renderer Library \u00b6 To build the AACS Sample App with Alexa Auto APL Renderer library, go to ${AUTO_SDK_HOME}/aacs/android/sample-app/ and enter the following command: ./gradlew assembleLocalRelease -PenabledAPL Using AACS Sample App \u00b6 After the gradle build command finishes building the AACS Sample App, you can test the sample app by asking, \"Alexa, tell me a joke.\" An APL document is rendered on the device. The Auto SDK 4.0 enables the ability to report the vehicle driving state to provide safer visual experiences while the vehicles is moving. To enable the driving state support, add -PenabledUXRestrictions to the build command. When you say \"Alexa, show coffee shops near me\" and view the details for a point of interest, the data displayed in the APL detail card will contain more information while the driving state is parked . Additionally, the Auto SDK 4.0 supports the ability to report the light conditions around the vehicle to support day/night mode and provide a custom theme id to alter the look and feel of the APL experience. ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions Note: The alexa-auto-ux-restrictions requires Android API level 29. Provide your own implementation for the CarUxRestrictionsController interface if your device uses API level less than 29. By default, the driving state will always be set to moving if the CarUxRestrictionsController is not implemented. Known Issues \u00b6 When interrupting music playback with APL utterance, APL card will be dismissed when music playback resumes, this issue could not be seen if music ducking support is enabled in AACS sample app. To do this, add audio ducking node in aacs.alexa , as shown in the following example: \"aacs.alexa\": { \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } } }","title":"Alexa Auto APL Renderer"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#alexa-auto-apl-renderer","text":"The Alexa Auto APL Renderer library enables the AACS Sample App to render Amazon Presentation Language (APL) documents on the user's device. The library consists of the following components: APLReceiver : This class receives the APL intents. After receiving an APL RenderDocument intent, it starts adding APLFragment to VoiceActivity or sends the APLDirective event to APLFragment . APLHandler : This class initializes APLPresenter , set APLLayout in APLPresenter when the layout is inflated. This class also handles APL intents, such as those for rendering or clearing APL documents. It also executes APL commands and implements an event interface named IAPLEventSender , which reports events to Alexa or the capability agent. APLFragment : This class inflates the APL layout to render the APL document. The APLLayout object in fragment_apl.xml defines the layout. This class also calls the APLhandler methods to handle APL intents.","title":"Alexa Auto APL Renderer"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#prerequisites-for-using-the-alexa-auto-apl-renderer-library","text":"The APL Renderer library for the AACS Sample App depends on the capabilities provided by an Auto SDK module called APL Render module. For example, the APL Render module provides the APLPresenter class implementation. The Alexa Auto APL Renderer library initializes this class to provide the orchestration logic in the APL rendering process. For information about how to build the APL Render module, see the APL Render documentation .","title":"Prerequisites for Using the Alexa Auto APL Renderer Library"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#using-alexa-auto-apl-renderer-library-with-aacs-sample-app","text":"To use the Alexa Auto APL Renderer Library with the AACS Sample App, include the appropriate build dependency, fonts package and configure APL in the AACS Sample App.","title":"Using Alexa Auto APL Renderer Library with AACS Sample App"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#including-build-dependency-aar","text":"The Alexa Auto APL Renderer library requires a prebuilt Android view host, which is available as an AAR on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To include the build dependency, you must place the Android view host AAR in the modules/apl-render/src/main/libs/ folder of the APL Render module.","title":"Including Build Dependency (AAR)"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#including-fonts-package","text":"The Alexa Auto APL Renderer library requires fonts package, which is available as a zip file on the developer portal. To download the fonts package, contact your Solutions Architect (SA) or Partner Manager. Note: To include the fonts package, you must create res/font/ folder in the modules/apl-render/src/main/ folder, unzip the fonts package, and copy all the files into res/font/ folder.","title":"Including Fonts Package"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#configuring-apl-in-aacs-sample-app","text":"The AACS Sample App passes aacs_config.json to AACS for configuring the Auto SDK. Follow these steps to enable APL and specify the display format: Enable APL in aacs_config.json : \"aacs.modules\" : { \"aacs.apl\" : { \"APL\" : { \"enabled\" : true } } } Add the gui configuration node in aacs.alexa , as shown in the following example: { \"aacs.alexa\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 900 , \"height\" : 1200 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } } ] } } } For descriptions of the visual characteristic parameters, see the Alexa Smart Screen SDK documentation . APL viewport can be adjusted by changing the width and height pixel values in Alexa.Display.Window configuration.","title":"Configuring APL in AACS Sample App"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#building-aacs-sample-app-with-alexa-auto-apl-renderer-library","text":"To build the AACS Sample App with Alexa Auto APL Renderer library, go to ${AUTO_SDK_HOME}/aacs/android/sample-app/ and enter the following command: ./gradlew assembleLocalRelease -PenabledAPL","title":"Building AACS Sample App with Alexa Auto APL Renderer Library"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#using-aacs-sample-app","text":"After the gradle build command finishes building the AACS Sample App, you can test the sample app by asking, \"Alexa, tell me a joke.\" An APL document is rendered on the device. The Auto SDK 4.0 enables the ability to report the vehicle driving state to provide safer visual experiences while the vehicles is moving. To enable the driving state support, add -PenabledUXRestrictions to the build command. When you say \"Alexa, show coffee shops near me\" and view the details for a point of interest, the data displayed in the APL detail card will contain more information while the driving state is parked . Additionally, the Auto SDK 4.0 supports the ability to report the light conditions around the vehicle to support day/night mode and provide a custom theme id to alter the look and feel of the APL experience. ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions Note: The alexa-auto-ux-restrictions requires Android API level 29. Provide your own implementation for the CarUxRestrictionsController interface if your device uses API level less than 29. By default, the driving state will always be set to moving if the CarUxRestrictionsController is not implemented.","title":"Using AACS Sample App"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/#known-issues","text":"When interrupting music playback with APL utterance, APL card will be dismissed when music playback resumes, this issue could not be seen if music ducking support is enabled in AACS sample app. To do this, add audio ducking node in aacs.alexa , as shown in the following example: \"aacs.alexa\": { \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } } }","title":"Known Issues"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/","text":"APL Render Module \u00b6 The APL Render module is an Android library that enables Alexa Presentation Language (APL) rendering capabilities in an Android application. For detailed information about APL, see the APL documentation . Table of Contents \u00b6 Overview Understanding Android View Host APL Render Module Functionality How to use the APL Render Module Defining the APL Layout Initializing the APL Runtime Implementing the Event Interface Instantiating APLPresenter Rendering an APL Document Overriding Android View Host Options Using APLOptions.Builder APL Runtime Properties Driving State Theme APL Extensions Backstack Local Information Data ILocalInfoDataConsumer ILocalInfoDataReporter Building the APL Render Library Overview \u00b6 Rendering an APL document on a device requires the implementation of various components and the logic that makes the components work together. To handle APL-related directives and events, the device must support APL interfaces. It needs integration of the APL Core Library to manage the document parsing and rendering workflow. In addition, you must build a view host for the device to render the APL document on the screen, as well as provide components to download layouts, images, and other resources. If the APL document generates multimedia content, such as a video or audio file, you need a media player to play back the content. Lastly, APL rendering needs the orchestration logic to manage the lifecycle of a rendered document, which includes user events, audio focus management, time out management, visual context, command execution, and much more. The Alexa Auto SDK, with the APL Render module and a prebuilt Android view host, simplifies the process of APL rendering because it provides the aforementioned components and logic for you. Understanding Android View Host \u00b6 The Android view host is the component responsible for rendering APL on the screen. Amazon provides a prebuilt Android view host as an Android Archive Library (AAR) on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To use the Android Render module, you must place the Android view host AAR in the src/main/libs/ folder of the APL Render module. APL Render Module Functionality \u00b6 The APL Render module provides all the functionality needed for enabling APL rendering capabilities in an Android application. The APL Render module provides the following capabilities: APL runtime initialization HTTP Resource downloader Android view host integration Android audio focus management Activity tracking for timeout management Audio and media players Interfaces to easily override functionality How to use the APL Render Module \u00b6 To use the APL Render module without customization, follow these steps: Define the APL layout. Initialize the APL runtime. Implement the event interface. Instantiate APLPresenter . Defining the APL Layout \u00b6 The application must define the layout of the screen on which the APL document is rendered. the width and height of the APLLayout must fall in range with one of the three supported automotive viewport profiles : auto extra small, auto small, and auto medium. Define an com.amazon.apl.android.APLLayout object, as shown in the following example, where the object is defined under res/layout : <? xml version = \"1.0\" encoding = \"utf-8\" ?> < LinearLayout xmlns : android = \"http://schemas.android.com/apk/res/android\" android : orientation = \"vertical\" android : layout_width = \"match_parent\" xmlns : app = \"http://schemas.android.com/apk/res-auto\" android : layout_height = \"match_parent\" > < com . amazon . apl . android . APLLayout android : layout_width = \"match_parent\" android : layout_height = \"match_parent\" android : background = \"?attr/colorPrimary\" android : id = \"@+id/apl\" android : theme = \"@style/Theme.AppCompat\" app : aplTheme = \"dark\" app : isRound = \"false\" app : mode = \"auto\" /> </ LinearLayout > The app:aplTheme field corresponds to the default APL theme to be used if one is not specified in the APL document. Typical values are light or dark . The app:mode field specifies the operating mode, which is a viewport property . For information about the viewport object, see the viewport documentation . The value for this field should be auto for an Automotive device. Initializing the APL Runtime \u00b6 The application must invoke the APLPresenter.initialize() static method before inflating the APLLayout UI component. The following code shows how to use the onCreate method of Activity to initialize the APL runtime: import com.amazon.apl.android.render.APLPresenter ; //--------------------------------------------------------------------- // Initialize the APL Runtime. This must be called during // Activity.onCreate() or prior to APLLayout inflation. //--------------------------------------------------------------------- onCreate () { Context context = getApplicationContext (); APLPresenter . initialize ( context ); } Implementing the Event Interface \u00b6 The application must implement the com.amazon.apl.android.render.interfaces.IAPLEventSender interface. The IAPLEventSender interface provides the APIs to allow the APL Render module to report events to Alexa or the capability agent. You can integrate the event interface into the APL handler that implements the Auto SDK APL AASB message interface. The following code shows how to do the integration: import com.amazon.aace.apl.APL ; import com.amazon.apl.android.render.interfaces.IAPLEventSender ; public class APLHandler extends APL implements IAPLEventSender { //--------------------------------------------------------------------- // Override IAPLEventSender methods. // APLHandler will register with APL Render library as the event sender. //--------------------------------------------------------------------- @Override public void sendRenderDocumentResult ( String token , boolean result , String error ) { renderDocumentResult ( token , result , error ); // APL::renderDocumentResult } @Override public void sendExecuteCommandsResult ( String token , boolean result , String error ) { executeCommandsResult ( token , result , error ); // APL::executeCommandsResult } ... } Instantiating APLPresenter \u00b6 The application must instantiate the APLPresenter object, which provides the orchestration logic in the APL rendering process. Note: Create APLPresenter after the APL platform interface handler is registered with the Auto SDK Engine. The following code shows how to instantiate the APLPresenter object: import com.amazon.apl.android.render.APLPresenter ; public class APLHandler extends APL implements IAPLEventSender { private APLPresenter mPresenter ; public void buildAPLPresenter ( JSONArray visualCharacteristics , String defaultWindowId ) { //--------------------------------------------------------------------- // Retrieve the APLLayout view with id 'apl' defined in apl_view.xml. // This assumes that 'activity' is the application's Activity. //--------------------------------------------------------------------- aplLayout = activity . findViewById ( R . id . apl ); //--------------------------------------------------------------------- // Application needs to handle the correlation of window ids from the // visual characteristics configuration to the APLLayout instance. //--------------------------------------------------------------------- HashMap aplLayouts = new HashMap < String , APLLayout > (); aplLayouts . put ( defaultWindowId , mAplLayout ); //--------------------------------------------------------------------- // Create APLPresenter to handle APL rendering. //--------------------------------------------------------------------- mPresenter = new APLPresenter ( aplLayouts , visualCharacteristics , defaultWindowId , this ); } The following list describes the parameters to APLPresenter : The first parameter is a map of the APLLayout objects. Each APLLayout is identified by a window ID, which specifies the window where the APL document is rendered. Typically, there is one APLLayout defined for the window where all the APL documents are rendered, but you can build skills that support rendering in multiple windows. The second parameter is a JSON array` pointing to the visual characteristics defined by the device. For more information about visual characteristics, see the Auto SDK APL module documentation and the Smart Screen SDK documentation . The third parameter is the default window ID, specifying the window where APL documents are rendered if Alexa does not provide a window ID. The last parameter is the object that implements the IAPLEventSender interface. Rendering an APL Document \u00b6 To render an APL document, call the onRenderDocument API on the APLPresenter . The APLHandler can delegate the APL APIs to the APLPresenter , as shown in the following code: public class APLHandler extends APL implements IAPLEventSender { ... //--------------------------------------------------------------------- // Override Auto SDK APL interfaces //--------------------------------------------------------------------- @Override public void renderDocument ( String payload , String token , String windowId ) { mAplPresenter . onRenderDocument ( payload , token , windowId ); // APLRender implements these interfaces } @Override public void executeCommands ( String payload , String token ) { mPresenter . onExecuteCommands ( payload , token ); } ... } Overriding Android View Host Options \u00b6 Rendering an APL document requires the APL Render module to set up an APLOptions object, which is passed to the view host. The APLOptions object is configured with providers, callbacks, and listeners, as described in the following list: Providers are objects implemented outside the view host.They provide objects used during the rendering process. For example, the data retriever provider downloads APL resources, such as layouts from content delivery networks (CDNs). The media player provider plays media, such as videos. Callbacks are interfaces used by the view host to report events, such as: user events (e.g., button clicks) document lifecycle events (e.g., completion of document rendering) Listeners are interfaces for reporting the APL rendered document state or screen lock events. The APL Render module sets up all the providers, callbacks, and listeners. If the application needs to override any of them, it uses the APLOptions.Builder object. Using APLOptions.Builder \u00b6 To override APLOptions , extend the APLPresenter object, as shown in the following code: class MyAPLPresenter extends APLPresenter { //--------------------------------------------------------------------- // IAPLOptionsBuilderProvider override //--------------------------------------------------------------------- @Override APLOptions . Builder getAPLOptionsBuilder () { APLOptions . Builder builder = super . getAPLOptionsBuilder (); // Listen in on APL finish callback builder . onAplFinishCallback (() -> { // Do something here super . onAplFinish (); }); return builder ; } } APL Runtime Properties \u00b6 The IAPLContentListener exposes an interface to control some APL runtime properties that affect how APL documents are rendered. The onAPLRuntimeProperties API takes in a JSON string that contains one or more properties to update. Driving State \u00b6 The drivingState property supports the values moving and parked . An APL experience may differ depending on the driving state in order to provide a safer driving experience. Theme \u00b6 The theme property allows the APL experience to render in different color schemes. There are six supported values: light, light-gray1, light-gray2, dark, dark-black, dark-gray. The light themes can be during for day driving, while the dark themes can be used for night driving. APL Extensions \u00b6 Backstack \u00b6 This library supports the Backstack extension. The application must ensure that the APLPresenter is not destroyed and recreated when a new APL document with the same token id is received. Otherwise, the Backstack will be reinstantiated and the previous stack of documents will be lost. Local Information Data \u00b6 This library contains a custom APL extension that is used by the APLPresenter to expose point of interest data to the application. This data can be used to drop corresponding pins on the head unit's integrated map. Two way communication is also provided so that the application or AP runtime can notify each other when a specific data point is active or selected. There are two interfaces that the application can use to interact with Local information data: ILocalInfoDataConsumer and ILocalInfoDataReporter . ILocalInfoDataConsumer \u00b6 The IPresenter ( https://github.com/alexa/alexa-auto-sdk/blob/master/aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/src/main/java/com/amazon/apl/android/render/interfaces/IPresenter.java ) interface exposes a method to set the data consumer, which must be set by the application: /** * Saves a reference to the local info data consumer. * * @param consumer The object that consume local info data events. */ void setLocalInfoDataConsumer(ILocalInfoDataConsumer consumer); The application will be notified through the consumer method aplDataAvailable with a JSON string object represention all the points of interest. The application will be notified when a specific data point is selected on the APL document using the consume method aplDataItemSelectedById . ILocalInfoDataReporter \u00b6 The APLPresenter implements the ILocalInfoDataReporter interface to allow the application to notify the APL runtime when a data point is selected outside of the APL runtime. To do this notification simply call platformDataItemSelectedById on the APLPresenter instance. Building the APL Render Library \u00b6 Note: Before proceeding to build the APL Render library, download the Android APL resource from the developer portal according to instructions from your Solutions Architect or Partner Manager. This library can be built using the included gradle wrapper as follows ./gradlew assembleRelease","title":"APL Render Module <!-- omit in toc -->"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-render-module","text":"The APL Render module is an Android library that enables Alexa Presentation Language (APL) rendering capabilities in an Android application. For detailed information about APL, see the APL documentation .","title":"APL Render Module "},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#table-of-contents","text":"Overview Understanding Android View Host APL Render Module Functionality How to use the APL Render Module Defining the APL Layout Initializing the APL Runtime Implementing the Event Interface Instantiating APLPresenter Rendering an APL Document Overriding Android View Host Options Using APLOptions.Builder APL Runtime Properties Driving State Theme APL Extensions Backstack Local Information Data ILocalInfoDataConsumer ILocalInfoDataReporter Building the APL Render Library","title":"Table of Contents"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#overview","text":"Rendering an APL document on a device requires the implementation of various components and the logic that makes the components work together. To handle APL-related directives and events, the device must support APL interfaces. It needs integration of the APL Core Library to manage the document parsing and rendering workflow. In addition, you must build a view host for the device to render the APL document on the screen, as well as provide components to download layouts, images, and other resources. If the APL document generates multimedia content, such as a video or audio file, you need a media player to play back the content. Lastly, APL rendering needs the orchestration logic to manage the lifecycle of a rendered document, which includes user events, audio focus management, time out management, visual context, command execution, and much more. The Alexa Auto SDK, with the APL Render module and a prebuilt Android view host, simplifies the process of APL rendering because it provides the aforementioned components and logic for you.","title":"Overview"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#understanding-android-view-host","text":"The Android view host is the component responsible for rendering APL on the screen. Amazon provides a prebuilt Android view host as an Android Archive Library (AAR) on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To use the Android Render module, you must place the Android view host AAR in the src/main/libs/ folder of the APL Render module.","title":"Understanding Android View Host"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-render-module-functionality","text":"The APL Render module provides all the functionality needed for enabling APL rendering capabilities in an Android application. The APL Render module provides the following capabilities: APL runtime initialization HTTP Resource downloader Android view host integration Android audio focus management Activity tracking for timeout management Audio and media players Interfaces to easily override functionality","title":"APL Render Module Functionality"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#how-to-use-the-apl-render-module","text":"To use the APL Render module without customization, follow these steps: Define the APL layout. Initialize the APL runtime. Implement the event interface. Instantiate APLPresenter .","title":"How to use the APL Render Module"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#defining-the-apl-layout","text":"The application must define the layout of the screen on which the APL document is rendered. the width and height of the APLLayout must fall in range with one of the three supported automotive viewport profiles : auto extra small, auto small, and auto medium. Define an com.amazon.apl.android.APLLayout object, as shown in the following example, where the object is defined under res/layout : <? xml version = \"1.0\" encoding = \"utf-8\" ?> < LinearLayout xmlns : android = \"http://schemas.android.com/apk/res/android\" android : orientation = \"vertical\" android : layout_width = \"match_parent\" xmlns : app = \"http://schemas.android.com/apk/res-auto\" android : layout_height = \"match_parent\" > < com . amazon . apl . android . APLLayout android : layout_width = \"match_parent\" android : layout_height = \"match_parent\" android : background = \"?attr/colorPrimary\" android : id = \"@+id/apl\" android : theme = \"@style/Theme.AppCompat\" app : aplTheme = \"dark\" app : isRound = \"false\" app : mode = \"auto\" /> </ LinearLayout > The app:aplTheme field corresponds to the default APL theme to be used if one is not specified in the APL document. Typical values are light or dark . The app:mode field specifies the operating mode, which is a viewport property . For information about the viewport object, see the viewport documentation . The value for this field should be auto for an Automotive device.","title":"Defining the APL Layout"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#initializing-the-apl-runtime","text":"The application must invoke the APLPresenter.initialize() static method before inflating the APLLayout UI component. The following code shows how to use the onCreate method of Activity to initialize the APL runtime: import com.amazon.apl.android.render.APLPresenter ; //--------------------------------------------------------------------- // Initialize the APL Runtime. This must be called during // Activity.onCreate() or prior to APLLayout inflation. //--------------------------------------------------------------------- onCreate () { Context context = getApplicationContext (); APLPresenter . initialize ( context ); }","title":"Initializing the APL Runtime"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#implementing-the-event-interface","text":"The application must implement the com.amazon.apl.android.render.interfaces.IAPLEventSender interface. The IAPLEventSender interface provides the APIs to allow the APL Render module to report events to Alexa or the capability agent. You can integrate the event interface into the APL handler that implements the Auto SDK APL AASB message interface. The following code shows how to do the integration: import com.amazon.aace.apl.APL ; import com.amazon.apl.android.render.interfaces.IAPLEventSender ; public class APLHandler extends APL implements IAPLEventSender { //--------------------------------------------------------------------- // Override IAPLEventSender methods. // APLHandler will register with APL Render library as the event sender. //--------------------------------------------------------------------- @Override public void sendRenderDocumentResult ( String token , boolean result , String error ) { renderDocumentResult ( token , result , error ); // APL::renderDocumentResult } @Override public void sendExecuteCommandsResult ( String token , boolean result , String error ) { executeCommandsResult ( token , result , error ); // APL::executeCommandsResult } ... }","title":"Implementing the Event Interface"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#instantiating-aplpresenter","text":"The application must instantiate the APLPresenter object, which provides the orchestration logic in the APL rendering process. Note: Create APLPresenter after the APL platform interface handler is registered with the Auto SDK Engine. The following code shows how to instantiate the APLPresenter object: import com.amazon.apl.android.render.APLPresenter ; public class APLHandler extends APL implements IAPLEventSender { private APLPresenter mPresenter ; public void buildAPLPresenter ( JSONArray visualCharacteristics , String defaultWindowId ) { //--------------------------------------------------------------------- // Retrieve the APLLayout view with id 'apl' defined in apl_view.xml. // This assumes that 'activity' is the application's Activity. //--------------------------------------------------------------------- aplLayout = activity . findViewById ( R . id . apl ); //--------------------------------------------------------------------- // Application needs to handle the correlation of window ids from the // visual characteristics configuration to the APLLayout instance. //--------------------------------------------------------------------- HashMap aplLayouts = new HashMap < String , APLLayout > (); aplLayouts . put ( defaultWindowId , mAplLayout ); //--------------------------------------------------------------------- // Create APLPresenter to handle APL rendering. //--------------------------------------------------------------------- mPresenter = new APLPresenter ( aplLayouts , visualCharacteristics , defaultWindowId , this ); } The following list describes the parameters to APLPresenter : The first parameter is a map of the APLLayout objects. Each APLLayout is identified by a window ID, which specifies the window where the APL document is rendered. Typically, there is one APLLayout defined for the window where all the APL documents are rendered, but you can build skills that support rendering in multiple windows. The second parameter is a JSON array` pointing to the visual characteristics defined by the device. For more information about visual characteristics, see the Auto SDK APL module documentation and the Smart Screen SDK documentation . The third parameter is the default window ID, specifying the window where APL documents are rendered if Alexa does not provide a window ID. The last parameter is the object that implements the IAPLEventSender interface.","title":"Instantiating APLPresenter"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#rendering-an-apl-document","text":"To render an APL document, call the onRenderDocument API on the APLPresenter . The APLHandler can delegate the APL APIs to the APLPresenter , as shown in the following code: public class APLHandler extends APL implements IAPLEventSender { ... //--------------------------------------------------------------------- // Override Auto SDK APL interfaces //--------------------------------------------------------------------- @Override public void renderDocument ( String payload , String token , String windowId ) { mAplPresenter . onRenderDocument ( payload , token , windowId ); // APLRender implements these interfaces } @Override public void executeCommands ( String payload , String token ) { mPresenter . onExecuteCommands ( payload , token ); } ... }","title":"Rendering an APL Document"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#overriding-android-view-host-options","text":"Rendering an APL document requires the APL Render module to set up an APLOptions object, which is passed to the view host. The APLOptions object is configured with providers, callbacks, and listeners, as described in the following list: Providers are objects implemented outside the view host.They provide objects used during the rendering process. For example, the data retriever provider downloads APL resources, such as layouts from content delivery networks (CDNs). The media player provider plays media, such as videos. Callbacks are interfaces used by the view host to report events, such as: user events (e.g., button clicks) document lifecycle events (e.g., completion of document rendering) Listeners are interfaces for reporting the APL rendered document state or screen lock events. The APL Render module sets up all the providers, callbacks, and listeners. If the application needs to override any of them, it uses the APLOptions.Builder object.","title":"Overriding Android View Host Options"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#using-aploptionsbuilder","text":"To override APLOptions , extend the APLPresenter object, as shown in the following code: class MyAPLPresenter extends APLPresenter { //--------------------------------------------------------------------- // IAPLOptionsBuilderProvider override //--------------------------------------------------------------------- @Override APLOptions . Builder getAPLOptionsBuilder () { APLOptions . Builder builder = super . getAPLOptionsBuilder (); // Listen in on APL finish callback builder . onAplFinishCallback (() -> { // Do something here super . onAplFinish (); }); return builder ; } }","title":"Using APLOptions.Builder"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-runtime-properties","text":"The IAPLContentListener exposes an interface to control some APL runtime properties that affect how APL documents are rendered. The onAPLRuntimeProperties API takes in a JSON string that contains one or more properties to update.","title":"APL Runtime Properties"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#driving-state","text":"The drivingState property supports the values moving and parked . An APL experience may differ depending on the driving state in order to provide a safer driving experience.","title":"Driving State"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#theme","text":"The theme property allows the APL experience to render in different color schemes. There are six supported values: light, light-gray1, light-gray2, dark, dark-black, dark-gray. The light themes can be during for day driving, while the dark themes can be used for night driving.","title":"Theme"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-extensions","text":"","title":"APL Extensions"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#backstack","text":"This library supports the Backstack extension. The application must ensure that the APLPresenter is not destroyed and recreated when a new APL document with the same token id is received. Otherwise, the Backstack will be reinstantiated and the previous stack of documents will be lost.","title":"Backstack"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#local-information-data","text":"This library contains a custom APL extension that is used by the APLPresenter to expose point of interest data to the application. This data can be used to drop corresponding pins on the head unit's integrated map. Two way communication is also provided so that the application or AP runtime can notify each other when a specific data point is active or selected. There are two interfaces that the application can use to interact with Local information data: ILocalInfoDataConsumer and ILocalInfoDataReporter .","title":"Local Information Data"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#ilocalinfodataconsumer","text":"The IPresenter ( https://github.com/alexa/alexa-auto-sdk/blob/master/aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/src/main/java/com/amazon/apl/android/render/interfaces/IPresenter.java ) interface exposes a method to set the data consumer, which must be set by the application: /** * Saves a reference to the local info data consumer. * * @param consumer The object that consume local info data events. */ void setLocalInfoDataConsumer(ILocalInfoDataConsumer consumer); The application will be notified through the consumer method aplDataAvailable with a JSON string object represention all the points of interest. The application will be notified when a specific data point is selected on the APL document using the consume method aplDataItemSelectedById .","title":"ILocalInfoDataConsumer"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#ilocalinfodatareporter","text":"The APLPresenter implements the ILocalInfoDataReporter interface to allow the application to notify the APL runtime when a data point is selected outside of the APL runtime. To do this notification simply call platformDataItemSelectedById on the APLPresenter instance.","title":"ILocalInfoDataReporter"},{"location":"android/aacs/app-components/alexa-auto-apl-renderer/modules/apl-render/#building-the-apl-render-library","text":"Note: Before proceeding to build the APL Render library, download the Android APL resource from the developer portal according to instructions from your Solutions Architect or Partner Manager. This library can be built using the included gradle wrapper as follows ./gradlew assembleRelease","title":"Building the APL Render Library"},{"location":"android/aacs/app-components/alexa-auto-apps-common-ui/","text":"Alexa Auto Apps Common UI \u00b6 This package provides themes, colors, fonts, styles, icons, and other common UI elements for the AACS Sample App and app components to use.","title":"Alexa Auto Apps Common UI"},{"location":"android/aacs/app-components/alexa-auto-apps-common-ui/#alexa-auto-apps-common-ui","text":"This package provides themes, colors, fonts, styles, icons, and other common UI elements for the AACS Sample App and app components to use.","title":"Alexa Auto Apps Common UI"},{"location":"android/aacs/app-components/alexa-auto-apps-common-util/","text":"Alexa Auto Apps Common Util \u00b6 This package provides the AACS Sample App and app components with various helper classes to simplify the implementation. The provided utilities include: Start, Stop and share files with AACS. Get and set the Alexa properties. Handle the file operations. Get the enabled Alexa Auto SDK extra modules. Get the network connectivity status. Check the preconditions. Manage the ambient light sensor and Alexa Auto theme update.","title":"Alexa Auto Apps Common Util"},{"location":"android/aacs/app-components/alexa-auto-apps-common-util/#alexa-auto-apps-common-util","text":"This package provides the AACS Sample App and app components with various helper classes to simplify the implementation. The provided utilities include: Start, Stop and share files with AACS. Get and set the Alexa properties. Handle the file operations. Get the enabled Alexa Auto SDK extra modules. Get the network connectivity status. Check the preconditions. Manage the ambient light sensor and Alexa Auto theme update.","title":"Alexa Auto Apps Common Util"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/","text":"AACS Car Control \u00b6 The AACS Car Control library is an Android library for the AACS Core Service to run car control commands in cars that are based on Android Automotive OS. A car control command is run by the AACS Core Service each time the user tries to voice-control a vehicle component. Table of Contents \u00b6 Overview Understanding Library Components Building the AACS Car Control Library Before Using the AACS Car Control Library Including AACS Car Control Library in a System Application Providing Permission in Android Manifest Ensuring Intent Target Specified in the Library is Used Sequence Diagrams How the AACS Car Control Library Works Overview \u00b6 Using the AACS Car Control Library, AACS allows user utterances to be directly applied to Android Automotive OS car control APIs and then to the Hardware Abstraction Layer to complete the car control workflow. The library translates between Auto SDK Car Control events and Android Automotive CarPropertyManager API calls, which controls various car features, such as air conditioning and fan settings. For information about CarPropertyManager , see the Android documentation on CarPropertyManager . The library works with Android Car API and CarPropertyManager API . These APIs are only available at Android API level 29 and up. The library is an optional module. You can build it into an Android archive (AAR) to be included in your application. Understanding Library Components \u00b6 The following list describes the purposes of the major components of the library: The AACS Car Control Broadcast Receiver: Receiving AASB AdjustControllerValue or SetControllerValue messages from the AACS Core Service. Instantiating the Car Control Handler to call specific controller operations. The exact operations supported depend on the controller type, which can be Power, Toggle, Mode, or Range. The AACS Car Control platform implementation ( CarControlHandler ): Instantiating the Android Car object to be called in the set and adjust methods for each controller type. Defining the get and set methods for each controller type. Defining the adjust methods for the Range or Power Controller. The AACS Car Control Helper/Util: Providing translation between [endpointID, controllerType, controllerID, value] in the AASB Car Control message from the Auto SDK Engine to [propertyId, areaId, value] used in the Android Automotive API call. Getting or saving the current Mode setting for the Mode Controller. Enabling you to parse an external configuration file if you want to use a customized CarControlEndpointMapping.json file. Car Control Endpoint Mapping configuration file maps [endpointID, controllerType, controllerID, value] from the Auto SDK Car Control Asset to [propertyId, areaId, value] used in the Android Automotive API call. A default CarControlEndpointMapping.json file is provided in the assets directory. Be sure to review CarControlEndpointMapping.json to verify that it contains values consistent with the ones specified in the CarControlConfig.json file in the Car Control module . For example, if you have changed an endpointId in CarControlConfig.json from \"default.light\" to \"default.roof.light\" , the CarControlEndpointMapping.json file must contain the same endpoint mapping information. Building the AACS Car Control Library \u00b6 You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Car Control library: ./gradlew :alexa-auto-carcontrol:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-carcontrol/aacscarcontrol/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Car Control AAR. To enable car control support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with car control enabled. ./gradlew assembleLocalRelease -PenabledCarControl For more build options, see the AACS Sample App README . Before Using the AACS Car Control Library \u00b6 Before using the library, follow these major steps: Install your application with the AACS and Car Control AARs as a system privileged app on Android Automotive OS. Provide permission in your app's Android Manifest. Ensure that the intent target specified in the library is used. Including AACS Car Control Library in a System Application \u00b6 For AACS to enable the permission namespace android.car.permission , it must run in a system privileged app. To install your application as a system privileged app, place it in the /system/priv-app/ directory. Providing Permission in Android Manifest \u00b6 For security reasons, for your application to send intents to or receive intents from the AACS Car Control Library, follow these steps: 1) In privapp-permissions-com.amazon.alexaautoclientservice.xml , specify android.car.permission . The following example file shows how to specify permissions for using intents for various car control operations. <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexaautoclientservice\" > <permission name= \"android.car.permission.CONTROL_CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_DOORS\" /> <permission name= \"android.car.permission.CONTROL_CAR_CLIMATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_SEATS\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_ENVIRONMENT\" /> <permission name= \"android.car.permission.CAR_ENERGY_PORTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_MIRRORS\" /> <permission name= \"android.car.permission.READ_CAR_DISPLAY_UNITS\" /> <permission name= \"android.car.permission.CONTROL_CAR_WINDOWS\" /> <permission name= \"android.car.permission.CAR_CONTROL_AUDIO_VOLUME\" /> <permission name= \"android.car.permission.CAR_DISPLAY_IN_CLUSTER\" /> <permission name= \"android.car.permission.CAR_INSTRUMENT_CLUSTER_CONTROL\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.READ_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CAR_DYNAMICS_STATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_DISPLAY_UNITS\" /> <permission name= \"android.permission.INTERNET\" /> <permission name= \"android.permission.RECORD_AUDIO\" /> <permission name= \"android.permission.ACCESS_FINE_LOCATION\" /> <permission name= \"android.permission.ACCESS_NETWORK_STATE\" /> <permission name= \"android.permission.ACCESS_WIFI_STATE\" /> <permission name= \"android.permission.RECEIVE_BOOT_COMPLETED\" /> <permission name= \"android.permission.CONTROL_INCALL_EXPERIENCE\" /> <permission name= \"android.permission.CAPTURE_AUDIO_OUTPUT\" /> <permission name= \"android.permission.INTERACT_ACROSS_USERS\" /> </privapp-permissions> </permissions> 2) Include privapp-permissions-com.amazon.alexaautoclientservice.xml in the /etc/permissions/ directory. Ensuring Intent Target Specified in the Library is Used \u00b6 The AACS Car Control Broadcast Receiver listens to intents from the AACS Core Service with the CarControl topic. The intent filter in the AACS Car Control Library already defines the intent target for CarControl . For the intent filter in the library to take effect, be sure to clear the intent target defined for CarControl in the AACS configuration as follows. Otherwise, the target specification in the AACS configuration overrides the intent filter in the library. \"CarControl\" : { \"type\" : [], \"package\" : [], \"class\" : [] } Sequence Diagrams \u00b6 The following diagram illustrates the flow when an utterance asks Alexa to set fan speed to 3. The following diagram illustrates the flow after the set value is finished at the hardware layer. How the AACS Car Control Library Works \u00b6 When the user issues an utterance, the Engine receives a car control event from Alexa, which the Engine passes to AACS through an AASB message. The AASB message received by AACS has the following attributes: Action is com.amazon.aacs.aasb.AdjustControllerValue or com.amazon.aacs.aasb.SetControllerValue . Category is com.amazon.aacs.aasb.CarControl . Extras is payload . The payload object includes detailed information about the action, which is specified in the messageDescription field of the AASB message. The following list describes the payload for each action: For SetControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"POWER\", \"endpointId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } For AdjustControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"TOGGLE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } For SetModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : \"{{String}}\" } For SetRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : {{Double}} } For AdjustModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Integer}} } For AdjustRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Double}} } After receiving the intent, the AACS Car Control Broadcast Receiver parses the payload and calls for the Car Control Handler to perform specific car control operations.","title":"AACS Car Control <!-- omit in toc -->"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#aacs-car-control","text":"The AACS Car Control library is an Android library for the AACS Core Service to run car control commands in cars that are based on Android Automotive OS. A car control command is run by the AACS Core Service each time the user tries to voice-control a vehicle component.","title":"AACS Car Control "},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#table-of-contents","text":"Overview Understanding Library Components Building the AACS Car Control Library Before Using the AACS Car Control Library Including AACS Car Control Library in a System Application Providing Permission in Android Manifest Ensuring Intent Target Specified in the Library is Used Sequence Diagrams How the AACS Car Control Library Works","title":"Table of Contents"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#overview","text":"Using the AACS Car Control Library, AACS allows user utterances to be directly applied to Android Automotive OS car control APIs and then to the Hardware Abstraction Layer to complete the car control workflow. The library translates between Auto SDK Car Control events and Android Automotive CarPropertyManager API calls, which controls various car features, such as air conditioning and fan settings. For information about CarPropertyManager , see the Android documentation on CarPropertyManager . The library works with Android Car API and CarPropertyManager API . These APIs are only available at Android API level 29 and up. The library is an optional module. You can build it into an Android archive (AAR) to be included in your application.","title":"Overview"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#understanding-library-components","text":"The following list describes the purposes of the major components of the library: The AACS Car Control Broadcast Receiver: Receiving AASB AdjustControllerValue or SetControllerValue messages from the AACS Core Service. Instantiating the Car Control Handler to call specific controller operations. The exact operations supported depend on the controller type, which can be Power, Toggle, Mode, or Range. The AACS Car Control platform implementation ( CarControlHandler ): Instantiating the Android Car object to be called in the set and adjust methods for each controller type. Defining the get and set methods for each controller type. Defining the adjust methods for the Range or Power Controller. The AACS Car Control Helper/Util: Providing translation between [endpointID, controllerType, controllerID, value] in the AASB Car Control message from the Auto SDK Engine to [propertyId, areaId, value] used in the Android Automotive API call. Getting or saving the current Mode setting for the Mode Controller. Enabling you to parse an external configuration file if you want to use a customized CarControlEndpointMapping.json file. Car Control Endpoint Mapping configuration file maps [endpointID, controllerType, controllerID, value] from the Auto SDK Car Control Asset to [propertyId, areaId, value] used in the Android Automotive API call. A default CarControlEndpointMapping.json file is provided in the assets directory. Be sure to review CarControlEndpointMapping.json to verify that it contains values consistent with the ones specified in the CarControlConfig.json file in the Car Control module . For example, if you have changed an endpointId in CarControlConfig.json from \"default.light\" to \"default.roof.light\" , the CarControlEndpointMapping.json file must contain the same endpoint mapping information.","title":"Understanding Library Components"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#building-the-aacs-car-control-library","text":"You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Car Control library: ./gradlew :alexa-auto-carcontrol:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-carcontrol/aacscarcontrol/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Car Control AAR. To enable car control support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with car control enabled. ./gradlew assembleLocalRelease -PenabledCarControl For more build options, see the AACS Sample App README .","title":"Building the AACS Car Control Library"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#before-using-the-aacs-car-control-library","text":"Before using the library, follow these major steps: Install your application with the AACS and Car Control AARs as a system privileged app on Android Automotive OS. Provide permission in your app's Android Manifest. Ensure that the intent target specified in the library is used.","title":"Before Using the AACS Car Control Library"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#including-aacs-car-control-library-in-a-system-application","text":"For AACS to enable the permission namespace android.car.permission , it must run in a system privileged app. To install your application as a system privileged app, place it in the /system/priv-app/ directory.","title":"Including AACS Car Control Library in a System Application"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#providing-permission-in-android-manifest","text":"For security reasons, for your application to send intents to or receive intents from the AACS Car Control Library, follow these steps: 1) In privapp-permissions-com.amazon.alexaautoclientservice.xml , specify android.car.permission . The following example file shows how to specify permissions for using intents for various car control operations. <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexaautoclientservice\" > <permission name= \"android.car.permission.CONTROL_CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_DOORS\" /> <permission name= \"android.car.permission.CONTROL_CAR_CLIMATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_SEATS\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_ENVIRONMENT\" /> <permission name= \"android.car.permission.CAR_ENERGY_PORTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_MIRRORS\" /> <permission name= \"android.car.permission.READ_CAR_DISPLAY_UNITS\" /> <permission name= \"android.car.permission.CONTROL_CAR_WINDOWS\" /> <permission name= \"android.car.permission.CAR_CONTROL_AUDIO_VOLUME\" /> <permission name= \"android.car.permission.CAR_DISPLAY_IN_CLUSTER\" /> <permission name= \"android.car.permission.CAR_INSTRUMENT_CLUSTER_CONTROL\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.READ_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CAR_DYNAMICS_STATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_DISPLAY_UNITS\" /> <permission name= \"android.permission.INTERNET\" /> <permission name= \"android.permission.RECORD_AUDIO\" /> <permission name= \"android.permission.ACCESS_FINE_LOCATION\" /> <permission name= \"android.permission.ACCESS_NETWORK_STATE\" /> <permission name= \"android.permission.ACCESS_WIFI_STATE\" /> <permission name= \"android.permission.RECEIVE_BOOT_COMPLETED\" /> <permission name= \"android.permission.CONTROL_INCALL_EXPERIENCE\" /> <permission name= \"android.permission.CAPTURE_AUDIO_OUTPUT\" /> <permission name= \"android.permission.INTERACT_ACROSS_USERS\" /> </privapp-permissions> </permissions> 2) Include privapp-permissions-com.amazon.alexaautoclientservice.xml in the /etc/permissions/ directory.","title":"Providing Permission in Android Manifest"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#ensuring-intent-target-specified-in-the-library-is-used","text":"The AACS Car Control Broadcast Receiver listens to intents from the AACS Core Service with the CarControl topic. The intent filter in the AACS Car Control Library already defines the intent target for CarControl . For the intent filter in the library to take effect, be sure to clear the intent target defined for CarControl in the AACS configuration as follows. Otherwise, the target specification in the AACS configuration overrides the intent filter in the library. \"CarControl\" : { \"type\" : [], \"package\" : [], \"class\" : [] }","title":"Ensuring Intent Target Specified in the Library is Used"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#sequence-diagrams","text":"The following diagram illustrates the flow when an utterance asks Alexa to set fan speed to 3. The following diagram illustrates the flow after the set value is finished at the hardware layer.","title":"Sequence Diagrams"},{"location":"android/aacs/app-components/alexa-auto-carcontrol/#how-the-aacs-car-control-library-works","text":"When the user issues an utterance, the Engine receives a car control event from Alexa, which the Engine passes to AACS through an AASB message. The AASB message received by AACS has the following attributes: Action is com.amazon.aacs.aasb.AdjustControllerValue or com.amazon.aacs.aasb.SetControllerValue . Category is com.amazon.aacs.aasb.CarControl . Extras is payload . The payload object includes detailed information about the action, which is specified in the messageDescription field of the AASB message. The following list describes the payload for each action: For SetControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"POWER\", \"endpointId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } For AdjustControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"TOGGLE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } For SetModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : \"{{String}}\" } For SetRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : {{Double}} } For AdjustModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Integer}} } For AdjustRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Double}} } After receiving the intent, the AACS Car Control Broadcast Receiver parses the payload and calls for the Car Control Handler to perform specific car control operations.","title":"How the AACS Car Control Library Works"},{"location":"android/aacs/app-components/alexa-auto-comms-ui/","text":"Alexa Auto Comms UI \u00b6 This library serves the following purposes: It handles Bluetooth-related directives. When a Bluetooth device is connected or disconnected, the BluetoothReceiver class receives the intent with the device's connection status, MAC address, and display name. When a device is paired, the class receives the intent for a device pairing, with the device's bond state, MAC address, and display name. The BluetoothReceiver class calls the BluetoothDirectiveHandler class to update the Bluetooth device database based on the change. It handles contacts upload or removal requests to Alexa. This library starts the AACS contacts service intents to handle contacts upload or removal requests. On the Android Automotive OS, the last connected phone is considered the primary device. Only one device can upload the address book to the cloud at a time. If the primary phone changes, the old address book is removed and the new address book is scheduled to upload after 30 seconds. If you want to change this default behavior, implement your own system UI for users to select the primary phone and call the Android system API setUserSelectedOutgoingPhoneAccount to set the user-selected outgoing phone account. Send a com.amazon.alexa.auto.comms.primaryPhoneChanged intent to Alexa Auto Comms UI to inform the change of the primary phone. ComponentName c = new ComponentName(\"com.amazon.alexa.auto.app\", \"com.amazon.alexa.auto.comms.ui.receiver.BluetoothReceiver\"); intent.setComponent(c); intent.addCategory(\"com.amazon.alexa.auto.comms\"); intent.setAction(\"com.amazon.alexa.auto.comms.primaryPhoneChanged\"); sendBroadcast(intent); A contacts consent screen is displayed during Alexa setup on the primary phone if the device does not have contacts upload permission. The contacts consent screen is also shown if a phone is paired after setup and does not have contacts upload permission. The Alexa communication settings screen displays a list of paired devices, both connected and disconnected, with contacts upload permission status. The user can enable or disable the contacts upload permission for each device. If the contacts permission for the primary phone is enabled, the contacts in that device will be uploaded. If the contacts permission for a non-primary phone is enabled, the contacts in that phone will not be uploaded until the phone is selected as the primary. The permission is retained until logout when it is reset. Databases \u00b6 There are two databases where devices are stored: BTDeviceRepository stores device information for every device that is paired. The devices are never removed from this database. ConnectedBTDeviceRepository stores device information for currently connected devices only. If a phone is disconnected, it will be removed and will only be found in the BTDeviceRepository . If a phone is disconnected and a user enables/disables contacts for the device in the communications screen, the permission is stored in the BTDeviceRepository device and the ConnectedBTDevice is updated with the BTDevice permission on the next connection. Prerequisites \u00b6 The following list describes the prerequisites for this library: AACS Telephony and Contacts libraries must be built. Your Android device must meet the prerequisites for using the AACS Telephony library . Known Issues \u00b6 On a reboot, Android automatically connects any phone that is paired which could cause the primary phone to change and contacts sync issues.","title":"Alexa Auto Comms UI"},{"location":"android/aacs/app-components/alexa-auto-comms-ui/#alexa-auto-comms-ui","text":"This library serves the following purposes: It handles Bluetooth-related directives. When a Bluetooth device is connected or disconnected, the BluetoothReceiver class receives the intent with the device's connection status, MAC address, and display name. When a device is paired, the class receives the intent for a device pairing, with the device's bond state, MAC address, and display name. The BluetoothReceiver class calls the BluetoothDirectiveHandler class to update the Bluetooth device database based on the change. It handles contacts upload or removal requests to Alexa. This library starts the AACS contacts service intents to handle contacts upload or removal requests. On the Android Automotive OS, the last connected phone is considered the primary device. Only one device can upload the address book to the cloud at a time. If the primary phone changes, the old address book is removed and the new address book is scheduled to upload after 30 seconds. If you want to change this default behavior, implement your own system UI for users to select the primary phone and call the Android system API setUserSelectedOutgoingPhoneAccount to set the user-selected outgoing phone account. Send a com.amazon.alexa.auto.comms.primaryPhoneChanged intent to Alexa Auto Comms UI to inform the change of the primary phone. ComponentName c = new ComponentName(\"com.amazon.alexa.auto.app\", \"com.amazon.alexa.auto.comms.ui.receiver.BluetoothReceiver\"); intent.setComponent(c); intent.addCategory(\"com.amazon.alexa.auto.comms\"); intent.setAction(\"com.amazon.alexa.auto.comms.primaryPhoneChanged\"); sendBroadcast(intent); A contacts consent screen is displayed during Alexa setup on the primary phone if the device does not have contacts upload permission. The contacts consent screen is also shown if a phone is paired after setup and does not have contacts upload permission. The Alexa communication settings screen displays a list of paired devices, both connected and disconnected, with contacts upload permission status. The user can enable or disable the contacts upload permission for each device. If the contacts permission for the primary phone is enabled, the contacts in that device will be uploaded. If the contacts permission for a non-primary phone is enabled, the contacts in that phone will not be uploaded until the phone is selected as the primary. The permission is retained until logout when it is reset.","title":"Alexa Auto Comms UI"},{"location":"android/aacs/app-components/alexa-auto-comms-ui/#databases","text":"There are two databases where devices are stored: BTDeviceRepository stores device information for every device that is paired. The devices are never removed from this database. ConnectedBTDeviceRepository stores device information for currently connected devices only. If a phone is disconnected, it will be removed and will only be found in the BTDeviceRepository . If a phone is disconnected and a user enables/disables contacts for the device in the communications screen, the permission is stored in the BTDeviceRepository device and the ConnectedBTDevice is updated with the BTDevice permission on the next connection.","title":"Databases"},{"location":"android/aacs/app-components/alexa-auto-comms-ui/#prerequisites","text":"The following list describes the prerequisites for this library: AACS Telephony and Contacts libraries must be built. Your Android device must meet the prerequisites for using the AACS Telephony library .","title":"Prerequisites"},{"location":"android/aacs/app-components/alexa-auto-comms-ui/#known-issues","text":"On a reboot, Android automatically connects any phone that is paired which could cause the primary phone to change and contacts sync issues.","title":"Known Issues"},{"location":"android/aacs/app-components/alexa-auto-contacts/","text":"AACS Contacts \u00b6 The AACS Contacts library is an Android library used by the AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information. Table of Contents \u00b6 Overview Building the Library Setup for AACS Contacts Library Providing Permission in Android Manifest Specifying Intent Targets Sequence Diagrams How the AACS Contacts Library Works with an Address Book Uploading Address Book Removing Address Book Overview \u00b6 Using the Contacts Library, AACS enables your app to interact with the Auto SDK Engine easily to add or remove an address book, which contains all contact information maintained by the Android Contacts Provider. For information about Contacts Provider, see the Contacts Provider documentation . Note: An address book can be of the type Contact or Navigation. The Contacts Library only works with the Contact type. For example, AACS cannot use the library to fetch data about a navigation favorite. See the Auto SDK Address Book module documentation for more information about the AddressBookType API. The following list describes the major components of the library: The AACS Contacts Service is responsible for: Receiving AASB AddAddressBook or RemoveAddressBook messages from the AACS Core Service. Receiving defined intents from your application to upload or remove an address book The AACS Contacts Library platform implementation ( PhoneBookController ) is responsible for: Fetching the address book from the Android Contacts Provider Parsing all contact data from the address book into an AASB AddAddressBook message Sending the AASB AddAddressBook intent to the AACS Core Service to upload the address book to Alexa Sending the AASB RemoveAddressBook intent to the AACS Core Service to remove from Alexa an address book with a specific addressBookSourceId , a unique address book identifier defined in the Address Book handler (Bluetooth MAC address of connected phone) Providing the API for adding or removing an address book for your application to call The AACS Contacts Library is an optional module, which you can use as is or as a reference when you integrate the Address Book module with AACS. You can build it into an Android archive (AAR) to be included in the AACS APK (recommended) or in your application APK. Building the Library \u00b6 You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Contacts library: ./gradlew :alexa-auto-contacts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-contacts/aacscontacts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Contacts AAR. To enable contacts support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with contacts enabled. ./gradlew assembleLocalRelease -PenabledContacts For more build options, see the AACS Sample App README . Setup for AACS Contacts Library \u00b6 Before using the AACS Contacts Library, follow these major steps: Provide permission in your application's Android manifest. Specify targets for intents from the AACS Core Service. Providing Permission in Android Manifest \u00b6 For security reasons, for your application to send intents to or receive intents from the AACS Contacts Service, specify the com.amazon.aacscontacts permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacscontacts\" /> Specifying Intent Targets \u00b6 The AACS Contacts Service listens to intents from the AACS Core Service with the AddressBook topic. To specify AACS Contacts Service with an intent target for the AddressBook topic, follow one of these steps: Manually specify the messages in the AACS configuration file, as described in the AACS README . The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify an intent target in the AACS configuration file. In this example, the AACS Contacts Library AAR is part of the AACS APK. \"AddressBook\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexaautoclientservice\", ...], \"class\": [\"<target_1_class_name>\", \"com.amazon.aacscontacts.AACSContactsService\", ...] } Omit ANY targets for AddressBook in the AACS configuration file. As a result, the intent filter defined in the AACS Contacts Library takes effect, enabling the AACS Contacts Service to receive the intents. Sequence Diagrams \u00b6 The following diagram illustrates the flow when an address book is uploaded to Alexa. The following diagram illustrates the flow when an address book is removed from Alexa. How the AACS Contacts Library Works with an Address Book \u00b6 This section describes how the Contacts Library uploads or removes an address book. Uploading Address Book \u00b6 Use one of the following methods to upload an address book to Alexa: Use intent. Your application can inform the AACS Contacts Library to upload an address book to Alexa by using an intent. When the AACS Contacts Library receives the intent, the library fetches contacts from the Contacts Provider on the head unit and uploads them to Alexa. To determine whether the upload is successful, your application can subscribe to the AASB AddressBook intents. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.upload . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (Must be Bluetooth MAC address from connected phone fetched from client application) and the name of the address book (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\", \"addressBookName\": \"<Name of phone book>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.uploadContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.uploadContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.uploadContacts(addressBookSourceId, addressBookName); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts upload working properly Removing Address Book \u00b6 Use one of the following methods to remove an address book from Alexa: Use intent. Your application can inform the AACS Contacts Service to remove an address book from Alexa by using an intent. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.remove . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.removeContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.removeContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.removeContacts(addressBookSourceId); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts remove working properly","title":"AACS Contacts <!-- omit in toc -->"},{"location":"android/aacs/app-components/alexa-auto-contacts/#aacs-contacts","text":"The AACS Contacts library is an Android library used by the AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information.","title":"AACS Contacts "},{"location":"android/aacs/app-components/alexa-auto-contacts/#table-of-contents","text":"Overview Building the Library Setup for AACS Contacts Library Providing Permission in Android Manifest Specifying Intent Targets Sequence Diagrams How the AACS Contacts Library Works with an Address Book Uploading Address Book Removing Address Book","title":"Table of Contents"},{"location":"android/aacs/app-components/alexa-auto-contacts/#overview","text":"Using the Contacts Library, AACS enables your app to interact with the Auto SDK Engine easily to add or remove an address book, which contains all contact information maintained by the Android Contacts Provider. For information about Contacts Provider, see the Contacts Provider documentation . Note: An address book can be of the type Contact or Navigation. The Contacts Library only works with the Contact type. For example, AACS cannot use the library to fetch data about a navigation favorite. See the Auto SDK Address Book module documentation for more information about the AddressBookType API. The following list describes the major components of the library: The AACS Contacts Service is responsible for: Receiving AASB AddAddressBook or RemoveAddressBook messages from the AACS Core Service. Receiving defined intents from your application to upload or remove an address book The AACS Contacts Library platform implementation ( PhoneBookController ) is responsible for: Fetching the address book from the Android Contacts Provider Parsing all contact data from the address book into an AASB AddAddressBook message Sending the AASB AddAddressBook intent to the AACS Core Service to upload the address book to Alexa Sending the AASB RemoveAddressBook intent to the AACS Core Service to remove from Alexa an address book with a specific addressBookSourceId , a unique address book identifier defined in the Address Book handler (Bluetooth MAC address of connected phone) Providing the API for adding or removing an address book for your application to call The AACS Contacts Library is an optional module, which you can use as is or as a reference when you integrate the Address Book module with AACS. You can build it into an Android archive (AAR) to be included in the AACS APK (recommended) or in your application APK.","title":"Overview"},{"location":"android/aacs/app-components/alexa-auto-contacts/#building-the-library","text":"You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Contacts library: ./gradlew :alexa-auto-contacts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-contacts/aacscontacts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Contacts AAR. To enable contacts support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with contacts enabled. ./gradlew assembleLocalRelease -PenabledContacts For more build options, see the AACS Sample App README .","title":"Building the Library"},{"location":"android/aacs/app-components/alexa-auto-contacts/#setup-for-aacs-contacts-library","text":"Before using the AACS Contacts Library, follow these major steps: Provide permission in your application's Android manifest. Specify targets for intents from the AACS Core Service.","title":"Setup for AACS Contacts Library"},{"location":"android/aacs/app-components/alexa-auto-contacts/#providing-permission-in-android-manifest","text":"For security reasons, for your application to send intents to or receive intents from the AACS Contacts Service, specify the com.amazon.aacscontacts permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacscontacts\" />","title":"Providing Permission in Android Manifest"},{"location":"android/aacs/app-components/alexa-auto-contacts/#specifying-intent-targets","text":"The AACS Contacts Service listens to intents from the AACS Core Service with the AddressBook topic. To specify AACS Contacts Service with an intent target for the AddressBook topic, follow one of these steps: Manually specify the messages in the AACS configuration file, as described in the AACS README . The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify an intent target in the AACS configuration file. In this example, the AACS Contacts Library AAR is part of the AACS APK. \"AddressBook\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexaautoclientservice\", ...], \"class\": [\"<target_1_class_name>\", \"com.amazon.aacscontacts.AACSContactsService\", ...] } Omit ANY targets for AddressBook in the AACS configuration file. As a result, the intent filter defined in the AACS Contacts Library takes effect, enabling the AACS Contacts Service to receive the intents.","title":"Specifying Intent Targets"},{"location":"android/aacs/app-components/alexa-auto-contacts/#sequence-diagrams","text":"The following diagram illustrates the flow when an address book is uploaded to Alexa. The following diagram illustrates the flow when an address book is removed from Alexa.","title":"Sequence Diagrams"},{"location":"android/aacs/app-components/alexa-auto-contacts/#how-the-aacs-contacts-library-works-with-an-address-book","text":"This section describes how the Contacts Library uploads or removes an address book.","title":"How the AACS Contacts Library Works with an Address Book"},{"location":"android/aacs/app-components/alexa-auto-contacts/#uploading-address-book","text":"Use one of the following methods to upload an address book to Alexa: Use intent. Your application can inform the AACS Contacts Library to upload an address book to Alexa by using an intent. When the AACS Contacts Library receives the intent, the library fetches contacts from the Contacts Provider on the head unit and uploads them to Alexa. To determine whether the upload is successful, your application can subscribe to the AASB AddressBook intents. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.upload . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (Must be Bluetooth MAC address from connected phone fetched from client application) and the name of the address book (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\", \"addressBookName\": \"<Name of phone book>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.uploadContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.uploadContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.uploadContacts(addressBookSourceId, addressBookName); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts upload working properly","title":"Uploading Address Book"},{"location":"android/aacs/app-components/alexa-auto-contacts/#removing-address-book","text":"Use one of the following methods to remove an address book from Alexa: Use intent. Your application can inform the AACS Contacts Service to remove an address book from Alexa by using an intent. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.remove . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.removeContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.removeContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.removeContacts(addressBookSourceId); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts remove working properly","title":"Removing Address Book"},{"location":"android/aacs/app-components/alexa-auto-device-usage/","text":"Alexa Auto Device Usage \u00b6 Alexa Auto Device Usage library provides an implementation that enables the AACS Sample App to capture network usage data of Alexa Auto Client Service (AACS) using Android NetworkStatsManager . The data is logged as a metric and is sent to Amazon endpoints if AACS is built with the Device Client Metrics (DCM) extension. To obtain the pre-built AACS AAR with DCM extension, contact your Amazon Solutions Architect (SA) or Partner Manager for more information. Overview \u00b6 The library consists of the following components: AASBReceiver . This Android BroadcastReceiver subsribes to AASB StartService message and AASB StopService message to get the current AACS running status, based on which the DeviceUsageHandler can start or stop the network data recording. DeviceUsageHandler . The handler is responsible for starting and stopping the NetworkStatsManagerRunner according to the AACS running status. It starts the NetworkStatsManagerRunner in an executor thread which queries the network usage every 5 minutes and publishes the data via DeviceUsage ReportNetworkDataUsageMessage message to the Auto SDK engine. NetworkStatsManagerRunner . This class captures the network usage data using NetworkStatsManager APIs and calls the DeviceUsageHandler to report the data. Providing Permissions for Alexa Auto Device Usage Library \u00b6 Using the Alexa Auto Device Usage Library requires the AACS sample app to hold certain Android permissions. If the Android version of your device is lower than 10 (Android Q): The Alexa application needs the android.permission.READ_PHONE_STATE permission to access the subscriber id (associated to the eSIM of a user), which is required to query the network consumption over the MOBILE interface. You can grant this permission to AACS sample app in \"Settings\" -> \"Apps & notifications\" -> \"Alexa\" -> \"Permissions\" -> \"Phone\". If the Android version of your device is 10 (Android Q) or higher: The Alexa application must be installed as a privileged system application and it must have the android.permission.READ_PRIVILEGED_PHONE_STATE privileged permission in order to be able to get the subscriber id . Note The Alexa Auto Device Usage Library carries all the Android permissions ( READ_PHONE_STATE , READ_PRIVILEGED_PHONE_STATE and PACKAGE_USAGE_STATS ) your application needs in order to enable the network usage data recording. To use this library, make sure your AACS sample app is built with the -PenabledDeviceUsage option, as specified in the Building AACS Sample App with Alexa Auto Device Usage Library section. If your device is on Android 10 or higher version, install AACS sample app as a system privileged app, and place the following privapp-permissions-com.amazon.alexa.auto.app.xml file under the /etc/permissions directory on your device: <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexa.auto.app\" > <permission name= \"android.permission.READ_PRIVILEGED_PHONE_STATE\" /> <permission name= \"android.permission.PACKAGE_USAGE_STATS\" /> </privapp-permissions> </permissions> Building AACS Sample App with Alexa Auto Device Usage Library \u00b6 To build the AACS Sample App with Alexa Auto Device Usage library, go to ${AAC_SDK_HOME}/samples/android-aacs-sample-app/ and enter the following command: // release build gradle assembleRelease -PenabledDeviceUsage // debug build gradle assembleDebug -PenabledDeviceUsage","title":"Alexa Auto Device Usage"},{"location":"android/aacs/app-components/alexa-auto-device-usage/#alexa-auto-device-usage","text":"Alexa Auto Device Usage library provides an implementation that enables the AACS Sample App to capture network usage data of Alexa Auto Client Service (AACS) using Android NetworkStatsManager . The data is logged as a metric and is sent to Amazon endpoints if AACS is built with the Device Client Metrics (DCM) extension. To obtain the pre-built AACS AAR with DCM extension, contact your Amazon Solutions Architect (SA) or Partner Manager for more information.","title":"Alexa Auto Device Usage"},{"location":"android/aacs/app-components/alexa-auto-device-usage/#overview","text":"The library consists of the following components: AASBReceiver . This Android BroadcastReceiver subsribes to AASB StartService message and AASB StopService message to get the current AACS running status, based on which the DeviceUsageHandler can start or stop the network data recording. DeviceUsageHandler . The handler is responsible for starting and stopping the NetworkStatsManagerRunner according to the AACS running status. It starts the NetworkStatsManagerRunner in an executor thread which queries the network usage every 5 minutes and publishes the data via DeviceUsage ReportNetworkDataUsageMessage message to the Auto SDK engine. NetworkStatsManagerRunner . This class captures the network usage data using NetworkStatsManager APIs and calls the DeviceUsageHandler to report the data.","title":"Overview"},{"location":"android/aacs/app-components/alexa-auto-device-usage/#providing-permissions-for-alexa-auto-device-usage-library","text":"Using the Alexa Auto Device Usage Library requires the AACS sample app to hold certain Android permissions. If the Android version of your device is lower than 10 (Android Q): The Alexa application needs the android.permission.READ_PHONE_STATE permission to access the subscriber id (associated to the eSIM of a user), which is required to query the network consumption over the MOBILE interface. You can grant this permission to AACS sample app in \"Settings\" -> \"Apps & notifications\" -> \"Alexa\" -> \"Permissions\" -> \"Phone\". If the Android version of your device is 10 (Android Q) or higher: The Alexa application must be installed as a privileged system application and it must have the android.permission.READ_PRIVILEGED_PHONE_STATE privileged permission in order to be able to get the subscriber id . Note The Alexa Auto Device Usage Library carries all the Android permissions ( READ_PHONE_STATE , READ_PRIVILEGED_PHONE_STATE and PACKAGE_USAGE_STATS ) your application needs in order to enable the network usage data recording. To use this library, make sure your AACS sample app is built with the -PenabledDeviceUsage option, as specified in the Building AACS Sample App with Alexa Auto Device Usage Library section. If your device is on Android 10 or higher version, install AACS sample app as a system privileged app, and place the following privapp-permissions-com.amazon.alexa.auto.app.xml file under the /etc/permissions directory on your device: <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexa.auto.app\" > <permission name= \"android.permission.READ_PRIVILEGED_PHONE_STATE\" /> <permission name= \"android.permission.PACKAGE_USAGE_STATS\" /> </privapp-permissions> </permissions>","title":"Providing Permissions for Alexa Auto Device Usage Library"},{"location":"android/aacs/app-components/alexa-auto-device-usage/#building-aacs-sample-app-with-alexa-auto-device-usage-library","text":"To build the AACS Sample App with Alexa Auto Device Usage library, go to ${AAC_SDK_HOME}/samples/android-aacs-sample-app/ and enter the following command: // release build gradle assembleRelease -PenabledDeviceUsage // debug build gradle assembleDebug -PenabledDeviceUsage","title":"Building AACS Sample App with Alexa Auto Device Usage Library"},{"location":"android/aacs/app-components/alexa-auto-lwa-auth/","text":"Alexa Auto Login with Amazon Authorization \u00b6 This package provides an implementation of AuthController defined in the alexa-auto-apis package. The AuthController implementation uses the Login with Amazon (LWA) authorization service provided by the Alexa Auto SDK and Alexa Auto Client Service (AACS). The AuthController implementation is useful for observing changes in the authentication state (indicated by the Boolean value of loggedIn ). The AuthController implementation also provides the workflow for starting authentication. After the user installs an app on an Alexa-enabled device for the first time or when the logged-off user tries to log in again, the authentication process starts. The workflow provided by AuthController supports LWA using code-based linking (CBL) as the authorization method. The CBL code obtained through the authentication workflow is displayed on the head unit device so that the user can enter the CBL code on their mobile device to authenticate the head unit device.","title":"Alexa Auto Login with Amazon Authorization"},{"location":"android/aacs/app-components/alexa-auto-lwa-auth/#alexa-auto-login-with-amazon-authorization","text":"This package provides an implementation of AuthController defined in the alexa-auto-apis package. The AuthController implementation uses the Login with Amazon (LWA) authorization service provided by the Alexa Auto SDK and Alexa Auto Client Service (AACS). The AuthController implementation is useful for observing changes in the authentication state (indicated by the Boolean value of loggedIn ). The AuthController implementation also provides the workflow for starting authentication. After the user installs an app on an Alexa-enabled device for the first time or when the logged-off user tries to log in again, the authentication process starts. The workflow provided by AuthController supports LWA using code-based linking (CBL) as the authorization method. The CBL code obtained through the authentication workflow is displayed on the head unit device so that the user can enter the CBL code on their mobile device to authenticate the head unit device.","title":"Alexa Auto Login with Amazon Authorization"},{"location":"android/aacs/app-components/alexa-auto-media-player/","text":"Alexa Auto Media Player \u00b6 Table of Contents \u00b6 Alexa Auto Media Player Include Alexa Auto Media Player in the Application Enable Media Ducking Media Resume Alexa Music After Reboot Login from Android Automotive Media UI Alexa Music Certification Alexa Auto Media Player \u00b6 The following list describes the purposes of this package: It provides the audio player capability for Alexa Auto Client Service (AACS) by receiving all audio player intents and notifying AACS about the progress of media playback. It manages the underlying media player, which is ExoPlayer. It handles audio focus. It implements a media session on top of the media player so that media can be controlled with standard Android Media Session APIs. This capability allows Alexa Media to integrate with the Android Automotive Media UI. Include Alexa Auto Media Player in the Application \u00b6 The Alexa Auto Media Player is by default enabled in the AACS Sample App. See the AACS Sample App README for build instructions. If you want to use Alexa Auto Media Player in your application, build the following app components and include all the generated AARs in your application: alexa-auto-apis alexa-auto-apps-common-ui alexa-auto-apps-common-util alexa-auto-media-player Enable Media Ducking \u00b6 You can enable audio ducking for the Alexa media using this configuration. By default, Alexa pauses MUSIC channel whenever Alexa TTS or ALARM channels are in the focus. Enabling ducking allows MUSIC channel to remain in the playing state when high priority channels like TTS and ALARM are active. For enabling ducking, please provide the following configuration: Note: Enable ducking only if your variant of android platform supports music stream ducking when TTS stream gets the audio focus. Those platforms do not provide a flag AUDIOFOCUS_LOSS_TRANSIENT_CAN_DUCK onAudioFocusChange is called and instead of that they provide a flag AUDIOFOCUS_LOSS_TRANSIENT . In such cases, it is recommended to disable the ducking to avoid unexpected audio behavior. { \"aacs.alexa\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } } Media Resume Alexa Music After Reboot \u00b6 Please refer to Media Resume Last Playing Media After Platform Reboot for the details about media resume feature. This feature works out of the box on Automotive Android OS with this component. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } } Login from Android Automotive Media UI \u00b6 This library provides an optional feature that enables the Android Automotive Media UI to display the \"not authenticated\" message if the app is not authenticated. It then offers the option for the user to invoke the login UI workflow. To enable this feature in the app with this library, implement AlexaApp , a registry interface defined in the Alexa Auto APIs package, and resolve dependencies by using the following interfaces: AuthController : This interface provides business logic to monitor the current authentication state (the value of loggedIn ). The interface is made available from AlexaAppRootComponent . AlexaSetupController : This interface enables the media UI to launch the login UI activity if the authentication state indicates that the user is not logged in. Note: See the alexa-auto-apis README for more information about consuming and publishing implementations. Alexa Music Certification \u00b6 This version of the Alexa Auto Media Player doesn\u2019t meet all the Alexa Music Certification requirements on Android Automotive OS. It passes API validation for Amazon Music, Audible, Kindle, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, and iHeart Radio Custom. Pandora doesn\u2019t have an API validation requirement. The Media Player doesn\u2019t pass Music Service Provider (MSP) logo attribution GUI validation for Amazon Music, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, iHeart Radio Custom, and Pandora. Audible and Kindle don't have a GUI validation requirement. The Android Automotive OS doesn't have placeholder for showing MSP logo which is required for passing GUI validation. The Media Player provides text based MSP attribution. The Android Automotive OS displays album art as the background image in media player screen, which doesn't pass GUI validation of not altering album art in any way. Due to the missing media controls in TemplateRuntime RenderPlayerInfo payload, the Media Player fails to display all the required media controls, which doesn't pass media controls GUI validation. The standard certification process is required and simplified by the Alexa Auto Media Player because the above mentioned API validation has been completed. Contact your Solutions Architect (SA) or Partner Manager for information about how to obtain certification. Known Issues \u00b6 On low resolution screens, Music Service Provider (MSP) name may cut-off when artist string is long.","title":"Alexa Auto Media Player"},{"location":"android/aacs/app-components/alexa-auto-media-player/#alexa-auto-media-player","text":"","title":"Alexa Auto Media Player"},{"location":"android/aacs/app-components/alexa-auto-media-player/#table-of-contents","text":"Alexa Auto Media Player Include Alexa Auto Media Player in the Application Enable Media Ducking Media Resume Alexa Music After Reboot Login from Android Automotive Media UI Alexa Music Certification","title":"Table of Contents"},{"location":"android/aacs/app-components/alexa-auto-media-player/#alexa-auto-media-player_1","text":"The following list describes the purposes of this package: It provides the audio player capability for Alexa Auto Client Service (AACS) by receiving all audio player intents and notifying AACS about the progress of media playback. It manages the underlying media player, which is ExoPlayer. It handles audio focus. It implements a media session on top of the media player so that media can be controlled with standard Android Media Session APIs. This capability allows Alexa Media to integrate with the Android Automotive Media UI.","title":"Alexa Auto Media Player"},{"location":"android/aacs/app-components/alexa-auto-media-player/#include-alexa-auto-media-player-in-the-application","text":"The Alexa Auto Media Player is by default enabled in the AACS Sample App. See the AACS Sample App README for build instructions. If you want to use Alexa Auto Media Player in your application, build the following app components and include all the generated AARs in your application: alexa-auto-apis alexa-auto-apps-common-ui alexa-auto-apps-common-util alexa-auto-media-player","title":"Include Alexa Auto Media Player in the Application"},{"location":"android/aacs/app-components/alexa-auto-media-player/#enable-media-ducking","text":"You can enable audio ducking for the Alexa media using this configuration. By default, Alexa pauses MUSIC channel whenever Alexa TTS or ALARM channels are in the focus. Enabling ducking allows MUSIC channel to remain in the playing state when high priority channels like TTS and ALARM are active. For enabling ducking, please provide the following configuration: Note: Enable ducking only if your variant of android platform supports music stream ducking when TTS stream gets the audio focus. Those platforms do not provide a flag AUDIOFOCUS_LOSS_TRANSIENT_CAN_DUCK onAudioFocusChange is called and instead of that they provide a flag AUDIOFOCUS_LOSS_TRANSIENT . In such cases, it is recommended to disable the ducking to avoid unexpected audio behavior. { \"aacs.alexa\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } }","title":"Enable Media Ducking"},{"location":"android/aacs/app-components/alexa-auto-media-player/#media-resume-alexa-music-after-reboot","text":"Please refer to Media Resume Last Playing Media After Platform Reboot for the details about media resume feature. This feature works out of the box on Automotive Android OS with this component. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } }","title":"Media Resume Alexa Music After Reboot"},{"location":"android/aacs/app-components/alexa-auto-media-player/#login-from-android-automotive-media-ui","text":"This library provides an optional feature that enables the Android Automotive Media UI to display the \"not authenticated\" message if the app is not authenticated. It then offers the option for the user to invoke the login UI workflow. To enable this feature in the app with this library, implement AlexaApp , a registry interface defined in the Alexa Auto APIs package, and resolve dependencies by using the following interfaces: AuthController : This interface provides business logic to monitor the current authentication state (the value of loggedIn ). The interface is made available from AlexaAppRootComponent . AlexaSetupController : This interface enables the media UI to launch the login UI activity if the authentication state indicates that the user is not logged in. Note: See the alexa-auto-apis README for more information about consuming and publishing implementations.","title":"Login from Android Automotive Media UI"},{"location":"android/aacs/app-components/alexa-auto-media-player/#alexa-music-certification","text":"This version of the Alexa Auto Media Player doesn\u2019t meet all the Alexa Music Certification requirements on Android Automotive OS. It passes API validation for Amazon Music, Audible, Kindle, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, and iHeart Radio Custom. Pandora doesn\u2019t have an API validation requirement. The Media Player doesn\u2019t pass Music Service Provider (MSP) logo attribution GUI validation for Amazon Music, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, iHeart Radio Custom, and Pandora. Audible and Kindle don't have a GUI validation requirement. The Android Automotive OS doesn't have placeholder for showing MSP logo which is required for passing GUI validation. The Media Player provides text based MSP attribution. The Android Automotive OS displays album art as the background image in media player screen, which doesn't pass GUI validation of not altering album art in any way. Due to the missing media controls in TemplateRuntime RenderPlayerInfo payload, the Media Player fails to display all the required media controls, which doesn't pass media controls GUI validation. The standard certification process is required and simplified by the Alexa Auto Media Player because the above mentioned API validation has been completed. Contact your Solutions Architect (SA) or Partner Manager for information about how to obtain certification.","title":"Alexa Music Certification"},{"location":"android/aacs/app-components/alexa-auto-media-player/#known-issues","text":"On low resolution screens, Music Service Provider (MSP) name may cut-off when artist string is long.","title":"Known Issues"},{"location":"android/aacs/app-components/alexa-auto-navigation/","text":"Alexa Auto Navigation \u00b6 This library serves the following purposes: It handles navigation-related directives. By parsing a navigation directive and interfacing with the selected map provider, it performs the action required by the directive. The map provider used by the AACS Sample App is Google Maps. However, you can extend the library to use other map providers. This library supports navigating to a single waypoint and canceling an ongoing navigation. It handles local search template runtime directives. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directive and renders local search cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). The templates are dismissed after displayCardTTSFinishedTimeout ms. As per the automotive HMI guidelines the local search cards must be dismissed after 30 secs. Configure the value of displayCardTTSFinishedTimeout as 30000 in the Auto SDK Configuration. { \"aacs.alexa\" { \"templateRuntimeCapabilityAgent\": { \"displayCardTTSFinishedTimeout\": 30000 } } For more details see TemplateRuntime Interface Prerequisites \u00b6 To see local search templates your device type needs to be navigation capable.","title":"Alexa Auto Navigation"},{"location":"android/aacs/app-components/alexa-auto-navigation/#alexa-auto-navigation","text":"This library serves the following purposes: It handles navigation-related directives. By parsing a navigation directive and interfacing with the selected map provider, it performs the action required by the directive. The map provider used by the AACS Sample App is Google Maps. However, you can extend the library to use other map providers. This library supports navigating to a single waypoint and canceling an ongoing navigation. It handles local search template runtime directives. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directive and renders local search cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). The templates are dismissed after displayCardTTSFinishedTimeout ms. As per the automotive HMI guidelines the local search cards must be dismissed after 30 secs. Configure the value of displayCardTTSFinishedTimeout as 30000 in the Auto SDK Configuration. { \"aacs.alexa\" { \"templateRuntimeCapabilityAgent\": { \"displayCardTTSFinishedTimeout\": 30000 } } For more details see TemplateRuntime Interface","title":"Alexa Auto Navigation"},{"location":"android/aacs/app-components/alexa-auto-navigation/#prerequisites","text":"To see local search templates your device type needs to be navigation capable.","title":"Prerequisites"},{"location":"android/aacs/app-components/alexa-auto-settings/","text":"Alexa Auto Settings \u00b6 This package provides code containing business logic and UI components for the settings menu which is shown to the user after setup is successful. The AlexaSettingsHomeFragment houses top level settings that are available to users. Known Gaps \u00b6 The following features have not been developed on the settings screen yet Navigation favorites permission Push to talk Communication settings do not satisfy CX requirements. Refer to the HMI Guidelines - Communications section for guidance or work with your Amazon partner manager","title":"Alexa Auto Settings"},{"location":"android/aacs/app-components/alexa-auto-settings/#alexa-auto-settings","text":"This package provides code containing business logic and UI components for the settings menu which is shown to the user after setup is successful. The AlexaSettingsHomeFragment houses top level settings that are available to users.","title":"Alexa Auto Settings"},{"location":"android/aacs/app-components/alexa-auto-settings/#known-gaps","text":"The following features have not been developed on the settings screen yet Navigation favorites permission Push to talk Communication settings do not satisfy CX requirements. Refer to the HMI Guidelines - Communications section for guidance or work with your Amazon partner manager","title":"Known Gaps"},{"location":"android/aacs/app-components/alexa-auto-setup/","text":"Alexa Auto Setup \u00b6 The following list describes the contents of this package: This package provides the UI for the setup workflow which includes login and subsequent setup steps, as well as interruption popups (listening for network status and driving state changes). The UI is provided as Android Fragment s along with View Model s which can be used independently for building a different flavor of the UI. At present, this package provides UI/ViewModel for CBL (Code Based Linking) and Preview mode authentication. Note: For the app to work it must either be configured as a system app or app permissions need to be manually enabled by navigating to Settings > Apps & Notifications > Show All Apps > com.amazon.alexaautoclientservice > Permissions > Enable Microphone Integration \u00b6 Gradle \u00b6 Include the project with gradle. Dependencies \u00b6 Please refer to alexa-auto-apis doc to find details on how to fetch/publish dependencies. CBLLoginViewModel needs access to following implementations (interfaces for them are defined in alexa-auto-apis package): AuthController : This interface provides business logic for new authentication workflow. The interface must be made available from AlexaAppRootComponent . LoginUIEventListener [Optional] : This interface allows UI to let the observer know when login is finished. This event can be used by observer to progress the app UI to logged-in state. The interface should be made available through AlexaAppLoggedOutScopedComponent , that should be made available through AlexaAppRootComponent#getScopedComponents() With the current implementation of the setup flow, there is a need for the developer to implement a CarUxRestrictionsController and listen for intents from com.amazon.alexa.auto.uxrestrictions.drivingStateChanged in order to be notified of driving state changes. This works out of the box if the developer is also using the default alexa-auto-ux-restrictions module, however if the developer wants to roll out their own solution for listening to driving state changes, they will need to override the aforementioned interface and intent. For more details, please refer to the alexa-auto-ux-restrictions module README , and take a look at the CarUxRestrictionsModule and DefaultCarUxRestrictionsController reference implementations. Known Gaps \u00b6 The setup flow in this app does satisfy CX requirements. Refer to HMI Guidelines - Setup section for guidance or work with your Amazon partner manager. Missing Steps \u00b6 Enable Push-to-talk permission","title":"Alexa Auto Setup"},{"location":"android/aacs/app-components/alexa-auto-setup/#alexa-auto-setup","text":"The following list describes the contents of this package: This package provides the UI for the setup workflow which includes login and subsequent setup steps, as well as interruption popups (listening for network status and driving state changes). The UI is provided as Android Fragment s along with View Model s which can be used independently for building a different flavor of the UI. At present, this package provides UI/ViewModel for CBL (Code Based Linking) and Preview mode authentication. Note: For the app to work it must either be configured as a system app or app permissions need to be manually enabled by navigating to Settings > Apps & Notifications > Show All Apps > com.amazon.alexaautoclientservice > Permissions > Enable Microphone","title":"Alexa Auto Setup"},{"location":"android/aacs/app-components/alexa-auto-setup/#integration","text":"","title":"Integration"},{"location":"android/aacs/app-components/alexa-auto-setup/#gradle","text":"Include the project with gradle.","title":"Gradle"},{"location":"android/aacs/app-components/alexa-auto-setup/#dependencies","text":"Please refer to alexa-auto-apis doc to find details on how to fetch/publish dependencies. CBLLoginViewModel needs access to following implementations (interfaces for them are defined in alexa-auto-apis package): AuthController : This interface provides business logic for new authentication workflow. The interface must be made available from AlexaAppRootComponent . LoginUIEventListener [Optional] : This interface allows UI to let the observer know when login is finished. This event can be used by observer to progress the app UI to logged-in state. The interface should be made available through AlexaAppLoggedOutScopedComponent , that should be made available through AlexaAppRootComponent#getScopedComponents() With the current implementation of the setup flow, there is a need for the developer to implement a CarUxRestrictionsController and listen for intents from com.amazon.alexa.auto.uxrestrictions.drivingStateChanged in order to be notified of driving state changes. This works out of the box if the developer is also using the default alexa-auto-ux-restrictions module, however if the developer wants to roll out their own solution for listening to driving state changes, they will need to override the aforementioned interface and intent. For more details, please refer to the alexa-auto-ux-restrictions module README , and take a look at the CarUxRestrictionsModule and DefaultCarUxRestrictionsController reference implementations.","title":"Dependencies"},{"location":"android/aacs/app-components/alexa-auto-setup/#known-gaps","text":"The setup flow in this app does satisfy CX requirements. Refer to HMI Guidelines - Setup section for guidance or work with your Amazon partner manager.","title":"Known Gaps"},{"location":"android/aacs/app-components/alexa-auto-setup/#missing-steps","text":"Enable Push-to-talk permission","title":"Missing Steps"},{"location":"android/aacs/app-components/alexa-auto-telephony/","text":"AACS Telephony \u00b6 The AACS Telephony library is an Android library for you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. The library handles phone-related directives and events from and to the Alexa Auto SDK Engine, via the AACS Core Service. The library also works with the Dialer app on the car head unit. By including this optional library in AACS or your own application, you can easily integrate phone capabilities (e.g., dialing, redialing, and answering calls) with Alexa. Table of Contents \u00b6 Overview Prerequisites Building the Library Setup for AACS Telephony Library Sequence Diagram Phone Call Controlling Answer Dial Redial SendDTMF Stop Update Device Configuration (Optional) Receiving Device Connection Changes Known Issue Overview \u00b6 AACS Telephony Library is responsible for communicating with the AACS Core Service and initiating the corresponding actions based on the incoming directives from the Engine. The following list describes its major components that carry out these responsibilities: The AACS Telephony Service is responsible for: Receiving and processing PhoneCallController AASB message intents from the AACS Core Service. Receiving defined intents from your application for specific actions, such as providing the proper Phone Account Handler to be used to place a call. The AACS Telephony platform implementation ( PhoneCallController ) with the Android telephony framework is responsible for: Fulfilling the phone-call-related directives, which are received as intents by the AACS Telephony Service Capturing and reporting call state changes to the AACS Core Service Capturing and reporting Bluetooth connection state changes to the AACS Core Service, and broadcasting the changes to any client listeners The AACS Telephony Library is an optional module, which you can use as is or as a reference when you integrate the Phone Call Controller module with AACS. You can enable it in the AACS Sample App or in your application APK. Prerequisites \u00b6 Your Android system needs to support the Android Telephony framework. Your Android system needs to have a default dialer app that provides dialer and in-call UI. Your Android system needs to support Bluetooth Hands-Free Profile (HFP) and Phone Book Access Profile (PBAP). Specifically, Bluetooth profiles with ID HEADSET_CLIENT and PBAP_CLIENT are required. For example, a device running Android Automotive OS supports these profiles. Building the Library \u00b6 You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Telephony library: ./gradlew :alexa-auto-telephony:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-telephony/aacstelephony/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Telephony AAR. To enable telephony support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with telephony enabled. ./gradlew assembleLocalRelease -PenabledTelephony For more build options, see the AACS Sample App README . Setup for AACS Telephony Library \u00b6 Before using the AACS Telephony Library, follow these major steps: Make the application containing the library into a system-privileged application. Provide the library with appropriate system permissions. Provide permission in your application's Android manifest so that the AACS Telephony Service can be started by your application. Specify targets for intents from the AACS Core Service. Making Application into a System-Privileged App \u00b6 The AACS Telephony Library needs to control the phone calls, and monitor the Bluetooth connection states and phone call states. Therefore, the application containing the library must be a system-privileged application. If the library is included in AACS, as recommended, you must run AACS as a system-privileged application. Similarly, if you put the library in your application, your application must be system-privileged. An application acquires system privilege when you install it in /system/priv-app/ . Providing System Permissions \u00b6 The AACS Telephony Library requires three system-level permissions: android.permission.CONTROL_INCALL_EXPERIENCE android.permission.INTERACT_ACROSS_USERS android.permission.CAPTURE_AUDIO_OUTPUT Grant the permissions to the package containing the AACS Telephony Library. For instructions about granting permissions, see the Android documentation . To grant permissions to AACS, if it contains the library, use com.amazon.alexaautoclientservice as the package name in the XML file referenced in the Android documentation. Providing Permission in Android Manifest \u00b6 For security reasons, for your application to send intents to or receive intents from the AACS Telephony Service, specify the com.amazon.aacstelephony permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacstelephony\" /> Intent Targets \u00b6 The AACS Telephony Service listens to intents from the AACS Core Service with these topics: AASB and PhoneCallController . To specify AACS Telephony Service as the intent target, follow one of these steps: Manually specify the messages in the AACS configuration file. The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify AACS Telephony Service as an intent target for both the AASB and PhoneCallController topics. In this example, the AACS Telephony Library AAR is part of the AACS sample app APK. For more information about specifying intent targets, see the AACS README . \"AASB\" : { \"type\": [\"<target_1_type>\",\"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] }, //... other modules \"PhoneCallController\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_type>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] } //... other modules Omit ANY targets for the AASB and PhoneCallController topics in the AACS configuration file. As a result, the intent filter defined in the AACS Telephony Library takes effect, enabling the AACS Telephony Service to receive the intents. Sequence Diagram \u00b6 The following sequence diagram illustrates the flow when the driver initiates a call with Alexa if the AACS Telephony Library is used. Phone Call Controlling \u00b6 This section describes the phone call controlling actions and work flows, whether the calls are initiated by Alexa or by the user from the head unit or mobile phone. Answer \u00b6 When a user asks Alexa to answer a call, the AACS Telephony Library answers the call that has the matching callId in the PhoneCallController.Answer payload of the AASB message. Dial \u00b6 When a user asks Alexa to dial a number or call an uploaded contact, the AACS Telephony Service calls the Android API getDefaultOutgoingPhoneAccount to determine the proper PhoneAccountHandle to use for initiating the call. The specific account returned by getDefaultOutgoingPhoneAccount depends on the following priorities: If the user-selected default PhoneAccount supports the specified scheme, it will be returned. If there exists only one PhoneAccount that supports the specified scheme, it will be returned. In the Android Automotive OS the last connected device with HFP enabled is considered as the user-selected phone account. The OEMs can override this default behavior by implementing their own phone selection UI and calling the system API setUserSelectedOutgoingPhoneAccount to set the user selected account whenever the user makes a selection. Note: The AACS Telephony Service does not cache the phone account handle. Each time it receives the Dial message from AACS, it calls the getDefaultOutgoingPhoneAccount to determine which phone account handle to use. Redial \u00b6 Similar to the Dial action, each Redial action requires the AACS Telephony Service to call the getDefaultOutgoingPhoneAccount to get the proper phone account handle. The AACS Telephony phone call controller queries the Android system on the head unit by using the CallLog.Calls.getLastOutgoingCall method, to get the last dialed number. SendDTMF \u00b6 When AACS Telephony Service gets a sendDTMF message, it applies the specified Dual Tone Multiple-Frequency (DTMF) tones to the call that has the matching callId in the PhoneCallController.SendDTMF payload of the AASB message. Stop \u00b6 When AACS Telephony Service gets a PhoneCallController.Stop AASB message, it stops the current call that has the matching callId in the message payload. Update Device Configuration \u00b6 This section describes how to update the device configuration. Note: the Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Use one of the following methods to update the device configuration: Use intent. Your application can send messages with a particular intent to the AACS Telephony Service to update the device configuration. Specify the attributes of the intent as follows: Action is com.amazon.aacstelephony.updateDeviceConfiguration . Category is com.amazon.aacstelephony . Extras is: { \"deviceProperty\": \"<Property name>\", \"enable\": <Boolean value to enable or disable specified property> } Use a direct API call. This method is applicable only if you put the AACS Telephony Library in your application. The following code shows how to use the PhoneCallController API: // Instantiate PhoneCallController PhoneCallController phoneCallController = new PhoneCallController ( context , aacsMessageSender ); phoneCallController . updateDeviceConfiguration ( deviceProperty , enable ); Tip: All the key constants, intent actions, and categories are defined in the TelephonyConstants class in the AACS Constants Library. (Optional) Receiving Device Connection Changes \u00b6 The AACS Telephony Library not only detects and reports the Bluetooth connection state changes to the Engine (and subsequently Alexa), but can also broadcast the changes to your application if you find the broadcasts useful. Whenever BluetoothStateListener in the AACS Telephony Service detects a connection change with the Phone Book Access Profile (PBAP), it sends an intent with the device name and address to the listeners. The attributes of the intent with the connection information are as follows: Action is com.amazon.aacstelephony.bluetooth.connected for connected events and com.amazon.aacstelephony.bluetooth.disconnected for disconnected events. Category is com.amazon.aacstelephony . Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" } It also detects when a phone is being paired and sends an intent with the device name, address, and bond state to the listener. There are 3 different bond states while a phone is pairing: BOND_BONDED , BOND_BONDING , and BOND_NONE . Action is com.amazon.aacstelephony.bluetooth.bondStateChanged Category is com.amazon.aacstelephony Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" \"bondState\":<{BOND_BONDED, BOND_BONDING, or BOND_NONE}> } The action \"com.amazon.aacstelephony.bluetooth.pairedDevice\" is also broadcasted during the initial connection check to add devices to notify the client application of devices paired before signing into Alexa. Action is com.amazon.aacstelephony.bluetooth.pairedDevice Category is com.amazon.aacstelephony Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" } Known Issue \u00b6 When there is an active phone call, and if the application (either AACS or your application) containing AACS Telephony Library crashes, when it comes back, the InCallService defined in AACS Telephony Library would not automatically rebound, and therefore you cannot control the active call with Alexa. This is due to the InCallService in this library is not with the default dialer. New calls after the crash would trigger the InCallService to rebind to the system and phone call controlling would work as usual. Besides, reconnecting Bluetooth also triggers a rebinding in this case.","title":"AACS Telephony"},{"location":"android/aacs/app-components/alexa-auto-telephony/#aacs-telephony","text":"The AACS Telephony library is an Android library for you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. The library handles phone-related directives and events from and to the Alexa Auto SDK Engine, via the AACS Core Service. The library also works with the Dialer app on the car head unit. By including this optional library in AACS or your own application, you can easily integrate phone capabilities (e.g., dialing, redialing, and answering calls) with Alexa.","title":"AACS Telephony"},{"location":"android/aacs/app-components/alexa-auto-telephony/#table-of-contents","text":"Overview Prerequisites Building the Library Setup for AACS Telephony Library Sequence Diagram Phone Call Controlling Answer Dial Redial SendDTMF Stop Update Device Configuration (Optional) Receiving Device Connection Changes Known Issue","title":"Table of Contents"},{"location":"android/aacs/app-components/alexa-auto-telephony/#overview","text":"AACS Telephony Library is responsible for communicating with the AACS Core Service and initiating the corresponding actions based on the incoming directives from the Engine. The following list describes its major components that carry out these responsibilities: The AACS Telephony Service is responsible for: Receiving and processing PhoneCallController AASB message intents from the AACS Core Service. Receiving defined intents from your application for specific actions, such as providing the proper Phone Account Handler to be used to place a call. The AACS Telephony platform implementation ( PhoneCallController ) with the Android telephony framework is responsible for: Fulfilling the phone-call-related directives, which are received as intents by the AACS Telephony Service Capturing and reporting call state changes to the AACS Core Service Capturing and reporting Bluetooth connection state changes to the AACS Core Service, and broadcasting the changes to any client listeners The AACS Telephony Library is an optional module, which you can use as is or as a reference when you integrate the Phone Call Controller module with AACS. You can enable it in the AACS Sample App or in your application APK.","title":"Overview"},{"location":"android/aacs/app-components/alexa-auto-telephony/#prerequisites","text":"Your Android system needs to support the Android Telephony framework. Your Android system needs to have a default dialer app that provides dialer and in-call UI. Your Android system needs to support Bluetooth Hands-Free Profile (HFP) and Phone Book Access Profile (PBAP). Specifically, Bluetooth profiles with ID HEADSET_CLIENT and PBAP_CLIENT are required. For example, a device running Android Automotive OS supports these profiles.","title":"Prerequisites"},{"location":"android/aacs/app-components/alexa-auto-telephony/#building-the-library","text":"You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Telephony library: ./gradlew :alexa-auto-telephony:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-telephony/aacstelephony/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Telephony AAR. To enable telephony support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with telephony enabled. ./gradlew assembleLocalRelease -PenabledTelephony For more build options, see the AACS Sample App README .","title":"Building the Library"},{"location":"android/aacs/app-components/alexa-auto-telephony/#setup-for-aacs-telephony-library","text":"Before using the AACS Telephony Library, follow these major steps: Make the application containing the library into a system-privileged application. Provide the library with appropriate system permissions. Provide permission in your application's Android manifest so that the AACS Telephony Service can be started by your application. Specify targets for intents from the AACS Core Service.","title":"Setup for AACS Telephony Library"},{"location":"android/aacs/app-components/alexa-auto-telephony/#making-application-into-a-system-privileged-app","text":"The AACS Telephony Library needs to control the phone calls, and monitor the Bluetooth connection states and phone call states. Therefore, the application containing the library must be a system-privileged application. If the library is included in AACS, as recommended, you must run AACS as a system-privileged application. Similarly, if you put the library in your application, your application must be system-privileged. An application acquires system privilege when you install it in /system/priv-app/ .","title":"Making Application into a System-Privileged App"},{"location":"android/aacs/app-components/alexa-auto-telephony/#providing-system-permissions","text":"The AACS Telephony Library requires three system-level permissions: android.permission.CONTROL_INCALL_EXPERIENCE android.permission.INTERACT_ACROSS_USERS android.permission.CAPTURE_AUDIO_OUTPUT Grant the permissions to the package containing the AACS Telephony Library. For instructions about granting permissions, see the Android documentation . To grant permissions to AACS, if it contains the library, use com.amazon.alexaautoclientservice as the package name in the XML file referenced in the Android documentation.","title":"Providing System Permissions"},{"location":"android/aacs/app-components/alexa-auto-telephony/#providing-permission-in-android-manifest","text":"For security reasons, for your application to send intents to or receive intents from the AACS Telephony Service, specify the com.amazon.aacstelephony permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacstelephony\" />","title":"Providing Permission in Android Manifest"},{"location":"android/aacs/app-components/alexa-auto-telephony/#intent-targets","text":"The AACS Telephony Service listens to intents from the AACS Core Service with these topics: AASB and PhoneCallController . To specify AACS Telephony Service as the intent target, follow one of these steps: Manually specify the messages in the AACS configuration file. The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify AACS Telephony Service as an intent target for both the AASB and PhoneCallController topics. In this example, the AACS Telephony Library AAR is part of the AACS sample app APK. For more information about specifying intent targets, see the AACS README . \"AASB\" : { \"type\": [\"<target_1_type>\",\"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] }, //... other modules \"PhoneCallController\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_type>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] } //... other modules Omit ANY targets for the AASB and PhoneCallController topics in the AACS configuration file. As a result, the intent filter defined in the AACS Telephony Library takes effect, enabling the AACS Telephony Service to receive the intents.","title":"Intent Targets"},{"location":"android/aacs/app-components/alexa-auto-telephony/#sequence-diagram","text":"The following sequence diagram illustrates the flow when the driver initiates a call with Alexa if the AACS Telephony Library is used.","title":"Sequence Diagram"},{"location":"android/aacs/app-components/alexa-auto-telephony/#phone-call-controlling","text":"This section describes the phone call controlling actions and work flows, whether the calls are initiated by Alexa or by the user from the head unit or mobile phone.","title":"Phone Call Controlling"},{"location":"android/aacs/app-components/alexa-auto-telephony/#answer","text":"When a user asks Alexa to answer a call, the AACS Telephony Library answers the call that has the matching callId in the PhoneCallController.Answer payload of the AASB message.","title":"Answer"},{"location":"android/aacs/app-components/alexa-auto-telephony/#dial","text":"When a user asks Alexa to dial a number or call an uploaded contact, the AACS Telephony Service calls the Android API getDefaultOutgoingPhoneAccount to determine the proper PhoneAccountHandle to use for initiating the call. The specific account returned by getDefaultOutgoingPhoneAccount depends on the following priorities: If the user-selected default PhoneAccount supports the specified scheme, it will be returned. If there exists only one PhoneAccount that supports the specified scheme, it will be returned. In the Android Automotive OS the last connected device with HFP enabled is considered as the user-selected phone account. The OEMs can override this default behavior by implementing their own phone selection UI and calling the system API setUserSelectedOutgoingPhoneAccount to set the user selected account whenever the user makes a selection. Note: The AACS Telephony Service does not cache the phone account handle. Each time it receives the Dial message from AACS, it calls the getDefaultOutgoingPhoneAccount to determine which phone account handle to use.","title":"Dial"},{"location":"android/aacs/app-components/alexa-auto-telephony/#redial","text":"Similar to the Dial action, each Redial action requires the AACS Telephony Service to call the getDefaultOutgoingPhoneAccount to get the proper phone account handle. The AACS Telephony phone call controller queries the Android system on the head unit by using the CallLog.Calls.getLastOutgoingCall method, to get the last dialed number.","title":"Redial"},{"location":"android/aacs/app-components/alexa-auto-telephony/#senddtmf","text":"When AACS Telephony Service gets a sendDTMF message, it applies the specified Dual Tone Multiple-Frequency (DTMF) tones to the call that has the matching callId in the PhoneCallController.SendDTMF payload of the AASB message.","title":"SendDTMF"},{"location":"android/aacs/app-components/alexa-auto-telephony/#stop","text":"When AACS Telephony Service gets a PhoneCallController.Stop AASB message, it stops the current call that has the matching callId in the message payload.","title":"Stop"},{"location":"android/aacs/app-components/alexa-auto-telephony/#update-device-configuration","text":"This section describes how to update the device configuration. Note: the Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Use one of the following methods to update the device configuration: Use intent. Your application can send messages with a particular intent to the AACS Telephony Service to update the device configuration. Specify the attributes of the intent as follows: Action is com.amazon.aacstelephony.updateDeviceConfiguration . Category is com.amazon.aacstelephony . Extras is: { \"deviceProperty\": \"<Property name>\", \"enable\": <Boolean value to enable or disable specified property> } Use a direct API call. This method is applicable only if you put the AACS Telephony Library in your application. The following code shows how to use the PhoneCallController API: // Instantiate PhoneCallController PhoneCallController phoneCallController = new PhoneCallController ( context , aacsMessageSender ); phoneCallController . updateDeviceConfiguration ( deviceProperty , enable ); Tip: All the key constants, intent actions, and categories are defined in the TelephonyConstants class in the AACS Constants Library.","title":"Update Device Configuration"},{"location":"android/aacs/app-components/alexa-auto-telephony/#optional-receiving-device-connection-changes","text":"The AACS Telephony Library not only detects and reports the Bluetooth connection state changes to the Engine (and subsequently Alexa), but can also broadcast the changes to your application if you find the broadcasts useful. Whenever BluetoothStateListener in the AACS Telephony Service detects a connection change with the Phone Book Access Profile (PBAP), it sends an intent with the device name and address to the listeners. The attributes of the intent with the connection information are as follows: Action is com.amazon.aacstelephony.bluetooth.connected for connected events and com.amazon.aacstelephony.bluetooth.disconnected for disconnected events. Category is com.amazon.aacstelephony . Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" } It also detects when a phone is being paired and sends an intent with the device name, address, and bond state to the listener. There are 3 different bond states while a phone is pairing: BOND_BONDED , BOND_BONDING , and BOND_NONE . Action is com.amazon.aacstelephony.bluetooth.bondStateChanged Category is com.amazon.aacstelephony Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" \"bondState\":<{BOND_BONDED, BOND_BONDING, or BOND_NONE}> } The action \"com.amazon.aacstelephony.bluetooth.pairedDevice\" is also broadcasted during the initial connection check to add devices to notify the client application of devices paired before signing into Alexa. Action is com.amazon.aacstelephony.bluetooth.pairedDevice Category is com.amazon.aacstelephony Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" }","title":"(Optional) Receiving Device Connection Changes"},{"location":"android/aacs/app-components/alexa-auto-telephony/#known-issue","text":"When there is an active phone call, and if the application (either AACS or your application) containing AACS Telephony Library crashes, when it comes back, the InCallService defined in AACS Telephony Library would not automatically rebound, and therefore you cannot control the active call with Alexa. This is due to the InCallService in this library is not with the default dialer. New calls after the crash would trigger the InCallService to rebind to the system and phone call controlling would work as usual. Besides, reconnecting Bluetooth also triggers a rebinding in this case.","title":"Known Issue"},{"location":"android/aacs/app-components/alexa-auto-templateruntime-renderer/","text":"Alexa Auto Template Runtime Renderer \u00b6 This library houses template runtime implementations. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directives and renders the display cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). The template is automatically dismissed 8 seconds after the voice response from Alexa is completed unless the card is interacted with, in which case the card dismissal gets extended by 8 seconds from the last interaction. The following template runtime directives are currently supported WeatherTemplate BodyTemplate1 BodyTemplate2 ListTemplate1 For more details refer the automotive HMI guidelines . Known Issues \u00b6 The weather card is comprised of 2 screens - current weather and weather forecast. The card currently scrolls continuously which is not the correct behavior. It should be paginated.","title":"Alexa Auto Template Runtime Renderer"},{"location":"android/aacs/app-components/alexa-auto-templateruntime-renderer/#alexa-auto-template-runtime-renderer","text":"This library houses template runtime implementations. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directives and renders the display cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). The template is automatically dismissed 8 seconds after the voice response from Alexa is completed unless the card is interacted with, in which case the card dismissal gets extended by 8 seconds from the last interaction. The following template runtime directives are currently supported WeatherTemplate BodyTemplate1 BodyTemplate2 ListTemplate1 For more details refer the automotive HMI guidelines .","title":"Alexa Auto Template Runtime Renderer"},{"location":"android/aacs/app-components/alexa-auto-templateruntime-renderer/#known-issues","text":"The weather card is comprised of 2 screens - current weather and weather forecast. The card currently scrolls continuously which is not the correct behavior. It should be paginated.","title":"Known Issues"},{"location":"android/aacs/app-components/alexa-auto-tts/","text":"Text-to-Speech Service \u00b6 Text-to-Speech (TTS) Service provides an implementation on the Android platform to synthesize non-Alexa speech on demand from text. It implements the Android abstract TextToSpeechService class, which is part of Android TTS framework APIs, and in the backend uses the Text-to-Speech functionality provided by the Auto SDK. Android applications can interact with these standard Android TTS APIs to convert text to speech. Table of Contents \u00b6 Overview Building the Library Architecture Configuration Sample Usage Initialization Get Capabilities Synthesize Audio Known Issues Overview \u00b6 Text-to-Speech Service implements TextToSpeechService , which is an abstract base class for TTS engine implementations. The following list describes the responsibilities of the service and the Android TTS framework: The service is responsible for: retrieving the TTS capabilities from AACS preparing the TTS audio and vending out the stream to the Android TTS framework APIs The Android TTS framework is responsible for: handling the states of TTS requests playing out the audio saving the audio to file The Text-to-Speech Service communicates with AACS to get the available locales and fetch the synthesized audio stream. Therefore, AACS must be started, configured, and running in connected state to ensure the Text-to-Speech Service can generate the designated TTS audio correctly. Building the Library \u00b6 Text-to-Speech Service is built as an Android Archive (AAR) to be included in your application along with the AACS AAR. You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the TTS library: ./gradlew :alexa-auto-tts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-tts/aacstts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS TTS AAR. AACS TTS is by default enabled in the AACS Sample App. See the AACS Sample App documentation for build instructions. Important! The Text-to-Speech Service requires the Local Voice Control and Alexa Custom Assistant extensions to function. Architecture \u00b6 The following diagram shows the high-level architecture of TTS Service and AACS. The blue box in the diagram represents the Text-to-Speech Service and the white boxes in the diagram represent the other components developed by Amazon. These components are all packaged in AARs to be added along with AACS AAR into AACS Sample App or your application. The other boxes represent components that do not belong to Amazon: The yellow boxes represent the components from the Android TTS framework, and the green box represents the OEM application using Android TTS APIs. Android Application is owned by OEMs to handle the Text-to-Speech interaction with the end user by creating an instance of the TextToSpeech object and issuing Text-to-Speech requests. TextToSpeech is the Facade class that acts as a bridge between the Text-to-Speech application, which issues the TTS requests, and the underlying TextToSpeechService , which renders the response. See Android documentation for TextToSpeech here. TextToSpeechService is an abstract base class for TTS engine implementations. For more information about this class, see Android documentation for TextToSpeechService . AmazonTextToSpeechService is the actual implementation of TextToSpeechService that communicates with AACS via the IPC library to issue Text-to-Speech requests. Core Service is responsible for accepting TTS requests from AmazonTextToSpeechService and for routing those requests to the Auto SDK's TextToSpeech platform interface, which issues a request to the appropriate TTS provider. For information about TTS providers, see Auto SDK Text-To-Speech-Provider module documentation. Configuration \u00b6 To specify the intent targets for AASB message intents from AACS, follow the instructions in AACS documentation . The TTS Service defines a list of intent filters in its Android manifest to subscribe to specific AASB message intents. If your application uses static configuration to specify the target for AASB topics, provide the following information as part of the AACS configuration to enable the communication between TTS Service and AACS. \u200b { ... \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"AlexaClient\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"TextToSpeech\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, ... } TTS Service subscribes to the AASB messages with the AASB , AlexaClient , and TextToSpeech topics by using a broadcast receiver. Make sure that you properly populate the type, the package name, and the class name into the intentTargets JSON node for these topics, as shown in the JSON example above. Sample Usage \u00b6 Your application uses the Text-to-Speech Service in the same way as it would use any TTS engine. To synthesize speech, the application must create a TextToSpeech object and then set the input text. The application can also specify the speech pitch and rate. Initialization \u00b6 Initialize the Text-to-Speech Service in one of two ways: If the Android application creates a TextToSpeech object without specifying the package name of the TTS engine to use, the default TTS engine is used. // Create the TextToSpeech using the default engine TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }); You can change the default engine to Text-to-Speech Service by following these steps: Open the Android Settings menu and navigate \"Preferred Engine\" as follows: app \u2192 \u201cGeneral Management\u201d \u2192 \u201cLanguage and Input\u201d \u2192 \"Text-to-Speech\" \u2192 \"Preferred Engine\" Choose \"Amazon Text-to-Speech Engine\" in the list. The Android application can also directly create Text-to-Speech Service by specifying the package name \"com.amazon.alexaautoclientservice\" when creating the TextToSpeech object. // Create the TextToSpeech by specifying the package name of the TextToSpeechService TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }, \"com.amazon.alexaautoclientservice\" ); You must initiate TTS Service at least once to warm up the language cache before making any synthesis requests. Get Capabilities \u00b6 The Android applications may query the Text-to-Speech Service to get the available voices. For information about voices, see Android Voice class . For information about languages, see Locale class . The following examples show how to get the available voices and languages from the Engine: // Query the engine about the set of available voices Set < Voice > voices = textToSpeech . getVoices (); // Query the engine about the set of available languages. Set < Locale > locales = textToSpeech . getAvailableLanguages (); // Check if the specified language as represented by the Locale is available and supported. int supported = textToSpeech . isLanguageAvailable ( Locale . US ) Synthesize Audio \u00b6 The Android TTS framework provides two ways of synthesizing TTS audio: Play out the audio immediately: The Android applications may call the speak API. public int speak ( CharSequence text , int queueMode , Bundle params , String utteranceId ) Save to a WAV file: The Android applications may call the synthesizeToFile API. public int synthesizeToFile ( CharSequence text , Bundle params , File file , String utteranceId ) Known Issues \u00b6 Conversion of MP3 to RAW Audio for TTS on the X86 platform is not yet supported.","title":"Text-to-Speech Service <!-- omit in toc -->"},{"location":"android/aacs/app-components/alexa-auto-tts/#text-to-speech-service","text":"Text-to-Speech (TTS) Service provides an implementation on the Android platform to synthesize non-Alexa speech on demand from text. It implements the Android abstract TextToSpeechService class, which is part of Android TTS framework APIs, and in the backend uses the Text-to-Speech functionality provided by the Auto SDK. Android applications can interact with these standard Android TTS APIs to convert text to speech.","title":"Text-to-Speech Service "},{"location":"android/aacs/app-components/alexa-auto-tts/#table-of-contents","text":"Overview Building the Library Architecture Configuration Sample Usage Initialization Get Capabilities Synthesize Audio Known Issues","title":"Table of Contents"},{"location":"android/aacs/app-components/alexa-auto-tts/#overview","text":"Text-to-Speech Service implements TextToSpeechService , which is an abstract base class for TTS engine implementations. The following list describes the responsibilities of the service and the Android TTS framework: The service is responsible for: retrieving the TTS capabilities from AACS preparing the TTS audio and vending out the stream to the Android TTS framework APIs The Android TTS framework is responsible for: handling the states of TTS requests playing out the audio saving the audio to file The Text-to-Speech Service communicates with AACS to get the available locales and fetch the synthesized audio stream. Therefore, AACS must be started, configured, and running in connected state to ensure the Text-to-Speech Service can generate the designated TTS audio correctly.","title":"Overview"},{"location":"android/aacs/app-components/alexa-auto-tts/#building-the-library","text":"Text-to-Speech Service is built as an Android Archive (AAR) to be included in your application along with the AACS AAR. You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the TTS library: ./gradlew :alexa-auto-tts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-tts/aacstts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS TTS AAR. AACS TTS is by default enabled in the AACS Sample App. See the AACS Sample App documentation for build instructions. Important! The Text-to-Speech Service requires the Local Voice Control and Alexa Custom Assistant extensions to function.","title":"Building the Library"},{"location":"android/aacs/app-components/alexa-auto-tts/#architecture","text":"The following diagram shows the high-level architecture of TTS Service and AACS. The blue box in the diagram represents the Text-to-Speech Service and the white boxes in the diagram represent the other components developed by Amazon. These components are all packaged in AARs to be added along with AACS AAR into AACS Sample App or your application. The other boxes represent components that do not belong to Amazon: The yellow boxes represent the components from the Android TTS framework, and the green box represents the OEM application using Android TTS APIs. Android Application is owned by OEMs to handle the Text-to-Speech interaction with the end user by creating an instance of the TextToSpeech object and issuing Text-to-Speech requests. TextToSpeech is the Facade class that acts as a bridge between the Text-to-Speech application, which issues the TTS requests, and the underlying TextToSpeechService , which renders the response. See Android documentation for TextToSpeech here. TextToSpeechService is an abstract base class for TTS engine implementations. For more information about this class, see Android documentation for TextToSpeechService . AmazonTextToSpeechService is the actual implementation of TextToSpeechService that communicates with AACS via the IPC library to issue Text-to-Speech requests. Core Service is responsible for accepting TTS requests from AmazonTextToSpeechService and for routing those requests to the Auto SDK's TextToSpeech platform interface, which issues a request to the appropriate TTS provider. For information about TTS providers, see Auto SDK Text-To-Speech-Provider module documentation.","title":"Architecture"},{"location":"android/aacs/app-components/alexa-auto-tts/#configuration","text":"To specify the intent targets for AASB message intents from AACS, follow the instructions in AACS documentation . The TTS Service defines a list of intent filters in its Android manifest to subscribe to specific AASB message intents. If your application uses static configuration to specify the target for AASB topics, provide the following information as part of the AACS configuration to enable the communication between TTS Service and AACS. \u200b { ... \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"AlexaClient\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"TextToSpeech\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, ... } TTS Service subscribes to the AASB messages with the AASB , AlexaClient , and TextToSpeech topics by using a broadcast receiver. Make sure that you properly populate the type, the package name, and the class name into the intentTargets JSON node for these topics, as shown in the JSON example above.","title":"Configuration"},{"location":"android/aacs/app-components/alexa-auto-tts/#sample-usage","text":"Your application uses the Text-to-Speech Service in the same way as it would use any TTS engine. To synthesize speech, the application must create a TextToSpeech object and then set the input text. The application can also specify the speech pitch and rate.","title":"Sample Usage"},{"location":"android/aacs/app-components/alexa-auto-tts/#initialization","text":"Initialize the Text-to-Speech Service in one of two ways: If the Android application creates a TextToSpeech object without specifying the package name of the TTS engine to use, the default TTS engine is used. // Create the TextToSpeech using the default engine TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }); You can change the default engine to Text-to-Speech Service by following these steps: Open the Android Settings menu and navigate \"Preferred Engine\" as follows: app \u2192 \u201cGeneral Management\u201d \u2192 \u201cLanguage and Input\u201d \u2192 \"Text-to-Speech\" \u2192 \"Preferred Engine\" Choose \"Amazon Text-to-Speech Engine\" in the list. The Android application can also directly create Text-to-Speech Service by specifying the package name \"com.amazon.alexaautoclientservice\" when creating the TextToSpeech object. // Create the TextToSpeech by specifying the package name of the TextToSpeechService TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }, \"com.amazon.alexaautoclientservice\" ); You must initiate TTS Service at least once to warm up the language cache before making any synthesis requests.","title":"Initialization"},{"location":"android/aacs/app-components/alexa-auto-tts/#get-capabilities","text":"The Android applications may query the Text-to-Speech Service to get the available voices. For information about voices, see Android Voice class . For information about languages, see Locale class . The following examples show how to get the available voices and languages from the Engine: // Query the engine about the set of available voices Set < Voice > voices = textToSpeech . getVoices (); // Query the engine about the set of available languages. Set < Locale > locales = textToSpeech . getAvailableLanguages (); // Check if the specified language as represented by the Locale is available and supported. int supported = textToSpeech . isLanguageAvailable ( Locale . US )","title":"Get Capabilities"},{"location":"android/aacs/app-components/alexa-auto-tts/#synthesize-audio","text":"The Android TTS framework provides two ways of synthesizing TTS audio: Play out the audio immediately: The Android applications may call the speak API. public int speak ( CharSequence text , int queueMode , Bundle params , String utteranceId ) Save to a WAV file: The Android applications may call the synthesizeToFile API. public int synthesizeToFile ( CharSequence text , Bundle params , File file , String utteranceId )","title":"Synthesize Audio"},{"location":"android/aacs/app-components/alexa-auto-tts/#known-issues","text":"Conversion of MP3 to RAW Audio for TTS on the X86 platform is not yet supported.","title":"Known Issues"},{"location":"android/aacs/app-components/alexa-auto-ux-restrictions/","text":"Alexa Auto UX Restrictions \u00b6 The following list describes the purposes of this library: It provides CarUxRestrictionsModule and controls CarUxRestrictionsController life cycle. CarUxRestrictionsModule is responsible for broadcasting driving state changes as intents to other app components. Current usecases for this module include the APL module and the setup module. It provides default implementation for CarUxRestrictionsController , which initializes Android CarUxRestrictionsManager , registers and unregisters OnUxRestrictionsChangedListener . To use the default implemetation, it requires Android car package exists on the device. OEM can also provide their own implementation for the car UX restrictions updates. This app component requires Android API 29. To build this component with AACS sample app, add the -PenabledUXRestrictions to your build command: ./gradlew assembleLocalRelease -PenabledUXRestrictions","title":"Alexa Auto UX Restrictions"},{"location":"android/aacs/app-components/alexa-auto-ux-restrictions/#alexa-auto-ux-restrictions","text":"The following list describes the purposes of this library: It provides CarUxRestrictionsModule and controls CarUxRestrictionsController life cycle. CarUxRestrictionsModule is responsible for broadcasting driving state changes as intents to other app components. Current usecases for this module include the APL module and the setup module. It provides default implementation for CarUxRestrictionsController , which initializes Android CarUxRestrictionsManager , registers and unregisters OnUxRestrictionsChangedListener . To use the default implemetation, it requires Android car package exists on the device. OEM can also provide their own implementation for the car UX restrictions updates. This app component requires Android API 29. To build this component with AACS sample app, add the -PenabledUXRestrictions to your build command: ./gradlew assembleLocalRelease -PenabledUXRestrictions","title":"Alexa Auto UX Restrictions"},{"location":"android/aacs/app-components/alexa-auto-voice-interaction/","text":"Alexa Auto Voice Interaction \u00b6 The following list describes the purposes of this library: It provides the Alexa Voice Interaction Service (VIS), which extends the Android Voice Interaction Service API. Alexa VIS enables Alexa as a voice assistant on an Android device. To start Alexa VIS, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , and selects Alexa. Note: After Alexa VIS is integrated with the Android Voice Interaction API, infotainment system only supports one voice agent at a time. For example, the user cannot use both Alexa and Google Voice Assistant at the same time. It is responsible for managing the Alexa Auto Client Service (AACS) lifecycle, based on the Alexa VIS lifecycle. When there is new voice session created, it starts an assistant activity displayed on top of other activities in the system. It provides the Alexa Voice Assist Settings, such as Alexa Privacy Mode and Alexa Locale. To open Alexa Voice Assist Settings, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , makes sure Alexa is selected, and clicks the Settings icon beside Assist app to open the Alexa Voice Assist Settings homepage. When the user selects Alexa as the assistant, AACS is started and connected to Alexa. When the user selects another voice assistant, Alexa VIS shuts down. It also stops AACS.","title":"Alexa Auto Voice Interaction"},{"location":"android/aacs/app-components/alexa-auto-voice-interaction/#alexa-auto-voice-interaction","text":"The following list describes the purposes of this library: It provides the Alexa Voice Interaction Service (VIS), which extends the Android Voice Interaction Service API. Alexa VIS enables Alexa as a voice assistant on an Android device. To start Alexa VIS, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , and selects Alexa. Note: After Alexa VIS is integrated with the Android Voice Interaction API, infotainment system only supports one voice agent at a time. For example, the user cannot use both Alexa and Google Voice Assistant at the same time. It is responsible for managing the Alexa Auto Client Service (AACS) lifecycle, based on the Alexa VIS lifecycle. When there is new voice session created, it starts an assistant activity displayed on top of other activities in the system. It provides the Alexa Voice Assist Settings, such as Alexa Privacy Mode and Alexa Locale. To open Alexa Voice Assist Settings, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , makes sure Alexa is selected, and clicks the Settings icon beside Assist app to open the Alexa Voice Assist Settings homepage. When the user selects Alexa as the assistant, AACS is started and connected to Alexa. When the user selects another voice assistant, Alexa VIS shuts down. It also stops AACS.","title":"Alexa Auto Voice Interaction"},{"location":"android/aacs/app-components/alexa-auto-voice-ui/","text":"Alexa Auto Voice UI \u00b6 The following list describes the purposes of this library: It handles Alexa Voice Chrome UI based on the user's request. Voice Chrome requires that Alexa be selected as the device's voice assistant. It provides the voice interaction session view and vends it out to the app components that inflate onto that view. To access the VIS component, consumers need to get the SessionViewController object via alexa-auto-apis . (See the example in alexa-auto-navigation : LocalSearchDirectiveHandler . It provides the voice interaction session activity and vends it out to the app components that add voice fragment onto that view. Consumers need to get the SessionActivityController object via alexa-auto-apis . (See the example in alexa-auto-apl-renderer : APLReceiver . It provides support for offline network error prompts. With this feature, an offline prompt is played to users when Alexa is unable to respond to utterances in case the internet is not reachable. The prompt is played in the currently active system locale and the error prompt files for the different locales are stored in res/raw/auto_error_offline_{locale}.mp3","title":"Alexa Auto Voice UI"},{"location":"android/aacs/app-components/alexa-auto-voice-ui/#alexa-auto-voice-ui","text":"The following list describes the purposes of this library: It handles Alexa Voice Chrome UI based on the user's request. Voice Chrome requires that Alexa be selected as the device's voice assistant. It provides the voice interaction session view and vends it out to the app components that inflate onto that view. To access the VIS component, consumers need to get the SessionViewController object via alexa-auto-apis . (See the example in alexa-auto-navigation : LocalSearchDirectiveHandler . It provides the voice interaction session activity and vends it out to the app components that add voice fragment onto that view. Consumers need to get the SessionActivityController object via alexa-auto-apis . (See the example in alexa-auto-apl-renderer : APLReceiver . It provides support for offline network error prompts. With this feature, an offline prompt is played to users when Alexa is unable to respond to utterances in case the internet is not reachable. The prompt is played in the currently active system locale and the error prompt files for the different locales are stored in res/raw/auto_error_offline_{locale}.mp3","title":"Alexa Auto Voice UI"},{"location":"android/aacs/common/annotations/aacs-annotation-api/","text":"AACS Annotation Documentation \u00b6 aacs-annotation-api \u00b6 This library contains all the annotation classes and must be included in the Gradle file to access the annotations in the code. ContextBroadcastReceiver \u00b6 AACS has introduced this annotation to optimize many foreground services used in the code. Some functionalities like the navigation provider will need to register broadcast receivers for receiving third-party proprietary framework intents, android intents, or third-party Auto SDK intents to be notified of the system change. Due to android imposed limitations , the implementation may not declare those intent filters in the manifest file. Creating a foreground service to register the broadcast receiver and running it forever is expensive. Unfortunately, it may be unavoidable in some cases e.g. receiving navigation state from navigation application. The @ContextBroadcastReceiver annotation is introduced to help solve this problem. Declaring a class with this annotation registers the class object and intent filter in the AlexaAutoClientService ,which is the backbone service of the app, throughout the lifecycle of the service. Individual app components do not need to create a separate foreground service for this purpose. Note: All the AASB-related intent filters must follow its documentation. They either need to be Services and Manifest declared Broadcast Receivers or Activities. This annotation does not change the behavior. But this annotation should be used whenever you want to implement the context registered Broadcast Receivers. This annotation can be used in the class as shown in the following example. @ContextBroadcastReceiver(categories = {NaviProviderConstants.CATEGORY_ALEXA_AUTO_CLIENT_NAVIGATION}, actions = {NaviProviderConstants.ACTION_RESPONSE_SHOWED_ALTERNATE_ROUTES, NaviProviderConstants.ACTION_RESPONSE_NAVIGATION_STATE, NaviProviderConstants.ACTION_RESPONSE_NAVIGATION_FAVORITES, NaviProviderConstants.ACTION_SIGNAL_NAVIGATION_ERROR, NaviProviderConstants.ACTION_SIGNAL_NAVIGATION_EVENT}) public class NaviObserver extends BroadcastReceiver { private static NaviObserver INSTANCE; private NaviObserver() {} public static NaviObserver getInstance() { if (INSTANCE == null) { INSTANCE = new NaviObserver(); } return INSTANCE; } } Optional categories : \u00b6 Array of the name of the category to match, such as NaviProviderConstants.CATEGORY_ALEXA_AUTO_CLIENT_NAVIGATION is required in the intent filter. Mandatory actions : \u00b6 Array of the action to match, such as NaviProviderConstants.ACTION_RESPONSE_NAVIGATION_STATE is required in the intent filter. Optional permission : \u00b6 String naming permissions that a broadcaster must hold to send an Intent to you. Don\u2019t provide it if no permission is required. Inherit from BroadcastReceiver : \u00b6 The annotated class must inherit class android.content.BroadcastReceiver to ensure that the receiver class is qualified for receiving the intents. Singleton Class: \u00b6 AACS implementation expects a singleton implementation of the BroadcastReceiver class and calls the getInstance method. This method ensures that only one object is active and multiple intents are not received unnecessarily. Client implementation and registered receiver always refer to the same object. Metadata in the manifest file: \u00b6 Declare the following metadata in the AndroidManifest.xml file. AlexaAutoClientService scans all the metadata declarations from the APK, refers to annotation auto-generated reference classes in the given packages, and register and unregister all the broadcast receivers declared with annotation @ContextBroadcastReceive in onCreate and onDestroy service methods respectively. For example: AlexaAutoClientService gets package com.amazon.alexa.auto.navigation.providers.external from the metadata, refers the auto generated class com.amazon.alexa.auto.navigation.providers.external.ContextBroadcastReceivers and register BroadcastReceiver com.amazon.alexa.auto.navigation.providers.external.NaviObserver for the declared actions, categories and permissions. <meta-data android:name=\"com.amazon.alexa.auto.navigation.providers.external\" android:value=\"package\"/> Note: android:name is key , and android:value is value . Value package is mandatory. Please do not duplicate the key because it can replace the earlier metadata. android:name must provide the package name of the Broadcast Receiver class. @NaviProviderModule This annotation is required to declare your class as a navigation provider. If you are a leading map provider and want to create a prebuilt AAR compatible with AACS and your proprietary navigation application, you can implement the NavigationProviderModule . Example: \u00b6 @NaviProviderModule(enabled = true) public class GoogleMapsNaviProvider implements NaviProvider { private static GoogleMapsNaviProvider INSTANCE; private GoogleMapsNaviProvider() { // For singleton } public static GoogleMapsNaviProvider getInstance() { if (INSTANCE == null) { INSTANCE = new GoogleMapsNaviProvider(); } return INSTANCE; } } enabled = true \u00b6 During build time, you can disable navigation provider by setting enabled = false or eliminating the enabled variable. This implementation is expecting only one navigation provider enabled. If no provider is included or no provider is enabled, by default DefaultNaviProvider is used as a active navigation provider. Inherit NaviProvider interface \u00b6 Navigation provider must inherit the com.amazon.alexa.auto.navigation.providers.NaviProvider interface. Navigation app component provides weak reference of the context object through public void initialize(WeakReference<Context> weakContext, NaviResponseReporter reporter) method. This Context can be used for broadcasting the intents. Refer to the ContextBroadcastReceiver section for receiving the intents. Provide all the asynchronous responses to the navigation app components using NaviResponseReporter object. Follow all the payload documentation to ensure that correct data is provided as quickly as possible. Singleton Implementation \u00b6 Navigation app component implementation expects a singleton implementation of the NaviProvider class and calls getInstance method. This method ensures that only one object is active, and the same is used by client implementation and the AACS navigation app component.","title":"AACS Annotation Documentation"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#aacs-annotation-documentation","text":"","title":"AACS Annotation Documentation"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#aacs-annotation-api","text":"This library contains all the annotation classes and must be included in the Gradle file to access the annotations in the code.","title":"aacs-annotation-api"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#contextbroadcastreceiver","text":"AACS has introduced this annotation to optimize many foreground services used in the code. Some functionalities like the navigation provider will need to register broadcast receivers for receiving third-party proprietary framework intents, android intents, or third-party Auto SDK intents to be notified of the system change. Due to android imposed limitations , the implementation may not declare those intent filters in the manifest file. Creating a foreground service to register the broadcast receiver and running it forever is expensive. Unfortunately, it may be unavoidable in some cases e.g. receiving navigation state from navigation application. The @ContextBroadcastReceiver annotation is introduced to help solve this problem. Declaring a class with this annotation registers the class object and intent filter in the AlexaAutoClientService ,which is the backbone service of the app, throughout the lifecycle of the service. Individual app components do not need to create a separate foreground service for this purpose. Note: All the AASB-related intent filters must follow its documentation. They either need to be Services and Manifest declared Broadcast Receivers or Activities. This annotation does not change the behavior. But this annotation should be used whenever you want to implement the context registered Broadcast Receivers. This annotation can be used in the class as shown in the following example. @ContextBroadcastReceiver(categories = {NaviProviderConstants.CATEGORY_ALEXA_AUTO_CLIENT_NAVIGATION}, actions = {NaviProviderConstants.ACTION_RESPONSE_SHOWED_ALTERNATE_ROUTES, NaviProviderConstants.ACTION_RESPONSE_NAVIGATION_STATE, NaviProviderConstants.ACTION_RESPONSE_NAVIGATION_FAVORITES, NaviProviderConstants.ACTION_SIGNAL_NAVIGATION_ERROR, NaviProviderConstants.ACTION_SIGNAL_NAVIGATION_EVENT}) public class NaviObserver extends BroadcastReceiver { private static NaviObserver INSTANCE; private NaviObserver() {} public static NaviObserver getInstance() { if (INSTANCE == null) { INSTANCE = new NaviObserver(); } return INSTANCE; } }","title":"ContextBroadcastReceiver"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#optional-categories","text":"Array of the name of the category to match, such as NaviProviderConstants.CATEGORY_ALEXA_AUTO_CLIENT_NAVIGATION is required in the intent filter.","title":"Optional categories:"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#mandatory-actions","text":"Array of the action to match, such as NaviProviderConstants.ACTION_RESPONSE_NAVIGATION_STATE is required in the intent filter.","title":"Mandatory actions :"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#optional-permission","text":"String naming permissions that a broadcaster must hold to send an Intent to you. Don\u2019t provide it if no permission is required.","title":"Optional permission:"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#inherit-from-broadcastreceiver","text":"The annotated class must inherit class android.content.BroadcastReceiver to ensure that the receiver class is qualified for receiving the intents.","title":"Inherit from BroadcastReceiver:"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#singleton-class","text":"AACS implementation expects a singleton implementation of the BroadcastReceiver class and calls the getInstance method. This method ensures that only one object is active and multiple intents are not received unnecessarily. Client implementation and registered receiver always refer to the same object.","title":"Singleton Class:"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#metadata-in-the-manifest-file","text":"Declare the following metadata in the AndroidManifest.xml file. AlexaAutoClientService scans all the metadata declarations from the APK, refers to annotation auto-generated reference classes in the given packages, and register and unregister all the broadcast receivers declared with annotation @ContextBroadcastReceive in onCreate and onDestroy service methods respectively. For example: AlexaAutoClientService gets package com.amazon.alexa.auto.navigation.providers.external from the metadata, refers the auto generated class com.amazon.alexa.auto.navigation.providers.external.ContextBroadcastReceivers and register BroadcastReceiver com.amazon.alexa.auto.navigation.providers.external.NaviObserver for the declared actions, categories and permissions. <meta-data android:name=\"com.amazon.alexa.auto.navigation.providers.external\" android:value=\"package\"/> Note: android:name is key , and android:value is value . Value package is mandatory. Please do not duplicate the key because it can replace the earlier metadata. android:name must provide the package name of the Broadcast Receiver class. @NaviProviderModule This annotation is required to declare your class as a navigation provider. If you are a leading map provider and want to create a prebuilt AAR compatible with AACS and your proprietary navigation application, you can implement the NavigationProviderModule .","title":"Metadata in the manifest file:"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#example","text":"@NaviProviderModule(enabled = true) public class GoogleMapsNaviProvider implements NaviProvider { private static GoogleMapsNaviProvider INSTANCE; private GoogleMapsNaviProvider() { // For singleton } public static GoogleMapsNaviProvider getInstance() { if (INSTANCE == null) { INSTANCE = new GoogleMapsNaviProvider(); } return INSTANCE; } }","title":"Example:"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#enabled-true","text":"During build time, you can disable navigation provider by setting enabled = false or eliminating the enabled variable. This implementation is expecting only one navigation provider enabled. If no provider is included or no provider is enabled, by default DefaultNaviProvider is used as a active navigation provider.","title":"enabled = true"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#inherit-naviprovider-interface","text":"Navigation provider must inherit the com.amazon.alexa.auto.navigation.providers.NaviProvider interface. Navigation app component provides weak reference of the context object through public void initialize(WeakReference<Context> weakContext, NaviResponseReporter reporter) method. This Context can be used for broadcasting the intents. Refer to the ContextBroadcastReceiver section for receiving the intents. Provide all the asynchronous responses to the navigation app components using NaviResponseReporter object. Follow all the payload documentation to ensure that correct data is provided as quickly as possible.","title":"Inherit NaviProvider interface"},{"location":"android/aacs/common/annotations/aacs-annotation-api/#singleton-implementation","text":"Navigation app component implementation expects a singleton implementation of the NaviProvider class and calls getInstance method. This method ensures that only one object is active, and the same is used by client implementation and the AACS navigation app component.","title":"Singleton Implementation"},{"location":"android/aacs/common/commonutils/","text":"AACS Common Utils \u00b6 Overview \u00b6 AACS Common Utils is an optional library. You can directly use it or reference it when integrating the Auto SDK with AACS, making the messaging with AACS easier. It contains util methods, such as those for building, sending, and parsing messages. The methods enable the the client to communicate with AACS. It also provides helper functions for handling messages from AACS. See the in-code documentation for more information about each class and method. How to use \u00b6 To make the AACS Common Utils Library available to your project, add it to the dependencies of your project's build.gradle file. dependencies { ... implementation project(':alexa-auto-client-service:commonutils:aacscommonutils') ... }","title":"AACS Common Utils"},{"location":"android/aacs/common/commonutils/#aacs-common-utils","text":"","title":"AACS Common Utils"},{"location":"android/aacs/common/commonutils/#overview","text":"AACS Common Utils is an optional library. You can directly use it or reference it when integrating the Auto SDK with AACS, making the messaging with AACS easier. It contains util methods, such as those for building, sending, and parsing messages. The methods enable the the client to communicate with AACS. It also provides helper functions for handling messages from AACS. See the in-code documentation for more information about each class and method.","title":"Overview"},{"location":"android/aacs/common/commonutils/#how-to-use","text":"To make the AACS Common Utils Library available to your project, add it to the dependencies of your project's build.gradle file. dependencies { ... implementation project(':alexa-auto-client-service:commonutils:aacscommonutils') ... }","title":"How to use"},{"location":"android/aacs/common/ipc/","text":"Using the IPC Library with AACS \u00b6 Overview \u00b6 The IPC (inter-process communication) library implements the IPC protocol required for communications between an HMI (human-machine interface) application and AACS (Alexa Auto Client Service). The library enables AACS to send and receive arbitrary types of payloads of arbitrary sizes. The library is implemented using standard Android constructs. You can use it as-is or as a reference when implementing IPC for your app. Getting Started with the IPC Library \u00b6 NOTE : This section assumes that you have completed the steps for building and installing AACS. To build the IPC library, follow these steps: Enter the following commands: cd $AACS_HOME/common/ipc gradle assembleDebug The aacsipc-debug.aar file is built. Copy aacsipc-debug.aar to the libs folder of your app. API Usage Guide \u00b6 The IPC library consists of two main classes for apps to interface with: AACSSender and AACSReceiver . For an additional in-code example that illustrates how an app uses the IPC library, see an AACS Android-service project. AACSSender \u00b6 AACSSender enables an application to send data to another application that uses AACSReceiver . Initialization - When AACSSender initializes, it instantiates an AACSSender object as follows: // AACSSender posts callbacks to the looper specified in the constructor // argument. If none is provided, it uses the mainlooper. AACSSender mAACSSender = new AACSSender ( Looper . getMainLooper ()); Sending a message - AACSSender sends non-streaming data, such as an AASB (Alexa Auto Service Bridge) JSON message, to AACS as follows: // replace with the entire aasb json message String aasbMessage = \"...\" ; // replace with topic of the aasb message String aasbTopic = \"...\" ; // replace with action of the aasb message String aasbAction = \"...\" ; // can also be a list of multiple targets List<TargetComponent> TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); Context context = getApplicationContext (); mAACSSender . sendAASBMessageAnySize ( aasbMessage , aasbAction , aasbTopic , target ( s ), context ); Fetching data from AACS - To stream data to the application, such as audio data, AACS first sends the application a streamId (for example, the AASB message AudioOutput/Prepare ). The application then requests the stream associated with that streamId from AACS through a fetch function as follows: // streamId previously extracted from the aasb message AudioOutput/Prepare> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . StreamFetchedFromReceiverCallback fetchCallback = ( readPipe ) -> { // readPipe is a ParcelFileDescriptor // inputStream is a ParcelFileDescriptor.AutoCloseInputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseInputStream inputStream = new ParcelFileDescriptor . AutoCloseInputStream ( readPipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR (application not responding) error. // perform application logic as necessary, reading the stream // (you could read the stream here, or queue it onto a different thread, etc) // once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) inputStream . close (); }; mAACSSender . fetch ( streamId , fetchCallback , target , context ); AACS fetching data from OEM application - If the default audio input platform handler is enabled and an external audio stream source is used, when AACS receives a StartAudioInput or StopAudioInput message, it sends an IPC fetch request or an IPC cancel fetch request. This request fetches or cancels fetching the audio input stream from the application. The application must implement AACSReceiver.FetchStreamCallback , provide the write pipe associated with the audio stream in onStreamRequested(String streamId, ParcelFileDescriptor writePipe) method, and stop providing the stream in onStreamFetchCancelled(String streamId) method, as shown in the following example: AACSReceiver . FetchStreamCallback aasbFetchCallback = new AACSReceiver . FetchStreamCallback () { @Override public void onStreamRequested ( String streamId , ParcelFileDescriptor writePipe ) { // Save the streamId and create a stream using the writePipe ParcelFileDescriptor . AutoCloseOutputStream stream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // Start writing your streamed data to the ParcelFileDescriptor.AutoCloseOutputStream // Close stream and pipe as needed when streaming is done } @Override public void onStreamFetchCancelled ( String streamId ) { // Stop writing to the ParcelFileDescriptor.AutoCloseOutputStream // associated with the given streamId } } Pushing data to AACS - To receive streamed data from the application, such as microphone data, AACS first sends the application a streamId (for example, the AASB message AudioInput/StartAudioInput ). The application then sends a stream associated with AACS together with streamId to indicate which request it's fulfilling through the push function as shown in the following code: // streamId previously extracted from the aasb message AudioInput/StartAudioInput> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . PushToStreamIdCallback pushCallback = ( streamId , writePipe ) -> { // writePipe is a ParcelFileDescriptor // outputStream is a ParcelFileDescriptor.AutoCloseOutputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseOutputStream outputStream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR error. // copy microphone data to outputStream //once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) outputStream . close (); }; mAACSSender . push ( streamId , pushCallback , target , context ); Sending configuration data to AACS - The application can send configuration data to AACS as follows: String configMessage = \"{\\n\" + \" \\\"configFilepaths\\\" : [\\\"\" + path + \"\\\"],\" + \" \\\"configStrings\\\" : []\" + \"}\" ; TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); mAACSSender . sendConfigMessageAnySize ( configMessage , target , getApplicationContext ()); configMessage must include the paths to the configuration file or the config strings. AACSReceiver \u00b6 AACSReceiver enables an application to receive data from another application that uses AACSSender . Initialization - Most of the logic for AACSReceiver is specified in callbacks. AACSReceiver is initialized by a builder. Callbacks must be provided to the builder before the builder creates AACSReceiver . The following code shows how a builder creates AACSReceiver : AACSReceiver . Builder builder = new AACSReceiver . Builder (); AACSReceiver receiver = builder // this step is optional. If no looper is provided, // the main looper is used by default. // .receive() and .shutdown() must be called from the indicated // looper. All callbacks that AACSReceiver calls or invokes are also posted // to that looper. . withLooper ( Looper . Looper . getMainLooper ) // this callback is invoked when the receiver gets a non-streamed message, // such as an AASB message. . withAASBCallback (( message ) -> { // Perform application logic based // on the AASB message in messageString. }). build (); Receiving from the sender - AACSReceiver doesn't create any direct intent receiver, which can be a service, activity, or broadcast receiver. The AACSReceiver relies on the service, activity, or broadcast receiver in the app to forward intents to it. The following code is an example illustrating how an activity overrides onNewIntent and sends an intent to be received by AACSReceiver : @Override protected void onNewIntent ( Intent intent ) { super . onNewIntent ( intent ); setIntent ( intent ); // Intents that are sent by AACS should be received here. mAACSReceiver . receiveMessage ( intent ); }","title":"Using the IPC Library with AACS"},{"location":"android/aacs/common/ipc/#using-the-ipc-library-with-aacs","text":"","title":"Using the IPC Library with AACS"},{"location":"android/aacs/common/ipc/#overview","text":"The IPC (inter-process communication) library implements the IPC protocol required for communications between an HMI (human-machine interface) application and AACS (Alexa Auto Client Service). The library enables AACS to send and receive arbitrary types of payloads of arbitrary sizes. The library is implemented using standard Android constructs. You can use it as-is or as a reference when implementing IPC for your app.","title":"Overview"},{"location":"android/aacs/common/ipc/#getting-started-with-the-ipc-library","text":"NOTE : This section assumes that you have completed the steps for building and installing AACS. To build the IPC library, follow these steps: Enter the following commands: cd $AACS_HOME/common/ipc gradle assembleDebug The aacsipc-debug.aar file is built. Copy aacsipc-debug.aar to the libs folder of your app.","title":"Getting Started with the IPC Library"},{"location":"android/aacs/common/ipc/#api-usage-guide","text":"The IPC library consists of two main classes for apps to interface with: AACSSender and AACSReceiver . For an additional in-code example that illustrates how an app uses the IPC library, see an AACS Android-service project.","title":"API Usage Guide"},{"location":"android/aacs/common/ipc/#aacssender","text":"AACSSender enables an application to send data to another application that uses AACSReceiver . Initialization - When AACSSender initializes, it instantiates an AACSSender object as follows: // AACSSender posts callbacks to the looper specified in the constructor // argument. If none is provided, it uses the mainlooper. AACSSender mAACSSender = new AACSSender ( Looper . getMainLooper ()); Sending a message - AACSSender sends non-streaming data, such as an AASB (Alexa Auto Service Bridge) JSON message, to AACS as follows: // replace with the entire aasb json message String aasbMessage = \"...\" ; // replace with topic of the aasb message String aasbTopic = \"...\" ; // replace with action of the aasb message String aasbAction = \"...\" ; // can also be a list of multiple targets List<TargetComponent> TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); Context context = getApplicationContext (); mAACSSender . sendAASBMessageAnySize ( aasbMessage , aasbAction , aasbTopic , target ( s ), context ); Fetching data from AACS - To stream data to the application, such as audio data, AACS first sends the application a streamId (for example, the AASB message AudioOutput/Prepare ). The application then requests the stream associated with that streamId from AACS through a fetch function as follows: // streamId previously extracted from the aasb message AudioOutput/Prepare> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . StreamFetchedFromReceiverCallback fetchCallback = ( readPipe ) -> { // readPipe is a ParcelFileDescriptor // inputStream is a ParcelFileDescriptor.AutoCloseInputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseInputStream inputStream = new ParcelFileDescriptor . AutoCloseInputStream ( readPipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR (application not responding) error. // perform application logic as necessary, reading the stream // (you could read the stream here, or queue it onto a different thread, etc) // once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) inputStream . close (); }; mAACSSender . fetch ( streamId , fetchCallback , target , context ); AACS fetching data from OEM application - If the default audio input platform handler is enabled and an external audio stream source is used, when AACS receives a StartAudioInput or StopAudioInput message, it sends an IPC fetch request or an IPC cancel fetch request. This request fetches or cancels fetching the audio input stream from the application. The application must implement AACSReceiver.FetchStreamCallback , provide the write pipe associated with the audio stream in onStreamRequested(String streamId, ParcelFileDescriptor writePipe) method, and stop providing the stream in onStreamFetchCancelled(String streamId) method, as shown in the following example: AACSReceiver . FetchStreamCallback aasbFetchCallback = new AACSReceiver . FetchStreamCallback () { @Override public void onStreamRequested ( String streamId , ParcelFileDescriptor writePipe ) { // Save the streamId and create a stream using the writePipe ParcelFileDescriptor . AutoCloseOutputStream stream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // Start writing your streamed data to the ParcelFileDescriptor.AutoCloseOutputStream // Close stream and pipe as needed when streaming is done } @Override public void onStreamFetchCancelled ( String streamId ) { // Stop writing to the ParcelFileDescriptor.AutoCloseOutputStream // associated with the given streamId } } Pushing data to AACS - To receive streamed data from the application, such as microphone data, AACS first sends the application a streamId (for example, the AASB message AudioInput/StartAudioInput ). The application then sends a stream associated with AACS together with streamId to indicate which request it's fulfilling through the push function as shown in the following code: // streamId previously extracted from the aasb message AudioInput/StartAudioInput> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . PushToStreamIdCallback pushCallback = ( streamId , writePipe ) -> { // writePipe is a ParcelFileDescriptor // outputStream is a ParcelFileDescriptor.AutoCloseOutputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseOutputStream outputStream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR error. // copy microphone data to outputStream //once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) outputStream . close (); }; mAACSSender . push ( streamId , pushCallback , target , context ); Sending configuration data to AACS - The application can send configuration data to AACS as follows: String configMessage = \"{\\n\" + \" \\\"configFilepaths\\\" : [\\\"\" + path + \"\\\"],\" + \" \\\"configStrings\\\" : []\" + \"}\" ; TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); mAACSSender . sendConfigMessageAnySize ( configMessage , target , getApplicationContext ()); configMessage must include the paths to the configuration file or the config strings.","title":"AACSSender "},{"location":"android/aacs/common/ipc/#aacsreceiver","text":"AACSReceiver enables an application to receive data from another application that uses AACSSender . Initialization - Most of the logic for AACSReceiver is specified in callbacks. AACSReceiver is initialized by a builder. Callbacks must be provided to the builder before the builder creates AACSReceiver . The following code shows how a builder creates AACSReceiver : AACSReceiver . Builder builder = new AACSReceiver . Builder (); AACSReceiver receiver = builder // this step is optional. If no looper is provided, // the main looper is used by default. // .receive() and .shutdown() must be called from the indicated // looper. All callbacks that AACSReceiver calls or invokes are also posted // to that looper. . withLooper ( Looper . Looper . getMainLooper ) // this callback is invoked when the receiver gets a non-streamed message, // such as an AASB message. . withAASBCallback (( message ) -> { // Perform application logic based // on the AASB message in messageString. }). build (); Receiving from the sender - AACSReceiver doesn't create any direct intent receiver, which can be a service, activity, or broadcast receiver. The AACSReceiver relies on the service, activity, or broadcast receiver in the app to forward intents to it. The following code is an example illustrating how an activity overrides onNewIntent and sends an intent to be received by AACSReceiver : @Override protected void onNewIntent ( Intent intent ) { super . onNewIntent ( intent ); setIntent ( intent ); // Intents that are sent by AACS should be received here. mAACSReceiver . receiveMessage ( intent ); }","title":"AACSReceiver "},{"location":"android/aacs/sample-app/","text":"AACS Sample App \u00b6 The AACS Sample App is an Android application that runs on your vehicle's head unit. It demonstrates how an application uses Alexa Auto Client Service (AACS), an Alexa Auto SDK feature that speeds up Alexa integration for in-vehicle infotainment (IVI). The app enables the user to select Alexa as an alternative to another voice assistant and configure the way the user interacts with Alexa. The app also allows Alexa and another application to run simultaneously. This document provides conceptual information about the purpose and features of the AACS Sample App. It provides the steps for building the app and setting up Alexa. It also describes the user experience when the user interacts with Alexa when the app is running. Note: Amazon recommends that you familiarize yourself with AACS by reading the AACS README . Table of Contents \u00b6 AACS Sample App Architecture Prerequisites Requirements for Using AACS Sample App Requirements for Using AACS Sample App with Preview Mode Requirements for Using AACS Sample App with APL Requirements for Building AACS Sample App Requirements for Using Optional Features About App Components Building the AACS Sample App Using AACS AAR Cloning the Auto SDK Repository Editing the Configuration File Including Build Dependency (AAR) Building and Signing the AACS Sample App APK Using the CLI Optional Arguments Using the CLI to Sign the APK Using Android Studio Alexa Setup Language Selection Starting Alexa on the Sign in Screen Starting Authorization Authorization With Preview Mode Authorization Without Preview Mode Interrupting Authorization Alexa Configuration for Logged-in Users Using the Alexa Menu Alexa Menu for Preview Mode Users Alexa Menu for Signed-in Users Alexa Menu Options Using the AACS Sample App Selecting Alexa as the Assistant Using Alexa Custom Assistant Module Library for Animation Using the AACS Sample App for Media Player Media Resume Last Playing Media After Platform Reboot Using the AACS Sample App for Alexa's Language Known Issues AACS Sample App Architecture \u00b6 The following diagram illustrates the AACS Sample App Architecture. Prerequisites \u00b6 You must meet the prerequisites described in this section before you can run the AACS Sample App. Requirements for Using AACS Sample App \u00b6 The following list describes the requirements for the AACS Sample App: The app can only run on an Android device. The app requires AACS to be running. You can obtain the AACS AAR according to the instructions in the AACS README . The app requires the Voice Chrome extension. The app is optimized for and tested with the Android Automotive operating system. It is tested with Android API level 28. Note: The AACS Sample App requires hardware accelerated encryption on your target device. Almost all hardware-based security concepts contain this acceleration. If you see a performance issue when running the app, your device might be missing mandatory security features. Requirements for Using AACS Sample App with Preview Mode \u00b6 Preview Mode is an Alexa feature that gives users a restricted set of Alexa features without requiring a login to the Amazon account. To allow users to use the app with Preview Mode, obtain an app component alexa-auto-preview-mode-util from Amazon with the help of your Solutions Architect (SA) or Partner Manager. Follow the instructions included to build the app component before you proceed. Requirements for Using AACS Sample App with APL \u00b6 Alexa has a visual design framework called Alexa Presentation Language (APL), which allows you to build interactive voice and visual experiences across the device landscape. To allow users to use the app with APL, follow the instructions in Alexa Auto APL Renderer README to configure and build the app. Requirements for Building AACS Sample App \u00b6 The following list describes the dependencies required for building the AACS Sample App: * Conan package manager version 1.33 or higher . The AACS Sample App build system integrates Conan into the Android Gradle system as the underlying package manager to build the Auto SDK native libraries. * Android SDK level 29 or higher . AACS service and AACS sample app are pure android projects built by Gradle. It requires the Android SDK to be installed on your work environment and the ANDROID_SDK_ROOT should point to root folder of the Android SDK. * Android Studio version 4.0 or higher (optional). Make sure that your Gradle version and Android Studio are compatible. See the Android Gradle Plugin Release Notes for information about matching Android Studio versions to Gradle versions. Requirements for Using Optional Features \u00b6 To use optional features delivered by Auto SDK extensions, contact your Solutions Architect or Partner Manager. The following list describes the extensions that you can use with the AACS Sample App: Alexa Custom Assistant extension gives the user the option of using a custom voice assistant when running the AACS Sample App. Mobile Authorization extension enables the user to log in to Amazon through the Alexa mobile app on the user's phone, without requiring the user to enter the CBL code. About App Components \u00b6 The AACS Sample App APK contains several app components, each of which consists of the compiled source code or resources used by the app to provide the UI layout, communicate with AACS, and so on. See the app components directory alexa-auto-sdk/aacs/android/app-components/ for the complete list of app components used by the AACS Sample App. See the respective README file about the purpose of each component. Building the AACS Sample App Using AACS AAR \u00b6 To build the AACS Sample App, follow these major steps: Clone the Auto SDK repository. Edit the configuration information for your device. Include the build dependencies. Build the AACS Sample App. Cloning the Auto SDK Repository \u00b6 Follow these steps to clone the Auto SDK repository: 1) Create your project directory (if you do not already have one): mkdir ~/Projects cd ~/Projects 2) Clone the alexa-auto-sdk repository into your project directory: git clone https://github.com/alexa/alexa-auto-sdk.git cd alexa-auto-sdk The Projects directory contains the Auto SDK directory structure with the android-aacs-sample-app directory and app-components directory, as shown in the following Auto SDK directory structure: . \u251c\u2500\u2500 aacs \u2502 \u2514\u2500\u2500 android \u2502 \u251c\u2500\u2500 app-components \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apis \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apl-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-carcontrol \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-comms-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-contacts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-device-usage \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-lwa-auth \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-media-player \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-navigation \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-preview-mode-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-settings \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-setup \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-telephony \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-templateruntime-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-tts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-ux-restrictions \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-voice-interaction \u2502 \u2502 \u2514\u2500\u2500 alexa-auto-voice-ui \u2502 \u251c\u2500\u2500 assets \u2502 \u251c\u2500\u2500 common \u2502 \u2502 \u251c\u2500\u2500 commonutils \u2502 \u2502 \u251c\u2500\u2500 constants \u2502 \u2502 \u2514\u2500\u2500 ipc \u2502 \u251c\u2500\u2500 sample-app \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-app \u2502 \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2514\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 service \u2502 \u251c\u2500\u2500 core-service \u2502 \u251c\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 modules Editing the Configuration File \u00b6 For Alexa Voice Service (AVS) to authenticate your device profile, specify the configuration information in this file: alexa-auto-sdk/aacs/android/sample-app/alexa-auto-app/src/main/assets/config/aacs_config.json The following list describes the required information for aacs.alexa.deviceInfo : For clientId , specify the Client ID that you generated when you set up your security profile for your development device. For productId , specify the Product ID that you entered when you filled in the product information for your development device. Note: clientId and productId must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . For deviceSerialNumber , specify the serial number of your device. For manufacturerName , specify the name of the device manufacturer. For description , specify a description of your device. Including Build Dependency (AAR) \u00b6 The AACS Sample App APK requires the Auto SDK Voice Chrome extension (autovoicechrome.aar) as a dependency. Follow these steps to include the AAR: Create the following directory: alexa-auto-sdk/aacs/android/app-components/alexa-auto-voice-interaction/libs Copy the AAR into the directory. After including the dependency, you can build the AACS Sample App APK either on the CLI or by using Android Studio. Building and Signing the AACS Sample App APK \u00b6 You can use the command line interface (CLI) or the Android Studio to build and sign the AACS Sample App APK. Using the CLI \u00b6 Follow these steps to build the AACS Sample App APK: 1) Enter the following command to change the directory: cd ~/Projects/alexa-auto-sdk/aacs/android/sample-app 2) Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds the Alexa Auto SDK, AACS, AACS Sample App and all the extensions present under the alexa-auto-sdk/extensions/extras directory for armv8 targets. To enable the local debug log during the build, use assembleLocalDebug in the gradlew command. To build AACS Sample App using the pre-built Alexa Auto SDK AARs, use assembleRemoteRelease in the gradlew command. The gradlew command creates the unsigned APK, which is located in the following directory: alexa-auto-app/build/outputs/apk/release/alexa-auto-app_release_4.0.apk The gradlew command also creates each app component's AAR, which is located in each component's build output directory. For example, the Alexa Auto Media Player AAR is in the following directory: ~/Projects/alexa-auto-sdk/aacs/android/app-components/alexa-auto-media-player/build/outputs/aar/alexa-auto-media-player_release.aar Optional Arguments \u00b6 The following optional arguments are supported: Enable Optional Modules To build AACS Sample App optional modules, use -Penabled<module_name> . For example, enable APL by appending -PenabledAPL to the build command. The supported module options are -PenabledAPL , -PenabledUXRestrictions , -PenabledPreviewMode , -PenabledDeviceUsage . To enable AACS optional libraries, use -P<enabledAACSModuleName> . For example, enable AACS Telephony service by appending -PenabledTelephony to the build command. The supported module options are -PenabledTelephony , -PenabledContacts , -PenabledCarControl . See the below for the full command to enable APL, UX restrictions, telephony and contacts: ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions -PenabledTelephony -PenabledContacts Specify Path to Extensions By default, the builder picks up all the extensions present under the alexa-auto-sdk/extensions/extras directory. To override with your custom paths to the extensions, use -Pextensions . See the below for the full command: ./gradlew assembleLocalRelease -Pextensions=~/your/custom/path/to/extension1,~/your/custom/path/to/extension2,... Clean Cache and Rebuild To clean the AACS and AACS Sample App build cache, run ./gradlew clean first before running the build command. To rebuild only outdated dependencies, append -Pforce to the build command. This option is required when you make a change on Alexa Auto SDK. It forces the builder to re-export all the package recipes and triggers rebuild for the packages on which changes are detected. To clean all the Alexa Auto SDK cache and rebuild all the dependencies: use -PcleanDeps . Skip Dependencies To skip the step of building dependencies, use -PskipDeps . Make sure the Alexa Auto SDK dependency AARs are already present under alexa-auto-sdk/aacs/android/service/core-service/libs directory before you use this option. Specify Architecture Specify the build target by appending the option -Parch=<your_arch> , for example: -Parch=x86_64 . The supported architectures are x86 , x86_64 , armv7 , armv8 . If not specified, the builder by default builds for the armv8 target. Enable Sensitive Logs Use the option -PsensitiveLogs to enable senstive logs. Note that sensitive logs are allowed in debug builds only. Change the dependency cache location Change the location of the Alexa Auto SDK build cache by using this option: -PconanHome=your/custom/home . The default location is set to alexa-auto-sdk/builder/.builder . Automatically Accept Licenses You need to manually accept the Android SDK licenses from command line when you build the first time. Use -PacceptLicenses to automatically accept the licenses. Specify Options for Dependencies Use -PconanOptions=<recipe_name>:<option>=<custom_option> to pass any options for dependencies to the builder. AACS Sample App uses Conan to build all the Auto SDK dependencies. You can use this option to change the Conan options for any dependency recipe. Using the CLI to Sign the APK \u00b6 The procedure for signing the APK requires these commands: zipalign is included in the Android SDK Build Tools. On a Mac, it is usually located in this directory: ~/Library/Android/sdk/build-tools/ /zipalign apksigner is in Android SDK Build Tools 24.0.3 or higher. On a Mac, it is usually in the following directory: ~/Library/Android/sdk/build-tools/ /apksigner You can include the build tools in your path so that you can run the commands from any directory. The following example is for Android SDK Build Tools version 30.0.2: echo \"export PATH=\\$PATH:~/Library/Android/sdk/build-tools/30.0.2/\" ~/.bash_profile && . ~/.bash_profile To sign the APK, follow these steps: Create a custom keystore using the following command, or skip to the next step and use an existing keystore: keytool -genkey -v -keystore <keystore_name>.keystore -alias <alias> -keyalg RSA -keysize 2048 -validity 10000 Enter the following command to change to the directory where the APK is: cd alexa-auto-app/build/outputs/apk/release Enter the following command to optimize the APK files zipalign -v -p 4 alexa-auto-app_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk Enter the following commands to sign the APK by using your keystore: apksigner sign --ks <path_to_keystore>/<keystore_name>.keystore --ks-pass pass:<passphrase> --out alexa-auto-app_signed_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk When prompted, enter the passphrase that you set when you created the keystore. Using Android Studio \u00b6 Note: These instructions assume that you have edited the configuration files . Launch Android Studio and select Open an existing Android Studio project. Open the folder containing the APK. For example, open the alexa-auto-app/samples/android-aacs-sample-app folder. Click the Open button. Under Build Variants , select localRelease . Add optional arguments in the alexa-auto-sdk/aacs/android/sample-app/gradle.properties file. See optional arguments for all the supported options. Remove the -P prefix when adding the option to the gradle.properties file. Note : Android Studio builds and signs the APK. Alexa Setup \u00b6 This section describes what the user must do to set up Alexa, which determines the user experience when the user interacts with Alexa. The information here supersedes the information in the Setup documentation . Note: The Alexa setup process is different for users of Preview Mode and users who signed in. The setup procedure includes the following steps: Select Alexa's language (if the language used for IVI is not supported by Alexa). Accept the use of Alexa in Preview Mode or perform a user login. Configure initial Alexa settings (for logged-in users). Note: To complete Alexa setup, the user must have internet connection. Language Selection \u00b6 The Alexa setup starts with selecting a language to be used by Alexa. The workflow for language selection depends on the language used by the IVI: If the language used for the IVI is supported by Alexa, there is no need to select a language because the app sets Alexa's language to match the IVI language. If the user prefers to use a different language for Alexa, the user can change it at a later time through the Alexa menu. If the language used for the IVI is not supported by Alexa, a menu is displayed for language selection. After the selection, the locale is changed according to the language selected, the setup workflow also displays text in the language selected. For a list of languages supported by Alexa, see the Alexa Voice Service documentation . Starting Alexa on the Sign in Screen \u00b6 The Sign in screen is displayed after the user selects the language. It displays the following contents depending on whether the AACS Sample App is used with Preview Mode: With Preview Mode: The screen shows two buttons. The user can click on the TRY ALEXA button to connect to Alexa in Preview mode, or on the SIGN-IN button to sign in using their Amazon account credentials. Without Preview Mode: The screen shows the SIGN-IN button only. Starting Authorization \u00b6 The exact authorization workflow depends on whether the AACS Sample App is used with Preview Mode. If so, the Alexa Voice Service (AVS) access token is retrieved without a user login. Otherwise, the user uses Login With Amazon (LWA) to gain access to Alexa. The Auto SDK can use various authorization methods, such as Code-Based Linking (CBL) and Mobile Authorization, to retrieve the access token. Authorization With Preview Mode \u00b6 On the Sign-in screen, the user can click TRY ALEXA , which means that the user will access Alexa through Preview Mode. The Preview Mode consent screen is then displayed wherein the user can review Amazon\u2019s Conditions of Use, Alexa & Alexa Device terms and Privacy policy. After clicking on the AGREE & ENABLE ALEXA button, the Success screen is displayed providing sample utterances for the user to try. Authorization Without Preview Mode \u00b6 The user can log in to Amazon to access the complete set of Alexa features. How the user logs in depends on whether the Auto SDK is running with the Bluetooth extension and Mobile Authorization extension. Without the Mobile Authorization feature, the user sees the Sign-in screen showing the URL and a code (in the form of a string and a QR code), which the user uses to finish the CBL authorization. After authorization, the user's Amazon account is linked to the vehicle. With the Mobile Authorization feature, when the user's phone is connected to the head unit via Bluetooth, the user sees a notification on the phone. After the user accepts the notification, the user is authenticated with the Amazon account information that the Alexa mobile app uses for Amazon login. For more information about Mobile Authorization, see the Mobile Authorization extension README. Interrupting Authorization \u00b6 When the user is in the process of login authorization, interrupting the setup flow at this stage will cause the app to reset to the general login page when the user returns to the app. In the case of the CBL authorization mode, if the user is interrupted at the code pair screen, the app will cancel the current authorization request. The user must regenerate a new code by pressing on the sign in button again. There are currently two types of interruption popups that the AACS Sample App implements: 1. Network status changes (e.g. NETWORK_DISCONNECTED ) 2. Driving state changes (e.g. CAR_STATE_DRIVE ) Alexa Configuration for Logged-in Users \u00b6 If the user is logged in, the user is prompted to further configure Alexa. The user is shown the location consent screen wherein they have the option to either enable location sharing or skip it. Next, if a Bluetooth-connected phone is detected, the app prompts the user to give permission for Alexa to access contacts. After this configuration step, the app displays the Success screen as confirmation that the user can start using Alexa. If your device is allow-listed by Amazon for supporting device setup, the user hears a first-time conversation from Alexa, which provides the on-boarding experience. Using the Alexa Menu \u00b6 The AACS Sample App provides an Alexa menu through which the user can change any settings configured during the setup process. For options with an On or Off value, the menu provides a toggle button. The Alexa menu is different for users of Preview Mode and users who signed in. Note: When developing your Android app, you may add options to the Alexa menu. Add such option at the end of the Alexa menu. Alexa Menu for Preview Mode Users \u00b6 In Preview Mode, the Alexa menu is organized as follows: Sign in Alexa Hands-Free Location sharing Sync navigation favorites Sounds Alexa's language Things to try Disable Alexa Alexa Menu for Signed-in Users \u00b6 For signed-in users, the Alexa menu is organized as follows: Alexa Hands-Free Do Not Disturb Location sharing Sync navigation favorites Communication Device name Contacts Sounds Alexa's language Things to try Sign out Alexa Menu Options \u00b6 The following table describes each Alexa menu option: Option Description Possible values (Default) Sign in (For Preview Mode users only) It allows the user to sign in with CBL or Mobile Authorization. Alexa Hands-Free If it is enabled, the user can say \"Alexa\" to invoke Alexa. If it is disabled, the user can still use PTT or TTT to invoke Alexa. On, Off (On) Do Not Disturb (For signed-in users only) If enabled, it disables Alexa notifications. On, Off (Off) Location sharing If it is enabled, the user can use location-based utterances like \"Alexa, show me some coffee shops near me\". If it is disabled, Alexa will not have access to the device's location and will expect the user to explicitly provide their location as a follow up voice utterance in order to respond to location-based utterances. On, Off (value specified during Alexa setup) Sync navigation favorites If it is enabled, navigation favorites from the local navigation provider would be uploaded. The user can say \"Alexa, navigate to gym\" where the gym address is expected to be in the favorites. If it is disabled, uploaded favorites would be cleared and Alexa will not have access to the device's navigation favorites list. On, Off (Off) Communication Name of the device on which the app runs (e.g., Sam's iPhone). Communication > Contacts If it is enabled, contacts are uploaded from the phone to Alexa, and the user can use Alexa to call or receive a call from a contact. On, Off (value specified during Alexa setup) Sounds Alexa sound settings. Sounds > Start/End of request sound If enabled, a sound is played with Alexa starts/stops listening. On, Off (On) Alexa's language The language used by Alexa when responding to your request. Languages supported by Alexa (language specified during Alexa setup or in Alexa menu) Things to try The Alexa utterances to try out for different domains Sign out (For signed-in users only) Button for the user to sign out of Alexa. It displays a confirmation message before the user is signed out. Disable Alexa (For Preview Mode users only) It displays a screen with a DISABLE button, which stops Alexa from being available in the vehicle. Using the AACS Sample App \u00b6 This section describes the user experience after you deploy the AACS Sample App on an Android device. Selecting Alexa as the Assistant \u00b6 While Google Assistant is usually the default voice assistant on an Android device, user has the option of selecting Alexa as the assistant. AACS sample app behaves differently in the following scenarios: * If AACS sample app is granted the android.permission.WRITE_SECURE_SETTINGS permission: * If there is no assistant currently selected, when a user launches the Alexa app from home screen, Alexa will be automatically set as the default assist app for the system. * If another assistant is currently selected as the default, when a user launches the Alexa app from home screen, a page will be displayed to ask user whether they want to replace the currently active assistant with Alexa. If the user confirms, Alexa will be set as the default assist app and the user can continue with the Alexa setup flow to sign in. Note: AACS Sample App modifies the system setting to make Alexa the system default assist app. This approach requires your Android system UI to properly respond to the system setting change, otherwise your Android system UI may become out of sync. If your Android system cannot handle the system setting change gracefully, remove the android.permission.WRITE_SECURE_SETTINGS from AACS sample app to enable the fallback approach. The behavior is further described in the following bullet point. * If AACS sample app does not have the android.permission.WRITE_SECURE_SETTINGS permission: * When user launches the Alexa app from home screen, a page will be displayed to ask user to manually select Alexa as default. The page provides a SETTINGS button which deep-links to the Assist & voice input setting page. Alternatively, the user can also set Alexa as default assistant using the following steps: 1. Go to the device's Settings. 2. Go to Apps & notifications > Default apps > Assist & voice input . Then select Alexa. Note: After selecting Alexa as the assistant, if the Auto SDK is built with the Alexa Custom Assistant extension, the user can invoke either Alexa or a custom voice assistant (e.g., Brandon). Using Alexa Custom Assistant Module Library for Animation \u00b6 If the Alexa Custom Assistant extension is installed, you can use the Alexa Custom Assistant Module Library to display custom animation when user is interacting with the custom assistant. For more information about how to enable custom animation, see the Alexa Custom Assistant extension README. Using the AACS Sample App for Media Player \u00b6 In addition to letting the user choose Alexa as the voice assistant, the AACS Sample app enables the user to start and control the media player. Alexa integrates with most music providers in cloud. After the user launches the app and selects Alexa as the assistant, the user can say, for example, \"Alexa, play the station [station call sign] on iHeartRadio.\" The app displays the user interface (UI) that comes with Android Automotive. The same UI is presented for all media providers, such as iHeartRadio and Amazon Music. However, the exact UI elements depend on the provider. For example, when the app plays music from iHeartRadio, it does not include a rewind button to go back. When the app plays music from Amazon Music, the rewind button is present. In addition, the user can say, \"Go back 30 seconds,\" to go back. The user can also use the app to listen to audio books. For example, if the user says, \"Alexa, play the start of lord of the rings book one,\" Alexa starts playing the audio book from Audible. The UI displayed by the app includes the buttons for skipping 30 seconds backward or forward. Media Resume Last Playing Media After Platform Reboot \u00b6 Generally, automotive infotainment platforms support media media resume after the reboot. Alexa Media Resume is a feature that helps Alexa play customers\u2019 favorite content when they restart their Alexa-enabled vehicles. Media Resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. Refer to Media Resume for more information about the feature. This feature works out of the box on Automotive Android OS. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } } Note If you are not using automotive android then it is assumed that your platform manages the sessions, enables the MediaBrowserService after reboot and sends the play command. In that case you may need to modify alexa-auto-media-player code to send the requestMediaPlayback message. Note The default implementation in PlaybackControlMessages.java gets the elapsed boot time using Android API SystemClock.elapsedRealtime() If your platform provides the correct elapsed boot time value using any different API, please update it. Using the AACS Sample App for Alexa's Language \u00b6 The AACS sample app enables the user to select Alexa's Language during the first-time user experience (FTUE) and after the FTUE: During the FTUE, if Alexa supports the System Language, then the AACS Sample app automatically sets Alexa\u2019s Language to match the System Language. Else, the app informs the customer of the limitation and ask them to manually select a language for Alexa\u2019s Language. After the FTUE, if a customer changes the System Language after setting up Alexa, and Alexa supports the new System Language, then the app automatically updates Alexa\u2019s Language to match the System Language. Else, the app informs the customer of Alexa\u2019s limitation and ask them to select a language for Alexa. If a customer changes Alexa\u2019s Language to something that doesn\u2019t match the System Language, and the System Language is supported by Alexa, then the app informs the customer of the mismatch and ask them to confirm before proceeding. Known Issues \u00b6 Android Emulator on macOS has poor audio quality, which would cause the Alexa Text-to-Speech (TTS) output to be unusable. In the Android Automotive Emulator, the Push-to-Talk button on the system navigation bar does not integrate with the Android Voice Interaction module properly. It is hard coded to invoke Google Assistant instead. Therefore, even if the user tries to switch from the default voice assistant to Alexa, the Push-to-Talk button on the system navigation bar still invokes the Google Assistant. Note: Please refer to the component level README files for more information/known issues that relate to the component","title":"AACS Sample App <!-- omit in toc -->"},{"location":"android/aacs/sample-app/#aacs-sample-app","text":"The AACS Sample App is an Android application that runs on your vehicle's head unit. It demonstrates how an application uses Alexa Auto Client Service (AACS), an Alexa Auto SDK feature that speeds up Alexa integration for in-vehicle infotainment (IVI). The app enables the user to select Alexa as an alternative to another voice assistant and configure the way the user interacts with Alexa. The app also allows Alexa and another application to run simultaneously. This document provides conceptual information about the purpose and features of the AACS Sample App. It provides the steps for building the app and setting up Alexa. It also describes the user experience when the user interacts with Alexa when the app is running. Note: Amazon recommends that you familiarize yourself with AACS by reading the AACS README .","title":"AACS Sample App "},{"location":"android/aacs/sample-app/#table-of-contents","text":"AACS Sample App Architecture Prerequisites Requirements for Using AACS Sample App Requirements for Using AACS Sample App with Preview Mode Requirements for Using AACS Sample App with APL Requirements for Building AACS Sample App Requirements for Using Optional Features About App Components Building the AACS Sample App Using AACS AAR Cloning the Auto SDK Repository Editing the Configuration File Including Build Dependency (AAR) Building and Signing the AACS Sample App APK Using the CLI Optional Arguments Using the CLI to Sign the APK Using Android Studio Alexa Setup Language Selection Starting Alexa on the Sign in Screen Starting Authorization Authorization With Preview Mode Authorization Without Preview Mode Interrupting Authorization Alexa Configuration for Logged-in Users Using the Alexa Menu Alexa Menu for Preview Mode Users Alexa Menu for Signed-in Users Alexa Menu Options Using the AACS Sample App Selecting Alexa as the Assistant Using Alexa Custom Assistant Module Library for Animation Using the AACS Sample App for Media Player Media Resume Last Playing Media After Platform Reboot Using the AACS Sample App for Alexa's Language Known Issues","title":"Table of Contents"},{"location":"android/aacs/sample-app/#aacs-sample-app-architecture","text":"The following diagram illustrates the AACS Sample App Architecture.","title":"AACS Sample App Architecture"},{"location":"android/aacs/sample-app/#prerequisites","text":"You must meet the prerequisites described in this section before you can run the AACS Sample App.","title":"Prerequisites"},{"location":"android/aacs/sample-app/#requirements-for-using-aacs-sample-app","text":"The following list describes the requirements for the AACS Sample App: The app can only run on an Android device. The app requires AACS to be running. You can obtain the AACS AAR according to the instructions in the AACS README . The app requires the Voice Chrome extension. The app is optimized for and tested with the Android Automotive operating system. It is tested with Android API level 28. Note: The AACS Sample App requires hardware accelerated encryption on your target device. Almost all hardware-based security concepts contain this acceleration. If you see a performance issue when running the app, your device might be missing mandatory security features.","title":"Requirements for Using AACS Sample App"},{"location":"android/aacs/sample-app/#requirements-for-using-aacs-sample-app-with-preview-mode","text":"Preview Mode is an Alexa feature that gives users a restricted set of Alexa features without requiring a login to the Amazon account. To allow users to use the app with Preview Mode, obtain an app component alexa-auto-preview-mode-util from Amazon with the help of your Solutions Architect (SA) or Partner Manager. Follow the instructions included to build the app component before you proceed.","title":"Requirements for Using AACS Sample App with Preview Mode"},{"location":"android/aacs/sample-app/#requirements-for-using-aacs-sample-app-with-apl","text":"Alexa has a visual design framework called Alexa Presentation Language (APL), which allows you to build interactive voice and visual experiences across the device landscape. To allow users to use the app with APL, follow the instructions in Alexa Auto APL Renderer README to configure and build the app.","title":"Requirements for Using AACS Sample App with APL"},{"location":"android/aacs/sample-app/#requirements-for-building-aacs-sample-app","text":"The following list describes the dependencies required for building the AACS Sample App: * Conan package manager version 1.33 or higher . The AACS Sample App build system integrates Conan into the Android Gradle system as the underlying package manager to build the Auto SDK native libraries. * Android SDK level 29 or higher . AACS service and AACS sample app are pure android projects built by Gradle. It requires the Android SDK to be installed on your work environment and the ANDROID_SDK_ROOT should point to root folder of the Android SDK. * Android Studio version 4.0 or higher (optional). Make sure that your Gradle version and Android Studio are compatible. See the Android Gradle Plugin Release Notes for information about matching Android Studio versions to Gradle versions.","title":"Requirements for Building AACS Sample App"},{"location":"android/aacs/sample-app/#requirements-for-using-optional-features","text":"To use optional features delivered by Auto SDK extensions, contact your Solutions Architect or Partner Manager. The following list describes the extensions that you can use with the AACS Sample App: Alexa Custom Assistant extension gives the user the option of using a custom voice assistant when running the AACS Sample App. Mobile Authorization extension enables the user to log in to Amazon through the Alexa mobile app on the user's phone, without requiring the user to enter the CBL code.","title":"Requirements for Using Optional Features"},{"location":"android/aacs/sample-app/#about-app-components","text":"The AACS Sample App APK contains several app components, each of which consists of the compiled source code or resources used by the app to provide the UI layout, communicate with AACS, and so on. See the app components directory alexa-auto-sdk/aacs/android/app-components/ for the complete list of app components used by the AACS Sample App. See the respective README file about the purpose of each component.","title":"About App Components"},{"location":"android/aacs/sample-app/#building-the-aacs-sample-app-using-aacs-aar","text":"To build the AACS Sample App, follow these major steps: Clone the Auto SDK repository. Edit the configuration information for your device. Include the build dependencies. Build the AACS Sample App.","title":"Building the AACS Sample App Using AACS AAR"},{"location":"android/aacs/sample-app/#cloning-the-auto-sdk-repository","text":"Follow these steps to clone the Auto SDK repository: 1) Create your project directory (if you do not already have one): mkdir ~/Projects cd ~/Projects 2) Clone the alexa-auto-sdk repository into your project directory: git clone https://github.com/alexa/alexa-auto-sdk.git cd alexa-auto-sdk The Projects directory contains the Auto SDK directory structure with the android-aacs-sample-app directory and app-components directory, as shown in the following Auto SDK directory structure: . \u251c\u2500\u2500 aacs \u2502 \u2514\u2500\u2500 android \u2502 \u251c\u2500\u2500 app-components \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apis \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apl-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-carcontrol \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-comms-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-contacts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-device-usage \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-lwa-auth \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-media-player \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-navigation \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-preview-mode-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-settings \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-setup \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-telephony \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-templateruntime-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-tts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-ux-restrictions \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-voice-interaction \u2502 \u2502 \u2514\u2500\u2500 alexa-auto-voice-ui \u2502 \u251c\u2500\u2500 assets \u2502 \u251c\u2500\u2500 common \u2502 \u2502 \u251c\u2500\u2500 commonutils \u2502 \u2502 \u251c\u2500\u2500 constants \u2502 \u2502 \u2514\u2500\u2500 ipc \u2502 \u251c\u2500\u2500 sample-app \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-app \u2502 \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2514\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 service \u2502 \u251c\u2500\u2500 core-service \u2502 \u251c\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 modules","title":"Cloning the Auto SDK Repository"},{"location":"android/aacs/sample-app/#editing-the-configuration-file","text":"For Alexa Voice Service (AVS) to authenticate your device profile, specify the configuration information in this file: alexa-auto-sdk/aacs/android/sample-app/alexa-auto-app/src/main/assets/config/aacs_config.json The following list describes the required information for aacs.alexa.deviceInfo : For clientId , specify the Client ID that you generated when you set up your security profile for your development device. For productId , specify the Product ID that you entered when you filled in the product information for your development device. Note: clientId and productId must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . For deviceSerialNumber , specify the serial number of your device. For manufacturerName , specify the name of the device manufacturer. For description , specify a description of your device.","title":"Editing the Configuration File"},{"location":"android/aacs/sample-app/#including-build-dependency-aar","text":"The AACS Sample App APK requires the Auto SDK Voice Chrome extension (autovoicechrome.aar) as a dependency. Follow these steps to include the AAR: Create the following directory: alexa-auto-sdk/aacs/android/app-components/alexa-auto-voice-interaction/libs Copy the AAR into the directory. After including the dependency, you can build the AACS Sample App APK either on the CLI or by using Android Studio.","title":"Including Build Dependency (AAR)"},{"location":"android/aacs/sample-app/#building-and-signing-the-aacs-sample-app-apk","text":"You can use the command line interface (CLI) or the Android Studio to build and sign the AACS Sample App APK.","title":"Building and Signing the AACS Sample App APK"},{"location":"android/aacs/sample-app/#using-the-cli","text":"Follow these steps to build the AACS Sample App APK: 1) Enter the following command to change the directory: cd ~/Projects/alexa-auto-sdk/aacs/android/sample-app 2) Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds the Alexa Auto SDK, AACS, AACS Sample App and all the extensions present under the alexa-auto-sdk/extensions/extras directory for armv8 targets. To enable the local debug log during the build, use assembleLocalDebug in the gradlew command. To build AACS Sample App using the pre-built Alexa Auto SDK AARs, use assembleRemoteRelease in the gradlew command. The gradlew command creates the unsigned APK, which is located in the following directory: alexa-auto-app/build/outputs/apk/release/alexa-auto-app_release_4.0.apk The gradlew command also creates each app component's AAR, which is located in each component's build output directory. For example, the Alexa Auto Media Player AAR is in the following directory: ~/Projects/alexa-auto-sdk/aacs/android/app-components/alexa-auto-media-player/build/outputs/aar/alexa-auto-media-player_release.aar","title":"Using the CLI"},{"location":"android/aacs/sample-app/#optional-arguments","text":"The following optional arguments are supported: Enable Optional Modules To build AACS Sample App optional modules, use -Penabled<module_name> . For example, enable APL by appending -PenabledAPL to the build command. The supported module options are -PenabledAPL , -PenabledUXRestrictions , -PenabledPreviewMode , -PenabledDeviceUsage . To enable AACS optional libraries, use -P<enabledAACSModuleName> . For example, enable AACS Telephony service by appending -PenabledTelephony to the build command. The supported module options are -PenabledTelephony , -PenabledContacts , -PenabledCarControl . See the below for the full command to enable APL, UX restrictions, telephony and contacts: ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions -PenabledTelephony -PenabledContacts Specify Path to Extensions By default, the builder picks up all the extensions present under the alexa-auto-sdk/extensions/extras directory. To override with your custom paths to the extensions, use -Pextensions . See the below for the full command: ./gradlew assembleLocalRelease -Pextensions=~/your/custom/path/to/extension1,~/your/custom/path/to/extension2,... Clean Cache and Rebuild To clean the AACS and AACS Sample App build cache, run ./gradlew clean first before running the build command. To rebuild only outdated dependencies, append -Pforce to the build command. This option is required when you make a change on Alexa Auto SDK. It forces the builder to re-export all the package recipes and triggers rebuild for the packages on which changes are detected. To clean all the Alexa Auto SDK cache and rebuild all the dependencies: use -PcleanDeps . Skip Dependencies To skip the step of building dependencies, use -PskipDeps . Make sure the Alexa Auto SDK dependency AARs are already present under alexa-auto-sdk/aacs/android/service/core-service/libs directory before you use this option. Specify Architecture Specify the build target by appending the option -Parch=<your_arch> , for example: -Parch=x86_64 . The supported architectures are x86 , x86_64 , armv7 , armv8 . If not specified, the builder by default builds for the armv8 target. Enable Sensitive Logs Use the option -PsensitiveLogs to enable senstive logs. Note that sensitive logs are allowed in debug builds only. Change the dependency cache location Change the location of the Alexa Auto SDK build cache by using this option: -PconanHome=your/custom/home . The default location is set to alexa-auto-sdk/builder/.builder . Automatically Accept Licenses You need to manually accept the Android SDK licenses from command line when you build the first time. Use -PacceptLicenses to automatically accept the licenses. Specify Options for Dependencies Use -PconanOptions=<recipe_name>:<option>=<custom_option> to pass any options for dependencies to the builder. AACS Sample App uses Conan to build all the Auto SDK dependencies. You can use this option to change the Conan options for any dependency recipe.","title":"Optional Arguments"},{"location":"android/aacs/sample-app/#using-the-cli-to-sign-the-apk","text":"The procedure for signing the APK requires these commands: zipalign is included in the Android SDK Build Tools. On a Mac, it is usually located in this directory: ~/Library/Android/sdk/build-tools/ /zipalign apksigner is in Android SDK Build Tools 24.0.3 or higher. On a Mac, it is usually in the following directory: ~/Library/Android/sdk/build-tools/ /apksigner You can include the build tools in your path so that you can run the commands from any directory. The following example is for Android SDK Build Tools version 30.0.2: echo \"export PATH=\\$PATH:~/Library/Android/sdk/build-tools/30.0.2/\" ~/.bash_profile && . ~/.bash_profile To sign the APK, follow these steps: Create a custom keystore using the following command, or skip to the next step and use an existing keystore: keytool -genkey -v -keystore <keystore_name>.keystore -alias <alias> -keyalg RSA -keysize 2048 -validity 10000 Enter the following command to change to the directory where the APK is: cd alexa-auto-app/build/outputs/apk/release Enter the following command to optimize the APK files zipalign -v -p 4 alexa-auto-app_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk Enter the following commands to sign the APK by using your keystore: apksigner sign --ks <path_to_keystore>/<keystore_name>.keystore --ks-pass pass:<passphrase> --out alexa-auto-app_signed_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk When prompted, enter the passphrase that you set when you created the keystore.","title":"Using the CLI to Sign the APK"},{"location":"android/aacs/sample-app/#using-android-studio","text":"Note: These instructions assume that you have edited the configuration files . Launch Android Studio and select Open an existing Android Studio project. Open the folder containing the APK. For example, open the alexa-auto-app/samples/android-aacs-sample-app folder. Click the Open button. Under Build Variants , select localRelease . Add optional arguments in the alexa-auto-sdk/aacs/android/sample-app/gradle.properties file. See optional arguments for all the supported options. Remove the -P prefix when adding the option to the gradle.properties file. Note : Android Studio builds and signs the APK.","title":"Using Android Studio"},{"location":"android/aacs/sample-app/#alexa-setup","text":"This section describes what the user must do to set up Alexa, which determines the user experience when the user interacts with Alexa. The information here supersedes the information in the Setup documentation . Note: The Alexa setup process is different for users of Preview Mode and users who signed in. The setup procedure includes the following steps: Select Alexa's language (if the language used for IVI is not supported by Alexa). Accept the use of Alexa in Preview Mode or perform a user login. Configure initial Alexa settings (for logged-in users). Note: To complete Alexa setup, the user must have internet connection.","title":"Alexa Setup"},{"location":"android/aacs/sample-app/#language-selection","text":"The Alexa setup starts with selecting a language to be used by Alexa. The workflow for language selection depends on the language used by the IVI: If the language used for the IVI is supported by Alexa, there is no need to select a language because the app sets Alexa's language to match the IVI language. If the user prefers to use a different language for Alexa, the user can change it at a later time through the Alexa menu. If the language used for the IVI is not supported by Alexa, a menu is displayed for language selection. After the selection, the locale is changed according to the language selected, the setup workflow also displays text in the language selected. For a list of languages supported by Alexa, see the Alexa Voice Service documentation .","title":"Language Selection"},{"location":"android/aacs/sample-app/#starting-alexa-on-the-sign-in-screen","text":"The Sign in screen is displayed after the user selects the language. It displays the following contents depending on whether the AACS Sample App is used with Preview Mode: With Preview Mode: The screen shows two buttons. The user can click on the TRY ALEXA button to connect to Alexa in Preview mode, or on the SIGN-IN button to sign in using their Amazon account credentials. Without Preview Mode: The screen shows the SIGN-IN button only.","title":"Starting Alexa on the Sign in Screen"},{"location":"android/aacs/sample-app/#starting-authorization","text":"The exact authorization workflow depends on whether the AACS Sample App is used with Preview Mode. If so, the Alexa Voice Service (AVS) access token is retrieved without a user login. Otherwise, the user uses Login With Amazon (LWA) to gain access to Alexa. The Auto SDK can use various authorization methods, such as Code-Based Linking (CBL) and Mobile Authorization, to retrieve the access token.","title":"Starting Authorization"},{"location":"android/aacs/sample-app/#authorization-with-preview-mode","text":"On the Sign-in screen, the user can click TRY ALEXA , which means that the user will access Alexa through Preview Mode. The Preview Mode consent screen is then displayed wherein the user can review Amazon\u2019s Conditions of Use, Alexa & Alexa Device terms and Privacy policy. After clicking on the AGREE & ENABLE ALEXA button, the Success screen is displayed providing sample utterances for the user to try.","title":"Authorization With Preview Mode"},{"location":"android/aacs/sample-app/#authorization-without-preview-mode","text":"The user can log in to Amazon to access the complete set of Alexa features. How the user logs in depends on whether the Auto SDK is running with the Bluetooth extension and Mobile Authorization extension. Without the Mobile Authorization feature, the user sees the Sign-in screen showing the URL and a code (in the form of a string and a QR code), which the user uses to finish the CBL authorization. After authorization, the user's Amazon account is linked to the vehicle. With the Mobile Authorization feature, when the user's phone is connected to the head unit via Bluetooth, the user sees a notification on the phone. After the user accepts the notification, the user is authenticated with the Amazon account information that the Alexa mobile app uses for Amazon login. For more information about Mobile Authorization, see the Mobile Authorization extension README.","title":"Authorization Without Preview Mode"},{"location":"android/aacs/sample-app/#interrupting-authorization","text":"When the user is in the process of login authorization, interrupting the setup flow at this stage will cause the app to reset to the general login page when the user returns to the app. In the case of the CBL authorization mode, if the user is interrupted at the code pair screen, the app will cancel the current authorization request. The user must regenerate a new code by pressing on the sign in button again. There are currently two types of interruption popups that the AACS Sample App implements: 1. Network status changes (e.g. NETWORK_DISCONNECTED ) 2. Driving state changes (e.g. CAR_STATE_DRIVE )","title":"Interrupting Authorization"},{"location":"android/aacs/sample-app/#alexa-configuration-for-logged-in-users","text":"If the user is logged in, the user is prompted to further configure Alexa. The user is shown the location consent screen wherein they have the option to either enable location sharing or skip it. Next, if a Bluetooth-connected phone is detected, the app prompts the user to give permission for Alexa to access contacts. After this configuration step, the app displays the Success screen as confirmation that the user can start using Alexa. If your device is allow-listed by Amazon for supporting device setup, the user hears a first-time conversation from Alexa, which provides the on-boarding experience.","title":"Alexa Configuration for Logged-in Users"},{"location":"android/aacs/sample-app/#using-the-alexa-menu","text":"The AACS Sample App provides an Alexa menu through which the user can change any settings configured during the setup process. For options with an On or Off value, the menu provides a toggle button. The Alexa menu is different for users of Preview Mode and users who signed in. Note: When developing your Android app, you may add options to the Alexa menu. Add such option at the end of the Alexa menu.","title":"Using the Alexa Menu"},{"location":"android/aacs/sample-app/#alexa-menu-for-preview-mode-users","text":"In Preview Mode, the Alexa menu is organized as follows: Sign in Alexa Hands-Free Location sharing Sync navigation favorites Sounds Alexa's language Things to try Disable Alexa","title":"Alexa Menu for Preview Mode Users"},{"location":"android/aacs/sample-app/#alexa-menu-for-signed-in-users","text":"For signed-in users, the Alexa menu is organized as follows: Alexa Hands-Free Do Not Disturb Location sharing Sync navigation favorites Communication Device name Contacts Sounds Alexa's language Things to try Sign out","title":"Alexa Menu for Signed-in Users"},{"location":"android/aacs/sample-app/#alexa-menu-options","text":"The following table describes each Alexa menu option: Option Description Possible values (Default) Sign in (For Preview Mode users only) It allows the user to sign in with CBL or Mobile Authorization. Alexa Hands-Free If it is enabled, the user can say \"Alexa\" to invoke Alexa. If it is disabled, the user can still use PTT or TTT to invoke Alexa. On, Off (On) Do Not Disturb (For signed-in users only) If enabled, it disables Alexa notifications. On, Off (Off) Location sharing If it is enabled, the user can use location-based utterances like \"Alexa, show me some coffee shops near me\". If it is disabled, Alexa will not have access to the device's location and will expect the user to explicitly provide their location as a follow up voice utterance in order to respond to location-based utterances. On, Off (value specified during Alexa setup) Sync navigation favorites If it is enabled, navigation favorites from the local navigation provider would be uploaded. The user can say \"Alexa, navigate to gym\" where the gym address is expected to be in the favorites. If it is disabled, uploaded favorites would be cleared and Alexa will not have access to the device's navigation favorites list. On, Off (Off) Communication Name of the device on which the app runs (e.g., Sam's iPhone). Communication > Contacts If it is enabled, contacts are uploaded from the phone to Alexa, and the user can use Alexa to call or receive a call from a contact. On, Off (value specified during Alexa setup) Sounds Alexa sound settings. Sounds > Start/End of request sound If enabled, a sound is played with Alexa starts/stops listening. On, Off (On) Alexa's language The language used by Alexa when responding to your request. Languages supported by Alexa (language specified during Alexa setup or in Alexa menu) Things to try The Alexa utterances to try out for different domains Sign out (For signed-in users only) Button for the user to sign out of Alexa. It displays a confirmation message before the user is signed out. Disable Alexa (For Preview Mode users only) It displays a screen with a DISABLE button, which stops Alexa from being available in the vehicle.","title":"Alexa Menu Options"},{"location":"android/aacs/sample-app/#using-the-aacs-sample-app","text":"This section describes the user experience after you deploy the AACS Sample App on an Android device.","title":"Using the AACS Sample App"},{"location":"android/aacs/sample-app/#selecting-alexa-as-the-assistant","text":"While Google Assistant is usually the default voice assistant on an Android device, user has the option of selecting Alexa as the assistant. AACS sample app behaves differently in the following scenarios: * If AACS sample app is granted the android.permission.WRITE_SECURE_SETTINGS permission: * If there is no assistant currently selected, when a user launches the Alexa app from home screen, Alexa will be automatically set as the default assist app for the system. * If another assistant is currently selected as the default, when a user launches the Alexa app from home screen, a page will be displayed to ask user whether they want to replace the currently active assistant with Alexa. If the user confirms, Alexa will be set as the default assist app and the user can continue with the Alexa setup flow to sign in. Note: AACS Sample App modifies the system setting to make Alexa the system default assist app. This approach requires your Android system UI to properly respond to the system setting change, otherwise your Android system UI may become out of sync. If your Android system cannot handle the system setting change gracefully, remove the android.permission.WRITE_SECURE_SETTINGS from AACS sample app to enable the fallback approach. The behavior is further described in the following bullet point. * If AACS sample app does not have the android.permission.WRITE_SECURE_SETTINGS permission: * When user launches the Alexa app from home screen, a page will be displayed to ask user to manually select Alexa as default. The page provides a SETTINGS button which deep-links to the Assist & voice input setting page. Alternatively, the user can also set Alexa as default assistant using the following steps: 1. Go to the device's Settings. 2. Go to Apps & notifications > Default apps > Assist & voice input . Then select Alexa. Note: After selecting Alexa as the assistant, if the Auto SDK is built with the Alexa Custom Assistant extension, the user can invoke either Alexa or a custom voice assistant (e.g., Brandon).","title":"Selecting Alexa as the Assistant"},{"location":"android/aacs/sample-app/#using-alexa-custom-assistant-module-library-for-animation","text":"If the Alexa Custom Assistant extension is installed, you can use the Alexa Custom Assistant Module Library to display custom animation when user is interacting with the custom assistant. For more information about how to enable custom animation, see the Alexa Custom Assistant extension README.","title":"Using Alexa Custom Assistant Module Library for Animation"},{"location":"android/aacs/sample-app/#using-the-aacs-sample-app-for-media-player","text":"In addition to letting the user choose Alexa as the voice assistant, the AACS Sample app enables the user to start and control the media player. Alexa integrates with most music providers in cloud. After the user launches the app and selects Alexa as the assistant, the user can say, for example, \"Alexa, play the station [station call sign] on iHeartRadio.\" The app displays the user interface (UI) that comes with Android Automotive. The same UI is presented for all media providers, such as iHeartRadio and Amazon Music. However, the exact UI elements depend on the provider. For example, when the app plays music from iHeartRadio, it does not include a rewind button to go back. When the app plays music from Amazon Music, the rewind button is present. In addition, the user can say, \"Go back 30 seconds,\" to go back. The user can also use the app to listen to audio books. For example, if the user says, \"Alexa, play the start of lord of the rings book one,\" Alexa starts playing the audio book from Audible. The UI displayed by the app includes the buttons for skipping 30 seconds backward or forward.","title":"Using the AACS Sample App for Media Player"},{"location":"android/aacs/sample-app/#media-resume-last-playing-media-after-platform-reboot","text":"Generally, automotive infotainment platforms support media media resume after the reboot. Alexa Media Resume is a feature that helps Alexa play customers\u2019 favorite content when they restart their Alexa-enabled vehicles. Media Resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. Refer to Media Resume for more information about the feature. This feature works out of the box on Automotive Android OS. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } } Note If you are not using automotive android then it is assumed that your platform manages the sessions, enables the MediaBrowserService after reboot and sends the play command. In that case you may need to modify alexa-auto-media-player code to send the requestMediaPlayback message. Note The default implementation in PlaybackControlMessages.java gets the elapsed boot time using Android API SystemClock.elapsedRealtime() If your platform provides the correct elapsed boot time value using any different API, please update it.","title":"Media Resume Last Playing Media After Platform Reboot"},{"location":"android/aacs/sample-app/#using-the-aacs-sample-app-for-alexas-language","text":"The AACS sample app enables the user to select Alexa's Language during the first-time user experience (FTUE) and after the FTUE: During the FTUE, if Alexa supports the System Language, then the AACS Sample app automatically sets Alexa\u2019s Language to match the System Language. Else, the app informs the customer of the limitation and ask them to manually select a language for Alexa\u2019s Language. After the FTUE, if a customer changes the System Language after setting up Alexa, and Alexa supports the new System Language, then the app automatically updates Alexa\u2019s Language to match the System Language. Else, the app informs the customer of Alexa\u2019s limitation and ask them to select a language for Alexa. If a customer changes Alexa\u2019s Language to something that doesn\u2019t match the System Language, and the System Language is supported by Alexa, then the app informs the customer of the mismatch and ask them to confirm before proceeding.","title":"Using the AACS Sample App for Alexa's Language"},{"location":"android/aacs/sample-app/#known-issues","text":"Android Emulator on macOS has poor audio quality, which would cause the Alexa Text-to-Speech (TTS) output to be unusable. In the Android Automotive Emulator, the Push-to-Talk button on the system navigation bar does not integrate with the Android Voice Interaction module properly. It is hard coded to invoke Google Assistant instead. Therefore, even if the user tries to switch from the default voice assistant to Alexa, the Push-to-Talk button on the system navigation bar still invokes the Google Assistant. Note: Please refer to the component level README files for more information/known issues that relate to the component","title":"Known Issues"},{"location":"android/aacs/service/","text":"Configuration Reference for AACS (Alexa Auto Client Service) \u00b6 Overview \u00b6 This document explains the various fields of the AACS configuration. The AACS configuration is similar to the Auto SDK configuration, with a few additional fields unique to AACS. Auto SDK Modules \u00b6 You configure a module in AACS in a similar way as you configure a module in the Auto SDK. For example, Auto SDK specifies a module in the configuration as aace.<module> , and AACS specifies a module in the configuration as aacs.<module> . See the Auto SDK module documentation for information about the Auto SDK configuration for each module. The following example shows the syntax for configuring the CBL module in AACS, which is the same as the syntax in the Auto SDK: { \"aacs.cbl\" : { \"enableUserProfile\": false } } Optionally, you can also configure the timeout value of AASB synchronous messages in aacs.messageBroker , as detailed in Core module documentation for configuring the MessageBroker. The default timeout duration is 500 ms. { \"aacs.messageBroker\": { ... \"defaultMessageTimeout\": 1000 } } The aacs.alexa module has a structure that is slightly different from its Auto SDK counterpart as explained in the following list: In AACS, there is no avsDeviceSDK node, because most of the configuration required for this section is done within AACS. The only required configuration from avsDeviceSDK is deviceInfo , and it is specified directly under aacs.alexa . aacs.alexa contains a node called localMediaSource , which explicitly specifies which media sources are available. The following example shows deviceInfo and localMediaSource in the configuration for aacs.alexa : { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"\", \"description\": \"\" }, \"localMediaSource\": { \"types\": [\"FM_RADIO\"] } } } localMediaSource \u00b6 Type: JSON Object Specifies which local media sources are available and handled in the application. If your application prefers AACS to handle the local media sources, use useDefaultLocalMediaSource instead. types \u00b6 Type: String Array Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT AACS Module Enablement \u00b6 AACS allows your application to enable/disable certain modules using AACS configuration file. To enable or disable certain modules, add certain JSON blocks to the AACS configuration inside \"aacs.modules\" block, as shown in the following examples: APL module is disabled by default. To enable APL, add the following configuration to the configuration file: \"aacs.modules\": { \"aacs.apl\": { \"APL\": { \"enabled\": true } } } Custom Domain module is disabled by default. Similarly to APL, to enable Custom Domain, add the following configuration to aacs.modules in the configuration file: \"aacs.customDomain\": { \"CustomDomain\": { \"enabled\": true } } Note : If Custom Domain module is enabled, you must provide a valid aacs.customDomain configuration to configure the engine with your custom interfaces. Otherwise, the Engine will fail to start. See the Custom Domain module documentation for the required configuration. CBL interface is deprecated in version 3.1, your application should use the Authorization interface instead for both alexa:cbl and alexa:auth_provider services. If you want to disable CBL module add the following configuration to aacs.modules in the configuration file: \"aacs.cbl\": { \"CBL\": { \"enabled\": false } } If your application wants to disable the Authorization module in the configuration: \"aacs.authorization\": { \"Authorization\": { \"enabled\": false } } Note : Both CBL and Alexa Authorization modules are needed to support alexa:cbl authorization For configuring module enablement, more information can be found in the Core module documentation. General \u00b6 aacs.general is used for most configurable values of AACS that are not required for the Auto SDK, as shown in the following example: { \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"syncSystemPropertyChange\": false, \"intentTargets\" : {...} } } version \u00b6 Type: String Indicates the version of AACS to be used. Releases of AACS will have current and minimum-supported versions. Versions outside this range will not be compatible and the service will not start as a result. Note: persistentSystemService configuration is deprecated. You no longer need to specify this field to run AACS as a persistent system service. If you have root access on the device and your application containing AACS AAR is a system application, then AACS is run as a system service. startServiceOnBootEnabled \u00b6 Type: Boolean When startServiceOnBootEnabled is set to true , AACS automatically starts running when the device is booted up. For the service to start on boot, it must have been run at least once after it was installed. When startServiceOnBootEnabled is set to false , AACS requires the application to send an intent to start the service. syncSystemPropertyChange \u00b6 Type: Boolean This field is optional. When syncSystemPropertyChange is set to true , AACS handles synchronizing the time zone and locale settings of Alexa with the device settings so your application does not need to implement this feature if it is expected in your UX. When it's not present, it's default to false . updateSystemPropertyAllowed \u00b6 Type: Boolean This field is optional. When updateSystemPropertyAllowed is set to true , AACS updates the system settings if the corresponding Alexa's property is changed, only if AACS AAR is in a system application. For this release, only time zone property is supported. When it's not present, it's default to false . intentTargets \u00b6 Type: JSON Object This field is optional. Specifies a target for messages of every topic. There is a JSON object for every message topic supported in AACS, where the key is the topic name. Note: If there are any extensions that require message handling, their topic will need to be added here. package \u00b6 Type: String Specifies the package name of the application that receives messages for this particular module. class \u00b6 Type: String Specifies the class name within the application that receives messages for this particular module. Default Platform Handlers \u00b6 AACS provides the default platform implementation for certain services, which you can enable through the configuration in aacs.defaultPlatformHandlers . For a full explanation of default platform handlers, see the AACS documentation . \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } } useDefaultLocationProvider \u00b6 Type: Boolean Set to true to enable the default LocationProvider platform implementation in AACS. If useDefaultLocationProvider is set to false , your application must separately handle the messages for this topic. useDefaultNetworkInfoProvider \u00b6 Type: Boolean Set to true to enable the default NetworkInfoProvider platform implementation in AACS. If useDefaultNetworkInfoProvider is set to false , your application must separately handle the messages for this topic. useDefaultExternalMediaAdapter \u00b6 Type: Boolean Set to true to enable the default ExternalMediaAdapter platform implementation in AACS. If useDefaultExternalMediaAdapter is set to false , your application must separately handle the messages for this topic. useDefaultPropertyManager \u00b6 Type: Boolean Set to true to enable the default PropertyManager platform implementation in AACS. This enables synchronous managing of properties using AACS's ContentProvider. If useDefaultPropertyManager is set to false , your application must separately handle the messages for this topic. useDefaultCustomDomainMessageDispatcher \u00b6 Type: Boolean Set to true to enable the default CustomDomain message dispatcher in AACS. If CustomDomain module is enabled and useDefaultCustomDomainMessageDispatcher is set to false, your application must separately handle the messages for topic CustomDomain . audioInput \u00b6 Type: JSON Object Configures AudioInput in AACS based on the audio type. This JSON object consists of JSON nodes for the audio types that contain this information. Available audio types are COMMUNICATION and VOICE . useDefault \u00b6 Type: Boolean Set to true to enable the default AudioInput platform implementation for the given audio type. If useDefault is set to false , AudioInput for the given audio type must be handled in your application. audioSource \u00b6 Type: String Specifies the Android audio source for the given audio type. This assumes that the useDefault field is set to true . Available Audio sources are MediaRecorder.AudioSource.MIC , MediaRecorder.AudioSource.DEFAULT , MediaRecorder.AudioSource.VOICE_RECOGNITION , MediaRecorder.AudioSource.VOICE_COMMUNICATION and EXTERNAL . If you do not specify a value, the default audio source is MediaRecorder.AudioSource.MIC . It is recommended to set handleAudioFocus to true . This will ensure that When Alexa is in LISTENING , THINKING and EXPECTING state, AACS will request audio focus resulting in other playing media to be ducked or paused. Using EXTERNAL for audioSource means AACS fetches the audio stream from an external application, and it requires a valid externalSource object to be present in the JSON object. The following sample configuration is for an external stream: \"VOICE\": { \"useDefault\": true, \"audioSource\": \"EXTERNAL\", \"externalSource\": { \"type\": \"ACTIVITY\", \"package\": \"com.example.application\", \"class\": \".MainActivity\" } } Note: When specifying both VOICE and COMMUNICATION 's audioSource values as non- EXTERNAL , be sure that their audioSource values are the same. audioOutput \u00b6 Type: JSON Object Configures audioOutput in AACS based on the audio type. This JSON object consists of JSON nodes for audio types that contain this information. Available audio types are TTS , ALARM , NOTIFICATION , EARCON , and RINGTONE . Note: AACS default audio output does not support MUSIC type of audio output. See alexa-auto-media-player README for more information on the MUSIC type implementation. useDefault \u00b6 Type: Boolean Set to true to enable the default AudioOutput platform implementation for the given audio type. If useDefault is set to false , AudioOutput for the given audio type must be handled in your application. useDefaultLocalMediaSource \u00b6 Type: Boolean (Followed with detailed localMediaSourceMetadata JSON array configuration if set true ) Set to true to enable the default LocalMediaSource platform implementation to configure local media sources. By default useDefaultLocalMediaSource is treated false so if not included in the config file or set to false explicitly, please define localMediaSource JSON array in the aacs.alexa node to enable AASB LocalMediaSource messages to be delivered to your application. Refer the following sample configuration for the useDefaultLocalMediaSource . \"useDefaultLocalMediaSource\" : true, \"localMediaSourceMetadata\": [ { \"sourceType\":\"BLUETOOTH\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"USB\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"FM_RADIO\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"AM_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"SATELLITE_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"LINE_IN\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"COMPACT_DISC\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"SIRIUS_XM\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"DAB\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" },{ \"sourceType\":\"DEFAULT\", \"supported\": true, \"mediaPackageName\":\"\", \"mediaServiceClass\":\"\", \"supportsSetPreset\": true } ] sourceType Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT . The DEFAULT source provides the facility to support all the media sources which are not listed in the given list. Note: This feature uses NotificationListenerService to monitor active sessions, provide BIND_NOTIFICATION_LISTENER_SERVICE permission to the application which includes AACS AAR to support the default local media source handling. If access is not provided, AACS would ignore the \"useDefaultLocalMediaSource\" : true configuration. This access is generally given by enabling the application with AACS AAR in Settings >> Apps >> Special Access >> Notification access . Note: If OEM wishes to make the application with AACS AAR as a system application, they can avoid the Notification Access step. Please add a line <uses-permission android:name=\"android.permission.MEDIA_CONTENT_CONTROL\" /> in the AACS AndroidManifest.xml file and provide all the required permissions to the system application in the Android operating system. Refer Local Media Source interface documentation DEFAULT media source. supported configures the given Local Media Source. if supported is set true , that media source would be handled and controlled through AACS. If supported is set false , AACS would ignore the media source. mediaPackageName and mediaServiceClass are mandatory configuration keys. mediaPackageName represents the package name of the media source and mediaServiceClass represents the The name of the class inside of package that implements the component of the media browser service. This is a requirement of the ComponentName . Please ensure that right data is provided here. Since DEFAULT player can act on behalf of all latest the media sources except Alexa music, MACC supported players and other configured local media sources, it is not full time associated to any package name and MediaBrowserService. It always represents 0th media controller of the onActiveSessionsChanged controller list. Besides these mandatory configuration keys, following optional keys are useful for the correct mapping of metadata. metadataTitleKey By default AACS uses METADATA_KEY_TITLE to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. For example, Consider sub title as title for some reason \"metadataTitleKey\":\"android.media.metadata.DISPLAY_SUBTITLE\" metadataTrackIdKey By default AACS uses METADATA_KEY_MEDIA_ID to extract the trackId from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataTrackNumberKey By default AACS uses METADATA_KEY_TRACK_NUMBER to extract the track number from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataArtistKey By default AACS uses METADATA_KEY_ARTIST to extract the artist from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataAlbumKey By default AACS uses METADATA_KEY_ALBUM to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataDurationKey By default AACS uses METADATA_KEY_DURATION to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. supportsSetFrequency This takes a boolean value. It should be set true for AM or FM where Alexa can set the frequency in the AM or FM application. Local Media Player like FM or AM application should be able to handle this request. To support it, these app needs to implement onPrepareFromSearch and onPlayFromSearch methods. They will receive a query string containing a json in following format. { \"ContentSelector\":\"FREQUENCY\", \"payload\":\"98.7 FM HD 1\" } Note Refer Local Media Source interface documentation for more information of the ContentSelector and payload. supportsSetPreset This takes a boolean value. It should be set true if media source can play media by preset number. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type PRESET as well. supportsSetChannel This takes a boolean value. It should be set true if media source like Sirius XM which can play media by channel name. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type CHANNEL as well.","title":"Configuration Reference for AACS (Alexa Auto Client Service)"},{"location":"android/aacs/service/#configuration-reference-for-aacs-alexa-auto-client-service","text":"","title":"Configuration Reference for AACS (Alexa Auto Client Service)"},{"location":"android/aacs/service/#overview","text":"This document explains the various fields of the AACS configuration. The AACS configuration is similar to the Auto SDK configuration, with a few additional fields unique to AACS.","title":"Overview"},{"location":"android/aacs/service/#auto-sdk-modules","text":"You configure a module in AACS in a similar way as you configure a module in the Auto SDK. For example, Auto SDK specifies a module in the configuration as aace.<module> , and AACS specifies a module in the configuration as aacs.<module> . See the Auto SDK module documentation for information about the Auto SDK configuration for each module. The following example shows the syntax for configuring the CBL module in AACS, which is the same as the syntax in the Auto SDK: { \"aacs.cbl\" : { \"enableUserProfile\": false } } Optionally, you can also configure the timeout value of AASB synchronous messages in aacs.messageBroker , as detailed in Core module documentation for configuring the MessageBroker. The default timeout duration is 500 ms. { \"aacs.messageBroker\": { ... \"defaultMessageTimeout\": 1000 } } The aacs.alexa module has a structure that is slightly different from its Auto SDK counterpart as explained in the following list: In AACS, there is no avsDeviceSDK node, because most of the configuration required for this section is done within AACS. The only required configuration from avsDeviceSDK is deviceInfo , and it is specified directly under aacs.alexa . aacs.alexa contains a node called localMediaSource , which explicitly specifies which media sources are available. The following example shows deviceInfo and localMediaSource in the configuration for aacs.alexa : { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"\", \"description\": \"\" }, \"localMediaSource\": { \"types\": [\"FM_RADIO\"] } } }","title":"Auto SDK Modules"},{"location":"android/aacs/service/#localmediasource","text":"Type: JSON Object Specifies which local media sources are available and handled in the application. If your application prefers AACS to handle the local media sources, use useDefaultLocalMediaSource instead.","title":"localMediaSource"},{"location":"android/aacs/service/#types","text":"Type: String Array Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT","title":"types"},{"location":"android/aacs/service/#aacs-module-enablement","text":"AACS allows your application to enable/disable certain modules using AACS configuration file. To enable or disable certain modules, add certain JSON blocks to the AACS configuration inside \"aacs.modules\" block, as shown in the following examples: APL module is disabled by default. To enable APL, add the following configuration to the configuration file: \"aacs.modules\": { \"aacs.apl\": { \"APL\": { \"enabled\": true } } } Custom Domain module is disabled by default. Similarly to APL, to enable Custom Domain, add the following configuration to aacs.modules in the configuration file: \"aacs.customDomain\": { \"CustomDomain\": { \"enabled\": true } } Note : If Custom Domain module is enabled, you must provide a valid aacs.customDomain configuration to configure the engine with your custom interfaces. Otherwise, the Engine will fail to start. See the Custom Domain module documentation for the required configuration. CBL interface is deprecated in version 3.1, your application should use the Authorization interface instead for both alexa:cbl and alexa:auth_provider services. If you want to disable CBL module add the following configuration to aacs.modules in the configuration file: \"aacs.cbl\": { \"CBL\": { \"enabled\": false } } If your application wants to disable the Authorization module in the configuration: \"aacs.authorization\": { \"Authorization\": { \"enabled\": false } } Note : Both CBL and Alexa Authorization modules are needed to support alexa:cbl authorization For configuring module enablement, more information can be found in the Core module documentation.","title":"AACS Module Enablement"},{"location":"android/aacs/service/#general","text":"aacs.general is used for most configurable values of AACS that are not required for the Auto SDK, as shown in the following example: { \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"syncSystemPropertyChange\": false, \"intentTargets\" : {...} } }","title":"General"},{"location":"android/aacs/service/#version","text":"Type: String Indicates the version of AACS to be used. Releases of AACS will have current and minimum-supported versions. Versions outside this range will not be compatible and the service will not start as a result. Note: persistentSystemService configuration is deprecated. You no longer need to specify this field to run AACS as a persistent system service. If you have root access on the device and your application containing AACS AAR is a system application, then AACS is run as a system service.","title":"version"},{"location":"android/aacs/service/#startserviceonbootenabled","text":"Type: Boolean When startServiceOnBootEnabled is set to true , AACS automatically starts running when the device is booted up. For the service to start on boot, it must have been run at least once after it was installed. When startServiceOnBootEnabled is set to false , AACS requires the application to send an intent to start the service.","title":"startServiceOnBootEnabled"},{"location":"android/aacs/service/#syncsystempropertychange","text":"Type: Boolean This field is optional. When syncSystemPropertyChange is set to true , AACS handles synchronizing the time zone and locale settings of Alexa with the device settings so your application does not need to implement this feature if it is expected in your UX. When it's not present, it's default to false .","title":"syncSystemPropertyChange"},{"location":"android/aacs/service/#updatesystempropertyallowed","text":"Type: Boolean This field is optional. When updateSystemPropertyAllowed is set to true , AACS updates the system settings if the corresponding Alexa's property is changed, only if AACS AAR is in a system application. For this release, only time zone property is supported. When it's not present, it's default to false .","title":"updateSystemPropertyAllowed"},{"location":"android/aacs/service/#intenttargets","text":"Type: JSON Object This field is optional. Specifies a target for messages of every topic. There is a JSON object for every message topic supported in AACS, where the key is the topic name. Note: If there are any extensions that require message handling, their topic will need to be added here.","title":"intentTargets"},{"location":"android/aacs/service/#package","text":"Type: String Specifies the package name of the application that receives messages for this particular module.","title":"package"},{"location":"android/aacs/service/#class","text":"Type: String Specifies the class name within the application that receives messages for this particular module.","title":"class"},{"location":"android/aacs/service/#default-platform-handlers","text":"AACS provides the default platform implementation for certain services, which you can enable through the configuration in aacs.defaultPlatformHandlers . For a full explanation of default platform handlers, see the AACS documentation . \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } }","title":"Default Platform Handlers"},{"location":"android/aacs/service/#usedefaultlocationprovider","text":"Type: Boolean Set to true to enable the default LocationProvider platform implementation in AACS. If useDefaultLocationProvider is set to false , your application must separately handle the messages for this topic.","title":"useDefaultLocationProvider"},{"location":"android/aacs/service/#usedefaultnetworkinfoprovider","text":"Type: Boolean Set to true to enable the default NetworkInfoProvider platform implementation in AACS. If useDefaultNetworkInfoProvider is set to false , your application must separately handle the messages for this topic.","title":"useDefaultNetworkInfoProvider"},{"location":"android/aacs/service/#usedefaultexternalmediaadapter","text":"Type: Boolean Set to true to enable the default ExternalMediaAdapter platform implementation in AACS. If useDefaultExternalMediaAdapter is set to false , your application must separately handle the messages for this topic.","title":"useDefaultExternalMediaAdapter"},{"location":"android/aacs/service/#usedefaultpropertymanager","text":"Type: Boolean Set to true to enable the default PropertyManager platform implementation in AACS. This enables synchronous managing of properties using AACS's ContentProvider. If useDefaultPropertyManager is set to false , your application must separately handle the messages for this topic.","title":"useDefaultPropertyManager"},{"location":"android/aacs/service/#usedefaultcustomdomainmessagedispatcher","text":"Type: Boolean Set to true to enable the default CustomDomain message dispatcher in AACS. If CustomDomain module is enabled and useDefaultCustomDomainMessageDispatcher is set to false, your application must separately handle the messages for topic CustomDomain .","title":"useDefaultCustomDomainMessageDispatcher"},{"location":"android/aacs/service/#audioinput","text":"Type: JSON Object Configures AudioInput in AACS based on the audio type. This JSON object consists of JSON nodes for the audio types that contain this information. Available audio types are COMMUNICATION and VOICE .","title":"audioInput"},{"location":"android/aacs/service/#usedefault","text":"Type: Boolean Set to true to enable the default AudioInput platform implementation for the given audio type. If useDefault is set to false , AudioInput for the given audio type must be handled in your application.","title":"useDefault"},{"location":"android/aacs/service/#audiosource","text":"Type: String Specifies the Android audio source for the given audio type. This assumes that the useDefault field is set to true . Available Audio sources are MediaRecorder.AudioSource.MIC , MediaRecorder.AudioSource.DEFAULT , MediaRecorder.AudioSource.VOICE_RECOGNITION , MediaRecorder.AudioSource.VOICE_COMMUNICATION and EXTERNAL . If you do not specify a value, the default audio source is MediaRecorder.AudioSource.MIC . It is recommended to set handleAudioFocus to true . This will ensure that When Alexa is in LISTENING , THINKING and EXPECTING state, AACS will request audio focus resulting in other playing media to be ducked or paused. Using EXTERNAL for audioSource means AACS fetches the audio stream from an external application, and it requires a valid externalSource object to be present in the JSON object. The following sample configuration is for an external stream: \"VOICE\": { \"useDefault\": true, \"audioSource\": \"EXTERNAL\", \"externalSource\": { \"type\": \"ACTIVITY\", \"package\": \"com.example.application\", \"class\": \".MainActivity\" } } Note: When specifying both VOICE and COMMUNICATION 's audioSource values as non- EXTERNAL , be sure that their audioSource values are the same.","title":"audioSource"},{"location":"android/aacs/service/#audiooutput","text":"Type: JSON Object Configures audioOutput in AACS based on the audio type. This JSON object consists of JSON nodes for audio types that contain this information. Available audio types are TTS , ALARM , NOTIFICATION , EARCON , and RINGTONE . Note: AACS default audio output does not support MUSIC type of audio output. See alexa-auto-media-player README for more information on the MUSIC type implementation.","title":"audioOutput"},{"location":"android/aacs/service/#usedefault_1","text":"Type: Boolean Set to true to enable the default AudioOutput platform implementation for the given audio type. If useDefault is set to false , AudioOutput for the given audio type must be handled in your application.","title":"useDefault"},{"location":"android/aacs/service/#usedefaultlocalmediasource","text":"Type: Boolean (Followed with detailed localMediaSourceMetadata JSON array configuration if set true ) Set to true to enable the default LocalMediaSource platform implementation to configure local media sources. By default useDefaultLocalMediaSource is treated false so if not included in the config file or set to false explicitly, please define localMediaSource JSON array in the aacs.alexa node to enable AASB LocalMediaSource messages to be delivered to your application. Refer the following sample configuration for the useDefaultLocalMediaSource . \"useDefaultLocalMediaSource\" : true, \"localMediaSourceMetadata\": [ { \"sourceType\":\"BLUETOOTH\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"USB\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"FM_RADIO\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"AM_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"SATELLITE_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"LINE_IN\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"COMPACT_DISC\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"SIRIUS_XM\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"DAB\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" },{ \"sourceType\":\"DEFAULT\", \"supported\": true, \"mediaPackageName\":\"\", \"mediaServiceClass\":\"\", \"supportsSetPreset\": true } ] sourceType Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT . The DEFAULT source provides the facility to support all the media sources which are not listed in the given list. Note: This feature uses NotificationListenerService to monitor active sessions, provide BIND_NOTIFICATION_LISTENER_SERVICE permission to the application which includes AACS AAR to support the default local media source handling. If access is not provided, AACS would ignore the \"useDefaultLocalMediaSource\" : true configuration. This access is generally given by enabling the application with AACS AAR in Settings >> Apps >> Special Access >> Notification access . Note: If OEM wishes to make the application with AACS AAR as a system application, they can avoid the Notification Access step. Please add a line <uses-permission android:name=\"android.permission.MEDIA_CONTENT_CONTROL\" /> in the AACS AndroidManifest.xml file and provide all the required permissions to the system application in the Android operating system. Refer Local Media Source interface documentation DEFAULT media source. supported configures the given Local Media Source. if supported is set true , that media source would be handled and controlled through AACS. If supported is set false , AACS would ignore the media source. mediaPackageName and mediaServiceClass are mandatory configuration keys. mediaPackageName represents the package name of the media source and mediaServiceClass represents the The name of the class inside of package that implements the component of the media browser service. This is a requirement of the ComponentName . Please ensure that right data is provided here. Since DEFAULT player can act on behalf of all latest the media sources except Alexa music, MACC supported players and other configured local media sources, it is not full time associated to any package name and MediaBrowserService. It always represents 0th media controller of the onActiveSessionsChanged controller list. Besides these mandatory configuration keys, following optional keys are useful for the correct mapping of metadata. metadataTitleKey By default AACS uses METADATA_KEY_TITLE to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. For example, Consider sub title as title for some reason \"metadataTitleKey\":\"android.media.metadata.DISPLAY_SUBTITLE\" metadataTrackIdKey By default AACS uses METADATA_KEY_MEDIA_ID to extract the trackId from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataTrackNumberKey By default AACS uses METADATA_KEY_TRACK_NUMBER to extract the track number from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataArtistKey By default AACS uses METADATA_KEY_ARTIST to extract the artist from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataAlbumKey By default AACS uses METADATA_KEY_ALBUM to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataDurationKey By default AACS uses METADATA_KEY_DURATION to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. supportsSetFrequency This takes a boolean value. It should be set true for AM or FM where Alexa can set the frequency in the AM or FM application. Local Media Player like FM or AM application should be able to handle this request. To support it, these app needs to implement onPrepareFromSearch and onPlayFromSearch methods. They will receive a query string containing a json in following format. { \"ContentSelector\":\"FREQUENCY\", \"payload\":\"98.7 FM HD 1\" } Note Refer Local Media Source interface documentation for more information of the ContentSelector and payload. supportsSetPreset This takes a boolean value. It should be set true if media source can play media by preset number. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type PRESET as well. supportsSetChannel This takes a boolean value. It should be set true if media source like Sirius XM which can play media by channel name. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type CHANNEL as well.","title":"useDefaultLocalMediaSource"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/","text":"AACS Instrumentation \u00b6 AACS instrumentation enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. You can start or stop instrumentation at any time and customize the log file location. To use AACS instrumentation, you must use the debug option when building the Alexa Auto SDK with AACS. Table of Contents \u00b6 Advantages of Using Instrumentation Information Captured by Instrumentation Using Instrumentation Sample Log File Advantages of Using Instrumentation \u00b6 Without instrumentation, you can use the Android Log() method with the android.util.Log class to monitor the interactions between your application and AACS. To view the resultant logs, use the Android Logcat utility. The information captured in this way does not include the details of each AASB message. To view the message details, use instrumentation. For example, you can view the message payload in the instrumentation log, which Logcat does not display to prevent privacy violations. Instrumentation produces logs that are more relevant for debugging your application, as the logs provided by android.util.Log often include Android system logs. Also, instrumentation captures all the messages exchanged among the AACS core service, AASB Message Broker interface, and your application. If you use the Log() method, you would need to define the type of message to be logged, the source of the message, and so on. Using a text editor, you can view instrumentation log entries. If you want to view them in a tabular format, use a web tool, such as json2table . Information Captured by Instrumentation \u00b6 The following list describes the information in each instrumentation log entry: Time stamp for message arrival at AACS or message dispatch from AACS Message direction (e.g., \"FROM_ENGINE\" or \"TO_ENGINE\") Topic for the message (e.g., Navigation, CarControl) Action (e.g., EndOfSpeechDetected ) Message ID Whether the message expects a reply Payload (e.g., {\"wakeword\":\"ALEXA\"} ) If the message is a reply, whether the reply is sent within the timeout period If the message is a reply, the ID of the message that requests the reply Using Instrumentation \u00b6 To manage instrumentation, use the Android activity manager through the Android Debug Bridge. Enter the adb shell am command as described in the following list: To start instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To stop instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.stopinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To specify the log file location, enter the following command. In this example, the log file location is /sdcard/Log/aacs.log . adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver --es fileLocation \"/sdcard/Log/aacs.log\" By default, the location is /sdcard . Sample Log File \u00b6 The following is an instrumentation log file example: {\"timeStamp\":\"2021-03-04 14:30:06.989\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"SpeechRecognizer\",\"action\":\"WakewordDetected\",\"messageId\":\"4f1bcd5d-098a-43dc-9447-340d69c75f2f\",\"replyExpected\":false,\"payload\":\"{\\\"wakeword\\\":\\\"ALEXA\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:12.523\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"messageId\":\"0475aa45-050b-43a5-b943-d89254cc0261\",\"replyExpected\":true,\"payload\":\"{\\\"channel\\\":\\\"SpeechSynthesizer\\\",\\\"token\\\":\\\"d3565d16-e85a-4b4d-b18e-bcbcee2374d3\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:13.517\",\"MessageDirection\":\"TO_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"replyReceivedTimeout\":false,\"replyToId\":\"e283cecc-7a9b-42d4-b164-ef0ee63a4f91\",\"payload\":\"{\\\"position\\\":489}\"}","title":"AACS Instrumentation"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#aacs-instrumentation","text":"AACS instrumentation enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. You can start or stop instrumentation at any time and customize the log file location. To use AACS instrumentation, you must use the debug option when building the Alexa Auto SDK with AACS.","title":"AACS Instrumentation"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#table-of-contents","text":"Advantages of Using Instrumentation Information Captured by Instrumentation Using Instrumentation Sample Log File","title":"Table of Contents"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#advantages-of-using-instrumentation","text":"Without instrumentation, you can use the Android Log() method with the android.util.Log class to monitor the interactions between your application and AACS. To view the resultant logs, use the Android Logcat utility. The information captured in this way does not include the details of each AASB message. To view the message details, use instrumentation. For example, you can view the message payload in the instrumentation log, which Logcat does not display to prevent privacy violations. Instrumentation produces logs that are more relevant for debugging your application, as the logs provided by android.util.Log often include Android system logs. Also, instrumentation captures all the messages exchanged among the AACS core service, AASB Message Broker interface, and your application. If you use the Log() method, you would need to define the type of message to be logged, the source of the message, and so on. Using a text editor, you can view instrumentation log entries. If you want to view them in a tabular format, use a web tool, such as json2table .","title":"Advantages of Using Instrumentation"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#information-captured-by-instrumentation","text":"The following list describes the information in each instrumentation log entry: Time stamp for message arrival at AACS or message dispatch from AACS Message direction (e.g., \"FROM_ENGINE\" or \"TO_ENGINE\") Topic for the message (e.g., Navigation, CarControl) Action (e.g., EndOfSpeechDetected ) Message ID Whether the message expects a reply Payload (e.g., {\"wakeword\":\"ALEXA\"} ) If the message is a reply, whether the reply is sent within the timeout period If the message is a reply, the ID of the message that requests the reply","title":"Information Captured by Instrumentation"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#using-instrumentation","text":"To manage instrumentation, use the Android activity manager through the Android Debug Bridge. Enter the adb shell am command as described in the following list: To start instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To stop instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.stopinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To specify the log file location, enter the following command. In this example, the log file location is /sdcard/Log/aacs.log . adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver --es fileLocation \"/sdcard/Log/aacs.log\" By default, the location is /sdcard .","title":"Using Instrumentation"},{"location":"android/aacs/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#sample-log-file","text":"The following is an instrumentation log file example: {\"timeStamp\":\"2021-03-04 14:30:06.989\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"SpeechRecognizer\",\"action\":\"WakewordDetected\",\"messageId\":\"4f1bcd5d-098a-43dc-9447-340d69c75f2f\",\"replyExpected\":false,\"payload\":\"{\\\"wakeword\\\":\\\"ALEXA\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:12.523\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"messageId\":\"0475aa45-050b-43a5-b943-d89254cc0261\",\"replyExpected\":true,\"payload\":\"{\\\"channel\\\":\\\"SpeechSynthesizer\\\",\\\"token\\\":\\\"d3565d16-e85a-4b4d-b18e-bcbcee2374d3\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:13.517\",\"MessageDirection\":\"TO_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"replyReceivedTimeout\":false,\"replyToId\":\"e283cecc-7a9b-42d4-b164-ef0ee63a4f91\",\"payload\":\"{\\\"position\\\":489}\"}","title":"Sample Log File"},{"location":"android/api/","text":"Android API Reference \u00b6 AASB Message Reference \u00b6 See AASB Message Reference for detailed information about each AASB message interface. AACS App Components Reference \u00b6 See AACS App Components for detailed information about the AACS App Components.","title":"Android API Reference"},{"location":"android/api/#android-api-reference","text":"","title":"Android API Reference"},{"location":"android/api/#aasb-message-reference","text":"See AASB Message Reference for detailed information about each AASB message interface.","title":"AASB Message Reference"},{"location":"android/api/#aacs-app-components-reference","text":"See AACS App Components for detailed information about the AACS App Components.","title":"AACS App Components Reference"},{"location":"android/jni/","text":"Alternative JNI Integration \u00b6 Your Android application should use the Alexa Auto Client Service (AACS) that provides an Auto SDK API that's better suited for an Android environment than the native core Auto SDK API. Additionally, AACS provides prebuilt feature integrations that are not available for you to use in your application if you do not use AACS. However, if you want to build an Auto SDK integration using the Message Broker API directly, Auto SDK provides JNI interfaces corresponding to the core native C++ API. JNI Class Reference \u00b6 See the JNI Class Reference for detailed information about the JNI API including the Engine , MessageBroker , and configuration factory classes.","title":"Alternative JNI Integration"},{"location":"android/jni/#alternative-jni-integration","text":"Your Android application should use the Alexa Auto Client Service (AACS) that provides an Auto SDK API that's better suited for an Android environment than the native core Auto SDK API. Additionally, AACS provides prebuilt feature integrations that are not available for you to use in your application if you do not use AACS. However, if you want to build an Auto SDK integration using the Message Broker API directly, Auto SDK provides JNI interfaces corresponding to the core native C++ API.","title":"Alternative JNI Integration"},{"location":"android/jni/#jni-class-reference","text":"See the JNI Class Reference for detailed information about the JNI API including the Engine , MessageBroker , and configuration factory classes.","title":"JNI Class Reference"},{"location":"builder/","text":"Builder Tool Command Reference \u00b6 $ build.py [ -h ] { build,clean,configure,imports } ... optional arguments: -h, --help show this help message and exit commands: { build,clean,configure,imports } build builds auto sdk components ( default ) clean cleans builder cache configure builder configuration imports manages external search paths Build command \u00b6 $ build.py build [ -h ] [ --home PATH ] [ -v ] [ -p PLATFORM ] [ -a ARCH ] [ -g ] [ -m MODULE [ MODULE ... ]] [ -n NAME ] [ -y ] [ -f PACKAGE [ PACKAGE ... ]] [ -i PATH [ PATH ... ]] [ -o OPTION ] [ -s SETTING ] [ --with-aasb ] [ --no-aasb ] [ --with-docs ] [ --no-docs ] [ --with-unit-tests ] [ --no-unit-tests ] [ --with-sampleapp ] [ --no-sampleapp ] [ --with-sensitive-logs ] [ --no-sensitive-logs ] [ --with-latency-logs ] [ --no-latency-logs ] [ --output FILE ] [ --no-output ] [ --skip-config ] Used to build Auto SDK modules and components. optional arguments: -h, --help show this help message and exit --home PATH, --builder-home PATH override builder home path -v, --verbose enable verbose logging -p PLATFORM, --platform PLATFORM target platform - android,qnx,etc. -a ARCH, --arch ARCH target architecture -g, --debug specify debug build type -m MODULE [ MODULE ... ] , --modules MODULE [ MODULE ... ] list of modules to build -n NAME, --name NAME optional package identifier -y, --accept-licenses auto-accept licenses -f PACKAGE [ PACKAGE ... ] , --force PACKAGE [ PACKAGE ... ] force export and build package -i PATH [ PATH ... ] , --include PATH [ PATH ... ] add include path to conan configuration -o OPTION, --conan-option OPTION specify a conan build option -s SETTING, --conan-setting SETTING specify a conan build setting --with-aasb, --aasb include aasb messages ( default: True ) --no-aasb --with-docs, --docs include docs ( default: True ) --no-docs --with-unit-tests, --unit-tests include unit tests ( default: False ) --no-unit-tests --with-sampleapp, --sampleapp include sample app ( default: False ) --no-sampleapp --with-sensitive-logs, --sensitive-logs emit sensitive data in debugging logs ( default: False ) --no-sensitive-logs --with-latency-logs, --latency-logs emit latency data in debugging logs ( default: False ) --no-latency-logs --output FILE filename for output build archive --no-output don ' t create output package --skip-config skip build configuration Clean command \u00b6 $ build.py clean [ -h ] [ --home PATH ] [ -v ] [ --skip-conan ] [ --skip-gradle ] pattern Used to clean packages from the Builder, Conan, and Gradle caches. positional arguments: pattern pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging --skip-conan skips cleaning the conan cache --skip-gradle skips cleaning the gradle cache Configure command \u00b6 $ build.py configure [ -h ] [ --home PATH ] [ -v ] { init,export } ... optional arguments: -h, --help show this help message and exit commands: { init,export } init initializes the builder configuration export exports packages from the builder configuration configure init \u00b6 $ build.py configure init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder configuration settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging configure export \u00b6 $ build.py configure export [ -h ] [ --home PATH ] [ -v ] PATTERN Used to re-export packages that are configured by the builder. positional arguments: PATTERN pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging Imports command \u00b6 $ build.py imports [ -h ] { init,list,add,remove,enable,disable } ... optional arguments: -h, --help show this help message and exit commands: { init,list,add,remove,enable,disable } init initialize the imports configuration list lists imports managed by the configuration add adds a new import remove removes imports enable enables imports disable disables imports imports init \u00b6 $ build.py imports init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder imports settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports list \u00b6 $ build.py imports list [ -h ] [ --home PATH ] [ -v ] Used to display the imports in the Builder settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports add \u00b6 $ build.py imports add [ -h ] [ --home PATH ] [ -v ] NAME PATH Used create a new import in the Builder settings. positional arguments: NAME import name PATH import search path optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports remove \u00b6 $ build.py imports remove [ -h ] [ --home PATH ] [ -v ] PATTERN Used to remove imports from the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports enable \u00b6 $ build.py imports enable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to enable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports disable \u00b6 $ build.py imports disable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to disable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"Builder Tool Command Reference"},{"location":"builder/#builder-tool-command-reference","text":"$ build.py [ -h ] { build,clean,configure,imports } ... optional arguments: -h, --help show this help message and exit commands: { build,clean,configure,imports } build builds auto sdk components ( default ) clean cleans builder cache configure builder configuration imports manages external search paths","title":"Builder Tool Command Reference"},{"location":"builder/#build-command","text":"$ build.py build [ -h ] [ --home PATH ] [ -v ] [ -p PLATFORM ] [ -a ARCH ] [ -g ] [ -m MODULE [ MODULE ... ]] [ -n NAME ] [ -y ] [ -f PACKAGE [ PACKAGE ... ]] [ -i PATH [ PATH ... ]] [ -o OPTION ] [ -s SETTING ] [ --with-aasb ] [ --no-aasb ] [ --with-docs ] [ --no-docs ] [ --with-unit-tests ] [ --no-unit-tests ] [ --with-sampleapp ] [ --no-sampleapp ] [ --with-sensitive-logs ] [ --no-sensitive-logs ] [ --with-latency-logs ] [ --no-latency-logs ] [ --output FILE ] [ --no-output ] [ --skip-config ] Used to build Auto SDK modules and components. optional arguments: -h, --help show this help message and exit --home PATH, --builder-home PATH override builder home path -v, --verbose enable verbose logging -p PLATFORM, --platform PLATFORM target platform - android,qnx,etc. -a ARCH, --arch ARCH target architecture -g, --debug specify debug build type -m MODULE [ MODULE ... ] , --modules MODULE [ MODULE ... ] list of modules to build -n NAME, --name NAME optional package identifier -y, --accept-licenses auto-accept licenses -f PACKAGE [ PACKAGE ... ] , --force PACKAGE [ PACKAGE ... ] force export and build package -i PATH [ PATH ... ] , --include PATH [ PATH ... ] add include path to conan configuration -o OPTION, --conan-option OPTION specify a conan build option -s SETTING, --conan-setting SETTING specify a conan build setting --with-aasb, --aasb include aasb messages ( default: True ) --no-aasb --with-docs, --docs include docs ( default: True ) --no-docs --with-unit-tests, --unit-tests include unit tests ( default: False ) --no-unit-tests --with-sampleapp, --sampleapp include sample app ( default: False ) --no-sampleapp --with-sensitive-logs, --sensitive-logs emit sensitive data in debugging logs ( default: False ) --no-sensitive-logs --with-latency-logs, --latency-logs emit latency data in debugging logs ( default: False ) --no-latency-logs --output FILE filename for output build archive --no-output don ' t create output package --skip-config skip build configuration","title":"Build command"},{"location":"builder/#clean-command","text":"$ build.py clean [ -h ] [ --home PATH ] [ -v ] [ --skip-conan ] [ --skip-gradle ] pattern Used to clean packages from the Builder, Conan, and Gradle caches. positional arguments: pattern pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging --skip-conan skips cleaning the conan cache --skip-gradle skips cleaning the gradle cache","title":"Clean command"},{"location":"builder/#configure-command","text":"$ build.py configure [ -h ] [ --home PATH ] [ -v ] { init,export } ... optional arguments: -h, --help show this help message and exit commands: { init,export } init initializes the builder configuration export exports packages from the builder configuration","title":"Configure command"},{"location":"builder/#configure-init","text":"$ build.py configure init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder configuration settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"configure init"},{"location":"builder/#configure-export","text":"$ build.py configure export [ -h ] [ --home PATH ] [ -v ] PATTERN Used to re-export packages that are configured by the builder. positional arguments: PATTERN pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"configure export"},{"location":"builder/#imports-command","text":"$ build.py imports [ -h ] { init,list,add,remove,enable,disable } ... optional arguments: -h, --help show this help message and exit commands: { init,list,add,remove,enable,disable } init initialize the imports configuration list lists imports managed by the configuration add adds a new import remove removes imports enable enables imports disable disables imports","title":"Imports command"},{"location":"builder/#imports-init","text":"$ build.py imports init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder imports settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports init"},{"location":"builder/#imports-list","text":"$ build.py imports list [ -h ] [ --home PATH ] [ -v ] Used to display the imports in the Builder settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports list"},{"location":"builder/#imports-add","text":"$ build.py imports add [ -h ] [ --home PATH ] [ -v ] NAME PATH Used create a new import in the Builder settings. positional arguments: NAME import name PATH import search path optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports add"},{"location":"builder/#imports-remove","text":"$ build.py imports remove [ -h ] [ --home PATH ] [ -v ] PATTERN Used to remove imports from the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports remove"},{"location":"builder/#imports-enable","text":"$ build.py imports enable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to enable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports enable"},{"location":"builder/#imports-disable","text":"$ build.py imports disable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to disable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports disable"},{"location":"explore/concepts/","text":"Explore Auto SDK Concepts \u00b6 Learn about the fundamental components that comprise the Auto SDK API. Core API overview \u00b6 The core Auto SDK API provides the \"Engine\" to manage communication with Alexa and other Amazon services on behalf of your application. The core API includes an asynchronous message-based mechanism, consisting of a \"Message Broker\" and \"AASB messages\", for the Engine and your application to communicate. >> Auto SDK Core API Overview Android API overview \u00b6 For Android applications, Auto SDK provides a set of Android libraries built upon the core Auto SDK API, simplifying your integration with an Android abstraction and pre-made feature implementations. >> Auto SDK Android API Overview Modules overview \u00b6 Auto SDK organizes its features into \"modules\" that enable you to select the features you want to use in your application. >> Understand Auto SDK Modules","title":"Explore Auto SDK Concepts"},{"location":"explore/concepts/#explore-auto-sdk-concepts","text":"Learn about the fundamental components that comprise the Auto SDK API.","title":"Explore Auto SDK Concepts"},{"location":"explore/concepts/#core-api-overview","text":"The core Auto SDK API provides the \"Engine\" to manage communication with Alexa and other Amazon services on behalf of your application. The core API includes an asynchronous message-based mechanism, consisting of a \"Message Broker\" and \"AASB messages\", for the Engine and your application to communicate. >> Auto SDK Core API Overview","title":"Core API overview"},{"location":"explore/concepts/#android-api-overview","text":"For Android applications, Auto SDK provides a set of Android libraries built upon the core Auto SDK API, simplifying your integration with an Android abstraction and pre-made feature implementations. >> Auto SDK Android API Overview","title":"Android API overview"},{"location":"explore/concepts/#modules-overview","text":"Auto SDK organizes its features into \"modules\" that enable you to select the features you want to use in your application. >> Understand Auto SDK Modules","title":"Modules overview"},{"location":"explore/concepts/android-api-overview/","text":"Auto SDK Android API Overview \u00b6 Auto SDK provides the Alexa Auto Client Service (AACS) to simplify integrating Auto SDK into an Android environment. AACS is a suite of Android libraries including a core service, called AlexaAutoClientService , and supporting feature and utility libraries. The core service sets up the Auto SDK Engine and related infrastructure for you so your application can interact with the AASB message API through standard Android intents. The Auto SDK Android developer documentation explains AACS in detail and guides you through integrating AACS into your Android system. At a high level, AACS takes care of the following: Owning the Engine lifecycle\u2014 AACS initializes the Engine and maps the Engine lifecycle to the lifecycle of AlexaAutoClientService . Instead of creating, starting, and stopping the Engine, your application starts and stops AlexaAutoClientService as a standard Android service. Mapping AASB messages to intents\u2014 Instead of directly using MessageBroker to register Java methods to handle particular AASB messages, AACS uses MessageBroker for you. Your application specifies intent targets for standard Android intents that represent AASB messages. When the Engine publishes an AASB message, AACS converts the message to an intent that Android delivers to your registered target broadcast receiver, activity, or service. Similarly, when you send an intent to the Engine, the AACS core service receives the intent and uses MessageBroker to publish the corresponding AASB message to the Engine. Simplifying IPC\u2014 AACS provides a utility library to simplify how your application parses and sends AACS intents. Providing out-of-box functionality\u2014 AACS comes with prebuilt implementations of many Auto SDK features. You can use the optional \"default handlers\" that run in the core service and the separate \"app component\" libraries to get complete or almost-complete deep integrations into the Android system. Using the default handlers and app components means fewer AASB message interfaces to integrate with, so your application gets up and running faster. Simplifying Engine configuration\u2014 AACS provides some of the basic required Engine configuration so your application doesn't have to. In general, the Engine configuration in your AACS configuration file is simpler than it would be without AACS. AACS intents \u00b6 Because the AACS core service takes care of using the Message Broker and converting AASB messages to intents, when your application uses AACS, \"subscribing to an AASB message\" means \"registering for an AACS intent\", typically as an intent filter in your application manifest. Similarly, \"publishing an AASB message\" means \"sending an explicit intent to AACS core service\". An AACS intent maps to an AASB message as follows: The AACS intent category contains the AASB message topic . If the AASB message has topic \"ExampleTopic\", the corresponding AACS intent has category \"com.amazon.aacs.aasb.ExampleTopic\". The AACS intent action contains the AASB message action . If the AASB message has action \"ExampleAction\", the corresponding AACS intent has action \"com.amazon.aacs.aasb.ExampleAction\". For a standard AASB message, the AACS intent extras contains the full AASB message. The AACS intent extras has a Bundle with name \"payload\". The \"payload\" bundle contains a key \"message\", and the value of \"message\" is the full AASB message as a serialized JSON string. Note: Some AASB messages represent larger data, such as audio streams or large JSON payloads. See the Auto SDK Android developer documentation for details about how AACS transmits large data.","title":"Android API Overview"},{"location":"explore/concepts/android-api-overview/#auto-sdk-android-api-overview","text":"Auto SDK provides the Alexa Auto Client Service (AACS) to simplify integrating Auto SDK into an Android environment. AACS is a suite of Android libraries including a core service, called AlexaAutoClientService , and supporting feature and utility libraries. The core service sets up the Auto SDK Engine and related infrastructure for you so your application can interact with the AASB message API through standard Android intents. The Auto SDK Android developer documentation explains AACS in detail and guides you through integrating AACS into your Android system. At a high level, AACS takes care of the following: Owning the Engine lifecycle\u2014 AACS initializes the Engine and maps the Engine lifecycle to the lifecycle of AlexaAutoClientService . Instead of creating, starting, and stopping the Engine, your application starts and stops AlexaAutoClientService as a standard Android service. Mapping AASB messages to intents\u2014 Instead of directly using MessageBroker to register Java methods to handle particular AASB messages, AACS uses MessageBroker for you. Your application specifies intent targets for standard Android intents that represent AASB messages. When the Engine publishes an AASB message, AACS converts the message to an intent that Android delivers to your registered target broadcast receiver, activity, or service. Similarly, when you send an intent to the Engine, the AACS core service receives the intent and uses MessageBroker to publish the corresponding AASB message to the Engine. Simplifying IPC\u2014 AACS provides a utility library to simplify how your application parses and sends AACS intents. Providing out-of-box functionality\u2014 AACS comes with prebuilt implementations of many Auto SDK features. You can use the optional \"default handlers\" that run in the core service and the separate \"app component\" libraries to get complete or almost-complete deep integrations into the Android system. Using the default handlers and app components means fewer AASB message interfaces to integrate with, so your application gets up and running faster. Simplifying Engine configuration\u2014 AACS provides some of the basic required Engine configuration so your application doesn't have to. In general, the Engine configuration in your AACS configuration file is simpler than it would be without AACS.","title":"Auto SDK Android API Overview"},{"location":"explore/concepts/android-api-overview/#aacs-intents","text":"Because the AACS core service takes care of using the Message Broker and converting AASB messages to intents, when your application uses AACS, \"subscribing to an AASB message\" means \"registering for an AACS intent\", typically as an intent filter in your application manifest. Similarly, \"publishing an AASB message\" means \"sending an explicit intent to AACS core service\". An AACS intent maps to an AASB message as follows: The AACS intent category contains the AASB message topic . If the AASB message has topic \"ExampleTopic\", the corresponding AACS intent has category \"com.amazon.aacs.aasb.ExampleTopic\". The AACS intent action contains the AASB message action . If the AASB message has action \"ExampleAction\", the corresponding AACS intent has action \"com.amazon.aacs.aasb.ExampleAction\". For a standard AASB message, the AACS intent extras contains the full AASB message. The AACS intent extras has a Bundle with name \"payload\". The \"payload\" bundle contains a key \"message\", and the value of \"message\" is the full AASB message as a serialized JSON string. Note: Some AASB messages represent larger data, such as audio streams or large JSON payloads. See the Auto SDK Android developer documentation for details about how AACS transmits large data.","title":"AACS intents"},{"location":"explore/concepts/core-api-overview/","text":"Auto SDK Core API Overview \u00b6 The Engine , MessageBroker , and AASB message interfaces comprise the core Auto SDK API. An application uses these three components, alongside a custom platform-specific integration, to build a complete Alexa client implementation for the vehicle. An Alexa client system architecture built with Auto SDK may look something like the following diagram: The Engine \u00b6 The Auto SDK Engine is a system of components that provide the core implementation of all Auto SDK features. The Engine manages communication with Amazon services, such as Alexa, on behalf of your application. With respect to Alexa, your application's Alexa client stack uses the Engine as the layer that sets up the connection to Alexa, publishes device capabilities, sends Alexa events, processes Alexa directives, and more. Your application creates and configures an instance of the Engine and uses a simple interface to manage the Engine lifecycle for the duration of the application run time. Aside from setting up the Engine, the primary responsibility of your application is to provide the platform-specific, custom integration details that make Alexa and other core SDK features work for your vehicle, in particular. Platform-specific integration might include building UI and interacting with external libraries, applications, or the underlying software frameworks of your operating system in order to complete the Auto SDK client stack with deep integration into your system. The Engine implements as much of the general functionality as possible; for integration details that it can't implement, the Engine delegates responsibility to your application \"handlers\" via AASB messages published through the MessageBroker . The Message Broker \u00b6 The Message Broker is the bridge in the Alexa Auto Services Bridge (AASB). The Message Broker provides a publish-subscribe API for the Engine and your application to communicate with each other by exchanging asynchronous AASB messages. In order to consume a message that the Engine publishes to your application, your application uses the MessageBroker class to subscribe to the message by specifying the message topic and action as well as a handler function for MessageBroker to invoke to deliver the message. Similarly, the Engine uses the Message Broker to subscribe to messages published by your application. AASB Message Interfaces \u00b6 Overview \u00b6 A typical Auto SDK module defines one or more \"interfaces\" that your application uses to communicate with the Engine. Interface refers to a logical grouping of related AASB messages that share the same topic . For example, messages pertaining to vehicle navigation belong to the Navigation interface, and each individual AASB message in the Navigation interface uses topic \"Navigation\". Within the topic , each interface has one or more actions to represent individual messages, so a topic + action combination identifies a single message. Some AASB messages are fire-and-forget, whereas others require a reply. There are two directions AASB messages can travel: \"Outgoing\" AASB messages are messages that the Engine publishes to your application. There are several reasons why the Engine might publish an outgoing message, such as requesting your application to handle a platform-specific deep integration, react to a state change, display a custom UI, and more. Your application subscribes to outgoing messages and performs the necessary actions upon receipt. \"Incoming\" AASB messages are messages that your application publishes to the Engine. An incoming message might be an asynchronous response to a particular outgoing message that your application received and handled. Alternatively, an incoming message might request the Engine to perform an operation or react to a state change. Auto SDK documentation refers to any component in your application that handles AASB messages for one particular interface as a \"handler\". For example, \"Navigation handler\" is the component in your application that handles outgoing and incoming AASB messages within the \"Navigation\" message topic. Message Structure \u00b6 AASB messages use a standard JSON protocol. Each AASB message has the following structure: { \"header\": { \"version\": {{STRING}}, \"messageType\": {{STRING}}, \"id\": {{STRING}}, \"messageDescription\": { \"topic\": {{STRING}}, \"action\": {{STRING}}, \"replyToId\": {{String}} } }, \"payload\": { // payload as defined by the interface } } Property Type Required Description header Object Yes Contains metadata about the message. header. version String Yes The version of the message payload . The version follows the \"major.minor\" convention. header. messageType String Yes The type of the message. Accepted values: Publish : The standard message type. Reply : The message type that correlates a reply to a previous message. E.g., a response to a request for data. header. id String Yes A universally unique identifier (UUID) for the message, generated to the RFC 4122 specification. header. messageDescription. topic String Yes The name of the interface. header. messageDescription. action String Yes The name of the individual message, unique within the topic , which determines the contents of the payload . header. messageDescription. replyToId String Yes if messageType is Reply , no otherwise The id of the message to which this message replies. Used to correlate a message to its response. payload Object No The content of the message. The combination of topic , action , and version define the structure. Example \u00b6 The following example describes a sample AASB message exchange when a user in the vehicle invokes Alexa with a button press. Your application provides an Alexa invocation button in its UI, and when the user taps the button, your application publishes a SpeechRecognizer.StartCapture message: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"7604450c-61c1-11ec-90d6-0242ac120003\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"StartCapture\" } }, \"payload\" : { \"initiator\" : \"TAP_TO_TALK\" } } The Engine subscribes to this message at startup time, so it is ready to consume the message when published by your application. In response to the message, the Engine determines everything it needs in order to invoke Alexa as a result of this request from your application, such as an access token, an audio stream, and states of components on the head unit. If the Engine needs something from your application, it will publish AASB messages; for example, if your application isn't already providing the user speech audio, the Engine publishes an AudioInput.StartAudioInput message to open the audio stream: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"9d4cedf3-eccd-4851-9c77-c1cec8af76e4\" , \"messageDescription\" : { \"topic\" : \"AudioInput\" , \"action\" : \"StartAudioInput\" } }, \"payload\" : { \"name\" : \"SpeechRecognizer\" , \"audioType\" : \"VOICE\" , \"streamId\" : \"f10dc9b6-eab2-4143-8378-cf6477f63fbb\" } } Your application receives this message from the Message Broker if it subscribed to the AudioInput topic and StartAudioInput action. The Message Broker delivers the message as an argument to the function specified when subscribing. Your application then records the user's audio from the microphone and provides it to the Engine through MessageBroker . Since Alexa will also need to know the state of the head unit in order to properly respond to the user, the Engine may request states from your application with additional AASB messages. For example, the Engine might publish a Navigation.GetNavigationState message because it needs to know details about any active navigation session in case the user is asking Alexa something about the route: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"50d7397a-6408-4754-a694-35b6c633b756\" , \"messageDescription\" : { \"topic\" : \"Navigation\" , \"action\" : \"GetNavigationState\" } } } Your application will receive this request if supports navigation and subscribed to the outgoing Navigation messages. Your application publishes a reply message with the current state: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Reply\" , \"id\" : \"539abbb5-2a4d-43cf-b867-840f2b206f07\" , \"messageDescription\" : { \"topic\" : \"Navigation\" , \"action\" : \"GetNavigationState\" , \"replyToId\" : \"50d7397a-6408-4754-a694-35b6c633b756\" } }, \"payload\" : { \"navigationState\" : \"<the state details are a JSON in this field>\" } } Once the Engine has everything it needs, it forwards the user's request to Alexa. Alexa processes the speech, and when she detects the user has finished speaking, the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message to your application: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"8028e40c-61c1-11ec-90d6-0242ac120003\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"EndOfSpeechDetected\" } } } Your application might use this as a trigger to play an end of listening audio cue. If the Engine doesn't need the audio stream any more (e.g., when hands-free listening is disabled), the Engine will tell your application to close the stream with an AudioInput.StopAudioInput message: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"1f3bfc25-d4cb-4b88-b7bc-a536f36e4402\" , \"messageDescription\" : { \"topic\" : \"AudioInput\" , \"action\" : \"StopAudioInput\" } }, \"payload\" : { \"streamId\" : \"f10dc9b6-eab2-4143-8378-cf6477f63fbb\" } } Alexa might send directives to the Engine depending what the user asked for. For example, if the user said \"turn on the fan\", the Engine publishes a message requesting your application's deep integration with the vehicle hardware to perform the action: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"b033e4b9-5420-47b4-949c-666e0c2d6c36\" , \"messageDescription\" : { \"topic\" : \"CarControl\" , \"action\" : \"SetControllerValue\" } }, \"payload\" : { \"capabilityType\" : \"POWER\" , \"endpointId\" : \"default.fan\" , \"turnOn\" : true } }","title":"Core API Overview"},{"location":"explore/concepts/core-api-overview/#auto-sdk-core-api-overview","text":"The Engine , MessageBroker , and AASB message interfaces comprise the core Auto SDK API. An application uses these three components, alongside a custom platform-specific integration, to build a complete Alexa client implementation for the vehicle. An Alexa client system architecture built with Auto SDK may look something like the following diagram:","title":"Auto SDK Core API Overview"},{"location":"explore/concepts/core-api-overview/#the-engine","text":"The Auto SDK Engine is a system of components that provide the core implementation of all Auto SDK features. The Engine manages communication with Amazon services, such as Alexa, on behalf of your application. With respect to Alexa, your application's Alexa client stack uses the Engine as the layer that sets up the connection to Alexa, publishes device capabilities, sends Alexa events, processes Alexa directives, and more. Your application creates and configures an instance of the Engine and uses a simple interface to manage the Engine lifecycle for the duration of the application run time. Aside from setting up the Engine, the primary responsibility of your application is to provide the platform-specific, custom integration details that make Alexa and other core SDK features work for your vehicle, in particular. Platform-specific integration might include building UI and interacting with external libraries, applications, or the underlying software frameworks of your operating system in order to complete the Auto SDK client stack with deep integration into your system. The Engine implements as much of the general functionality as possible; for integration details that it can't implement, the Engine delegates responsibility to your application \"handlers\" via AASB messages published through the MessageBroker .","title":"The Engine"},{"location":"explore/concepts/core-api-overview/#the-message-broker","text":"The Message Broker is the bridge in the Alexa Auto Services Bridge (AASB). The Message Broker provides a publish-subscribe API for the Engine and your application to communicate with each other by exchanging asynchronous AASB messages. In order to consume a message that the Engine publishes to your application, your application uses the MessageBroker class to subscribe to the message by specifying the message topic and action as well as a handler function for MessageBroker to invoke to deliver the message. Similarly, the Engine uses the Message Broker to subscribe to messages published by your application.","title":"The Message Broker"},{"location":"explore/concepts/core-api-overview/#aasb-message-interfaces","text":"","title":"AASB Message Interfaces"},{"location":"explore/concepts/core-api-overview/#overview","text":"A typical Auto SDK module defines one or more \"interfaces\" that your application uses to communicate with the Engine. Interface refers to a logical grouping of related AASB messages that share the same topic . For example, messages pertaining to vehicle navigation belong to the Navigation interface, and each individual AASB message in the Navigation interface uses topic \"Navigation\". Within the topic , each interface has one or more actions to represent individual messages, so a topic + action combination identifies a single message. Some AASB messages are fire-and-forget, whereas others require a reply. There are two directions AASB messages can travel: \"Outgoing\" AASB messages are messages that the Engine publishes to your application. There are several reasons why the Engine might publish an outgoing message, such as requesting your application to handle a platform-specific deep integration, react to a state change, display a custom UI, and more. Your application subscribes to outgoing messages and performs the necessary actions upon receipt. \"Incoming\" AASB messages are messages that your application publishes to the Engine. An incoming message might be an asynchronous response to a particular outgoing message that your application received and handled. Alternatively, an incoming message might request the Engine to perform an operation or react to a state change. Auto SDK documentation refers to any component in your application that handles AASB messages for one particular interface as a \"handler\". For example, \"Navigation handler\" is the component in your application that handles outgoing and incoming AASB messages within the \"Navigation\" message topic.","title":"Overview"},{"location":"explore/concepts/core-api-overview/#message-structure","text":"AASB messages use a standard JSON protocol. Each AASB message has the following structure: { \"header\": { \"version\": {{STRING}}, \"messageType\": {{STRING}}, \"id\": {{STRING}}, \"messageDescription\": { \"topic\": {{STRING}}, \"action\": {{STRING}}, \"replyToId\": {{String}} } }, \"payload\": { // payload as defined by the interface } } Property Type Required Description header Object Yes Contains metadata about the message. header. version String Yes The version of the message payload . The version follows the \"major.minor\" convention. header. messageType String Yes The type of the message. Accepted values: Publish : The standard message type. Reply : The message type that correlates a reply to a previous message. E.g., a response to a request for data. header. id String Yes A universally unique identifier (UUID) for the message, generated to the RFC 4122 specification. header. messageDescription. topic String Yes The name of the interface. header. messageDescription. action String Yes The name of the individual message, unique within the topic , which determines the contents of the payload . header. messageDescription. replyToId String Yes if messageType is Reply , no otherwise The id of the message to which this message replies. Used to correlate a message to its response. payload Object No The content of the message. The combination of topic , action , and version define the structure.","title":"Message Structure"},{"location":"explore/concepts/core-api-overview/#example","text":"The following example describes a sample AASB message exchange when a user in the vehicle invokes Alexa with a button press. Your application provides an Alexa invocation button in its UI, and when the user taps the button, your application publishes a SpeechRecognizer.StartCapture message: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"7604450c-61c1-11ec-90d6-0242ac120003\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"StartCapture\" } }, \"payload\" : { \"initiator\" : \"TAP_TO_TALK\" } } The Engine subscribes to this message at startup time, so it is ready to consume the message when published by your application. In response to the message, the Engine determines everything it needs in order to invoke Alexa as a result of this request from your application, such as an access token, an audio stream, and states of components on the head unit. If the Engine needs something from your application, it will publish AASB messages; for example, if your application isn't already providing the user speech audio, the Engine publishes an AudioInput.StartAudioInput message to open the audio stream: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"9d4cedf3-eccd-4851-9c77-c1cec8af76e4\" , \"messageDescription\" : { \"topic\" : \"AudioInput\" , \"action\" : \"StartAudioInput\" } }, \"payload\" : { \"name\" : \"SpeechRecognizer\" , \"audioType\" : \"VOICE\" , \"streamId\" : \"f10dc9b6-eab2-4143-8378-cf6477f63fbb\" } } Your application receives this message from the Message Broker if it subscribed to the AudioInput topic and StartAudioInput action. The Message Broker delivers the message as an argument to the function specified when subscribing. Your application then records the user's audio from the microphone and provides it to the Engine through MessageBroker . Since Alexa will also need to know the state of the head unit in order to properly respond to the user, the Engine may request states from your application with additional AASB messages. For example, the Engine might publish a Navigation.GetNavigationState message because it needs to know details about any active navigation session in case the user is asking Alexa something about the route: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"50d7397a-6408-4754-a694-35b6c633b756\" , \"messageDescription\" : { \"topic\" : \"Navigation\" , \"action\" : \"GetNavigationState\" } } } Your application will receive this request if supports navigation and subscribed to the outgoing Navigation messages. Your application publishes a reply message with the current state: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Reply\" , \"id\" : \"539abbb5-2a4d-43cf-b867-840f2b206f07\" , \"messageDescription\" : { \"topic\" : \"Navigation\" , \"action\" : \"GetNavigationState\" , \"replyToId\" : \"50d7397a-6408-4754-a694-35b6c633b756\" } }, \"payload\" : { \"navigationState\" : \"<the state details are a JSON in this field>\" } } Once the Engine has everything it needs, it forwards the user's request to Alexa. Alexa processes the speech, and when she detects the user has finished speaking, the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message to your application: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"8028e40c-61c1-11ec-90d6-0242ac120003\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"EndOfSpeechDetected\" } } } Your application might use this as a trigger to play an end of listening audio cue. If the Engine doesn't need the audio stream any more (e.g., when hands-free listening is disabled), the Engine will tell your application to close the stream with an AudioInput.StopAudioInput message: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"1f3bfc25-d4cb-4b88-b7bc-a536f36e4402\" , \"messageDescription\" : { \"topic\" : \"AudioInput\" , \"action\" : \"StopAudioInput\" } }, \"payload\" : { \"streamId\" : \"f10dc9b6-eab2-4143-8378-cf6477f63fbb\" } } Alexa might send directives to the Engine depending what the user asked for. For example, if the user said \"turn on the fan\", the Engine publishes a message requesting your application's deep integration with the vehicle hardware to perform the action: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"b033e4b9-5420-47b4-949c-666e0c2d6c36\" , \"messageDescription\" : { \"topic\" : \"CarControl\" , \"action\" : \"SetControllerValue\" } }, \"payload\" : { \"capabilityType\" : \"POWER\" , \"endpointId\" : \"default.fan\" , \"turnOn\" : true } }","title":"Example"},{"location":"explore/concepts/modules-overview/","text":"Understand Auto SDK Modules \u00b6 Overview \u00b6 Auto SDK organizes its features into modules . A single module groups the logically related Auto SDK components that are required to enable a particular feature area. For example, the Navigation module contains the SDK components that enable your application to build a deep integration with a navigation provider, whereas the Address Book module contains the SDK components that enable your application to upload a user's contacts to Alexa. A typical Auto SDK module includes the following types of components: Platform abstraction components such as AASB message interfaces and Engine configuration specifications. These components define the module-specific API that your application interacts with. Engine implementation components such as Engine infrastructure and implementations that correspond to platform APIs in the module. The module's Engine components augment the Engine with the feature set that the module provides. Dependencies such as external libraries (e.g., AVS Device SDK) that the module uses to enable its feature set. Only the build system and Engine implementation components of the module directly use these dependencies, so they are abstracted from your application. Build system tools such as scripts, Conan recipes, dependency management tools, and more, that support building the Auto SDK code and dependencies that belong to the particular module. The module organization of Auto SDK enables you to easily use only the features you want and leave out the ones you don't. \"Using a module\" typically means including the module in the Auto SDK build, linking the generated module library in your application, configuring the Engine with any configuration the module specifies, and implementing the logic to integrate with the AASB messages defined by the module. On Android, the Auto SDK Android API further simplifies this setup and integration. The Core module is the only module that your application is required to use for a bare minimum Auto SDK integration. Core is required because it defines Auto SDK infrastructure and AASB message interfaces that all other modules depend on, and it provides the Engine and MessageBroker classes that are the primary surface API to the native integration layer. To add Alexa to your application, the Alexa module is required because it adds the support for Auto SDK to communicate with Alexa; however, you are not required to integrate every AASB message interface in the Alexa module platform layer. See Auto SDK Features for detailed descriptions and integration guides for Core , Alexa , and all other Auto SDK modules available to your application. Extensions \u00b6 Some Auto SDK modules are not available on Github with the rest of Auto SDK. With help from your Amazon Solutions Architect (SA) or Partner Manager, you can access these modules from each respective \"Auto SDK extension\" on the Alexa developer console. For each extension you download, use the version that corresponds to the Auto SDK version that you use. When you upgrade Auto SDK versions, ensure you download and use the corresponding version of any extensions as well. An extension includes one or more modules and the documentation for each module's API and setup instructions. In general, the contents of a particular extension look, build, and function as any other standard Auto SDK modules; only the delivery mechanism differs.","title":"Understand Modules"},{"location":"explore/concepts/modules-overview/#understand-auto-sdk-modules","text":"","title":"Understand Auto SDK Modules"},{"location":"explore/concepts/modules-overview/#overview","text":"Auto SDK organizes its features into modules . A single module groups the logically related Auto SDK components that are required to enable a particular feature area. For example, the Navigation module contains the SDK components that enable your application to build a deep integration with a navigation provider, whereas the Address Book module contains the SDK components that enable your application to upload a user's contacts to Alexa. A typical Auto SDK module includes the following types of components: Platform abstraction components such as AASB message interfaces and Engine configuration specifications. These components define the module-specific API that your application interacts with. Engine implementation components such as Engine infrastructure and implementations that correspond to platform APIs in the module. The module's Engine components augment the Engine with the feature set that the module provides. Dependencies such as external libraries (e.g., AVS Device SDK) that the module uses to enable its feature set. Only the build system and Engine implementation components of the module directly use these dependencies, so they are abstracted from your application. Build system tools such as scripts, Conan recipes, dependency management tools, and more, that support building the Auto SDK code and dependencies that belong to the particular module. The module organization of Auto SDK enables you to easily use only the features you want and leave out the ones you don't. \"Using a module\" typically means including the module in the Auto SDK build, linking the generated module library in your application, configuring the Engine with any configuration the module specifies, and implementing the logic to integrate with the AASB messages defined by the module. On Android, the Auto SDK Android API further simplifies this setup and integration. The Core module is the only module that your application is required to use for a bare minimum Auto SDK integration. Core is required because it defines Auto SDK infrastructure and AASB message interfaces that all other modules depend on, and it provides the Engine and MessageBroker classes that are the primary surface API to the native integration layer. To add Alexa to your application, the Alexa module is required because it adds the support for Auto SDK to communicate with Alexa; however, you are not required to integrate every AASB message interface in the Alexa module platform layer. See Auto SDK Features for detailed descriptions and integration guides for Core , Alexa , and all other Auto SDK modules available to your application.","title":"Overview"},{"location":"explore/concepts/modules-overview/#extensions","text":"Some Auto SDK modules are not available on Github with the rest of Auto SDK. With help from your Amazon Solutions Architect (SA) or Partner Manager, you can access these modules from each respective \"Auto SDK extension\" on the Alexa developer console. For each extension you download, use the version that corresponds to the Auto SDK version that you use. When you upgrade Auto SDK versions, ensure you download and use the corresponding version of any extensions as well. An extension includes one or more modules and the documentation for each module's API and setup instructions. In general, the contents of a particular extension look, build, and function as any other standard Auto SDK modules; only the delivery mechanism differs.","title":"Extensions"},{"location":"explore/features/","text":"Explore Auto SDK Features \u00b6 Learn about the Auto SDK features that you can integrate into your application. Modules on Github \u00b6 Auto SDK provides the following modules on Github: Address Book module \u00b6 The Address Book module personalizes the communications and navigation capabilities of Alexa by linking the user's phone contacts and favorite navigation locations. When used with the Phone Control and Navigation modules, Address Book enables the user to call contacts by name and navigate to their favorite destinations. >> Address Book module reference Alexa module \u00b6 The Alexa module provides the core Alexa client implementation to your application. The Engine components of the Alexa module manage the connection to the Alexa Voice Service (AVS) and support the standard AVS capabilities such as speaking to Alexa, streaming media, viewing visual content, setting alerts, and more. >> Alexa module reference Alexa Presentation Language (APL) module \u00b6 The APL module enables your application to display rich visual experiences when the user interacts with Alexa. >> APL module reference Bluetooth module \u00b6 The Bluetooth module allows the Auto SDK Engine to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Additional Auto SDK modules use the functionality of the Bluetooth module to provide bluetooth-based features, such as mobile authorization, to users of Android or iOS smartphones. >> Bluetooth module reference Car Control module \u00b6 The Car Control module enables the user to control vehicle features\u2014turning on seat heaters, adjusting the AC setting, opening windows, and much more\u2014just by asking Alexa. >> Car Control module reference Code-Based Linking (CBL) module \u00b6 The CBL module implements the code-based linking mechanism of acquiring Login with Amazon (LWA) access tokens, which are required to use Alexa. Your application displays a URL and code to the user to complete the sign-in from a second device, and the Engine takes care of fetching the tokens. >> CBL module reference Connectivity module \u00b6 The Connectivity module enables a reduced data consumption mode for Alexa. Your application can offer different tiers of Alexa functionality based on the status of the head unit's data connectivity plan. >> Connectivity module reference Core module \u00b6 The Core module provides the Auto SDK infrastructure upon which all other modules depend. Core includes interfaces for audio input and output, authorization, logging, location reporting, metrics, setting management, network status reporting, and more. >> Core module reference Custom Domain module \u00b6 The Custom Domain module enables you to enhance your voice assistant with custom functionality. Custom Domain creates a bi-directional communication channel between the head unit and your own cloud skills so your application can exchange custom events and directives with your skills. >> Custom Domain module reference Loopback Detector module \u00b6 The Loopback Detector module suppresses false wake word detections in which Alexa uses her own name in her speech output. The Engine uses a loopback audio stream from the vehicle's own speakers to detect any wake words and prevent false wake-ups during interactions. >> Loopback Detector module reference Messaging module \u00b6 The Messaging module adds voice-forward Short Message Service (SMS) features to your application. Users can request Alexa to send or read text messages using the phone connected to the head unit. >> Messaging module reference Navigation module \u00b6 The Navigation module provides support for Alexa to interface with the head unit's onboard navigation system. Users can ask Alexa to navigate to points of interest and addresses, add stops to the route, answer questions about the route, and more. >> Navigation module reference Phone Control module \u00b6 The Phone Control module adds voice-forward telephony features to your application. Users can ask Alexa to call numbers or contacts using the vehicle's native telephony system or connected phone. >> Phone Control module reference System Audio module \u00b6 The System Audio module provides an out-of-box implementation of the Core module's audio input and output interfaces to simplify the audio management your native C++ integration. >> System Audio module reference Text-To-Speech module \u00b6 The Text-To-Speech module enables your application to request synthesis of Alexa speech on demand from text or Speech Synthesis Markup Language (SSML) string. You can use Text-To-Speech with Text-To-Speech-Provider to provide turn-by-turn navigation instructions in Alexa's voice. >> Text-To-Speech module reference Text-To-Speech Provider module \u00b6 The Text-To-Speech Provider module synthesizes Alexa speech on demand. The Text-To-Speech Provider module requires the Local Voice Control Auto SDK extension. >> Text-To-Speech Provider module reference Extension modules \u00b6 Auto SDK provides the following modules in private extensions on the Alexa developer console. Contact your Amazon Solutions Architect (SA) or Partner Manager for access. Alexa Communication module \u00b6 The Alexa Communication (or Alexa Comms ) module enables users to place two-way Alexa-to-Alexa calls to a remote Alexa device, drop in on a remote Alexa device, or send an announcement to a remote Alexa device. The Alexa Communication module is part of the Alexa Communication Auto SDK extension . Alexa Custom Assistant module \u00b6 The Alexa Custom Assistant module enables you to develop in-vehicle infotainment (IVI) software in which the user can easily interact with both Alexa and your own branded voice assistant. The Alexa Custom Assistant module is part of the Alexa Custom Assistant Auto SDK extension . Alexa Custom Assistant requires the Local Voice Control extension. Amazonlite module \u00b6 The Amazonlite module enables hands-free voice-initiated interactions with Alexa powered by the Amazonlite wake word detection engine. The Amazonlite module is part of the Amazonlite Auto SDK extension . Device Client Metrics (DCM) module \u00b6 The DCM module enables the Engine to upload Auto SDK performance metrics, such as user-perceived latency, to the Amazon cloud. The DCM module is part of the Device Client Metrics Auto SDK extension . Geolocation module \u00b6 The Geolocation module adds location consent features to Auto SDK. Without the Geolocation module, the user consents to share location with Alexa while registering the head unit to their Amazon account (i.e., during the sign in flow). With Geolocation , the user can provide or revoke consent directly from your application. The Geolocation module is part of the Geolocation Auto SDK extension . Local Voice Control (LVC) extension \u00b6 The Local Voice Control ( LVC ) extension provides several modules that work together to enable features\u2014car control, calling, navigation, local search, entertainment, and more\u2014without an internet connection. In addition to Auto SDK modules, the LVC extension provides separate components that run a local Alexa endpoint inside the vehicle head unit. Local Voice Control module \u00b6 The Local Voice Control module adds core functionality to Auto SDK to enable offline features. The module infrastructure bridges the Auto SDK Engine to the offline Alexa endpoint running in the head unit and is necessary for all other modules in the LVC extension. Local Skill Service module \u00b6 The Local Skill Service module provides a multipurpose service to the Auto SDK Engine that enables components running alongside the offline Alexa endpoint to communicate with the Auto SDK Engine. The Local Skill Service infrastructure is necessary for other modules in the LVC extension. Local Navigation module \u00b6 The Local Navigation module enables you to provide customers with offline Alexa local search and navigation to points of interest and addresses. Address Book Local Service module \u00b6 The Address Book Local Service module works with the Address Book module and the Local Skill Service module to augment the offline communications and navigation capabilities of Alexa with the user's phone contacts and favorite navigation locations. Car Control Local Service module \u00b6 The Car Control Local Service module works with the Car Control module and the Local Skill Service module to enable users to control vehicle features offline with Alexa. Mobile Authorization module \u00b6 The Mobile Authorization module simplifies your user's sign-in experience. Instead of opening a web browser and entering a code, the user signs in to Alexa with the Alexa app on their bluetooth-paired smartphone. The Mobile Authorization module is part of the Mobile Authorization Auto SDK extension . Voice Chrome extension for Android \u00b6 The Voice Chrome extension provides an Android library that you can use to add the Alexa visual attention state \"voice chrome\" to the UI of your application. Note: The Voice Chrome library is an Android app component you can use with Alexa Auto Client Service for Android, not a standard Auto SDK module that has a native C++ Engine implementation.","title":"Explore Auto SDK Features"},{"location":"explore/features/#explore-auto-sdk-features","text":"Learn about the Auto SDK features that you can integrate into your application.","title":"Explore Auto SDK Features"},{"location":"explore/features/#modules-on-github","text":"Auto SDK provides the following modules on Github:","title":"Modules on Github"},{"location":"explore/features/#address-book-module","text":"The Address Book module personalizes the communications and navigation capabilities of Alexa by linking the user's phone contacts and favorite navigation locations. When used with the Phone Control and Navigation modules, Address Book enables the user to call contacts by name and navigate to their favorite destinations. >> Address Book module reference","title":"Address Book module"},{"location":"explore/features/#alexa-module","text":"The Alexa module provides the core Alexa client implementation to your application. The Engine components of the Alexa module manage the connection to the Alexa Voice Service (AVS) and support the standard AVS capabilities such as speaking to Alexa, streaming media, viewing visual content, setting alerts, and more. >> Alexa module reference","title":"Alexa module"},{"location":"explore/features/#alexa-presentation-language-apl-module","text":"The APL module enables your application to display rich visual experiences when the user interacts with Alexa. >> APL module reference","title":"Alexa Presentation Language (APL) module"},{"location":"explore/features/#bluetooth-module","text":"The Bluetooth module allows the Auto SDK Engine to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Additional Auto SDK modules use the functionality of the Bluetooth module to provide bluetooth-based features, such as mobile authorization, to users of Android or iOS smartphones. >> Bluetooth module reference","title":"Bluetooth module"},{"location":"explore/features/#car-control-module","text":"The Car Control module enables the user to control vehicle features\u2014turning on seat heaters, adjusting the AC setting, opening windows, and much more\u2014just by asking Alexa. >> Car Control module reference","title":"Car Control module"},{"location":"explore/features/#code-based-linking-cbl-module","text":"The CBL module implements the code-based linking mechanism of acquiring Login with Amazon (LWA) access tokens, which are required to use Alexa. Your application displays a URL and code to the user to complete the sign-in from a second device, and the Engine takes care of fetching the tokens. >> CBL module reference","title":"Code-Based Linking (CBL) module"},{"location":"explore/features/#connectivity-module","text":"The Connectivity module enables a reduced data consumption mode for Alexa. Your application can offer different tiers of Alexa functionality based on the status of the head unit's data connectivity plan. >> Connectivity module reference","title":"Connectivity module"},{"location":"explore/features/#core-module","text":"The Core module provides the Auto SDK infrastructure upon which all other modules depend. Core includes interfaces for audio input and output, authorization, logging, location reporting, metrics, setting management, network status reporting, and more. >> Core module reference","title":"Core module"},{"location":"explore/features/#custom-domain-module","text":"The Custom Domain module enables you to enhance your voice assistant with custom functionality. Custom Domain creates a bi-directional communication channel between the head unit and your own cloud skills so your application can exchange custom events and directives with your skills. >> Custom Domain module reference","title":"Custom Domain module"},{"location":"explore/features/#loopback-detector-module","text":"The Loopback Detector module suppresses false wake word detections in which Alexa uses her own name in her speech output. The Engine uses a loopback audio stream from the vehicle's own speakers to detect any wake words and prevent false wake-ups during interactions. >> Loopback Detector module reference","title":"Loopback Detector module"},{"location":"explore/features/#messaging-module","text":"The Messaging module adds voice-forward Short Message Service (SMS) features to your application. Users can request Alexa to send or read text messages using the phone connected to the head unit. >> Messaging module reference","title":"Messaging module"},{"location":"explore/features/#navigation-module","text":"The Navigation module provides support for Alexa to interface with the head unit's onboard navigation system. Users can ask Alexa to navigate to points of interest and addresses, add stops to the route, answer questions about the route, and more. >> Navigation module reference","title":"Navigation module"},{"location":"explore/features/#phone-control-module","text":"The Phone Control module adds voice-forward telephony features to your application. Users can ask Alexa to call numbers or contacts using the vehicle's native telephony system or connected phone. >> Phone Control module reference","title":"Phone Control module"},{"location":"explore/features/#system-audio-module","text":"The System Audio module provides an out-of-box implementation of the Core module's audio input and output interfaces to simplify the audio management your native C++ integration. >> System Audio module reference","title":"System Audio module"},{"location":"explore/features/#text-to-speech-module","text":"The Text-To-Speech module enables your application to request synthesis of Alexa speech on demand from text or Speech Synthesis Markup Language (SSML) string. You can use Text-To-Speech with Text-To-Speech-Provider to provide turn-by-turn navigation instructions in Alexa's voice. >> Text-To-Speech module reference","title":"Text-To-Speech module"},{"location":"explore/features/#text-to-speech-provider-module","text":"The Text-To-Speech Provider module synthesizes Alexa speech on demand. The Text-To-Speech Provider module requires the Local Voice Control Auto SDK extension. >> Text-To-Speech Provider module reference","title":"Text-To-Speech Provider module"},{"location":"explore/features/#extension-modules","text":"Auto SDK provides the following modules in private extensions on the Alexa developer console. Contact your Amazon Solutions Architect (SA) or Partner Manager for access.","title":"Extension modules"},{"location":"explore/features/#alexa-communication-module","text":"The Alexa Communication (or Alexa Comms ) module enables users to place two-way Alexa-to-Alexa calls to a remote Alexa device, drop in on a remote Alexa device, or send an announcement to a remote Alexa device. The Alexa Communication module is part of the Alexa Communication Auto SDK extension .","title":"Alexa Communication module"},{"location":"explore/features/#alexa-custom-assistant-module","text":"The Alexa Custom Assistant module enables you to develop in-vehicle infotainment (IVI) software in which the user can easily interact with both Alexa and your own branded voice assistant. The Alexa Custom Assistant module is part of the Alexa Custom Assistant Auto SDK extension . Alexa Custom Assistant requires the Local Voice Control extension.","title":"Alexa Custom Assistant module"},{"location":"explore/features/#amazonlite-module","text":"The Amazonlite module enables hands-free voice-initiated interactions with Alexa powered by the Amazonlite wake word detection engine. The Amazonlite module is part of the Amazonlite Auto SDK extension .","title":"Amazonlite module"},{"location":"explore/features/#device-client-metrics-dcm-module","text":"The DCM module enables the Engine to upload Auto SDK performance metrics, such as user-perceived latency, to the Amazon cloud. The DCM module is part of the Device Client Metrics Auto SDK extension .","title":"Device Client Metrics (DCM) module"},{"location":"explore/features/#geolocation-module","text":"The Geolocation module adds location consent features to Auto SDK. Without the Geolocation module, the user consents to share location with Alexa while registering the head unit to their Amazon account (i.e., during the sign in flow). With Geolocation , the user can provide or revoke consent directly from your application. The Geolocation module is part of the Geolocation Auto SDK extension .","title":"Geolocation module"},{"location":"explore/features/#local-voice-control-lvc-extension","text":"The Local Voice Control ( LVC ) extension provides several modules that work together to enable features\u2014car control, calling, navigation, local search, entertainment, and more\u2014without an internet connection. In addition to Auto SDK modules, the LVC extension provides separate components that run a local Alexa endpoint inside the vehicle head unit.","title":"Local Voice Control (LVC) extension"},{"location":"explore/features/#local-voice-control-module","text":"The Local Voice Control module adds core functionality to Auto SDK to enable offline features. The module infrastructure bridges the Auto SDK Engine to the offline Alexa endpoint running in the head unit and is necessary for all other modules in the LVC extension.","title":"Local Voice Control module"},{"location":"explore/features/#local-skill-service-module","text":"The Local Skill Service module provides a multipurpose service to the Auto SDK Engine that enables components running alongside the offline Alexa endpoint to communicate with the Auto SDK Engine. The Local Skill Service infrastructure is necessary for other modules in the LVC extension.","title":"Local Skill Service module"},{"location":"explore/features/#local-navigation-module","text":"The Local Navigation module enables you to provide customers with offline Alexa local search and navigation to points of interest and addresses.","title":"Local Navigation module"},{"location":"explore/features/#address-book-local-service-module","text":"The Address Book Local Service module works with the Address Book module and the Local Skill Service module to augment the offline communications and navigation capabilities of Alexa with the user's phone contacts and favorite navigation locations.","title":"Address Book Local Service module"},{"location":"explore/features/#car-control-local-service-module","text":"The Car Control Local Service module works with the Car Control module and the Local Skill Service module to enable users to control vehicle features offline with Alexa.","title":"Car Control Local Service module"},{"location":"explore/features/#mobile-authorization-module","text":"The Mobile Authorization module simplifies your user's sign-in experience. Instead of opening a web browser and entering a code, the user signs in to Alexa with the Alexa app on their bluetooth-paired smartphone. The Mobile Authorization module is part of the Mobile Authorization Auto SDK extension .","title":"Mobile Authorization module"},{"location":"explore/features/#voice-chrome-extension-for-android","text":"The Voice Chrome extension provides an Android library that you can use to add the Alexa visual attention state \"voice chrome\" to the UI of your application. Note: The Voice Chrome library is an Android app component you can use with Alexa Auto Client Service for Android, not a standard Auto SDK module that has a native C++ Engine implementation.","title":"Voice Chrome extension for Android"},{"location":"explore/features/address-book/","text":"Address Book Module \u00b6 Overview \u00b6 The Address Book module enables your Alexa Auto SDK client application to augment the communication and navigation capabilities of Alexa with the user's contacts and favorite addresses. By using this module in your application, the user can upload their phone contacts or navigation favorites to Alexa. This module works alongside the Phone Control module for calling contacts on a paired phone (e.g., \"Alexa, call Mom\") and the Navigation module for requesting directions to favorite destinations (e.g., \"Alexa, take me to work\"). Additionally, these features are supported offline if your application integrates with the modules of the Local Voice Control (LVC) extension. The user contacts and favorite addresses uploaded with the Address Book module are only available for use on the head unit that uploaded them and not any other Alexa devices. Note: To use the Address Book functionality, your product must be placed on the allow list by Amazon. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Managing Address Books \u00b6 Your application's Address Book module integration is responsible for managing the lifecycle of each address book (i.e., a set of contacts or navigation favorites). These responsibilities include the following: Prior to uploading any address books to the Auto SDK Engine, obtain consent from the user to allow Alexa to access their data. If the user revokes the permission for Alexa to access their data, immediately notify the Engine to remove the address book(s) so the Engine can delete the data from Alexa. Your implementation must ensure that the address books are removed successfully. If a previously uploaded address book becomes unavailable, such as when the user disconnects their phone from the head unit, notify the Engine to remove the address book. When the address book is available again, such as when the user reconnects their phone, notify the Engine to upload the address book again. Upload address books after starting the Engine if the user already granted permission. By default, the Engine deletes all address books from Alexa at Engine start to account for any cases in which deletion previously failed (e.g., network connection issues). This ensures the user's data is up-to-date across ignition cycles. However, note that there is an option to reduce the frequency of address book uploads described below. Reducing Data Usage \u00b6 Note: The below enhancement is not available for applications that use the LVC extension. Since uploading an address book might consume significant data, your Address Book module integration has an option to reduce the data usage of repeated uploads. You can disable automatic address book removal at Engine start by providing the configuration specified in the Configuring the Address Book Module section. If your integration disables the automatic address book deletion at Engine start, an address book might not need to be uploaded to Alexa at every start. Skip reuploading address books when all of the following conditions are true: The last successful upload was less than 24 hours ago. Note that Alexa periodically removes uploaded address books to comply with the Alexa data retention policy, so Amazon recommends reuploading the address books after 24 hours. The user connects the same phone used for the last successful upload. The phone contacts and navigation favorites on the phone are the same as the address book contents of the last successful upload. Configuring the Address Book Module \u00b6 To configure the Address Book module, use the \"aace.addressBook\" JSON object specified below in your Engine configuration: { \"aace.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Property Type Required Description Example aace.addressBook. cleanAllAddressBooksAtStart boolean No Whether the Engine should automatically delete all of the user's address books from Alexa at Engine start. This defaults to true if the configuration is omitted. false Note: The \"aace.addressBook\" configuration is optional since its only property is optional. Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::addressBook::config::AddressBookConfiguration::createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse AddressBookConfiguration C++ sample code #include <AACE/AddressBook/AddressBookConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto addressBookConfig = aace :: addressBook :: config :: AddressBookConfiguration :: createAddressBookConfig ( false ); configurations . push_back ( addressBookConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Android Integration \u00b6 To use the Address Book module Engine configuration with AACS, use \"aacs.addressBook\" instead of \"aace.addressBook\" in your AACS configuration file: { \"aacs.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory method com.amazon.aace.addressbook.config.createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. import com.amazon.aace.addressBook.config.AddressBookConfiguration ; // Configure the Engine EngineConfiguration addressBookConfiguration = AddressBookConfiguration . createAddressBookConfig ( false ); mEngine . configure ( new EngineConfiguration [] { // other config objects, addressBookConfiguration , // ... }); Using the Address Book Module AASB Messages \u00b6 Uploading an Address Book \u00b6 To upload an address book to Alexa, publish the AddAddressBook message . The Engine publishes the AddAddressBookReply message to indicate upload completion or failure. Click to expand or collapse sequence diagram: Uploading Contacts Click to expand or collapse sequence diagram: Uploading Navigation Favorites Removing an Address Book \u00b6 To remove an address book to Alexa, publish the RemoveAddressBook message . The Engine publishes the RemoveAddressBookReply message to indicate removal completion or failure. Click to expand or collapse sequence diagram: Removing Contacts Click to expand or collapse sequence diagram: Removing Navigation Favorites Integrating the Address Book Module Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the Engine's MessageBroker to publish \"AddressBook\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/AddressBook/AddressBook/ContactName.h> #include <AASB/Message/AddressBook/AddressBook/NavigationName.h> #include <AASB/Message/AddressBook/AddressBook/PhoneData.h> #include <AASB/Message/AddressBook/AddressBook/PostalAddress.h> #include <AASB/Message/AddressBook/AddressBook/AddAddressBookMessage.h> #include <AASB/Message/AddressBook/AddressBook/RemoveAddressBookMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAddressBookHandler { // Subscribe to reply messages from the Engine void MyAddressBookHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAddAddressBookReplyMessage ( message ); }, AddAddressBookMessageReply :: topic (), AddAddressBookMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRemoveAddressBookReplyMessage ( message ); }, RemoveAddressBookMessageReply :: topic (), RemoveAddressBookMessageReply :: action ()); } // Handle the AddAddressBook reply message from the Engine void MyAddressBookHandler::handleAddAddressBookReplyMessage ( const std :: string & message ) { AddAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the upload result for the message... } // Handle the RemoveAddressBook reply message from the Engine void MyAddressBookHandler::handleRemoveAddressBookReplyMessage ( const std :: string & message ) { RemoveAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the removal result for the message... } // To upload contacts to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadContacts ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: CONTACT ; msg . payload . addressBookData = populateContacts ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateContacts ( const std :: string & id ) { // Populate an AddressBook object with the contacts data from the connected phone AddressBook addressBook ; // For each contact, add a ContactName to addressBook.contactNames // and add a PhoneData to addressBook.phoneData // ... return addressBook ; } // To upload navigation favorites to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadNavigationFavorites ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: NAVIGATION ; msg . payload . addressBookData = populateNavigationFavorites ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateNavigationFavorites ( const std :: string & id ) { // Populate an AddressBook object with the navigation favorites data from the head unit AddressBook addressBook ; // For each navigation address, add a NavigationName to addressBook.navigationNames // and add a PostalAddress to addressBook.postalAddresses // ... return addressBook ; } // To remove an address book, publish a RemoveAddressBook message to the Engine bool MyAddressBookHandler::removeAddressBook ( const std :: string & id ) { RemoveAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the RemoveAddressBookReply message // Return the success status from reply message payload } }; Android Integration \u00b6 The Alexa Auto Client Service (AACS) provides the AACS Contacts Library to integrate the Auto SDK Address Book module on Android. See the AACS Contacts Library documentation for more information.","title":"Address Book Module"},{"location":"explore/features/address-book/#address-book-module","text":"","title":"Address Book Module"},{"location":"explore/features/address-book/#overview","text":"The Address Book module enables your Alexa Auto SDK client application to augment the communication and navigation capabilities of Alexa with the user's contacts and favorite addresses. By using this module in your application, the user can upload their phone contacts or navigation favorites to Alexa. This module works alongside the Phone Control module for calling contacts on a paired phone (e.g., \"Alexa, call Mom\") and the Navigation module for requesting directions to favorite destinations (e.g., \"Alexa, take me to work\"). Additionally, these features are supported offline if your application integrates with the modules of the Local Voice Control (LVC) extension. The user contacts and favorite addresses uploaded with the Address Book module are only available for use on the head unit that uploaded them and not any other Alexa devices. Note: To use the Address Book functionality, your product must be placed on the allow list by Amazon. Contact your Amazon Solutions Architect (SA) or Partner Manager for details.","title":"Overview"},{"location":"explore/features/address-book/#managing-address-books","text":"Your application's Address Book module integration is responsible for managing the lifecycle of each address book (i.e., a set of contacts or navigation favorites). These responsibilities include the following: Prior to uploading any address books to the Auto SDK Engine, obtain consent from the user to allow Alexa to access their data. If the user revokes the permission for Alexa to access their data, immediately notify the Engine to remove the address book(s) so the Engine can delete the data from Alexa. Your implementation must ensure that the address books are removed successfully. If a previously uploaded address book becomes unavailable, such as when the user disconnects their phone from the head unit, notify the Engine to remove the address book. When the address book is available again, such as when the user reconnects their phone, notify the Engine to upload the address book again. Upload address books after starting the Engine if the user already granted permission. By default, the Engine deletes all address books from Alexa at Engine start to account for any cases in which deletion previously failed (e.g., network connection issues). This ensures the user's data is up-to-date across ignition cycles. However, note that there is an option to reduce the frequency of address book uploads described below.","title":"Managing Address Books"},{"location":"explore/features/address-book/#reducing-data-usage","text":"Note: The below enhancement is not available for applications that use the LVC extension. Since uploading an address book might consume significant data, your Address Book module integration has an option to reduce the data usage of repeated uploads. You can disable automatic address book removal at Engine start by providing the configuration specified in the Configuring the Address Book Module section. If your integration disables the automatic address book deletion at Engine start, an address book might not need to be uploaded to Alexa at every start. Skip reuploading address books when all of the following conditions are true: The last successful upload was less than 24 hours ago. Note that Alexa periodically removes uploaded address books to comply with the Alexa data retention policy, so Amazon recommends reuploading the address books after 24 hours. The user connects the same phone used for the last successful upload. The phone contacts and navigation favorites on the phone are the same as the address book contents of the last successful upload.","title":"Reducing Data Usage"},{"location":"explore/features/address-book/#configuring-the-address-book-module","text":"To configure the Address Book module, use the \"aace.addressBook\" JSON object specified below in your Engine configuration: { \"aace.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Property Type Required Description Example aace.addressBook. cleanAllAddressBooksAtStart boolean No Whether the Engine should automatically delete all of the user's address books from Alexa at Engine start. This defaults to true if the configuration is omitted. false Note: The \"aace.addressBook\" configuration is optional since its only property is optional. Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::addressBook::config::AddressBookConfiguration::createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse AddressBookConfiguration C++ sample code #include <AACE/AddressBook/AddressBookConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto addressBookConfig = aace :: addressBook :: config :: AddressBookConfiguration :: createAddressBookConfig ( false ); configurations . push_back ( addressBookConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations );","title":"Configuring the Address Book Module"},{"location":"explore/features/address-book/#android-integration","text":"To use the Address Book module Engine configuration with AACS, use \"aacs.addressBook\" instead of \"aace.addressBook\" in your AACS configuration file: { \"aacs.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory method com.amazon.aace.addressbook.config.createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. import com.amazon.aace.addressBook.config.AddressBookConfiguration ; // Configure the Engine EngineConfiguration addressBookConfiguration = AddressBookConfiguration . createAddressBookConfig ( false ); mEngine . configure ( new EngineConfiguration [] { // other config objects, addressBookConfiguration , // ... });","title":"Android Integration"},{"location":"explore/features/address-book/#using-the-address-book-module-aasb-messages","text":"","title":"Using the Address Book Module AASB Messages"},{"location":"explore/features/address-book/#uploading-an-address-book","text":"To upload an address book to Alexa, publish the AddAddressBook message . The Engine publishes the AddAddressBookReply message to indicate upload completion or failure. Click to expand or collapse sequence diagram: Uploading Contacts Click to expand or collapse sequence diagram: Uploading Navigation Favorites","title":"Uploading an Address Book"},{"location":"explore/features/address-book/#removing-an-address-book","text":"To remove an address book to Alexa, publish the RemoveAddressBook message . The Engine publishes the RemoveAddressBookReply message to indicate removal completion or failure. Click to expand or collapse sequence diagram: Removing Contacts Click to expand or collapse sequence diagram: Removing Navigation Favorites","title":"Removing an Address Book"},{"location":"explore/features/address-book/#integrating-the-address-book-module-into-your-application","text":"","title":"Integrating the Address Book Module Into Your Application"},{"location":"explore/features/address-book/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to publish \"AddressBook\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/AddressBook/AddressBook/ContactName.h> #include <AASB/Message/AddressBook/AddressBook/NavigationName.h> #include <AASB/Message/AddressBook/AddressBook/PhoneData.h> #include <AASB/Message/AddressBook/AddressBook/PostalAddress.h> #include <AASB/Message/AddressBook/AddressBook/AddAddressBookMessage.h> #include <AASB/Message/AddressBook/AddressBook/RemoveAddressBookMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAddressBookHandler { // Subscribe to reply messages from the Engine void MyAddressBookHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAddAddressBookReplyMessage ( message ); }, AddAddressBookMessageReply :: topic (), AddAddressBookMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRemoveAddressBookReplyMessage ( message ); }, RemoveAddressBookMessageReply :: topic (), RemoveAddressBookMessageReply :: action ()); } // Handle the AddAddressBook reply message from the Engine void MyAddressBookHandler::handleAddAddressBookReplyMessage ( const std :: string & message ) { AddAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the upload result for the message... } // Handle the RemoveAddressBook reply message from the Engine void MyAddressBookHandler::handleRemoveAddressBookReplyMessage ( const std :: string & message ) { RemoveAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the removal result for the message... } // To upload contacts to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadContacts ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: CONTACT ; msg . payload . addressBookData = populateContacts ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateContacts ( const std :: string & id ) { // Populate an AddressBook object with the contacts data from the connected phone AddressBook addressBook ; // For each contact, add a ContactName to addressBook.contactNames // and add a PhoneData to addressBook.phoneData // ... return addressBook ; } // To upload navigation favorites to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadNavigationFavorites ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: NAVIGATION ; msg . payload . addressBookData = populateNavigationFavorites ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateNavigationFavorites ( const std :: string & id ) { // Populate an AddressBook object with the navigation favorites data from the head unit AddressBook addressBook ; // For each navigation address, add a NavigationName to addressBook.navigationNames // and add a PostalAddress to addressBook.postalAddresses // ... return addressBook ; } // To remove an address book, publish a RemoveAddressBook message to the Engine bool MyAddressBookHandler::removeAddressBook ( const std :: string & id ) { RemoveAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the RemoveAddressBookReply message // Return the success status from reply message payload } };","title":"C++ MessageBroker Integration"},{"location":"explore/features/address-book/#android-integration_1","text":"The Alexa Auto Client Service (AACS) provides the AACS Contacts Library to integrate the Auto SDK Address Book module on Android. See the AACS Contacts Library documentation for more information.","title":"Android Integration"},{"location":"explore/features/alexa/","text":"Alexa Module \u00b6 Overview \u00b6 The Alexa Auto SDK Alexa module provides interfaces for standard Alexa features. The Engine handles steps to send events and sequence directives so you can focus on using the provided AASB messages to interact with Alexa. Important!: Not every interface of the Alexa module documentation is updated to reflect the Auto SDK 4.0 Message Broker message API. Some pages still include text, code samples, or diagrams that show deprecated platform interfaces rather than their corresponding AASB message interface equivalents. Your application will use the the AASB message interfaces with MessageBroker. The Alexa documentation will be fully updated in the next Auto SDK version. Configure the Alexa module \u00b6 The Alexa module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programmatically with the relevant configuration factory functions. Your application must provide the aace.alexa configuration in the same format as the example specified below. Alternatively, use the AlexaConfiguration factory functions to generate individual elements of this configuration. { \"aace.alexa\": { \"avsDeviceSDK\": { \"deviceInfo\": { \"clientId\": \"${CLIENT_ID}\", \"productId\": \"${PRODUCT_ID}\", \"deviceSerialNumber\": \"${DEVICE_SERIAL_NUMBER}\", \"manufacturerName\": \"${MANUFACTURER_NAME}\", \"description\": \"${DEVICE_DESCRIPTION}\" }, \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"${CERTS_PATH}\" }, \"miscDatabase\": { \"databaseFilePath\": \"${DATA_PATH}/miscDatabase.db\" }, \"certifiedSender\": { \"databaseFilePath\": \"${DATA_PATH}/certifiedSender.db\" }, \"alertsCapabilityAgent\": { \"databaseFilePath\": \"${DATA_PATH}/alertsCapabilityAgent.db\" }, \"notifications\": { \"databaseFilePath\": \"${DATA_PATH}/notifications.db\" }, \"capabilitiesDelegate\": { \"databaseFilePath\": \"${DATA_PATH}/capabilitiesDatabase.db\" }, \"deviceSettings\": { \"databaseFilePath\": \"${DATA_PATH}/deviceSettings.db\", \"locales\": [\"{{STRING}}\", ...], \"defaultLocale\":\"en-US\", \"localeCombinations\": [ [\"{{STRING}}\",\"{{STRING}}\"], [\"{{STRING}}\", \"{{STRING}}\"], ... ], \"defaultTimezone\":\"America/Vancouver\" } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 20000 } }, \"aasb.alexa\": { \"LocalMediaSource\": { \"types\": [\"FM_RADIO\", \"AM_RADIO\",\"BLUETOOTH\", \"USB\", \"SATELLITE_RADIO\", \"LINE_IN\", \"COMPACT_DISC\", \"DAB\", \"DEFAULT\"] } } } The deviceInfo field contains the details of the device. The fields libcurlUtils , miscDatabase , certifiedSender , alertsCapabilityAgent , notifications , and capabilitiesDelegate specify the respective database file paths. The deviceSettings field specifies the settings on the device. The following list describes the settings: databaseFilePath is the path to the SQLite database that stores persistent settings. The database will be created on initialization if it does not already exist. defaultLocale specifies the default locale setting, which is Alexa's locale setting until updated on the device. The default value of defaultLocale is \u201cen-US\u201d. locales specifies the list of locales supported by the device. The default value is [\"en-US\",\"en-GB\",\"de-DE\",\"en-IN\",\"en-CA\",\"ja-JP\",\"en-AU\",\"fr-FR\",\"it-IT\",\"es-ES\",\"es-MX\",\"fr-CA\",\"es-US\", \"hi-IN\", \"pt-BR\"] . localeCombinations specifies the list of locale pairs available on a device that supports multi-locale mode. Through the Dynamic Language Switching feature, Alexa can communicate with the user of such device in languages specified in the locale pairs. In each pair, the first value is the primary locale, which Alexa uses most often when interacting with the user. The second value is the secondary locale, which specifies an additional language that Alexa uses when responding to an utterance in the corresponding language. For example, if [\"en-US\", \"es-US\"] is declared in localeCombinations and the device specifies this pair as the current locale setting, Alexa primarily operates in English for the U.S. but can understand and respond to utterances in Spanish for the U.S., without requiring the device to update the locale setting. By default, localeCombinations is a list of the following combinations, which are also the supported combinations as of 2021-02-02. It is possible for the default value to be different from the list of supported combinations in the future. For updates to the supported combinations, see the Alexa Voice Service documentation . [\"en-US\", \"es-US\"] [\"es-US\", \"en-US\"] [\"en-IN\", \"hi-IN\"] [\"hi-IN\", \"en-IN\"] [\"en-CA\", \"fr-CA\"] [\"fr-CA\", \"en-CA\"] [\"en-US\", \"es-ES\"] [\"es-ES\", \"en-US\"] [\"en-US\", \"de-DE\"] [\"de-DE\", \"en-US\"] [\"en-US\", \"fr-FR\"] [\"fr-FR\", \"en-US\"] [\"en-US\", \"it-IT\"] [\"it-IT\", \"en-US\"] [\"en-US\", \"ja-JP\"] [\"ja-JP\", \"en-US\"] When a device operates in multi-locale mode, an application can select any locale pair in the list above as the locale setting if the following conditions are met: The device's primary locale setting is the first locale in the selected pair. The device also supports the secondary locale in the pair. The pair is specified in localeCombinations . Note: Dynamic Language Switching is only available in online mode. Use the Alexa module interfaces \u00b6 Explore the following interfaces to learn how to integrate Alexa features in your application. Invoke Alexa with SpeechRecognizer \u00b6 Use SpeechRecognizer to capture the user's speech with the microphone when the user invokes Alexa. SpeechRecognizer interface>> Play Alexa speech to the user with SpeechSynthesizer \u00b6 Use SpeechSynthesizer to provide an audio output channel for the Engine to play back Alexa's speech to the user. SpeechSynthesizer interface>> Track Alexa state changes with AlexaClient \u00b6 Use the AlexaClient interface to observe changes in Alexa's connection and attention state when building the UI for your application. AlexaClient interface>> Start the out-of-box experience with DeviceSetup \u00b6 Trigger an out-of-box introductory conversation with Alexa experience using the DeviceSetup interface. DeviceSetup interface>> Find things to try with FeatureDiscovery \u00b6 Use FeatureDiscovery to display dynamic suggested utterances that help users discover new features. FeatureDiscovery interface>> Display cards on screen with TemplateRuntime \u00b6 Provide a visual experience by building a UI based on the templates and media playback info provided by TemplateRuntime . TemplateRuntime interface>> Stream Alexa media content with AudioPlayer \u00b6 AudioPlayer interface>> Press media playback control buttons with PlaybackController \u00b6 PlaybackController interface>> Adjust equalizer settings with EqualizerController \u00b6 EqualizerController interface>> Resume media playback at startup with MediaPlaybackRequestor \u00b6 MediaPlaybackRequestor interface>> Control local media with LocalMediaSource \u00b6 LocalMediaSource interface>> Deep link into external media apps with ExternalMediaAdapter \u00b6 ExternalMediaAdapter interface>> Control volume with AlexaSpeaker \u00b6 AlexaSpeaker interface>> Manage timers, alarms, and reminders with Alerts \u00b6 Alerts interface>> Render notification indicators with Notifications \u00b6 Notifications interface>> Block notifications with DoNotDisturb \u00b6 DoNotDisturb interface>>","title":"Alexa Module"},{"location":"explore/features/alexa/#alexa-module","text":"","title":"Alexa Module"},{"location":"explore/features/alexa/#overview","text":"The Alexa Auto SDK Alexa module provides interfaces for standard Alexa features. The Engine handles steps to send events and sequence directives so you can focus on using the provided AASB messages to interact with Alexa. Important!: Not every interface of the Alexa module documentation is updated to reflect the Auto SDK 4.0 Message Broker message API. Some pages still include text, code samples, or diagrams that show deprecated platform interfaces rather than their corresponding AASB message interface equivalents. Your application will use the the AASB message interfaces with MessageBroker. The Alexa documentation will be fully updated in the next Auto SDK version.","title":"Overview"},{"location":"explore/features/alexa/#configure-the-alexa-module","text":"The Alexa module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programmatically with the relevant configuration factory functions. Your application must provide the aace.alexa configuration in the same format as the example specified below. Alternatively, use the AlexaConfiguration factory functions to generate individual elements of this configuration. { \"aace.alexa\": { \"avsDeviceSDK\": { \"deviceInfo\": { \"clientId\": \"${CLIENT_ID}\", \"productId\": \"${PRODUCT_ID}\", \"deviceSerialNumber\": \"${DEVICE_SERIAL_NUMBER}\", \"manufacturerName\": \"${MANUFACTURER_NAME}\", \"description\": \"${DEVICE_DESCRIPTION}\" }, \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"${CERTS_PATH}\" }, \"miscDatabase\": { \"databaseFilePath\": \"${DATA_PATH}/miscDatabase.db\" }, \"certifiedSender\": { \"databaseFilePath\": \"${DATA_PATH}/certifiedSender.db\" }, \"alertsCapabilityAgent\": { \"databaseFilePath\": \"${DATA_PATH}/alertsCapabilityAgent.db\" }, \"notifications\": { \"databaseFilePath\": \"${DATA_PATH}/notifications.db\" }, \"capabilitiesDelegate\": { \"databaseFilePath\": \"${DATA_PATH}/capabilitiesDatabase.db\" }, \"deviceSettings\": { \"databaseFilePath\": \"${DATA_PATH}/deviceSettings.db\", \"locales\": [\"{{STRING}}\", ...], \"defaultLocale\":\"en-US\", \"localeCombinations\": [ [\"{{STRING}}\",\"{{STRING}}\"], [\"{{STRING}}\", \"{{STRING}}\"], ... ], \"defaultTimezone\":\"America/Vancouver\" } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 20000 } }, \"aasb.alexa\": { \"LocalMediaSource\": { \"types\": [\"FM_RADIO\", \"AM_RADIO\",\"BLUETOOTH\", \"USB\", \"SATELLITE_RADIO\", \"LINE_IN\", \"COMPACT_DISC\", \"DAB\", \"DEFAULT\"] } } } The deviceInfo field contains the details of the device. The fields libcurlUtils , miscDatabase , certifiedSender , alertsCapabilityAgent , notifications , and capabilitiesDelegate specify the respective database file paths. The deviceSettings field specifies the settings on the device. The following list describes the settings: databaseFilePath is the path to the SQLite database that stores persistent settings. The database will be created on initialization if it does not already exist. defaultLocale specifies the default locale setting, which is Alexa's locale setting until updated on the device. The default value of defaultLocale is \u201cen-US\u201d. locales specifies the list of locales supported by the device. The default value is [\"en-US\",\"en-GB\",\"de-DE\",\"en-IN\",\"en-CA\",\"ja-JP\",\"en-AU\",\"fr-FR\",\"it-IT\",\"es-ES\",\"es-MX\",\"fr-CA\",\"es-US\", \"hi-IN\", \"pt-BR\"] . localeCombinations specifies the list of locale pairs available on a device that supports multi-locale mode. Through the Dynamic Language Switching feature, Alexa can communicate with the user of such device in languages specified in the locale pairs. In each pair, the first value is the primary locale, which Alexa uses most often when interacting with the user. The second value is the secondary locale, which specifies an additional language that Alexa uses when responding to an utterance in the corresponding language. For example, if [\"en-US\", \"es-US\"] is declared in localeCombinations and the device specifies this pair as the current locale setting, Alexa primarily operates in English for the U.S. but can understand and respond to utterances in Spanish for the U.S., without requiring the device to update the locale setting. By default, localeCombinations is a list of the following combinations, which are also the supported combinations as of 2021-02-02. It is possible for the default value to be different from the list of supported combinations in the future. For updates to the supported combinations, see the Alexa Voice Service documentation . [\"en-US\", \"es-US\"] [\"es-US\", \"en-US\"] [\"en-IN\", \"hi-IN\"] [\"hi-IN\", \"en-IN\"] [\"en-CA\", \"fr-CA\"] [\"fr-CA\", \"en-CA\"] [\"en-US\", \"es-ES\"] [\"es-ES\", \"en-US\"] [\"en-US\", \"de-DE\"] [\"de-DE\", \"en-US\"] [\"en-US\", \"fr-FR\"] [\"fr-FR\", \"en-US\"] [\"en-US\", \"it-IT\"] [\"it-IT\", \"en-US\"] [\"en-US\", \"ja-JP\"] [\"ja-JP\", \"en-US\"] When a device operates in multi-locale mode, an application can select any locale pair in the list above as the locale setting if the following conditions are met: The device's primary locale setting is the first locale in the selected pair. The device also supports the secondary locale in the pair. The pair is specified in localeCombinations . Note: Dynamic Language Switching is only available in online mode.","title":"Configure the Alexa module"},{"location":"explore/features/alexa/#use-the-alexa-module-interfaces","text":"Explore the following interfaces to learn how to integrate Alexa features in your application.","title":"Use the Alexa module interfaces"},{"location":"explore/features/alexa/#invoke-alexa-with-speechrecognizer","text":"Use SpeechRecognizer to capture the user's speech with the microphone when the user invokes Alexa. SpeechRecognizer interface>>","title":"Invoke Alexa with SpeechRecognizer"},{"location":"explore/features/alexa/#play-alexa-speech-to-the-user-with-speechsynthesizer","text":"Use SpeechSynthesizer to provide an audio output channel for the Engine to play back Alexa's speech to the user. SpeechSynthesizer interface>>","title":"Play Alexa speech to the user with SpeechSynthesizer"},{"location":"explore/features/alexa/#track-alexa-state-changes-with-alexaclient","text":"Use the AlexaClient interface to observe changes in Alexa's connection and attention state when building the UI for your application. AlexaClient interface>>","title":"Track Alexa state changes with AlexaClient"},{"location":"explore/features/alexa/#start-the-out-of-box-experience-with-devicesetup","text":"Trigger an out-of-box introductory conversation with Alexa experience using the DeviceSetup interface. DeviceSetup interface>>","title":"Start the out-of-box experience with DeviceSetup"},{"location":"explore/features/alexa/#find-things-to-try-with-featurediscovery","text":"Use FeatureDiscovery to display dynamic suggested utterances that help users discover new features. FeatureDiscovery interface>>","title":"Find things to try with FeatureDiscovery"},{"location":"explore/features/alexa/#display-cards-on-screen-with-templateruntime","text":"Provide a visual experience by building a UI based on the templates and media playback info provided by TemplateRuntime . TemplateRuntime interface>>","title":"Display cards on screen with TemplateRuntime"},{"location":"explore/features/alexa/#stream-alexa-media-content-with-audioplayer","text":"AudioPlayer interface>>","title":"Stream Alexa media content with AudioPlayer"},{"location":"explore/features/alexa/#press-media-playback-control-buttons-with-playbackcontroller","text":"PlaybackController interface>>","title":"Press media playback control buttons with PlaybackController"},{"location":"explore/features/alexa/#adjust-equalizer-settings-with-equalizercontroller","text":"EqualizerController interface>>","title":"Adjust equalizer settings with EqualizerController"},{"location":"explore/features/alexa/#resume-media-playback-at-startup-with-mediaplaybackrequestor","text":"MediaPlaybackRequestor interface>>","title":"Resume media playback at startup with MediaPlaybackRequestor"},{"location":"explore/features/alexa/#control-local-media-with-localmediasource","text":"LocalMediaSource interface>>","title":"Control local media with LocalMediaSource"},{"location":"explore/features/alexa/#deep-link-into-external-media-apps-with-externalmediaadapter","text":"ExternalMediaAdapter interface>>","title":"Deep link into external media apps with ExternalMediaAdapter"},{"location":"explore/features/alexa/#control-volume-with-alexaspeaker","text":"AlexaSpeaker interface>>","title":"Control volume with AlexaSpeaker"},{"location":"explore/features/alexa/#manage-timers-alarms-and-reminders-with-alerts","text":"Alerts interface>>","title":"Manage timers, alarms, and reminders with Alerts"},{"location":"explore/features/alexa/#render-notification-indicators-with-notifications","text":"Notifications interface>>","title":"Render notification indicators with Notifications"},{"location":"explore/features/alexa/#block-notifications-with-donotdisturb","text":"DoNotDisturb interface>>","title":"Block notifications with DoNotDisturb"},{"location":"explore/features/alexa/Alerts/","text":"Alerts Interface \u00b6 When an alert is received from Alexa, it is the responsibility of the platform implementation to play the alert sounds in a platform-specific media player. See the AVS Alerts interface documentation for more information about alerts. The state of the alert is also made available for the platform to react to. The playback is handled by whichever audio channel is assigned to the ALERT type. To implement a custom handler for alerts, extend the Alerts class: #include <AACE/Alexa/Alerts.h> class MyAlerts : public aace::alexa::Alerts { public: void MyAlerts::alertStateChanged( const std::string& alertToken, AlertState state, const std::string& reason ) override { //handle the alert state change } void MyAlerts::alertCreated( const std::string& alertToken, const std::string& detailedInfo ) override { //handle the alert detailed info when alert is created (optional) /* * JSON string detailedInfo : * { * \"time\" : <String> * \"type\" : <String> * \"label\" : <String> * } */ } void MyAlerts::alertDeleted( const std::string& alertToken ) override { //handle the alert when alert is deleted (optional) } }; ... // Register the platform interface with the Engine auto myAlertsMediaPlayer = std::make_shared<MyMediaPlayer>(...); auto myAlertsSpeaker = std::make_shared<MySpeaker>(...); auto myAlerts = std::make_shared<MyAlerts>(myAudioPlayerMediaPlayer, myAudioPlayerSpeaker); engine->registerPlatformInterface( myAlerts );","title":"Alerts"},{"location":"explore/features/alexa/Alerts/#alerts-interface","text":"When an alert is received from Alexa, it is the responsibility of the platform implementation to play the alert sounds in a platform-specific media player. See the AVS Alerts interface documentation for more information about alerts. The state of the alert is also made available for the platform to react to. The playback is handled by whichever audio channel is assigned to the ALERT type. To implement a custom handler for alerts, extend the Alerts class: #include <AACE/Alexa/Alerts.h> class MyAlerts : public aace::alexa::Alerts { public: void MyAlerts::alertStateChanged( const std::string& alertToken, AlertState state, const std::string& reason ) override { //handle the alert state change } void MyAlerts::alertCreated( const std::string& alertToken, const std::string& detailedInfo ) override { //handle the alert detailed info when alert is created (optional) /* * JSON string detailedInfo : * { * \"time\" : <String> * \"type\" : <String> * \"label\" : <String> * } */ } void MyAlerts::alertDeleted( const std::string& alertToken ) override { //handle the alert when alert is deleted (optional) } }; ... // Register the platform interface with the Engine auto myAlertsMediaPlayer = std::make_shared<MyMediaPlayer>(...); auto myAlertsSpeaker = std::make_shared<MySpeaker>(...); auto myAlerts = std::make_shared<MyAlerts>(myAudioPlayerMediaPlayer, myAudioPlayerSpeaker); engine->registerPlatformInterface( myAlerts );","title":"Alerts Interface"},{"location":"explore/features/alexa/AlexaClient/","text":"AlexaClient Interface \u00b6 Render Alexa's attention state \u00b6 Your application can subscribe to the AlexaClient.DialogStateChanged message to be notified what state Alexa dialog is in (e.g., Alexa started listening to the user's speech or started speaking her response). This message helps your application render Alexa's attention state UI such as Voice Chrome and audio cues without having to derive these states by tracking your application's microphone and media player. The following diagram shows how you might use the dialog state changes to provide Alexa attention feedback during an interaction. Click to expand or collapse sequence diagram: Alexa invocation Monitor Alexa's connection status \u00b6 Your application can subscribe to the AlexaClient.ConnectionStatusChanged message to be notified when the status of the Engine's connection to Alexa has changed (e.g., the Engine lost connection to Alexa). You might use this information, for instance, to enable or disable certain functionality or display information to the user. Monitor Alexa's authorization state \u00b6 Your application can subscribe to the AlexaClient.AuthStateChanged message to be notified what state the Engine is in with respect to the user sign in. For example, the state is REFRESHED when the Engine has an access token.","title":"AlexaClient"},{"location":"explore/features/alexa/AlexaClient/#alexaclient-interface","text":"","title":"AlexaClient Interface"},{"location":"explore/features/alexa/AlexaClient/#render-alexas-attention-state","text":"Your application can subscribe to the AlexaClient.DialogStateChanged message to be notified what state Alexa dialog is in (e.g., Alexa started listening to the user's speech or started speaking her response). This message helps your application render Alexa's attention state UI such as Voice Chrome and audio cues without having to derive these states by tracking your application's microphone and media player. The following diagram shows how you might use the dialog state changes to provide Alexa attention feedback during an interaction. Click to expand or collapse sequence diagram: Alexa invocation","title":"Render Alexa's attention state"},{"location":"explore/features/alexa/AlexaClient/#monitor-alexas-connection-status","text":"Your application can subscribe to the AlexaClient.ConnectionStatusChanged message to be notified when the status of the Engine's connection to Alexa has changed (e.g., the Engine lost connection to Alexa). You might use this information, for instance, to enable or disable certain functionality or display information to the user.","title":"Monitor Alexa's connection status"},{"location":"explore/features/alexa/AlexaClient/#monitor-alexas-authorization-state","text":"Your application can subscribe to the AlexaClient.AuthStateChanged message to be notified what state the Engine is in with respect to the user sign in. For example, the state is REFRESHED when the Engine has an access token.","title":"Monitor Alexa's authorization state"},{"location":"explore/features/alexa/AlexaSpeaker/","text":"AlexaSpeaker Interface \u00b6 The Alexa service keeps track of two device volume types: ALEXA_VOLUME and ALERTS_VOLUME . The aace::alexa::AlexaSpeaker class should be implemented by the platform to both set the volume and mute state of these two speaker types and allow the user to set the volume and mute state of these two speaker types locally via GUI if applicable. SpeakerManager is a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\". You can programmatically generate speaker manager configuration using the aace::alexa::config::AlexaConfiguration::createSpeakerManagerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"speakerManager\": { \"enabled\": false } } } Set a custom volume range \u00b6 You can use a custom volume control to support an Alexa device's native input volume range. By default, Alexa supports voice utterances that specify volume values between 0 and 10, but some devices may support a different range (i.e. 0 to 100). By placing on Amazon's allow list your Alexa device's volume range for your target platform, you can specify input volume levels per your device's range. Your device's input volume range is then mapped appropriately to the Alexa volume range. Contact your Alexa Auto Solution Architect (SA) for help with allow lists. Placing a device on the allow list requires the following parameters: DeviceTypeID: <YOUR_DEVICE_TYPE_ID> Min: <YOUR_MIN_VOLUME_VALUE> Max: <YOUR_MAX_VOLUME_VALUE> This does not impact the range used in the directives to the device. You must continue to use the SDK 0-100 volume range used by AudioOutput and AlexaSpeaker and map these values to the correct range in your implementation.","title":"AlexaSpeaker"},{"location":"explore/features/alexa/AlexaSpeaker/#alexaspeaker-interface","text":"The Alexa service keeps track of two device volume types: ALEXA_VOLUME and ALERTS_VOLUME . The aace::alexa::AlexaSpeaker class should be implemented by the platform to both set the volume and mute state of these two speaker types and allow the user to set the volume and mute state of these two speaker types locally via GUI if applicable. SpeakerManager is a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\". You can programmatically generate speaker manager configuration using the aace::alexa::config::AlexaConfiguration::createSpeakerManagerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"speakerManager\": { \"enabled\": false } } }","title":"AlexaSpeaker Interface"},{"location":"explore/features/alexa/AlexaSpeaker/#set-a-custom-volume-range","text":"You can use a custom volume control to support an Alexa device's native input volume range. By default, Alexa supports voice utterances that specify volume values between 0 and 10, but some devices may support a different range (i.e. 0 to 100). By placing on Amazon's allow list your Alexa device's volume range for your target platform, you can specify input volume levels per your device's range. Your device's input volume range is then mapped appropriately to the Alexa volume range. Contact your Alexa Auto Solution Architect (SA) for help with allow lists. Placing a device on the allow list requires the following parameters: DeviceTypeID: <YOUR_DEVICE_TYPE_ID> Min: <YOUR_MIN_VOLUME_VALUE> Max: <YOUR_MAX_VOLUME_VALUE> This does not impact the range used in the directives to the device. You must continue to use the SDK 0-100 volume range used by AudioOutput and AlexaSpeaker and map these values to the correct range in your implementation.","title":"Set a custom volume range"},{"location":"explore/features/alexa/AudioPlayer/","text":"AudioPlayer Interface \u00b6 When an audio media stream is received from Alexa, it is the responsibility of the platform implementation to play the stream in a platform-specific media player. The aace::alexa::AudioPlayer class informs the platform of the changes in player state being tracked by the Engine. This can be used to update the platform GUI, for example. To implement a custom handler for audio player output, extend the AudioPlayer class: #include <AACE/Alexa/AudioPlayer.h> class MyAudioPlayer : public aace::alexa::AudioPlayer { public: void playerActivityChanged( PlayerActivity state ) override { // on state change, update playback control UI } }; ... // Register the platform interface with the Engine auto myAudioPlayer = std::make_shared<MyAudioPlayer>(); engine->registerPlatformInterface( myAudioPlayer ); View media metadata on screen with TemplateRuntime \u00b6 Your application subscribes to the TemplateRuntime.RenderPlayerInfo AASB message to receive metadata about the active media playback for you to display. See the TemplateRuntime AVS documentation for details about the payload.","title":"AudioPlayer"},{"location":"explore/features/alexa/AudioPlayer/#audioplayer-interface","text":"When an audio media stream is received from Alexa, it is the responsibility of the platform implementation to play the stream in a platform-specific media player. The aace::alexa::AudioPlayer class informs the platform of the changes in player state being tracked by the Engine. This can be used to update the platform GUI, for example. To implement a custom handler for audio player output, extend the AudioPlayer class: #include <AACE/Alexa/AudioPlayer.h> class MyAudioPlayer : public aace::alexa::AudioPlayer { public: void playerActivityChanged( PlayerActivity state ) override { // on state change, update playback control UI } }; ... // Register the platform interface with the Engine auto myAudioPlayer = std::make_shared<MyAudioPlayer>(); engine->registerPlatformInterface( myAudioPlayer );","title":"AudioPlayer Interface"},{"location":"explore/features/alexa/AudioPlayer/#view-media-metadata-on-screen-with-templateruntime","text":"Your application subscribes to the TemplateRuntime.RenderPlayerInfo AASB message to receive metadata about the active media playback for you to display. See the TemplateRuntime AVS documentation for details about the payload.","title":"View media metadata on screen with TemplateRuntime"},{"location":"explore/features/alexa/DeviceSetup/","text":"DeviceSetup Interface \u00b6 Note: This feature requires Amazon to allowlist your device. For help, contact your Amazon Solutions Architect or partner manager. After the user signs in to your application during or after the out-of-box experience, your application starts the Engine and publishes the DeviceSetup.SetupCompleted message to notify Alexa that the setup is complete. The Engine publishes the DeviceSetup.SetupCompletedResponse to your application to indicate Alexa was notified successfully. In response to the SetupCompleted event, Alexa starts an onboarding experience including a short first-time conversation with the user. Because SetupCompleted triggers an onboarding experience, do not publish the message if the signed-in user has already seen the experience. The onboarding experience is for first-time users only and might differ for returning users. Note: Do not publish the SetupCompleted message if user is in Connectivity mode or Preview Mode or if the user has disabled hands-free listening. Publishing SetupCompleted in these conditions causes undesirable user experience.","title":"DeviceSetup"},{"location":"explore/features/alexa/DeviceSetup/#devicesetup-interface","text":"Note: This feature requires Amazon to allowlist your device. For help, contact your Amazon Solutions Architect or partner manager. After the user signs in to your application during or after the out-of-box experience, your application starts the Engine and publishes the DeviceSetup.SetupCompleted message to notify Alexa that the setup is complete. The Engine publishes the DeviceSetup.SetupCompletedResponse to your application to indicate Alexa was notified successfully. In response to the SetupCompleted event, Alexa starts an onboarding experience including a short first-time conversation with the user. Because SetupCompleted triggers an onboarding experience, do not publish the message if the signed-in user has already seen the experience. The onboarding experience is for first-time users only and might differ for returning users. Note: Do not publish the SetupCompleted message if user is in Connectivity mode or Preview Mode or if the user has disabled hands-free listening. Publishing SetupCompleted in these conditions causes undesirable user experience.","title":"DeviceSetup Interface"},{"location":"explore/features/alexa/DoNotDisturb/","text":"DoNotDisturb Interface \u00b6 The DoNotDisturb (DND) interface allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . The Engine uses the registered DND implementation to notify the client when DND has been set or unset. A user's voice request to change the DND state triggers audio playback, but no audio playback occurs when a user sets the DND state using the touch screen. To implement a custom handler for DND extend the DoNotDisturb class: #include <AACE/Alexa/DoNotDisturb> class MyDoNotDisturbHandler : public aace::alexa::DoNotDisturb { public: void setDoNotDisturb( bool doNotDisturb ) override { // set your DoNotDisturb indicator } // on user GUI setting change ... bool doNotDisturb = userSetState; doNotDisturbChanged(doNotDisturb); ... }; ... // Register the platform interface with the Engine auto m_doNotDisturbHandler = std::make_shared<MyDoNotDisturbHandler>(); engine->registerPlatformInterface(m_doNotDisturbHandler);","title":"DoNotDisturb"},{"location":"explore/features/alexa/DoNotDisturb/#donotdisturb-interface","text":"The DoNotDisturb (DND) interface allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . The Engine uses the registered DND implementation to notify the client when DND has been set or unset. A user's voice request to change the DND state triggers audio playback, but no audio playback occurs when a user sets the DND state using the touch screen. To implement a custom handler for DND extend the DoNotDisturb class: #include <AACE/Alexa/DoNotDisturb> class MyDoNotDisturbHandler : public aace::alexa::DoNotDisturb { public: void setDoNotDisturb( bool doNotDisturb ) override { // set your DoNotDisturb indicator } // on user GUI setting change ... bool doNotDisturb = userSetState; doNotDisturbChanged(doNotDisturb); ... }; ... // Register the platform interface with the Engine auto m_doNotDisturbHandler = std::make_shared<MyDoNotDisturbHandler>(); engine->registerPlatformInterface(m_doNotDisturbHandler);","title":"DoNotDisturb Interface"},{"location":"explore/features/alexa/EqualizerController/","text":"EqualizerController Interface \u00b6 The Equalizer Controller enables Alexa voice control of the device's audio equalizer settings, which includes making gain level adjustments to any of the supported frequency bands (\"BASS\", \"MIDRANGE\", and/or \"TREBLE\") using the device's onboard audio processing. The platform implementation is responsible for the following: Determining how each supported band affects the audio Mapping Alexa's equalizer bands to the bands supported on the device, if they do not directly correspond Scaling Alexa's level values as necessary so that each step corresponds to one decibel of amplitude gain on the device Applying equalization to only selected portions of the audio output so that Alexa's speech, alarms, etc. will not be affected Persisting settings across power cycles You can programmatically generate Equalizer Controller configuration with details such as supported bands, default state, and decibel adjustment range using the aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"equalizer\": { \"bands\": { \"BASS\": true, \"MIDRANGE\": false, \"TREBLE\": true }, \"defaultState\": { \"bands\": { \"BASS\": 4, \"TREBLE\": -1 } }, \"minLevel\": -6, \"maxLevel\": 6 } } } For example, 2 supported bands with amplitude gains ranging from -8dB to +8dB, each with a default of 0dB auto eqConfig = aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig( {EqualizerBand::BASS, EqualizerBand::TREBLE}, -8, 8, { {EqualizerBand::BASS, 0}, {EqualizerBand::TREBLE, 0} } ); engine->configure( { //other config objects..., eqConfig, ... } ); ... To implement a custom handler for Equalizer Controller, extend the EqualizerController class: #include <AACE/Alexa/EqualizerController.h> using EqualizerBand = aace::alexa::EqualizerController::EqualizerBand; using EqualizerBandLevel = aace::alexa::EqualizerController::EqualizerBandLevel; class MyEqualizerControllerHandler : public aace::alexa::EqualizerController { public: void setBandLevels( std::vector<EqualizerBandLevel> bandLevels ) override { // Handle performing audio equalization on the device // according to the provided band dB level settings // This invocation may come from \"Alexa, reset bass\", // \"Alexa, reset my equalizer\", \"Alexa, increase treble\", etc. } std::vector<EqualizerBandLevel> getBandLevels() override { // Return the current band level settings on the device return m_currentBandLevels; } }; ... // Register the platform interface with the Engine auto m_equalizerController = std::make_shared<MyEqualizerControllerHandler>(); engine->registerPlatformInterface( m_equalizerController ); ... // If levels are adjusted using local on-device controls, call inherited methods to notify the Engine: // To set a band to an absolute gain level in decibels std::vector<EqualizerBandLevel> settings{ {EqualizerBand::BASS, 4} }; // Sets bass amplitude to +4dB m_equalizerController->localSetBandLevels( settings ); // To make a relative adjustment to level settings std::vector<EqualizerBandLevel> adjustments{ {EqualizerBand::BASS, -2} }; // Decreases bass gain by 2dB m_equalizerController->localAdjustBandLevels( adjustments ); // To reset gain levels to the configured defaults (usually 0dB) std::vector<EqualizerBand> bands{EqualizerBand::BASS, EqualizerBand::TREBLE}; // Resets bass and treble bands m_equalizerController->localResetBands( bands );","title":"EqualizerController"},{"location":"explore/features/alexa/EqualizerController/#equalizercontroller-interface","text":"The Equalizer Controller enables Alexa voice control of the device's audio equalizer settings, which includes making gain level adjustments to any of the supported frequency bands (\"BASS\", \"MIDRANGE\", and/or \"TREBLE\") using the device's onboard audio processing. The platform implementation is responsible for the following: Determining how each supported band affects the audio Mapping Alexa's equalizer bands to the bands supported on the device, if they do not directly correspond Scaling Alexa's level values as necessary so that each step corresponds to one decibel of amplitude gain on the device Applying equalization to only selected portions of the audio output so that Alexa's speech, alarms, etc. will not be affected Persisting settings across power cycles You can programmatically generate Equalizer Controller configuration with details such as supported bands, default state, and decibel adjustment range using the aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"equalizer\": { \"bands\": { \"BASS\": true, \"MIDRANGE\": false, \"TREBLE\": true }, \"defaultState\": { \"bands\": { \"BASS\": 4, \"TREBLE\": -1 } }, \"minLevel\": -6, \"maxLevel\": 6 } } } For example, 2 supported bands with amplitude gains ranging from -8dB to +8dB, each with a default of 0dB auto eqConfig = aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig( {EqualizerBand::BASS, EqualizerBand::TREBLE}, -8, 8, { {EqualizerBand::BASS, 0}, {EqualizerBand::TREBLE, 0} } ); engine->configure( { //other config objects..., eqConfig, ... } ); ... To implement a custom handler for Equalizer Controller, extend the EqualizerController class: #include <AACE/Alexa/EqualizerController.h> using EqualizerBand = aace::alexa::EqualizerController::EqualizerBand; using EqualizerBandLevel = aace::alexa::EqualizerController::EqualizerBandLevel; class MyEqualizerControllerHandler : public aace::alexa::EqualizerController { public: void setBandLevels( std::vector<EqualizerBandLevel> bandLevels ) override { // Handle performing audio equalization on the device // according to the provided band dB level settings // This invocation may come from \"Alexa, reset bass\", // \"Alexa, reset my equalizer\", \"Alexa, increase treble\", etc. } std::vector<EqualizerBandLevel> getBandLevels() override { // Return the current band level settings on the device return m_currentBandLevels; } }; ... // Register the platform interface with the Engine auto m_equalizerController = std::make_shared<MyEqualizerControllerHandler>(); engine->registerPlatformInterface( m_equalizerController ); ... // If levels are adjusted using local on-device controls, call inherited methods to notify the Engine: // To set a band to an absolute gain level in decibels std::vector<EqualizerBandLevel> settings{ {EqualizerBand::BASS, 4} }; // Sets bass amplitude to +4dB m_equalizerController->localSetBandLevels( settings ); // To make a relative adjustment to level settings std::vector<EqualizerBandLevel> adjustments{ {EqualizerBand::BASS, -2} }; // Decreases bass gain by 2dB m_equalizerController->localAdjustBandLevels( adjustments ); // To reset gain levels to the configured defaults (usually 0dB) std::vector<EqualizerBand> bands{EqualizerBand::BASS, EqualizerBand::TREBLE}; // Resets bass and treble bands m_equalizerController->localResetBands( bands );","title":"EqualizerController Interface"},{"location":"explore/features/alexa/ExternalMediaAdapter/","text":"ExternalMediaAdapter Interface \u00b6 The External Media Player (EMP) Adapter allows you to declare and use external media application sources in your application. In order to interface with the EMP Adapter, you must use one of the following: A media connection client to interface the EMP Adapter to the external app. AACS provides an app component called the Media App Command and Control (MACC) client that provides most of the deep-linking integration specified below. The AACS Sample App supports an example using the Media App Command and Control (MACC) client to play the Android Spotify app. An embedded media app. For information about external embedded media app solutions, contact your SA or Partner Manager. Note: If the media app service requires additional customer experience details, incorporate the requirement in your implementation. For example, if the provider requires your application to show the provider's logo in a particular way, modify the implementation to meet the requirement. When advised by your SA or Partner Manager, configure the External Media Player Adapter to the device's capabilities. See aace::alexa::config::AlexaConfiguration::createExternalMediaPlayerConfig for details on configuring the supported agent, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"externalMediaPlayer\": { \"agent\": \"<agent>\" } } You must register and implement each ExternalMediaAdapter (along with its associated external client or library). After the engine establishes a connection to the Alexa service, you can run discovery to validate each external media application. You can report discovered external media players by calling reportDiscoveredPlayers() at any point during runtime. When the Alexa service recognizes the player, you will get a call to the authorize() method including the player's authorization status. Both the reportDiscoveredPlayers() method and the authorize() method can contain one or more players in their JSON payloads. Validating the application enables Alexa to exercise playback control over the registered source type. The login() and logout() methods inform AVS of login state changes, if applicable. If your application has the ability to handle cloud-based login and logout, you should also call the loginComplete() and logoutComplete() methods where appropriate. When the user makes an Alexa voice request (for example, \"Play Spotify\"), the play() method is invoked. This method contains various parameters, including the player id of the player to which the playback information should be routed. Whether through voice or GUI event, the playControl() method is called with the relevant PlayControlType . Similar to play() the control should be routed to the appropriate player. The PlayControlType is determined by player's supportedOperations , which are specified by your implementation in the return value of getState() . The ExternalMediaAdapter interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your external player. Even though your player manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your player\u2019s playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your player\u2019s state. Particular event names indicate if the player is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. The tables below describe each supported event name and what it means to the Engine. Usage of these events depends on the particular type of player controlled by the ExternalMediaAdapter instance, so contact your Solutions Architect (SA) or Partner Manager for guidance regarding supported embedded and external app solutions. playerEvent() event name Description \"PlaybackSessionStarted\" A new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackStarted\" During an active session, the player has started to play or resumed from a paused state. The Engine considers the player active and in focus. \"TrackChanged\" During an active session, one track has ended and another has started. The Engine uses this primarily for state reporting. \"PlaybackNext\" During an active session, the player skipped from one track to the next track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlaybackPrevious\" During an active session, the player skipped from one track to the previous track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlayModeChanged\" During an active session, some user setting for the track or playback session changed, such as the favorite setting or the shuffle mode. The Engine uses this primarily for state reporting. \"PlaybackStopped\" During an active session, the player has paused or stopped, either as a result of a GUI interaction or a user voice request to Alexa. The Engine considers the player active and in focus, just not currently playing. User voice requests to resume still control the player. \"PlaybackSessionEnded\" An active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. playerError() event name Description \"INTERNAL_ERROR\" Any fatal player error has occurred \"UNKNOWN_ERROR\" An unknown error occurred \"UNPLAYABLE_BY_AUTHORIZATION\" The media couldn't be played due to an unauthorized account \"UNPLAYABLE_BY_STREAM_CONCURRENCY\" The media couldn't be played due to the number of accounts currently streaming \"UNPLAYABLE_BY_ACCOUNT\" The media couldn't be played due to the account type \"UNPLAYABLE_BY_REGION\" The media couldn't be played due to the current region \"UNPLAYABLE_BY_PARENTAL_CONTROL\" The media couldn't be played due to parental settings \"UNPLAYABLE_BY_SUBSCRIPTION\" The media couldn't be played due to the subscription type \"OPERATION_REJECTED_UNINTERRUPTIBLE\" The operation could not be performed due to non interruptible media \"OPERATION_REJECTED_END_OF_QUEUE\" The operation could not be performed due to the end of media being reached \"OPERATION_UNSUPPORTED\" The operation was not supported \"OPERATION_REJECTED_SKIP_LIMIT\" The operation failed because a skip limit was reached \"PLAYER_UNKNOWN\" An unknown player was detected \"PLAYER_NOT_FOUND\" The player was not discovered \"PLAYER_CONNECTION_REJECTED\" The connection to the player failed \"PLAYER_CONNECTION_TIMEOUT\" The connection to the player timed out The seek() and adjustSeek() methods are invokable via Alexa if the currently in-focus external player supports them. seek() specifies an absolute offset, whereas adjustSeek() specifies a relative offset. The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently-focused external player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . The getState() method is called to synchronize the external player's state with the cloud. This method is used to maintain correct state during startup, and after every Alexa request. You construct the ExternalMediaAdapterState object using the data taken from the media app connection client or embedded player app (associated via localPlayerId ) and return the state information. The following table describes the fields comprising a ExternalMediaAdapterState , which includes two sub-components: PlaybackState , and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedOperation trackOffset long No optional shuffleEnabled boolean Yes report shuffle status repeatEnabled boolean Yes report repeat status favorites Favorites No see Favorites type String Yes must be set as \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No empty trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType Yes see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean Yes true if the application is in an active state accessToken String No empty tokenRefreshInterval long No empty playerCookie String No A player may declare arbitrary information for itself spiVersion String Yes must be set as \"1.0\" supportedOperations should be a list of the operations that the external media adapter supports. Below is a list of all possible supportedOperations . SupportedPlaybackOperation.PLAY, SupportedPlaybackOperation.PAUSE, SupportedPlaybackOperation.STOP, SupportedPlaybackOperation.PREVIOUS, SupportedPlaybackOperation.NEXT, SupportedPlaybackOperation.ENABLE_SHUFFLE, SupportedPlaybackOperation.DISABLE_SHUFFLE, SupportedPlaybackOperation.ENABLE_REPEAT_ONE, SupportedPlaybackOperation.ENABLE_REPEAT, SupportedPlaybackOperation.DISABLE_REPEAT, SupportedPlaybackOperation.SEEK, SupportedPlaybackOperation.ADJUST_SEEK, SupportedPlaybackOperation.FAVORITE, SupportedPlaybackOperation.UNFAVORITE, SupportedPlaybackOperation.FAST_FORWARD, SupportedPlaybackOperation.REWIND, SupportedPlaybackOperation.START_OVER Note: Currently PLAY/PAUSE/STOP will always be supported for a source. Passing null will allow ALL supported operations for the source.","title":"ExternalMediaAdapter"},{"location":"explore/features/alexa/ExternalMediaAdapter/#externalmediaadapter-interface","text":"The External Media Player (EMP) Adapter allows you to declare and use external media application sources in your application. In order to interface with the EMP Adapter, you must use one of the following: A media connection client to interface the EMP Adapter to the external app. AACS provides an app component called the Media App Command and Control (MACC) client that provides most of the deep-linking integration specified below. The AACS Sample App supports an example using the Media App Command and Control (MACC) client to play the Android Spotify app. An embedded media app. For information about external embedded media app solutions, contact your SA or Partner Manager. Note: If the media app service requires additional customer experience details, incorporate the requirement in your implementation. For example, if the provider requires your application to show the provider's logo in a particular way, modify the implementation to meet the requirement. When advised by your SA or Partner Manager, configure the External Media Player Adapter to the device's capabilities. See aace::alexa::config::AlexaConfiguration::createExternalMediaPlayerConfig for details on configuring the supported agent, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"externalMediaPlayer\": { \"agent\": \"<agent>\" } } You must register and implement each ExternalMediaAdapter (along with its associated external client or library). After the engine establishes a connection to the Alexa service, you can run discovery to validate each external media application. You can report discovered external media players by calling reportDiscoveredPlayers() at any point during runtime. When the Alexa service recognizes the player, you will get a call to the authorize() method including the player's authorization status. Both the reportDiscoveredPlayers() method and the authorize() method can contain one or more players in their JSON payloads. Validating the application enables Alexa to exercise playback control over the registered source type. The login() and logout() methods inform AVS of login state changes, if applicable. If your application has the ability to handle cloud-based login and logout, you should also call the loginComplete() and logoutComplete() methods where appropriate. When the user makes an Alexa voice request (for example, \"Play Spotify\"), the play() method is invoked. This method contains various parameters, including the player id of the player to which the playback information should be routed. Whether through voice or GUI event, the playControl() method is called with the relevant PlayControlType . Similar to play() the control should be routed to the appropriate player. The PlayControlType is determined by player's supportedOperations , which are specified by your implementation in the return value of getState() . The ExternalMediaAdapter interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your external player. Even though your player manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your player\u2019s playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your player\u2019s state. Particular event names indicate if the player is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. The tables below describe each supported event name and what it means to the Engine. Usage of these events depends on the particular type of player controlled by the ExternalMediaAdapter instance, so contact your Solutions Architect (SA) or Partner Manager for guidance regarding supported embedded and external app solutions. playerEvent() event name Description \"PlaybackSessionStarted\" A new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackStarted\" During an active session, the player has started to play or resumed from a paused state. The Engine considers the player active and in focus. \"TrackChanged\" During an active session, one track has ended and another has started. The Engine uses this primarily for state reporting. \"PlaybackNext\" During an active session, the player skipped from one track to the next track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlaybackPrevious\" During an active session, the player skipped from one track to the previous track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlayModeChanged\" During an active session, some user setting for the track or playback session changed, such as the favorite setting or the shuffle mode. The Engine uses this primarily for state reporting. \"PlaybackStopped\" During an active session, the player has paused or stopped, either as a result of a GUI interaction or a user voice request to Alexa. The Engine considers the player active and in focus, just not currently playing. User voice requests to resume still control the player. \"PlaybackSessionEnded\" An active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. playerError() event name Description \"INTERNAL_ERROR\" Any fatal player error has occurred \"UNKNOWN_ERROR\" An unknown error occurred \"UNPLAYABLE_BY_AUTHORIZATION\" The media couldn't be played due to an unauthorized account \"UNPLAYABLE_BY_STREAM_CONCURRENCY\" The media couldn't be played due to the number of accounts currently streaming \"UNPLAYABLE_BY_ACCOUNT\" The media couldn't be played due to the account type \"UNPLAYABLE_BY_REGION\" The media couldn't be played due to the current region \"UNPLAYABLE_BY_PARENTAL_CONTROL\" The media couldn't be played due to parental settings \"UNPLAYABLE_BY_SUBSCRIPTION\" The media couldn't be played due to the subscription type \"OPERATION_REJECTED_UNINTERRUPTIBLE\" The operation could not be performed due to non interruptible media \"OPERATION_REJECTED_END_OF_QUEUE\" The operation could not be performed due to the end of media being reached \"OPERATION_UNSUPPORTED\" The operation was not supported \"OPERATION_REJECTED_SKIP_LIMIT\" The operation failed because a skip limit was reached \"PLAYER_UNKNOWN\" An unknown player was detected \"PLAYER_NOT_FOUND\" The player was not discovered \"PLAYER_CONNECTION_REJECTED\" The connection to the player failed \"PLAYER_CONNECTION_TIMEOUT\" The connection to the player timed out The seek() and adjustSeek() methods are invokable via Alexa if the currently in-focus external player supports them. seek() specifies an absolute offset, whereas adjustSeek() specifies a relative offset. The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently-focused external player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . The getState() method is called to synchronize the external player's state with the cloud. This method is used to maintain correct state during startup, and after every Alexa request. You construct the ExternalMediaAdapterState object using the data taken from the media app connection client or embedded player app (associated via localPlayerId ) and return the state information. The following table describes the fields comprising a ExternalMediaAdapterState , which includes two sub-components: PlaybackState , and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedOperation trackOffset long No optional shuffleEnabled boolean Yes report shuffle status repeatEnabled boolean Yes report repeat status favorites Favorites No see Favorites type String Yes must be set as \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No empty trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType Yes see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean Yes true if the application is in an active state accessToken String No empty tokenRefreshInterval long No empty playerCookie String No A player may declare arbitrary information for itself spiVersion String Yes must be set as \"1.0\" supportedOperations should be a list of the operations that the external media adapter supports. Below is a list of all possible supportedOperations . SupportedPlaybackOperation.PLAY, SupportedPlaybackOperation.PAUSE, SupportedPlaybackOperation.STOP, SupportedPlaybackOperation.PREVIOUS, SupportedPlaybackOperation.NEXT, SupportedPlaybackOperation.ENABLE_SHUFFLE, SupportedPlaybackOperation.DISABLE_SHUFFLE, SupportedPlaybackOperation.ENABLE_REPEAT_ONE, SupportedPlaybackOperation.ENABLE_REPEAT, SupportedPlaybackOperation.DISABLE_REPEAT, SupportedPlaybackOperation.SEEK, SupportedPlaybackOperation.ADJUST_SEEK, SupportedPlaybackOperation.FAVORITE, SupportedPlaybackOperation.UNFAVORITE, SupportedPlaybackOperation.FAST_FORWARD, SupportedPlaybackOperation.REWIND, SupportedPlaybackOperation.START_OVER Note: Currently PLAY/PAUSE/STOP will always be supported for a source. Passing null will allow ALL supported operations for the source.","title":"ExternalMediaAdapter Interface"},{"location":"explore/features/alexa/FeatureDiscovery/","text":"FeatureDiscovery Interface \u00b6 Overview \u00b6 The Feature Discovery interface enables your Alexa Auto SDK client application to dynamically retrieve the Alexa utterances (hints) from the cloud, helping the customers to discover Alexa features and learn how to use Alexa in the different domains. To use the Feature Discovery functionality, your product must be onboarded and placed on the allow list by Amazon. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Auto SDK provides the FeatureDiscovery AASB message interface for your application to request a list of suggested utterances. In your application, publish the GetFeatures message to request a list of utterances associated with the specified domain and eventType . Subscribe to the GetFeatures reply message to receive the response. Note: The Auto SDK Engine does not cache the suggested utterances returned by Alexa. Therefore, your application is responsible for implementing caching mechanism for the utterances and deciding when to refresh the local cache. GetFeatures Request \u00b6 The GetFeatures message requests the suggested utterances from Alexa. The discoveryRequests field is a string containing an escaped JSON with the following format: [ { \"locale\" : {{String}}, \"domain\" : {{String}}, \"eventType\" : {{String}}, \"limit\": {{Integer}} }, ... ] Definition of the DiscoveryRequests JSON array: Property Type Required Description discoveryRequests List\\<DiscoveryRequest> Yes An array of feature discovery requests Definition of each DiscoveryRequest JSON Object: Property Type Required Description Example domain String Yes The category of the utterances to be returned. See the Domain and EventType section for the accepted values. \"ENTERTAINMENT\" eventType String Yes The event type of the utterances to be returned. The event type specifies what action or state change happened. See the Domain and EventType section for the accepted values. \"SETUP\" locale String No The locale of the utterances to be returned. If omitted, the Alexa locale retrieved by PropertyManager will be used in the request. For a list of the Alexa Voice Service (AVS) supported locales, see the Alexa Voice Service (AVS) documentation . \"en-US\" limit Integer No The maximum number of utterances to return. The default value is 1. 5 Note: When requesting the utterances, you can combine multiple discovery requests in one GetFeatures message by specifying multiple discovery request objects in the discoveryRequests JSON array. The Auto SDK Engine will reply with a single GetFeatures message that contains a merged response of the multiple requests. If you specify multiple request objects in the GetFeatures message, expect more latency to receive the message reply. Domain and EventType \u00b6 Each utterance configured in the Alexa cloud is associated with a scenario, which is a combination of domain and eventType . The combination determines where the utterance should be displayed. When requesting Alexa utterances, your application must specify the domain and eventType values in the GetFeatures message payload. Property Type Accepted Values domain String \"GETTING_STARTED\", \"TALENTS\", \"ENTERTAINMENT\", \"COMMS\", \"WEATHER\", \"SMART_HOME\", \"NEWS\", \"NAVIGATION\", \"TRAFFIC\", \"SKILLS\", \"LISTS\", \"SHOPPING\", \"QUESTIONS_ANSWERS\", \"SPORTS\" or \"CALENDAR\". eventType String \"THINGS_TO_TRY\" or \"SETUP\". The valid combinations of domain and eventType are as follows: Domain EventType Scenario Example Utterance \"GETTING_STARTED\" \"SETUP\" Hints displayed on the success page of the Alexa setup flow. \"Alexa, play music.\" \"Alexa, find a nearby gas station.\" \"GETTING_STARTED\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Getting Started\" category. \"Alexa, what\u2019s the weather?\" \"Alexa, what's my Flash Briefing?\" \"TALENTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Alexa's Talents\" category. \"Alexa, tell me a story.\" \"ENTERTAINMENT\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Entertainment\" category. \"Alexa, play rock music from the 70s.\" \"COMMS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Communication\" category. \"Alexa, send a message to John.\" \"WEATHER\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Weather\" category. \"Alexa, will it rain today?\" \"SMART_HOME\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Smart Home\" category. \"Alexa, lock the front door.\" \"NEWS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"News and Information\" category. \"Alexa, what\u2019s the news?\" \"NAVIGATION\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Navigation\" category. \"Alexa, take me to the airport.\" \"TRAFFIC\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Traffic Information\" category. \"Alexa, how\u2019s my commute to work?\" \"SKILLS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Skills\" category. \"Alexa, what automotive skills do you have?\" \"LISTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Lists\" category. \"Alexa, what's on my to-do list?\" \"SHOPPING\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Shopping\" category. \"Alexa, reorder toothpaste.\" \"QUESTIONS_ANSWERS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Questions and Answers\" category. \"Alexa, how far away is the moon?\" \"SPORTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Sports\" category. \"Alexa, what's my sports update?\" \"CALENDAR\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Calendar\" category. \"Alexa, add a 2:00 PM coffee chat to my calendar.\" GetFeatures Reply \u00b6 The GetFeaturesReply message returns the suggested utterances from the GetFeatures message request. The discoveryResponses field is a string containing an escaped JSON with the following format: [ { \"domain\" : {{String}}, \"eventType\" : {{String}}, \"locale\" : {{String}}, \"localizedContent\": [ { \"utteranceText\": {{String}}, \"descriptionText\": {{String}} } ] }, ... ] Definition of DiscoveryResponses JSON array: Property Type Required Description discoveryResponses List\\<DiscoveryResponse> Yes An array of feature discovery responses Definition of each DiscoveryResponse JSON Object: Property Type Description Example domain String The category of the utterances received. See the Domain and EventType section for the accepted values. \"ENTERTAINMENT\" eventType String The event type of the utterances received. The event type specifies what action or state change happened. See the Domain and EventType section for the accepted values. \"SETUP\" locale String The locale of the utterances received. \"en-US\" localizedContent List\\<LocalizedHint> An array of LocalizedHint objects. - Definition of the LocalizedHint JSON Object: Property Type Description Example utteranceText String The exact utterance for the feature. The utterance is represented in plain text. \"Alexa, what time is it?\" descriptionText String The description of the utterance. It can be an empty string if no description is found. \"You can ask Alexa about the time.\" Integrating the FeatureDiscovery messages Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the Engine's MessageBroker to publish FeatureDiscovery AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Alexa/FeatureDiscovery/GetFeaturesMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyFeatureDiscoveryHandler { // Subscribe to reply messages from the Engine void MyFeatureDiscoveryHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetFeaturesReplyMessage ( message ); }, GetFeaturesMessageReply :: topic (), GetFeaturesMessageReply :: action ()); } // Handle the GetFeaturesReply message from the Engine void MyFeatureDiscoveryHandler::handleGetFeaturesReplyMessage ( const std :: string & message ) { GetFeaturesMessageReply msg = json :: parse ( message ); parseDiscoveryResponses ( msg . payload . discoveryResponses ); } void MyFeatureDiscoveryHandler::parseDiscoveryResponses ( const std :: string & discoveryResponses ) { const auto & responseArray = json :: parse ( discoveryResponses ); if ( responseArray . empty ()) { // No feature was discovered, returning } else { for ( const auto & response : responseArray ) { if ( ! response . contains ( \"localizedContent\" ) || ! response [ \"localizedContent\" ]. is_array ()) { continue ; } for ( const auto & feature : response [ \"localizedContent\" ]) { if ( feature . contains ( \"utteranceText\" )) { // On another thread, do something with the utterances received... } } } } } // Construct and send the FeatureDiscovery requests. void MyFeatureDiscoveryHandler::getFeatures ( const std :: string & domain ) { json requestsArray = json :: array (); requestsArray . push_back ({{ \"domain\" , domain }, { \"eventType\" , \"THINGS_TO_TRY\" }, { \"limit\" , 5 }}); GetFeaturesMessage msg ; msg . payload . discoveryRequests = requestsArray . dump (); m_messageBroker -> publish ( msg . toString ()); } }; Android Integration \u00b6 The Alexa Auto Client Service (AACS) sample app provides a sample implementation to integrate the Auto SDK FeatureDiscovery messages on Android. See the Alexa Auto Settings App Component for the reference implementation.","title":"FeatureDiscovery"},{"location":"explore/features/alexa/FeatureDiscovery/#featurediscovery-interface","text":"","title":"FeatureDiscovery Interface"},{"location":"explore/features/alexa/FeatureDiscovery/#overview","text":"The Feature Discovery interface enables your Alexa Auto SDK client application to dynamically retrieve the Alexa utterances (hints) from the cloud, helping the customers to discover Alexa features and learn how to use Alexa in the different domains. To use the Feature Discovery functionality, your product must be onboarded and placed on the allow list by Amazon. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Auto SDK provides the FeatureDiscovery AASB message interface for your application to request a list of suggested utterances. In your application, publish the GetFeatures message to request a list of utterances associated with the specified domain and eventType . Subscribe to the GetFeatures reply message to receive the response. Note: The Auto SDK Engine does not cache the suggested utterances returned by Alexa. Therefore, your application is responsible for implementing caching mechanism for the utterances and deciding when to refresh the local cache.","title":"Overview"},{"location":"explore/features/alexa/FeatureDiscovery/#getfeatures-request","text":"The GetFeatures message requests the suggested utterances from Alexa. The discoveryRequests field is a string containing an escaped JSON with the following format: [ { \"locale\" : {{String}}, \"domain\" : {{String}}, \"eventType\" : {{String}}, \"limit\": {{Integer}} }, ... ] Definition of the DiscoveryRequests JSON array: Property Type Required Description discoveryRequests List\\<DiscoveryRequest> Yes An array of feature discovery requests Definition of each DiscoveryRequest JSON Object: Property Type Required Description Example domain String Yes The category of the utterances to be returned. See the Domain and EventType section for the accepted values. \"ENTERTAINMENT\" eventType String Yes The event type of the utterances to be returned. The event type specifies what action or state change happened. See the Domain and EventType section for the accepted values. \"SETUP\" locale String No The locale of the utterances to be returned. If omitted, the Alexa locale retrieved by PropertyManager will be used in the request. For a list of the Alexa Voice Service (AVS) supported locales, see the Alexa Voice Service (AVS) documentation . \"en-US\" limit Integer No The maximum number of utterances to return. The default value is 1. 5 Note: When requesting the utterances, you can combine multiple discovery requests in one GetFeatures message by specifying multiple discovery request objects in the discoveryRequests JSON array. The Auto SDK Engine will reply with a single GetFeatures message that contains a merged response of the multiple requests. If you specify multiple request objects in the GetFeatures message, expect more latency to receive the message reply.","title":"GetFeatures Request"},{"location":"explore/features/alexa/FeatureDiscovery/#domain-and-eventtype","text":"Each utterance configured in the Alexa cloud is associated with a scenario, which is a combination of domain and eventType . The combination determines where the utterance should be displayed. When requesting Alexa utterances, your application must specify the domain and eventType values in the GetFeatures message payload. Property Type Accepted Values domain String \"GETTING_STARTED\", \"TALENTS\", \"ENTERTAINMENT\", \"COMMS\", \"WEATHER\", \"SMART_HOME\", \"NEWS\", \"NAVIGATION\", \"TRAFFIC\", \"SKILLS\", \"LISTS\", \"SHOPPING\", \"QUESTIONS_ANSWERS\", \"SPORTS\" or \"CALENDAR\". eventType String \"THINGS_TO_TRY\" or \"SETUP\". The valid combinations of domain and eventType are as follows: Domain EventType Scenario Example Utterance \"GETTING_STARTED\" \"SETUP\" Hints displayed on the success page of the Alexa setup flow. \"Alexa, play music.\" \"Alexa, find a nearby gas station.\" \"GETTING_STARTED\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Getting Started\" category. \"Alexa, what\u2019s the weather?\" \"Alexa, what's my Flash Briefing?\" \"TALENTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Alexa's Talents\" category. \"Alexa, tell me a story.\" \"ENTERTAINMENT\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Entertainment\" category. \"Alexa, play rock music from the 70s.\" \"COMMS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Communication\" category. \"Alexa, send a message to John.\" \"WEATHER\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Weather\" category. \"Alexa, will it rain today?\" \"SMART_HOME\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Smart Home\" category. \"Alexa, lock the front door.\" \"NEWS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"News and Information\" category. \"Alexa, what\u2019s the news?\" \"NAVIGATION\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Navigation\" category. \"Alexa, take me to the airport.\" \"TRAFFIC\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Traffic Information\" category. \"Alexa, how\u2019s my commute to work?\" \"SKILLS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Skills\" category. \"Alexa, what automotive skills do you have?\" \"LISTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Lists\" category. \"Alexa, what's on my to-do list?\" \"SHOPPING\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Shopping\" category. \"Alexa, reorder toothpaste.\" \"QUESTIONS_ANSWERS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Questions and Answers\" category. \"Alexa, how far away is the moon?\" \"SPORTS\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Sports\" category. \"Alexa, what's my sports update?\" \"CALENDAR\" \"THINGS_TO_TRY\" Hints displayed in the Things-to-Try settings menu under the \"Calendar\" category. \"Alexa, add a 2:00 PM coffee chat to my calendar.\"","title":"Domain and EventType"},{"location":"explore/features/alexa/FeatureDiscovery/#getfeatures-reply","text":"The GetFeaturesReply message returns the suggested utterances from the GetFeatures message request. The discoveryResponses field is a string containing an escaped JSON with the following format: [ { \"domain\" : {{String}}, \"eventType\" : {{String}}, \"locale\" : {{String}}, \"localizedContent\": [ { \"utteranceText\": {{String}}, \"descriptionText\": {{String}} } ] }, ... ] Definition of DiscoveryResponses JSON array: Property Type Required Description discoveryResponses List\\<DiscoveryResponse> Yes An array of feature discovery responses Definition of each DiscoveryResponse JSON Object: Property Type Description Example domain String The category of the utterances received. See the Domain and EventType section for the accepted values. \"ENTERTAINMENT\" eventType String The event type of the utterances received. The event type specifies what action or state change happened. See the Domain and EventType section for the accepted values. \"SETUP\" locale String The locale of the utterances received. \"en-US\" localizedContent List\\<LocalizedHint> An array of LocalizedHint objects. - Definition of the LocalizedHint JSON Object: Property Type Description Example utteranceText String The exact utterance for the feature. The utterance is represented in plain text. \"Alexa, what time is it?\" descriptionText String The description of the utterance. It can be an empty string if no description is found. \"You can ask Alexa about the time.\"","title":"GetFeatures Reply"},{"location":"explore/features/alexa/FeatureDiscovery/#integrating-the-featurediscovery-messages-into-your-application","text":"","title":"Integrating the FeatureDiscovery messages Into Your Application"},{"location":"explore/features/alexa/FeatureDiscovery/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to publish FeatureDiscovery AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Alexa/FeatureDiscovery/GetFeaturesMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyFeatureDiscoveryHandler { // Subscribe to reply messages from the Engine void MyFeatureDiscoveryHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetFeaturesReplyMessage ( message ); }, GetFeaturesMessageReply :: topic (), GetFeaturesMessageReply :: action ()); } // Handle the GetFeaturesReply message from the Engine void MyFeatureDiscoveryHandler::handleGetFeaturesReplyMessage ( const std :: string & message ) { GetFeaturesMessageReply msg = json :: parse ( message ); parseDiscoveryResponses ( msg . payload . discoveryResponses ); } void MyFeatureDiscoveryHandler::parseDiscoveryResponses ( const std :: string & discoveryResponses ) { const auto & responseArray = json :: parse ( discoveryResponses ); if ( responseArray . empty ()) { // No feature was discovered, returning } else { for ( const auto & response : responseArray ) { if ( ! response . contains ( \"localizedContent\" ) || ! response [ \"localizedContent\" ]. is_array ()) { continue ; } for ( const auto & feature : response [ \"localizedContent\" ]) { if ( feature . contains ( \"utteranceText\" )) { // On another thread, do something with the utterances received... } } } } } // Construct and send the FeatureDiscovery requests. void MyFeatureDiscoveryHandler::getFeatures ( const std :: string & domain ) { json requestsArray = json :: array (); requestsArray . push_back ({{ \"domain\" , domain }, { \"eventType\" , \"THINGS_TO_TRY\" }, { \"limit\" , 5 }}); GetFeaturesMessage msg ; msg . payload . discoveryRequests = requestsArray . dump (); m_messageBroker -> publish ( msg . toString ()); } };","title":"C++ MessageBroker Integration"},{"location":"explore/features/alexa/FeatureDiscovery/#android-integration","text":"The Alexa Auto Client Service (AACS) sample app provides a sample implementation to integrate the Auto SDK FeatureDiscovery messages on Android. See the Alexa Auto Settings App Component for the reference implementation.","title":"Android Integration"},{"location":"explore/features/alexa/LocalMediaSource/","text":"LocalMediaSource Interface \u00b6 Overview \u00b6 The LocalMediaSource interface allows the platform to register a local media source by type ( BLUETOOTH , USB , AM_RADIO , FM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT ). Registering a local media source allows playback control of that source via Alexa (e.g. \"Alexa, play the CD player\"). It also enables playback initiation via Alexa by frequency, channel, or preset for relevant source types (e.g. \"Alexa, play 98.7 FM\"). DEFAULT media source is a generic media source that can be used for controlling any local media source on the OEM infotainment system. It is recommended to use DEFAULT media source for all local media except Alexa music, MACC-supported deep linked media players, and other registered Local Media Sources. DEFAULT media player can not be launched by name like \"Alexa, Play CD player\" but it can be used to control playback actions reported in the supportedOperations . For example, \"Alexa, play\" resumes the default player playback as long a the DEFAULT source is in focus . The following is an example of registering a CD player local media source using type Source.COMPACT_DISC : auto m_CDLocalMediaSource = std::make_shared<MyCDLocalMediaSource>( Source.COMPACT_DISC ); engine->registerPlatformInterface( m_CDLocalMediaSource ); To implement a custom handler for a CD player local media source extend the LocalMediaSource class: #include <AACE/Alexa/LocalMediaSource.h> class MyCDLocalMediaSource : public aace::alexa::LocalMediaSource { public: MyCDLocalMediaSource( LocalMediaSource::Source source ) { m_source = source; ... } ... }; ... Starting Playback with Content Selection by Voice \u00b6 The play() method is called when Alexa invokes play by ContentSelector type ( FREQUENCY , CHANNEL , PRESET ) for a radio local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM , DAB ). The payload is a string that depends on the ContentSelector type and local media Source type (e.g., \"1\", \"98.7 FM HD 1\"). bool play( ContentSelector type, std::string payload, const std::string& sessionId ) override { // play initiation for frequency, channel, or presets ... } The table below provides details about the supported ContentSelector types based on Source type: Source type Supported content selector(s) FM FREQUENCY, PRESET AM FREQUENCY, PRESET SXM CHANNEL, PRESET DAB CHANNEL DEFAULT PRESET The supported ranges and increments for valid frequency, preset, and channel may vary depending on the region you are in. Contact your partner manager for more detailed information. Note: The DAB channel payload is the radio station name string. If supported, then the name string must be handled by the client's DAB implementation. The play() method will not be invoked if a source cannot handle the specified ContentSelector type. The DEFAULT Local Media Source handles \"Alexa, play preset \\ \\\" utterances without requiring that users explicitly say which local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM ) actually corresponds to the preset. The meaning of the preset in the payload parameter of play(ContentSelector contentSelectorType, const std::string& payload, const std::string& sessionId) is determined by the DEFAULT platform implementation and should suit the needs of the vehicle's infotainment system, i.e. when the play() method is called, your implementation should map the preset to a preset that makes sense for the current context. Note: The GlobalPreset platform interface is deprecated. Use DEFAULT LocalMediaSource instead. Controlling Playback by Voice \u00b6 The playControl() method is called with a PlayControlType ( RESUME , PAUSE , STOP , NEXT , PREVIOUS , START_OVER , FAST_FORWARD , REWIND , ENABLE_REPEAT_ONE , ENABLE_REPEAT , DISABLE_REPEAT , ENABLE_SHUFFLE , DISABLE_SHUFFLE , FAVORITE , UNFAVORITE ) when Alexa invokes a playback control on the local media source. bool playControl( PlayControlType controlType ) override { // handle the control type appropriately for CD player return true; } Note: The play() method is used to initiate playback with specified content selection, whereas playControl(RESUME) is used to play or resume the source when content is not specified or not supported. E.g. FM receives play() when the user requests FM with a specific frequency (\"Alexa, play 98.7 FM radio\"), and USB receives playControl(RESUME) when the user requests playback with just the source name (\"Alexa, play USB\"). The seek() and adjustSeek() methods are invoked to seek the currently focused LocalMediaSource . These methods are only used by sources that are capable of seeking. seek() is for specifying an absolute offset, whereas adjustSeek() is for specifying a relative offset. bool seek( long offset ) override { // handle seeking CD player } ... bool adjustSeek( long offset ) override { // handle adjusting seek for CD player } The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently focused local media player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . @Override public boolean volumeChanged( float volume ) { // handle volume change } ... @Override public boolean mutedStateChanged( MutedState state ) { // handle setting mute state } ... Reporting Playback Events \u00b6 The LocalMediaSource interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your local source. Even though your local source manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your local source's playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your local source's state. Particular event names indicate if the source is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. playerEvent() event name Description \"PlaybackSessionStarted\" The local media source is switched from the inactive to active media state or a new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackSessionEnded\" The local media source is switched from the active to inactive media state or an active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. \"PlaybackStarted\" During an active session, the local source has started to play or resumed from a paused state. \"PlaybackStopped\" During an active session, the player stopped, either as a result of a GUI interaction or a user voice request to Alexa. playerError() event name Description \"INTERNAL_ERROR\" During an active session, an internal error caused playback to stop. Both playerEvent() and playerError() are expected to provide the appropriate sessionId. Call playerEvent(\"PlaybackSessionStarted\", sessionId) to tell the Engine that the user brought the LocalMediaSource to the foreground with a GUI interaction. The Engine considers the source to have an active playback session, although it may or may not be playing yet. If no other Alexa media source is playing, utterances such as \u201cAlexa, play\u201d target this source. You must also call playerEvent(\"PlaybackSessionStarted\", sessionId) when the source is brought into the foreground by a call to play() or playControl() as a result of a user voice request. Once the source starts playing, call playerEvent(\"PlaybackStarted\", sessionId) . Call playerEvent(\"PlaybackSessionEnded\", sessionId) to tell the Engine that the LocalMediaSource is no longer in the foreground, typically as a result of a GUI interaction from the user after the player is stopped. The Engine considers the source inactive or not in focus, and starting a new playback session for the source requires a further GUI interaction or user voice request to Alexa that targets the source by name. class MyFMRadioLocalMediaSource : public aace::alexa::LocalMediaSource { ... // public method in source handler void setAlexaFocusForFMRadio( bool isFocused ) { ... if (isFocused) { ... // FM Radio begins playback independently of Alexa playerEvent(\"PlaybackSessionStarted\", m_sessionId); } else { ... // Notify Alexa that FM Radio is no longer the active media source on the device as a result of platform driven change playerEvent(\"PlaybackSessionEnded\", m_sessionId); } ... } ... Note: Only one LocalMediaSource type can have Alexa focus at a time. Note: setFocus() and setFocus(bool) methods are deprecated for the LocalMediaSource platform interface. playerEvent() with \"PlaybackSessionStarted\" or \"PlaybackSessionEnded\" should be used instead of setFocus(true) and setFocus(false) . Please abide by following rules related to sessionId in your LocalMediaSource integration: sessionId is a universally unique identifier (UUID) generated according to the RFC 4122 specification. If a media source starts because of a call to play(contentSelector, payload, sessionId) from the Engine, note the sessionId parameter and use it in any playerEvent() calls until the session is inactive. If a media source starts for any other reason (e.g. a call to playControl(RESUME) from the Engine, or user GUI interaction on the head unit), create a new sessionId and use it in any playerEvent() calls until the session is inactive. A sessionId is always associated with one media source playback session, so USB 's sessionId should be different than COMPACT_DISC 's sessionId . An individual LocalMediaSource should maintain the sessionId for the whole cycle from playback session start to playback session end. For any \"opening\" playerEvent() call for a particular sessionId (e.g. \"PlaybackSessionStarted\" , \"PlaybackStarted\" ), you must report a corresponding closing call (e.g. \"PlaybackStopped\" , \"PlaybackSessionEnded\" ) at the appropriate time (i.e., when the source is stopped, switched, etc.) Reporting Playback State \u00b6 The getState() method is called to synchronize the local player's state with the cloud. This method is used to maintain correct state during startup and with every Alexa request. All relevant information should be added to the LocalMediaSourceState and returned. Many fields of the LocalMediaSourceState are not required for local media source players. You should omit these as noted below. LocalMediaSourceState getState() override { LocalMediaSourceState stateToReturn = std::make_shared<LocalMediaSourceState>(); stateToReturn.playbackState.albumName = \"mock albumName\"; // fill in all required state information (see below) return stateToReturn; } The following table describes the fields comprising a LocalMediaSourceState , which includes two sub-components: PlaybackState and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedPlaybackOperation trackOffset long No optional shuffleEnabled boolean No optional repeatEnabled boolean No optional favorites Favorites No see Favorites type String Yes must be set to \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No optional trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType No see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean No empty accessToken String No empty tokenRefreshInterval long No empty supportedContentSelectors ContentSelector[] No see ContentSelector spiVersion String Yes must be \"1.0\" supportedOperations should list the operations that the local media source supports. Below is a list of all SupportedPlaybackOperation : LocalMediaSource::SupportedPlaybackOperation::PLAY, LocalMediaSource::SupportedPlaybackOperation::PAUSE, LocalMediaSource::SupportedPlaybackOperation::STOP, LocalMediaSource::SupportedPlaybackOperation::PREVIOUS, LocalMediaSource::SupportedPlaybackOperation::NEXT, LocalMediaSource::SupportedPlaybackOperation::ENABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::DISABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT_ONE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::DISABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::SEEK, LocalMediaSource::SupportedPlaybackOperation::ADJUST_SEEK, LocalMediaSource::SupportedPlaybackOperation::FAVORITE, LocalMediaSource::SupportedPlaybackOperation::UNFAVORITE, LocalMediaSource::SupportedPlaybackOperation::FAST_FORWARD, LocalMediaSource::SupportedPlaybackOperation::REWIND, LocalMediaSource::SupportedPlaybackOperation::START_OVER Note: Currently PLAY/PAUSE/STOP are always supported for a source. Passing null allows ALL supported operations for the source. supportedContentSelectors should list the content selection types the local source can support. Below is a table of valid pairs. Source Supportable ContentSelector Values AM_RADIO PRESET , FREQUENCY FM_RADIO PRESET , FREQUENCY SIRIUS_XM PRESET , CHANNEL DEFAULT PRESET launched specifies whether the source is enabled. The player is disabled for use with Alexa when this value is false, such as when a removable source like USB is disconnected. Example Sequence Diagrams \u00b6 The following diagrams show examples of Local Media Source usage: 1. Starting FM by voice 2. Switching from FM to DEFAULT media source with GUI 3. Switching between different DEFAULT sources","title":"LocalMediaSource"},{"location":"explore/features/alexa/LocalMediaSource/#localmediasource-interface","text":"","title":"LocalMediaSource Interface"},{"location":"explore/features/alexa/LocalMediaSource/#overview","text":"The LocalMediaSource interface allows the platform to register a local media source by type ( BLUETOOTH , USB , AM_RADIO , FM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT ). Registering a local media source allows playback control of that source via Alexa (e.g. \"Alexa, play the CD player\"). It also enables playback initiation via Alexa by frequency, channel, or preset for relevant source types (e.g. \"Alexa, play 98.7 FM\"). DEFAULT media source is a generic media source that can be used for controlling any local media source on the OEM infotainment system. It is recommended to use DEFAULT media source for all local media except Alexa music, MACC-supported deep linked media players, and other registered Local Media Sources. DEFAULT media player can not be launched by name like \"Alexa, Play CD player\" but it can be used to control playback actions reported in the supportedOperations . For example, \"Alexa, play\" resumes the default player playback as long a the DEFAULT source is in focus . The following is an example of registering a CD player local media source using type Source.COMPACT_DISC : auto m_CDLocalMediaSource = std::make_shared<MyCDLocalMediaSource>( Source.COMPACT_DISC ); engine->registerPlatformInterface( m_CDLocalMediaSource ); To implement a custom handler for a CD player local media source extend the LocalMediaSource class: #include <AACE/Alexa/LocalMediaSource.h> class MyCDLocalMediaSource : public aace::alexa::LocalMediaSource { public: MyCDLocalMediaSource( LocalMediaSource::Source source ) { m_source = source; ... } ... }; ...","title":"Overview"},{"location":"explore/features/alexa/LocalMediaSource/#starting-playback-with-content-selection-by-voice","text":"The play() method is called when Alexa invokes play by ContentSelector type ( FREQUENCY , CHANNEL , PRESET ) for a radio local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM , DAB ). The payload is a string that depends on the ContentSelector type and local media Source type (e.g., \"1\", \"98.7 FM HD 1\"). bool play( ContentSelector type, std::string payload, const std::string& sessionId ) override { // play initiation for frequency, channel, or presets ... } The table below provides details about the supported ContentSelector types based on Source type: Source type Supported content selector(s) FM FREQUENCY, PRESET AM FREQUENCY, PRESET SXM CHANNEL, PRESET DAB CHANNEL DEFAULT PRESET The supported ranges and increments for valid frequency, preset, and channel may vary depending on the region you are in. Contact your partner manager for more detailed information. Note: The DAB channel payload is the radio station name string. If supported, then the name string must be handled by the client's DAB implementation. The play() method will not be invoked if a source cannot handle the specified ContentSelector type. The DEFAULT Local Media Source handles \"Alexa, play preset \\ \\\" utterances without requiring that users explicitly say which local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM ) actually corresponds to the preset. The meaning of the preset in the payload parameter of play(ContentSelector contentSelectorType, const std::string& payload, const std::string& sessionId) is determined by the DEFAULT platform implementation and should suit the needs of the vehicle's infotainment system, i.e. when the play() method is called, your implementation should map the preset to a preset that makes sense for the current context. Note: The GlobalPreset platform interface is deprecated. Use DEFAULT LocalMediaSource instead.","title":"Starting Playback with Content Selection by Voice"},{"location":"explore/features/alexa/LocalMediaSource/#controlling-playback-by-voice","text":"The playControl() method is called with a PlayControlType ( RESUME , PAUSE , STOP , NEXT , PREVIOUS , START_OVER , FAST_FORWARD , REWIND , ENABLE_REPEAT_ONE , ENABLE_REPEAT , DISABLE_REPEAT , ENABLE_SHUFFLE , DISABLE_SHUFFLE , FAVORITE , UNFAVORITE ) when Alexa invokes a playback control on the local media source. bool playControl( PlayControlType controlType ) override { // handle the control type appropriately for CD player return true; } Note: The play() method is used to initiate playback with specified content selection, whereas playControl(RESUME) is used to play or resume the source when content is not specified or not supported. E.g. FM receives play() when the user requests FM with a specific frequency (\"Alexa, play 98.7 FM radio\"), and USB receives playControl(RESUME) when the user requests playback with just the source name (\"Alexa, play USB\"). The seek() and adjustSeek() methods are invoked to seek the currently focused LocalMediaSource . These methods are only used by sources that are capable of seeking. seek() is for specifying an absolute offset, whereas adjustSeek() is for specifying a relative offset. bool seek( long offset ) override { // handle seeking CD player } ... bool adjustSeek( long offset ) override { // handle adjusting seek for CD player } The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently focused local media player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . @Override public boolean volumeChanged( float volume ) { // handle volume change } ... @Override public boolean mutedStateChanged( MutedState state ) { // handle setting mute state } ...","title":"Controlling Playback by Voice"},{"location":"explore/features/alexa/LocalMediaSource/#reporting-playback-events","text":"The LocalMediaSource interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your local source. Even though your local source manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your local source's playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your local source's state. Particular event names indicate if the source is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. playerEvent() event name Description \"PlaybackSessionStarted\" The local media source is switched from the inactive to active media state or a new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackSessionEnded\" The local media source is switched from the active to inactive media state or an active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. \"PlaybackStarted\" During an active session, the local source has started to play or resumed from a paused state. \"PlaybackStopped\" During an active session, the player stopped, either as a result of a GUI interaction or a user voice request to Alexa. playerError() event name Description \"INTERNAL_ERROR\" During an active session, an internal error caused playback to stop. Both playerEvent() and playerError() are expected to provide the appropriate sessionId. Call playerEvent(\"PlaybackSessionStarted\", sessionId) to tell the Engine that the user brought the LocalMediaSource to the foreground with a GUI interaction. The Engine considers the source to have an active playback session, although it may or may not be playing yet. If no other Alexa media source is playing, utterances such as \u201cAlexa, play\u201d target this source. You must also call playerEvent(\"PlaybackSessionStarted\", sessionId) when the source is brought into the foreground by a call to play() or playControl() as a result of a user voice request. Once the source starts playing, call playerEvent(\"PlaybackStarted\", sessionId) . Call playerEvent(\"PlaybackSessionEnded\", sessionId) to tell the Engine that the LocalMediaSource is no longer in the foreground, typically as a result of a GUI interaction from the user after the player is stopped. The Engine considers the source inactive or not in focus, and starting a new playback session for the source requires a further GUI interaction or user voice request to Alexa that targets the source by name. class MyFMRadioLocalMediaSource : public aace::alexa::LocalMediaSource { ... // public method in source handler void setAlexaFocusForFMRadio( bool isFocused ) { ... if (isFocused) { ... // FM Radio begins playback independently of Alexa playerEvent(\"PlaybackSessionStarted\", m_sessionId); } else { ... // Notify Alexa that FM Radio is no longer the active media source on the device as a result of platform driven change playerEvent(\"PlaybackSessionEnded\", m_sessionId); } ... } ... Note: Only one LocalMediaSource type can have Alexa focus at a time. Note: setFocus() and setFocus(bool) methods are deprecated for the LocalMediaSource platform interface. playerEvent() with \"PlaybackSessionStarted\" or \"PlaybackSessionEnded\" should be used instead of setFocus(true) and setFocus(false) . Please abide by following rules related to sessionId in your LocalMediaSource integration: sessionId is a universally unique identifier (UUID) generated according to the RFC 4122 specification. If a media source starts because of a call to play(contentSelector, payload, sessionId) from the Engine, note the sessionId parameter and use it in any playerEvent() calls until the session is inactive. If a media source starts for any other reason (e.g. a call to playControl(RESUME) from the Engine, or user GUI interaction on the head unit), create a new sessionId and use it in any playerEvent() calls until the session is inactive. A sessionId is always associated with one media source playback session, so USB 's sessionId should be different than COMPACT_DISC 's sessionId . An individual LocalMediaSource should maintain the sessionId for the whole cycle from playback session start to playback session end. For any \"opening\" playerEvent() call for a particular sessionId (e.g. \"PlaybackSessionStarted\" , \"PlaybackStarted\" ), you must report a corresponding closing call (e.g. \"PlaybackStopped\" , \"PlaybackSessionEnded\" ) at the appropriate time (i.e., when the source is stopped, switched, etc.)","title":"Reporting Playback Events"},{"location":"explore/features/alexa/LocalMediaSource/#reporting-playback-state","text":"The getState() method is called to synchronize the local player's state with the cloud. This method is used to maintain correct state during startup and with every Alexa request. All relevant information should be added to the LocalMediaSourceState and returned. Many fields of the LocalMediaSourceState are not required for local media source players. You should omit these as noted below. LocalMediaSourceState getState() override { LocalMediaSourceState stateToReturn = std::make_shared<LocalMediaSourceState>(); stateToReturn.playbackState.albumName = \"mock albumName\"; // fill in all required state information (see below) return stateToReturn; } The following table describes the fields comprising a LocalMediaSourceState , which includes two sub-components: PlaybackState and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedPlaybackOperation trackOffset long No optional shuffleEnabled boolean No optional repeatEnabled boolean No optional favorites Favorites No see Favorites type String Yes must be set to \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No optional trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType No see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean No empty accessToken String No empty tokenRefreshInterval long No empty supportedContentSelectors ContentSelector[] No see ContentSelector spiVersion String Yes must be \"1.0\" supportedOperations should list the operations that the local media source supports. Below is a list of all SupportedPlaybackOperation : LocalMediaSource::SupportedPlaybackOperation::PLAY, LocalMediaSource::SupportedPlaybackOperation::PAUSE, LocalMediaSource::SupportedPlaybackOperation::STOP, LocalMediaSource::SupportedPlaybackOperation::PREVIOUS, LocalMediaSource::SupportedPlaybackOperation::NEXT, LocalMediaSource::SupportedPlaybackOperation::ENABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::DISABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT_ONE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::DISABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::SEEK, LocalMediaSource::SupportedPlaybackOperation::ADJUST_SEEK, LocalMediaSource::SupportedPlaybackOperation::FAVORITE, LocalMediaSource::SupportedPlaybackOperation::UNFAVORITE, LocalMediaSource::SupportedPlaybackOperation::FAST_FORWARD, LocalMediaSource::SupportedPlaybackOperation::REWIND, LocalMediaSource::SupportedPlaybackOperation::START_OVER Note: Currently PLAY/PAUSE/STOP are always supported for a source. Passing null allows ALL supported operations for the source. supportedContentSelectors should list the content selection types the local source can support. Below is a table of valid pairs. Source Supportable ContentSelector Values AM_RADIO PRESET , FREQUENCY FM_RADIO PRESET , FREQUENCY SIRIUS_XM PRESET , CHANNEL DEFAULT PRESET launched specifies whether the source is enabled. The player is disabled for use with Alexa when this value is false, such as when a removable source like USB is disconnected.","title":"Reporting Playback State"},{"location":"explore/features/alexa/LocalMediaSource/#example-sequence-diagrams","text":"The following diagrams show examples of Local Media Source usage: 1. Starting FM by voice 2. Switching from FM to DEFAULT media source with GUI 3. Switching between different DEFAULT sources","title":"Example Sequence Diagrams"},{"location":"explore/features/alexa/MediaPlaybackRequestor/","text":"MediaPlaybackRequestor Interface \u00b6 Alexa Media-Resume is a feature that helps Alexa play customers\u2019 favorite content when they start their Alexa-enabled vehicles. Media-resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. To resume the media, Alexa auto SDK needs to send RequestMediaPlayback event with the Invocation reason AUTOMOTIVE_STARTUP . To implement a handler, extend the aace::alexa::MediaPlaybackRequestor class: #include <AACE/Alexa/MediaPlaybackRequestor.h> class MediaPlaybackRequestorHandler : public aace::alexa::MediaPlaybackRequestor { public: void mediaPlaybackResponse(MediaPlaybackRequestStatus mediaPlaybackRequestStatus) override { //Handle the status change } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MediaPlaybackRequestorHandler>()); requestMediaPlayback is the API to send the event to the cloud. This API needs InvocationReason and elapsedBootTime as input parameters. mediaPlaybackResponse callback receives the status of the requestMediaPlayback API call asynchronously. InvocationReason enum indicates the invocation reason for calling the event. AUTOMOTIVE_STARTUP represents a situation where platform automatically calls requestMediaPlayback API to automatically resume the media after infotainment system reboot. EXPLICIT_USER_ACTION represents resuming the media after explicit driver action by pressing the button or switch. Music resuming on EXPLICIT_USER_ACTION is not yet supported and this will be enabled in the future. Please check with your partner manager before using this action. MediaPlaybackRequestStatus enum indicate the status of the requestMediaPlayback API call. SUCCESS means RequestMediaPlayback event is successfully reported to the cloud. FAILED_CAN_RETRY means requestMediaPlayback API call can not be processed because Alexa Auto SDK is not in the connected state but platform implementation can retry after some time. FAILED_TIMEOUT means threshold time is crossed and media can not be resumed now. Driver can play media by making a voice request. ERROR means API could not be called successfully and media can not be resumed. This feature needs following configuration. Please contact to your partner manager for finalizing the threshold numbers. \"aace.alexa\": { \"requestMediaPlayback\": { \"mediaResumeThreshold\": 30000 } } mediaResumeThreshold is the maximum time in milliseconds to receive the requestMediaPlayback API call from the platform implementation. Platform implementation should consider their boot time, time to initialize alexa and get connected to send the RequestMediaPlayback event successfully. Platform team and partner manager should try to keep this time minimum for the better user experience. Delayed media resume can surprise driver and result in driver distraction. Note: This feature assumes that client platform maintains the media sessions and request individual media applications to resume playback if that media application was active and playing before the device shuts down. Note: requestMediaPlayback API call expects a elapsed boot time i.e. number of milliseconds elapsed from the device boot up. This feature assumes that client platform provides the correct value using their proprietary methods. The mediaResumeThreshold value and elapsedBootTime value are compared together for the guardrail condition.","title":"MediaPlaybackRequestor"},{"location":"explore/features/alexa/MediaPlaybackRequestor/#mediaplaybackrequestor-interface","text":"Alexa Media-Resume is a feature that helps Alexa play customers\u2019 favorite content when they start their Alexa-enabled vehicles. Media-resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. To resume the media, Alexa auto SDK needs to send RequestMediaPlayback event with the Invocation reason AUTOMOTIVE_STARTUP . To implement a handler, extend the aace::alexa::MediaPlaybackRequestor class: #include <AACE/Alexa/MediaPlaybackRequestor.h> class MediaPlaybackRequestorHandler : public aace::alexa::MediaPlaybackRequestor { public: void mediaPlaybackResponse(MediaPlaybackRequestStatus mediaPlaybackRequestStatus) override { //Handle the status change } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MediaPlaybackRequestorHandler>()); requestMediaPlayback is the API to send the event to the cloud. This API needs InvocationReason and elapsedBootTime as input parameters. mediaPlaybackResponse callback receives the status of the requestMediaPlayback API call asynchronously. InvocationReason enum indicates the invocation reason for calling the event. AUTOMOTIVE_STARTUP represents a situation where platform automatically calls requestMediaPlayback API to automatically resume the media after infotainment system reboot. EXPLICIT_USER_ACTION represents resuming the media after explicit driver action by pressing the button or switch. Music resuming on EXPLICIT_USER_ACTION is not yet supported and this will be enabled in the future. Please check with your partner manager before using this action. MediaPlaybackRequestStatus enum indicate the status of the requestMediaPlayback API call. SUCCESS means RequestMediaPlayback event is successfully reported to the cloud. FAILED_CAN_RETRY means requestMediaPlayback API call can not be processed because Alexa Auto SDK is not in the connected state but platform implementation can retry after some time. FAILED_TIMEOUT means threshold time is crossed and media can not be resumed now. Driver can play media by making a voice request. ERROR means API could not be called successfully and media can not be resumed. This feature needs following configuration. Please contact to your partner manager for finalizing the threshold numbers. \"aace.alexa\": { \"requestMediaPlayback\": { \"mediaResumeThreshold\": 30000 } } mediaResumeThreshold is the maximum time in milliseconds to receive the requestMediaPlayback API call from the platform implementation. Platform implementation should consider their boot time, time to initialize alexa and get connected to send the RequestMediaPlayback event successfully. Platform team and partner manager should try to keep this time minimum for the better user experience. Delayed media resume can surprise driver and result in driver distraction. Note: This feature assumes that client platform maintains the media sessions and request individual media applications to resume playback if that media application was active and playing before the device shuts down. Note: requestMediaPlayback API call expects a elapsed boot time i.e. number of milliseconds elapsed from the device boot up. This feature assumes that client platform provides the correct value using their proprietary methods. The mediaResumeThreshold value and elapsedBootTime value are compared together for the guardrail condition.","title":"MediaPlaybackRequestor Interface"},{"location":"explore/features/alexa/Notifications/","text":"Notifications Interface \u00b6 It is the responsibility of the platform implementation to provide a visual indication to the user when notifications (for example, package shipment notifications, notifications from skills, etc.) are available from Alexa. See the AVS Notifications interface documentation for more information about notifications. The Engine uses the registered Notifications implementation to notify you when a notification indicator should be displayed or removed. It does not give any information about the notifications. Audio playback for the notification is handled by whichever audio channel is assigned to the NOTIFICATION type. To implement a custom handler for Notifications extend the Notifications class: #include <AACE/Alexa/Notifications.h> using IndicatorState = aace::alexa::Notifications::IndicatorState; class MyNotificationsHandler : public aace::alexa::Notifications { public: void setIndicator( IndicatorState state ) override { // set your notifications indicator! } }; ... // Register the platform interface with the Engine auto m_notificationsHandler = std::make_shared<MyNotificationsHandler>(); engine->registerPlatformInterface(m_notificationsHandler);","title":"Notifications"},{"location":"explore/features/alexa/Notifications/#notifications-interface","text":"It is the responsibility of the platform implementation to provide a visual indication to the user when notifications (for example, package shipment notifications, notifications from skills, etc.) are available from Alexa. See the AVS Notifications interface documentation for more information about notifications. The Engine uses the registered Notifications implementation to notify you when a notification indicator should be displayed or removed. It does not give any information about the notifications. Audio playback for the notification is handled by whichever audio channel is assigned to the NOTIFICATION type. To implement a custom handler for Notifications extend the Notifications class: #include <AACE/Alexa/Notifications.h> using IndicatorState = aace::alexa::Notifications::IndicatorState; class MyNotificationsHandler : public aace::alexa::Notifications { public: void setIndicator( IndicatorState state ) override { // set your notifications indicator! } }; ... // Register the platform interface with the Engine auto m_notificationsHandler = std::make_shared<MyNotificationsHandler>(); engine->registerPlatformInterface(m_notificationsHandler);","title":"Notifications Interface"},{"location":"explore/features/alexa/PlaybackController/","text":"PlaybackController Interface \u00b6 The Engine provides a platform interface aace::alexa::PlaybackController for the platform implementation to report on-device transport control button presses for media playing through Alexa. For example, if the user presses the on-screen pause button while listening to Amazon Music through Alexa's AudioPlayer interface, the platform implementation calls a PlaybackController method to report the button press to the Engine. Note: PlaybackController method calls to manage AudioPlayer 's state or playback queue proactively report button presses or the equivalent so that Alexa can react; they do not report changes to the playback state that happen locally first. The Alexa cloud manages the playback queue for AudioPlayer content, so each PlaybackController method call is a request for Alexa to act on the user's local request. The result of the request will come as one or more method invocations on the AudioOutput associated with the channel used for AudioPlayer . Note: If your implementation needs to stop AudioPlayer media in response to system events, such as audio focus transitions to audio playing outside the scope of the Auto SDK, use PlaybackController to notify the Engine of such changes. However, keep in mind that the expected usage of the interface does not change when it is used in this use case. Note: PlaybackController only controls media coming from Alexa, i.e. the AudioPlayer . PlaybackController should not be used with the expectation of controlling playback for non-media Alexa audio sources like SpeechSynthesizer or Alexa-aware external media sources integrated with ExternalMediaAdapter or LocalMediaSource . Additionally, calling a PlaybackController method while audio is playing through another Alexa-aware external media source will produce unexpected results and is not recommended. Whenever Alexa plays media through AudioPlayer , the Engine calls the platform interface method aace::alexa::TemplateRuntime::renderPlayerInfo() to provide visual metadata associated with the media that your implementation should render for the end user. The payload of this method includes descriptions of GUI controls to be displayed and the state in which to display them. When the user interacts with these on-screen controls, your implementation must use the PlaybackController interface to report the button presses to the Engine. The table below maps the controls from the renderPlayerInfo() payload to the corresponding calls in PlaybackController . RenderPlayerInfo control name PlaybackController PlaybackButton \"PLAY_PAUSE\" PLAY \"PLAY_PAUSE\" PAUSE \"NEXT\" NEXT \"PREVIOUS\" PREVIOUS \"SKIP_FORWARD\" SKIP_FORWARD \"SKIP_BACKWARD\" SKIP_BACKWARD PlaybackToggle \"SHUFFLE\" SHUFFLE \"LOOP\" LOOP \"REPEAT\" REPEAT \"THUMBS_UP\" THUMBS_UP \"THUMBS_DOWN\" THUMBS_DOWN To implement a custom handler for the playback controller, extend the PlaybackController class: #include <AACE/Alexa/PlaybackController.h> class MyPlaybackController : public aace::alexa::PlaybackController { ... void platformPlayButtonPressed() { // called by some platform event buttonPressed(PlaybackButton::PLAY); } ... void platformScrubForwardGUIButtonPressed(){ //called by the platform on an available GUI button event buttonPressed(PlaybackButton::SKIP_FORWARD); } ... void platformShuffleGUIButtonPressed(){ //called by the platform on an available GUI toggle event togglePressed(PlaybackToggle::SHUFFLE, true); //the action should send the value opposing the last playerinfo state for that toggle control } ... }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyPlaybackController>() );","title":"PlaybackController"},{"location":"explore/features/alexa/PlaybackController/#playbackcontroller-interface","text":"The Engine provides a platform interface aace::alexa::PlaybackController for the platform implementation to report on-device transport control button presses for media playing through Alexa. For example, if the user presses the on-screen pause button while listening to Amazon Music through Alexa's AudioPlayer interface, the platform implementation calls a PlaybackController method to report the button press to the Engine. Note: PlaybackController method calls to manage AudioPlayer 's state or playback queue proactively report button presses or the equivalent so that Alexa can react; they do not report changes to the playback state that happen locally first. The Alexa cloud manages the playback queue for AudioPlayer content, so each PlaybackController method call is a request for Alexa to act on the user's local request. The result of the request will come as one or more method invocations on the AudioOutput associated with the channel used for AudioPlayer . Note: If your implementation needs to stop AudioPlayer media in response to system events, such as audio focus transitions to audio playing outside the scope of the Auto SDK, use PlaybackController to notify the Engine of such changes. However, keep in mind that the expected usage of the interface does not change when it is used in this use case. Note: PlaybackController only controls media coming from Alexa, i.e. the AudioPlayer . PlaybackController should not be used with the expectation of controlling playback for non-media Alexa audio sources like SpeechSynthesizer or Alexa-aware external media sources integrated with ExternalMediaAdapter or LocalMediaSource . Additionally, calling a PlaybackController method while audio is playing through another Alexa-aware external media source will produce unexpected results and is not recommended. Whenever Alexa plays media through AudioPlayer , the Engine calls the platform interface method aace::alexa::TemplateRuntime::renderPlayerInfo() to provide visual metadata associated with the media that your implementation should render for the end user. The payload of this method includes descriptions of GUI controls to be displayed and the state in which to display them. When the user interacts with these on-screen controls, your implementation must use the PlaybackController interface to report the button presses to the Engine. The table below maps the controls from the renderPlayerInfo() payload to the corresponding calls in PlaybackController . RenderPlayerInfo control name PlaybackController PlaybackButton \"PLAY_PAUSE\" PLAY \"PLAY_PAUSE\" PAUSE \"NEXT\" NEXT \"PREVIOUS\" PREVIOUS \"SKIP_FORWARD\" SKIP_FORWARD \"SKIP_BACKWARD\" SKIP_BACKWARD PlaybackToggle \"SHUFFLE\" SHUFFLE \"LOOP\" LOOP \"REPEAT\" REPEAT \"THUMBS_UP\" THUMBS_UP \"THUMBS_DOWN\" THUMBS_DOWN To implement a custom handler for the playback controller, extend the PlaybackController class: #include <AACE/Alexa/PlaybackController.h> class MyPlaybackController : public aace::alexa::PlaybackController { ... void platformPlayButtonPressed() { // called by some platform event buttonPressed(PlaybackButton::PLAY); } ... void platformScrubForwardGUIButtonPressed(){ //called by the platform on an available GUI button event buttonPressed(PlaybackButton::SKIP_FORWARD); } ... void platformShuffleGUIButtonPressed(){ //called by the platform on an available GUI toggle event togglePressed(PlaybackToggle::SHUFFLE, true); //the action should send the value opposing the last playerinfo state for that toggle control } ... }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyPlaybackController>() );","title":"PlaybackController Interface"},{"location":"explore/features/alexa/SpeechRecognizer/","text":"SpeechRecognizer Interface \u00b6 The SpeechRecognizer interface is one of the key required interfaces in the Alexa experience. Integrate with the SpeechRecognizer AASB message interface (and the additional required interfaces as described in the following sections) to allow the user to invoke Alexa. Provide audio data to the Engine \u00b6 At Engine startup time, the SpeechRecognizer component in the Engine opens an audio input channel of type VOICE for your application to provide the user speech to Alexa. Your application subscribes to the AudioInput.StartAudioInput and AudioInput.StopAudioInput messages as outlined in the AudioInput interface documentation. When the Engine expects to receive audio from your application, the Engine publishes a StartAudioInput message with audioType set to VOICE . Your application provides the voice audio input until the Engine publishes the StopAudioInput message for the same audio type. The user decides when to speak to Alexa by invoking her with a tap-to-talk GUI button press, a push-to-talk physical button press, or\u2014in vehicles supporting voice-initiated listening\u2014an \"Alexa\" utterance. Invoke Alexa with tap-and-release \u00b6 For button press-and-release Alexa invocation, your application publishes the SpeechRecognizer.StartCapture message with initiator set to TAP_TO_TALK to tell the Engine that the user pressed the Alexa invocation button and wants to speak to Alexa. When requested, your application provides audio to the Engine until Alexa detects the end of the user's speech. The Engine publishes a SpeechRecognizer.EndOfSpeechDetected message to your application and requests your application to stop providing audio if no other Engine components require it. Invoke Alexa with press-and-hold \u00b6 For button press-and-hold Alexa invocation, your application publishes the SpeechRecognizer.StartCapture message with initiator set to HOLD_TO_TALK to tell the Engine that the user is holding down the Alexa invocation button and wants to speak to Alexa until releasing the button. When requested, the application provides audio to the Engine. When the user finishes speaking and releases the button, your application notifies the Engine by publishing the SpeechRecognizer.StopCapture message , and the Engine requests your application to stop providing audio if no other Engine components require it. Invoke Alexa with voice using Amazonlite wake word engine \u00b6 Note: To use the Amazonlite wake word engine in your application, contact your Amazon Solutions Architect or partner manager. When the application uses the Amazonlite Auto SDK module for wake word detection, your application notifies the Engine when the user has hands-free listening enabled (i.e., privacy mode is off) by publishing a PropertyManager.SetProperty message with property set to aace.alexa.wakewordEnabled and value set to true . The Engine enables Amazonlite wake word detection and requests audio input from your application. Your application provides audio to the Engine for continuous wake word detection until your application disables hands-free listening by setting the aace.alexa.wakewordEnabled property to false . After disabling Amazonlite wake word detection, the Engine requests your application to stop providing audio if there no other Engine components require it. When Amazonlite detects the \"Alexa\" wake word in the continuous audio stream provided by your application, the Engine publishes the SpeechRecognizer.WakewordDetected message and starts an interaction similar to one triggered by tap-to-talk invocation. When Alexa detects the end of the user's speech, the Engine publishes the SpeechRecognizer.EndOfSpeechDetected message but keeps the audio input stream open for further wake word detection. Reduce data usage with audio encoding \u00b6 To save bandwidth when the Engine sends user speech to Alexa in SpeechRecognizer.Recognize events, you can configure the Engine to encode the audio with the Opus audio encoding format by adding the following object to your Engine configuration: { \"aace.alexa\": { \"speechRecognizer\": { \"encoder\": { \"name\": \"opus\" } } } } When you set this configuration in your application, the Engine still expects your application to provide audio in the Linear PCM format specified in the AudioInput interface documentation; the Engine internally changes the encoding to Opus prior to including the audio attachment in the Recognize event. Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function If your application generates Engine configuration programmatically instead of using a JSON file, you can use the aace::alexa::config::AlexaConfiguration::createSpeechRecognizerConfig factory function to create the EngineConfiguration object. #include <AACE/Alexa/AlexaConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto speechRecognizerConfig = aace :: alexa :: config :: AlexaConfiguration :: createSpeechRecognizerConfig ( \"opus\" ); configurations . push_back ( speechRecognizerConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Click to expand or collapse details\u2014 Generate the configuration programatically with the Java factory method AACS is the recommended way to integrate Auto SDK for Android, so your application should provide the aacs.alexa configuration in the AACS configuration file. However, if your application does not use AACS, and it generates Engine configuration programmatically instead of using a JSON file, you can use the com.amazon.aace.alexa.config.AlexaConfiguration.createSpeechRecognizerConfig factory method to create the EngineConfiguration object. import com.amazon.aace.alexa.config.AlexaConfiguration ; EngineConfiguration speechRecognizerConfig = AlexaConfiguration . createSpeechRecognizerConfig ( \"opus\" ); mEngine . configure ( new EngineConfiguration [] { // ...add other EngineConfiguration objects... speechRecognizerConfig });","title":"SpeechRecognizer"},{"location":"explore/features/alexa/SpeechRecognizer/#speechrecognizer-interface","text":"The SpeechRecognizer interface is one of the key required interfaces in the Alexa experience. Integrate with the SpeechRecognizer AASB message interface (and the additional required interfaces as described in the following sections) to allow the user to invoke Alexa.","title":"SpeechRecognizer Interface"},{"location":"explore/features/alexa/SpeechRecognizer/#provide-audio-data-to-the-engine","text":"At Engine startup time, the SpeechRecognizer component in the Engine opens an audio input channel of type VOICE for your application to provide the user speech to Alexa. Your application subscribes to the AudioInput.StartAudioInput and AudioInput.StopAudioInput messages as outlined in the AudioInput interface documentation. When the Engine expects to receive audio from your application, the Engine publishes a StartAudioInput message with audioType set to VOICE . Your application provides the voice audio input until the Engine publishes the StopAudioInput message for the same audio type. The user decides when to speak to Alexa by invoking her with a tap-to-talk GUI button press, a push-to-talk physical button press, or\u2014in vehicles supporting voice-initiated listening\u2014an \"Alexa\" utterance.","title":"Provide audio data to the Engine"},{"location":"explore/features/alexa/SpeechRecognizer/#invoke-alexa-with-tap-and-release","text":"For button press-and-release Alexa invocation, your application publishes the SpeechRecognizer.StartCapture message with initiator set to TAP_TO_TALK to tell the Engine that the user pressed the Alexa invocation button and wants to speak to Alexa. When requested, your application provides audio to the Engine until Alexa detects the end of the user's speech. The Engine publishes a SpeechRecognizer.EndOfSpeechDetected message to your application and requests your application to stop providing audio if no other Engine components require it.","title":"Invoke Alexa with tap-and-release"},{"location":"explore/features/alexa/SpeechRecognizer/#invoke-alexa-with-press-and-hold","text":"For button press-and-hold Alexa invocation, your application publishes the SpeechRecognizer.StartCapture message with initiator set to HOLD_TO_TALK to tell the Engine that the user is holding down the Alexa invocation button and wants to speak to Alexa until releasing the button. When requested, the application provides audio to the Engine. When the user finishes speaking and releases the button, your application notifies the Engine by publishing the SpeechRecognizer.StopCapture message , and the Engine requests your application to stop providing audio if no other Engine components require it.","title":"Invoke Alexa with press-and-hold"},{"location":"explore/features/alexa/SpeechRecognizer/#invoke-alexa-with-voice-using-amazonlite-wake-word-engine","text":"Note: To use the Amazonlite wake word engine in your application, contact your Amazon Solutions Architect or partner manager. When the application uses the Amazonlite Auto SDK module for wake word detection, your application notifies the Engine when the user has hands-free listening enabled (i.e., privacy mode is off) by publishing a PropertyManager.SetProperty message with property set to aace.alexa.wakewordEnabled and value set to true . The Engine enables Amazonlite wake word detection and requests audio input from your application. Your application provides audio to the Engine for continuous wake word detection until your application disables hands-free listening by setting the aace.alexa.wakewordEnabled property to false . After disabling Amazonlite wake word detection, the Engine requests your application to stop providing audio if there no other Engine components require it. When Amazonlite detects the \"Alexa\" wake word in the continuous audio stream provided by your application, the Engine publishes the SpeechRecognizer.WakewordDetected message and starts an interaction similar to one triggered by tap-to-talk invocation. When Alexa detects the end of the user's speech, the Engine publishes the SpeechRecognizer.EndOfSpeechDetected message but keeps the audio input stream open for further wake word detection.","title":"Invoke Alexa with voice using Amazonlite wake word engine"},{"location":"explore/features/alexa/SpeechRecognizer/#reduce-data-usage-with-audio-encoding","text":"To save bandwidth when the Engine sends user speech to Alexa in SpeechRecognizer.Recognize events, you can configure the Engine to encode the audio with the Opus audio encoding format by adding the following object to your Engine configuration: { \"aace.alexa\": { \"speechRecognizer\": { \"encoder\": { \"name\": \"opus\" } } } } When you set this configuration in your application, the Engine still expects your application to provide audio in the Linear PCM format specified in the AudioInput interface documentation; the Engine internally changes the encoding to Opus prior to including the audio attachment in the Recognize event. Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function If your application generates Engine configuration programmatically instead of using a JSON file, you can use the aace::alexa::config::AlexaConfiguration::createSpeechRecognizerConfig factory function to create the EngineConfiguration object. #include <AACE/Alexa/AlexaConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto speechRecognizerConfig = aace :: alexa :: config :: AlexaConfiguration :: createSpeechRecognizerConfig ( \"opus\" ); configurations . push_back ( speechRecognizerConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Click to expand or collapse details\u2014 Generate the configuration programatically with the Java factory method AACS is the recommended way to integrate Auto SDK for Android, so your application should provide the aacs.alexa configuration in the AACS configuration file. However, if your application does not use AACS, and it generates Engine configuration programmatically instead of using a JSON file, you can use the com.amazon.aace.alexa.config.AlexaConfiguration.createSpeechRecognizerConfig factory method to create the EngineConfiguration object. import com.amazon.aace.alexa.config.AlexaConfiguration ; EngineConfiguration speechRecognizerConfig = AlexaConfiguration . createSpeechRecognizerConfig ( \"opus\" ); mEngine . configure ( new EngineConfiguration [] { // ...add other EngineConfiguration objects... speechRecognizerConfig });","title":"Reduce data usage with audio encoding"},{"location":"explore/features/alexa/SpeechSynthesizer/","text":"SpeechSynthesizer Interface \u00b6 At startup time, the SpeechSynthesizer component in the Engine opens an audio output channel of type TTS for the application to play Alexa speech responses to the user. SpeechSynthesizer has no messages of its own for the application to handle because it uses the standard audio output framework specified in the Core module. When Alexa responds to a user request with speech, the Engine publishes an AudioOutput.Prepare message with audioType TTS . The application uses the payload of the message to open the audio stream and buffer the audio data. The application plays the audio to the user when the Engine publishes an AudioOutput.Play message with matching token .","title":"SpeechSynthesizer"},{"location":"explore/features/alexa/SpeechSynthesizer/#speechsynthesizer-interface","text":"At startup time, the SpeechSynthesizer component in the Engine opens an audio output channel of type TTS for the application to play Alexa speech responses to the user. SpeechSynthesizer has no messages of its own for the application to handle because it uses the standard audio output framework specified in the Core module. When Alexa responds to a user request with speech, the Engine publishes an AudioOutput.Prepare message with audioType TTS . The application uses the payload of the message to open the audio stream and buffer the audio data. The application plays the audio to the user when the Engine publishes an AudioOutput.Play message with matching token .","title":"SpeechSynthesizer Interface"},{"location":"explore/features/alexa/TemplateRuntime/","text":"TemplateRuntime Interface \u00b6 Alexa sends visual metadata (display card templates) for your device to display. When template information is received from Alexa, it is the responsibility of the platform implementation to handle the rendering of any UI with the information that is received from Alexa. There are two display card template types: The Template type provides visuals associated with a user request to accompany Alexa speech. The PlayerInfo type provides visuals associated with media playing through the AudioPlayer interface. This includes playback control buttons, which must be used with the PlaybackController interface. You can programmatically generate template runtime configuration using the aace::alexa::config::AlexaConfiguration::createTemplateRuntimeTimeoutConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"templateRuntimeCapabilityAgent\": { \"displayCardTTSFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackStoppedPausedTimeout\": <TIMEOUT_IN_MS> } } To implement a custom handler for GUI templates, extend the TemplateRuntime class: #include <AACE/Alexa/TemplateRuntime.h> class MyTemplateRuntime : public aace::alexa::TemplateRuntime { public: void renderTemplate( const std::string& payload, FocusState focusState ) override { // handle rendering the template data specified in payload } void renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) override { // handle rendering the player info data specified in payload } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyTemplateRuntime>() ); Note: In the case of lists, it is the responsibility of the platform implementation to handle pagination. Alexa sends down the entire list as a JSON response and starts reading out the first five elements of the list. At the end of the first five elements, Alexa prompts the user whether or not to read the remaining elements from the list. If the user chooses to proceed with the remaining elements, Alexa sends down the entire list as a JSON response but starts reading from the sixth element onwards.","title":"TemplateRuntime"},{"location":"explore/features/alexa/TemplateRuntime/#templateruntime-interface","text":"Alexa sends visual metadata (display card templates) for your device to display. When template information is received from Alexa, it is the responsibility of the platform implementation to handle the rendering of any UI with the information that is received from Alexa. There are two display card template types: The Template type provides visuals associated with a user request to accompany Alexa speech. The PlayerInfo type provides visuals associated with media playing through the AudioPlayer interface. This includes playback control buttons, which must be used with the PlaybackController interface. You can programmatically generate template runtime configuration using the aace::alexa::config::AlexaConfiguration::createTemplateRuntimeTimeoutConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"templateRuntimeCapabilityAgent\": { \"displayCardTTSFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackStoppedPausedTimeout\": <TIMEOUT_IN_MS> } } To implement a custom handler for GUI templates, extend the TemplateRuntime class: #include <AACE/Alexa/TemplateRuntime.h> class MyTemplateRuntime : public aace::alexa::TemplateRuntime { public: void renderTemplate( const std::string& payload, FocusState focusState ) override { // handle rendering the template data specified in payload } void renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) override { // handle rendering the player info data specified in payload } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyTemplateRuntime>() ); Note: In the case of lists, it is the responsibility of the platform implementation to handle pagination. Alexa sends down the entire list as a JSON response and starts reading out the first five elements of the list. At the end of the first five elements, Alexa prompts the user whether or not to read the remaining elements from the list. If the user chooses to proceed with the remaining elements, Alexa sends down the entire list as a JSON response but starts reading from the sixth element onwards.","title":"TemplateRuntime Interface"},{"location":"explore/features/apl/","text":"Alexa Presentation Language (APL) Module \u00b6 Overview \u00b6 The Alexa Presentation Language (APL) module enables your Alexa Auto SDK client application to use visual capabilities of Alexa. By using this module in your application, you enable your device to receive visual experiences from certified Alexa Skills that support APL. Additionally, this modules provides messages for reporting the driving state of the vehicle, the day/night mode, and theme id. All of those properties affect how APL is rendered in the vehicle. Support for three new Alexa Automotive viewport profiles is now available. APL directives from the Alexa Voice Service (AVS) contain metadata needed to render Alexa's visual responses for devices with a graphical user interface (GUI). The lifecycle of an APL document includes sending events, providing document and window state, and more. For more information about APL, see the APL documentation . Note: The APL module doesn't render APL documents; it provides the conduit to render APL documents and process user events from the GUI or voice user interface (VUI). APL rendering is available separately for Android platforms. Automotive Viewport Profiles \u00b6 APL supports various types of viewport profiles for different types of devices and screen sizes. There are three new viewport profiles specifically added for vehicles: auto extra small, auto small and auto medium. Please refer to the viewport profile documentation for specific sizes and configuration information. Vehicle Driving State \u00b6 The vehicle driving state describes the motion state of the vehicle. The two supported values are moving and parked . Setting the appropriate driving state helps make visual experiences safer in the vehicle. When the vehicle is parked , APL experiences may contain more visual elements. When the vehicle is moving , some visual elements may be hidden to reduce cognitive load on the driver and make the experience safer. Video will automatically be disabled when the vehicle is moving . Day and Night Mode \u00b6 Day and night mode provide a way to render APL experiences in different contrasts based on the ambient light conditions of the vehicle. During the day when more light is available, the APL experience will typically be rendered with a light background and dark font. During the night or when travelling through a tunnel, the APL experience will be rendered with a dark background and light font. Automotive Themes \u00b6 Automotive themes allow the OEM to customize some aspects of the APL experience such as background and font color. Themes have predefined color values and affect supported Alexa Responsive Templates . This can help make the APL experience match more closely to the look and feel of the native UI in the head unit. There are a total of six available themes that include three for day mode and three for night mode. Day mode includes a default theme, and two additional themes with values gray1 and gray2 . Night mode includes a default theme, and two additional themes with values black and gray . The OEM application must ensure that a valid theme is set for day and night modes. The theme is optional, and in the case that it is not provided then the default theme is used. Supported APL Experiences \u00b6 Only APL experiences that have been certified for Automotive devices will be allowed to send APL directives. We are working to provide a process for skill developers to support automotive devices. More information will be provided in the online documentation . Contact your Amazon Solutions Architect (SA) or Partner Manager for more information about what Alexa domains and skills support APL in the vehicle. APL Viewhost \u00b6 The viewhost is a software component responsible for rendering the APL payload on screen. The Auto SDK provides a native Android viewhost solution. Contact your Amazon Solutions Architect (SA) or Partner Manager for more information. Template Runtime \u00b6 APL and Template Runtime both provide visual experiences. The Auto SDK supports both capabilities on the vehicle. Alexa skills typically give APL preference if both capabilities are reported, and will return APL directives. The new Auto SDK audio ducking feature is necessary for Template Runtime render player info cards and APL cards to be active at the same time. Configuring the APL Module \u00b6 The APL module can be optionally configured with the following Engine setting: { \"alexaPresentationCapabilityAgent\": { \"displayDocumentInteractionIdleTimeout\": <TIMEOUT_IN_MS> } } Note: The default value for the configuration timeout is 30 seconds. Using the APL AASB Messages \u00b6 General APL Message \u00b6 When a user interacts with an APL enabled Alexa skill, the Engine publishes the RenderDocument message . It is the responsibility of the application to integrate a viewhost capable of rendering APL documents. During the APL lifecyle, there will be context information (such as document and window state) as well as user events generated by interaction with the rendered APL document. The skill can send additional directives, which must be forwarded to the viewhost. This diagram illustrates the sequence of interacting with an APL enabled Alexa skill. Click to expand or collapse sequence diagram: General APL Directive Flow Set Platform Property Message \u00b6 This diagram illustrates the sequence of setting platform properties for APL. Click to expand or collapse sequence diagram: Setting platform properties Integrating the APL Module Into Your Application \u00b6 The Auto SDK provides out of the box support for APL through the Alexa Auto Client Service (AACS). However, you can use the Engine's MessageBroker to subscribe to and publish \"APL\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/APL/APL/ActivityEvent.h> #include <AASB/Message/APL/APL/ClearAllExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ClearCardMessage.h> #include <AASB/Message/APL/APL/ClearDocumentMessage.h> #include <AASB/Message/APL/APL/DataSourceUpdateMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsResultMessage.h> #include <AASB/Message/APL/APL/InterruptCommandSequenceMessage.h> #include <AASB/Message/APL/APL/ProcessActivityEventMessage.h> #include <AASB/Message/APL/APL/RenderDocumentMessage.h> #include <AASB/Message/APL/APL/RenderDocumentResultMessage.h> #include <AASB/Message/APL/APL/SendDataSourceFetchRequestEventMessage.h> #include <AASB/Message/APL/APL/SendDeviceWindowStateMessage.h> #include <AASB/Message/APL/APL/SendRuntimeErrorEventMessage.h> #include <AASB/Message/APL/APL/SendUserEventMessage.h> #include <AASB/Message/APL/APL/SendDocumentStateMessage.h> #include <AASB/Message/APL/APL/SetAPLMaxVersionMessage.h> #include <AASB/Message/APL/APL/SetDocumentIdleTimeoutMessage.h> #include <AASB/Message/APL/APL/SetPlatformPropertyMessage.h> #include <AASB/Message/APL/APL/UpdateAPLRuntimePropertiesMessage.h> #include <nlohmann/json.hpp> using json = nlohmann::json; class MyAPLHandler { // Subscribe to messages from the Engine void MyAPLHandler::subscribeToAASBMessages() { m_messageBroker->subscribe( [=](const std::string& message) { handleRenderDocumentMessage(message); }, RenderDocumentMessage::topic(), RenderDocumentMessage::action()); ... // Handle the RenderDocument message from the Engine void MyAPLHandler::handleRenderDocumentMessage(const std::string& message) { RenderDocumentMessage msg = json::parse(message); std::string payload = msg.payload.payload; std::string token = msg.payload.token; // ...Pass data to viewhost for rendering... } Registering an APL Handler \u00b6 To implement a custom handler for APL, extend the aace::apl::APL class as follows: class APLHandler : public aace::apl::APL { public: APLHandler(); void renderDocument(const std::string& jsonPayload, const std::string& token, const std::string& windowId) override; void clearDocument(const std::string& token) override; void executeCommands(const std::string& jsonPayload, const std::string& token) override; void interruptCommandSequence(const std::string& token) override; void dataSourceUpdate(const std::string& sourceType, const std::string& jsonPayload, const std::string& token) override; }; Android Integration \u00b6 The Alexa Auto Client Service (AACS) provides the AACS APL Renderer component to integrate the Auto SDK APL module on Android. See the AACS APL Renderer documentation for more information. Visual Characteristics \u00b6 The APL module requires that the platform implementation define the visual characteristics of the device. Visual characteristics are passed directly to the Smart Screen SDK, and therefore have the format described in the Alexa Smart Screen SDK documentation . Include the visualCharacteristics configuration in the JSON object aace.alexa/avsDeviceSDK/gui as shown in the following example. You can pass the configuration to the Engine using a StreamConfiguration or ConfigurationFile object. { \"aace.alexa\" : { \"avsDeviceSDK\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 1280 , \"height\" : 720 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display\" , \"version\" : \"1.0\" , \"configurations\" : { \"display\" : { \"type\" : \"PIXEL\" , \"touch\" : [ \"UNSUPPORTED\" ], \"shape\" : \"RECTANGLE\" , \"dimensions\" : { \"resolution\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } }, \"physicalSize\" : { \"unit\" : \"INCHES\" , \"value\" : { \"width\" : 8.9 , \"height\" : 6.05 } }, \"pixelDensity\" : { \"unit\" : \"DPI\" , \"value\" : 288 }, \"densityIndependentResolution\" : { \"unit\" : \"DP\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } } } } } } ] } } } }","title":"Alexa Presentation Language (APL) Module"},{"location":"explore/features/apl/#alexa-presentation-language-apl-module","text":"","title":"Alexa Presentation Language (APL) Module"},{"location":"explore/features/apl/#overview","text":"The Alexa Presentation Language (APL) module enables your Alexa Auto SDK client application to use visual capabilities of Alexa. By using this module in your application, you enable your device to receive visual experiences from certified Alexa Skills that support APL. Additionally, this modules provides messages for reporting the driving state of the vehicle, the day/night mode, and theme id. All of those properties affect how APL is rendered in the vehicle. Support for three new Alexa Automotive viewport profiles is now available. APL directives from the Alexa Voice Service (AVS) contain metadata needed to render Alexa's visual responses for devices with a graphical user interface (GUI). The lifecycle of an APL document includes sending events, providing document and window state, and more. For more information about APL, see the APL documentation . Note: The APL module doesn't render APL documents; it provides the conduit to render APL documents and process user events from the GUI or voice user interface (VUI). APL rendering is available separately for Android platforms.","title":"Overview "},{"location":"explore/features/apl/#automotive-viewport-profiles","text":"APL supports various types of viewport profiles for different types of devices and screen sizes. There are three new viewport profiles specifically added for vehicles: auto extra small, auto small and auto medium. Please refer to the viewport profile documentation for specific sizes and configuration information.","title":"Automotive Viewport Profiles "},{"location":"explore/features/apl/#vehicle-driving-state","text":"The vehicle driving state describes the motion state of the vehicle. The two supported values are moving and parked . Setting the appropriate driving state helps make visual experiences safer in the vehicle. When the vehicle is parked , APL experiences may contain more visual elements. When the vehicle is moving , some visual elements may be hidden to reduce cognitive load on the driver and make the experience safer. Video will automatically be disabled when the vehicle is moving .","title":"Vehicle Driving State "},{"location":"explore/features/apl/#day-and-night-mode","text":"Day and night mode provide a way to render APL experiences in different contrasts based on the ambient light conditions of the vehicle. During the day when more light is available, the APL experience will typically be rendered with a light background and dark font. During the night or when travelling through a tunnel, the APL experience will be rendered with a dark background and light font.","title":"Day and Night Mode "},{"location":"explore/features/apl/#automotive-themes","text":"Automotive themes allow the OEM to customize some aspects of the APL experience such as background and font color. Themes have predefined color values and affect supported Alexa Responsive Templates . This can help make the APL experience match more closely to the look and feel of the native UI in the head unit. There are a total of six available themes that include three for day mode and three for night mode. Day mode includes a default theme, and two additional themes with values gray1 and gray2 . Night mode includes a default theme, and two additional themes with values black and gray . The OEM application must ensure that a valid theme is set for day and night modes. The theme is optional, and in the case that it is not provided then the default theme is used.","title":"Automotive Themes "},{"location":"explore/features/apl/#supported-apl-experiences","text":"Only APL experiences that have been certified for Automotive devices will be allowed to send APL directives. We are working to provide a process for skill developers to support automotive devices. More information will be provided in the online documentation . Contact your Amazon Solutions Architect (SA) or Partner Manager for more information about what Alexa domains and skills support APL in the vehicle.","title":"Supported APL Experiences "},{"location":"explore/features/apl/#apl-viewhost","text":"The viewhost is a software component responsible for rendering the APL payload on screen. The Auto SDK provides a native Android viewhost solution. Contact your Amazon Solutions Architect (SA) or Partner Manager for more information.","title":"APL Viewhost "},{"location":"explore/features/apl/#template-runtime","text":"APL and Template Runtime both provide visual experiences. The Auto SDK supports both capabilities on the vehicle. Alexa skills typically give APL preference if both capabilities are reported, and will return APL directives. The new Auto SDK audio ducking feature is necessary for Template Runtime render player info cards and APL cards to be active at the same time.","title":"Template Runtime "},{"location":"explore/features/apl/#configuring-the-apl-module","text":"The APL module can be optionally configured with the following Engine setting: { \"alexaPresentationCapabilityAgent\": { \"displayDocumentInteractionIdleTimeout\": <TIMEOUT_IN_MS> } } Note: The default value for the configuration timeout is 30 seconds.","title":"Configuring the APL Module "},{"location":"explore/features/apl/#using-the-apl-aasb-messages","text":"","title":"Using the APL AASB Messages "},{"location":"explore/features/apl/#general-apl-message","text":"When a user interacts with an APL enabled Alexa skill, the Engine publishes the RenderDocument message . It is the responsibility of the application to integrate a viewhost capable of rendering APL documents. During the APL lifecyle, there will be context information (such as document and window state) as well as user events generated by interaction with the rendered APL document. The skill can send additional directives, which must be forwarded to the viewhost. This diagram illustrates the sequence of interacting with an APL enabled Alexa skill. Click to expand or collapse sequence diagram: General APL Directive Flow","title":"General APL Message"},{"location":"explore/features/apl/#set-platform-property-message","text":"This diagram illustrates the sequence of setting platform properties for APL. Click to expand or collapse sequence diagram: Setting platform properties","title":"Set Platform Property Message"},{"location":"explore/features/apl/#integrating-the-apl-module-into-your-application","text":"The Auto SDK provides out of the box support for APL through the Alexa Auto Client Service (AACS). However, you can use the Engine's MessageBroker to subscribe to and publish \"APL\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/APL/APL/ActivityEvent.h> #include <AASB/Message/APL/APL/ClearAllExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ClearCardMessage.h> #include <AASB/Message/APL/APL/ClearDocumentMessage.h> #include <AASB/Message/APL/APL/DataSourceUpdateMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsResultMessage.h> #include <AASB/Message/APL/APL/InterruptCommandSequenceMessage.h> #include <AASB/Message/APL/APL/ProcessActivityEventMessage.h> #include <AASB/Message/APL/APL/RenderDocumentMessage.h> #include <AASB/Message/APL/APL/RenderDocumentResultMessage.h> #include <AASB/Message/APL/APL/SendDataSourceFetchRequestEventMessage.h> #include <AASB/Message/APL/APL/SendDeviceWindowStateMessage.h> #include <AASB/Message/APL/APL/SendRuntimeErrorEventMessage.h> #include <AASB/Message/APL/APL/SendUserEventMessage.h> #include <AASB/Message/APL/APL/SendDocumentStateMessage.h> #include <AASB/Message/APL/APL/SetAPLMaxVersionMessage.h> #include <AASB/Message/APL/APL/SetDocumentIdleTimeoutMessage.h> #include <AASB/Message/APL/APL/SetPlatformPropertyMessage.h> #include <AASB/Message/APL/APL/UpdateAPLRuntimePropertiesMessage.h> #include <nlohmann/json.hpp> using json = nlohmann::json; class MyAPLHandler { // Subscribe to messages from the Engine void MyAPLHandler::subscribeToAASBMessages() { m_messageBroker->subscribe( [=](const std::string& message) { handleRenderDocumentMessage(message); }, RenderDocumentMessage::topic(), RenderDocumentMessage::action()); ... // Handle the RenderDocument message from the Engine void MyAPLHandler::handleRenderDocumentMessage(const std::string& message) { RenderDocumentMessage msg = json::parse(message); std::string payload = msg.payload.payload; std::string token = msg.payload.token; // ...Pass data to viewhost for rendering... }","title":"Integrating the APL Module Into Your Application "},{"location":"explore/features/apl/#registering-an-apl-handler","text":"To implement a custom handler for APL, extend the aace::apl::APL class as follows: class APLHandler : public aace::apl::APL { public: APLHandler(); void renderDocument(const std::string& jsonPayload, const std::string& token, const std::string& windowId) override; void clearDocument(const std::string& token) override; void executeCommands(const std::string& jsonPayload, const std::string& token) override; void interruptCommandSequence(const std::string& token) override; void dataSourceUpdate(const std::string& sourceType, const std::string& jsonPayload, const std::string& token) override; };","title":"Registering an APL Handler "},{"location":"explore/features/apl/#android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS APL Renderer component to integrate the Auto SDK APL module on Android. See the AACS APL Renderer documentation for more information.","title":"Android Integration "},{"location":"explore/features/apl/#visual-characteristics","text":"The APL module requires that the platform implementation define the visual characteristics of the device. Visual characteristics are passed directly to the Smart Screen SDK, and therefore have the format described in the Alexa Smart Screen SDK documentation . Include the visualCharacteristics configuration in the JSON object aace.alexa/avsDeviceSDK/gui as shown in the following example. You can pass the configuration to the Engine using a StreamConfiguration or ConfigurationFile object. { \"aace.alexa\" : { \"avsDeviceSDK\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 1280 , \"height\" : 720 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display\" , \"version\" : \"1.0\" , \"configurations\" : { \"display\" : { \"type\" : \"PIXEL\" , \"touch\" : [ \"UNSUPPORTED\" ], \"shape\" : \"RECTANGLE\" , \"dimensions\" : { \"resolution\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } }, \"physicalSize\" : { \"unit\" : \"INCHES\" , \"value\" : { \"width\" : 8.9 , \"height\" : 6.05 } }, \"pixelDensity\" : { \"unit\" : \"DPI\" , \"value\" : 288 }, \"densityIndependentResolution\" : { \"unit\" : \"DP\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } } } } } } ] } } } }","title":"Visual Characteristics "},{"location":"explore/features/bluetooth/","text":"Bluetooth Module \u00b6 Overview \u00b6 The Bluetooth module allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features, such as Alexa Mobile Accessory (AMA) or Mobile Authorization, to users of Android or iOS smartphones. Requirements for Bluetooth Classic or BLE \u00b6 The variant of the Bluetooth standard determines the tasks required to support the client. Bluetooth Classic \u00b6 Complete the following tasks to support different clients: For Android phones, create a RFCOMM socket with the corresponding Service Discovery Protocol (SDP) record. (RFCOMM is a Bluetooth transport protocol.) For iOS phones, create an iOS Accessory Protocol 2 (iAP2) communication channel. For information about these tasks, see Supporting Bluetooth Classic . BLE \u00b6 Add a new Generic Attribute Profile (GATT) service and advertise the service. For information about this task, see Supporting BLE . Choosing a Transport Protocol \u00b6 Consider the following factors when choosing the protocol to use with Bluetooth: Capabilities and limitations of remote devices (e.g., Android or iOS phones) Capabilities of the Bluetooth software stack, which includes the system service, driver, and firmware (e.g., whether the software supports RFCOMM or iAP2) Capabilities of the Bluetooth chipset used on the head unit (e.g., single-mode or dual-mode) The following table shows the transport protocol to use based on the head unit chipset and the type of smartphone. Note: To use Bluetooth for Mobile Authorization, you must use RFCOMM as the transport protocol. Single-mode chipset Dual-mode chipset iOS phone iAP2 iAP2 or GATT Android phone RFCOMM RFCOMM or GATT Supporting Bluetooth Classic \u00b6 Follow one of these steps, depending on the transport protocol, to create a communication channel between the head unit and the phone: For RFCOMM communication, assign an unused RFCOMM channel to the head unit to listen on. The implementation must register an SDP record with the local SDP server, which is part of the Bluetooth software stack. The server contains the specified UUID, service name, and auto-assigned channel. Remote Bluetooth devices can use the same UUID to query the SDP server and discover the channel to connect to. The SDP record is removed when the socket is closed or if the application closes unexpectedly. Android clients discover the head unit by using the method that is described in BluetoothDevice.getUuids . For iAP2, allocate a communication channel with the specified protocol identifier. For information about iAP2, see the Accessory Interface Specification for Apple Devices. Supporting BLE \u00b6 In your implementation, create a new GATT service according to the JSON configuration specified in the GATTServer.start call. The following JSON shows a sample configuration: { \"characteristics\" : [ { \"id\" : \"A49921F7-9E7D-46F6-8832-9F44658892AC\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic TX\" , \"permissions\" : [ \"write\" ], \"properties\" : [ \"write\" ] }, { \"descriptors\" : [ { \"id\" : \"00002902-0000-1000-8000-00805f9b34fb\" , \"name\" : \"Configuration\" , \"permissions\" : [ \"read\" , \"write\" ] } ], \"id\" : \"34D7A574-5298-4C35-8109-1EAA2E9476E8\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic RX\" , \"permissions\" : [ \"read\" ], \"properties\" : [ \"notify\" , \"read\" ] } ] } Using the Bluetooth Module \u00b6 For Linux and QNX, register the following C++ platform interface with the Auto SDK: Note : The Bluetooth interface does not have AASB messages yet. Use the BluetoothProvider platform interface as described below. class BluetoothProvider : public aace :: core :: PlatformInterface { /** * Create a GATT Server. * * @return the created GATT server. nullptr if GATT is not supported. */ virtual std :: shared_ptr < GATTServer > createGATTServer (); /** * Create an RFCOMM server socket and register the corresponding SDP record. * * @param name service name for SDP record * @param uuid uuid for SDP record * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingRfcomm ( const std :: string & name , const std :: string & uuid ); /** * Create an iAP2 server socket with specified protocol. * * @param protocol the protocol to use when communicating with the device * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingiAP2 ( const std :: string & protocol ); }; Note: Amazon does not provide reference implementation for Linux and QNX. For Android, AACS uses the Bluetooth module with the Mobile Authorization extension to enable a simplified user sign in experience on a bluetooth-paired phone. There is no setup required for the Bluetooth module beyond the setup to use the Mobile Authorization extension. See the Mobile Authorization extension documentation for details. Sequence Diagrams \u00b6 The sequence diagrams illustrate the flow for a Bluetooth Classic connection and the flow for a BLE connection. Bluetooth Classic Connection \u00b6 BLE Connection \u00b6 Requirement for Accepting Connections from Another Device \u00b6 The Alexa app hosting either the GATT service or RFCOMM server socket must run in the background to accept connections from another device.","title":"Bluetooth Module"},{"location":"explore/features/bluetooth/#bluetooth-module","text":"","title":"Bluetooth Module"},{"location":"explore/features/bluetooth/#overview","text":"The Bluetooth module allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features, such as Alexa Mobile Accessory (AMA) or Mobile Authorization, to users of Android or iOS smartphones.","title":"Overview"},{"location":"explore/features/bluetooth/#requirements-for-bluetooth-classic-or-ble","text":"The variant of the Bluetooth standard determines the tasks required to support the client.","title":"Requirements for Bluetooth Classic or BLE"},{"location":"explore/features/bluetooth/#bluetooth-classic","text":"Complete the following tasks to support different clients: For Android phones, create a RFCOMM socket with the corresponding Service Discovery Protocol (SDP) record. (RFCOMM is a Bluetooth transport protocol.) For iOS phones, create an iOS Accessory Protocol 2 (iAP2) communication channel. For information about these tasks, see Supporting Bluetooth Classic .","title":"Bluetooth Classic"},{"location":"explore/features/bluetooth/#ble","text":"Add a new Generic Attribute Profile (GATT) service and advertise the service. For information about this task, see Supporting BLE .","title":"BLE"},{"location":"explore/features/bluetooth/#choosing-a-transport-protocol","text":"Consider the following factors when choosing the protocol to use with Bluetooth: Capabilities and limitations of remote devices (e.g., Android or iOS phones) Capabilities of the Bluetooth software stack, which includes the system service, driver, and firmware (e.g., whether the software supports RFCOMM or iAP2) Capabilities of the Bluetooth chipset used on the head unit (e.g., single-mode or dual-mode) The following table shows the transport protocol to use based on the head unit chipset and the type of smartphone. Note: To use Bluetooth for Mobile Authorization, you must use RFCOMM as the transport protocol. Single-mode chipset Dual-mode chipset iOS phone iAP2 iAP2 or GATT Android phone RFCOMM RFCOMM or GATT","title":"Choosing a Transport Protocol"},{"location":"explore/features/bluetooth/#supporting-bluetooth-classic","text":"Follow one of these steps, depending on the transport protocol, to create a communication channel between the head unit and the phone: For RFCOMM communication, assign an unused RFCOMM channel to the head unit to listen on. The implementation must register an SDP record with the local SDP server, which is part of the Bluetooth software stack. The server contains the specified UUID, service name, and auto-assigned channel. Remote Bluetooth devices can use the same UUID to query the SDP server and discover the channel to connect to. The SDP record is removed when the socket is closed or if the application closes unexpectedly. Android clients discover the head unit by using the method that is described in BluetoothDevice.getUuids . For iAP2, allocate a communication channel with the specified protocol identifier. For information about iAP2, see the Accessory Interface Specification for Apple Devices.","title":"Supporting Bluetooth Classic"},{"location":"explore/features/bluetooth/#supporting-ble","text":"In your implementation, create a new GATT service according to the JSON configuration specified in the GATTServer.start call. The following JSON shows a sample configuration: { \"characteristics\" : [ { \"id\" : \"A49921F7-9E7D-46F6-8832-9F44658892AC\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic TX\" , \"permissions\" : [ \"write\" ], \"properties\" : [ \"write\" ] }, { \"descriptors\" : [ { \"id\" : \"00002902-0000-1000-8000-00805f9b34fb\" , \"name\" : \"Configuration\" , \"permissions\" : [ \"read\" , \"write\" ] } ], \"id\" : \"34D7A574-5298-4C35-8109-1EAA2E9476E8\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic RX\" , \"permissions\" : [ \"read\" ], \"properties\" : [ \"notify\" , \"read\" ] } ] }","title":"Supporting BLE"},{"location":"explore/features/bluetooth/#using-the-bluetooth-module","text":"For Linux and QNX, register the following C++ platform interface with the Auto SDK: Note : The Bluetooth interface does not have AASB messages yet. Use the BluetoothProvider platform interface as described below. class BluetoothProvider : public aace :: core :: PlatformInterface { /** * Create a GATT Server. * * @return the created GATT server. nullptr if GATT is not supported. */ virtual std :: shared_ptr < GATTServer > createGATTServer (); /** * Create an RFCOMM server socket and register the corresponding SDP record. * * @param name service name for SDP record * @param uuid uuid for SDP record * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingRfcomm ( const std :: string & name , const std :: string & uuid ); /** * Create an iAP2 server socket with specified protocol. * * @param protocol the protocol to use when communicating with the device * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingiAP2 ( const std :: string & protocol ); }; Note: Amazon does not provide reference implementation for Linux and QNX. For Android, AACS uses the Bluetooth module with the Mobile Authorization extension to enable a simplified user sign in experience on a bluetooth-paired phone. There is no setup required for the Bluetooth module beyond the setup to use the Mobile Authorization extension. See the Mobile Authorization extension documentation for details.","title":"Using the Bluetooth Module"},{"location":"explore/features/bluetooth/#sequence-diagrams","text":"The sequence diagrams illustrate the flow for a Bluetooth Classic connection and the flow for a BLE connection.","title":"Sequence Diagrams"},{"location":"explore/features/bluetooth/#bluetooth-classic-connection","text":"","title":"Bluetooth Classic Connection"},{"location":"explore/features/bluetooth/#ble-connection","text":"","title":"BLE Connection"},{"location":"explore/features/bluetooth/#requirement-for-accepting-connections-from-another-device","text":"The Alexa app hosting either the GATT service or RFCOMM server socket must run in the background to accept connections from another device.","title":"Requirement for Accepting Connections from Another Device"},{"location":"explore/features/car-control/","text":"Car Control Module \u00b6 Overview \u00b6 The Alexa Auto SDK Car Control module enables you to build a custom experience that allows users to use Alexa to voice-control vehicle features. The following concepts comprise the Car Control module APIs: Endpoints \u00b6 The head unit device acting as an Alexa Auto SDK client is an \"endpoint\" that connects to the Alexa service. Other Auto SDK modules, such as Alexa , configure capabilities on this \"root\" or \"default\" endpoint because the capabilities pertain to the head unit itself. The Car Control module enables the default Auto SDK client endpoint to act as a proxy to receive events and directives on behalf of connected endpoints. You can configure a separate endpoint for every vehicle component that the head unit can control through device-level connections. This enables the user to target individual vehicle components directly with utterances like \"Alexa, turn on the AC\" or \"Alexa, set the temperature to 65.\" Capabilities \u00b6 In the utterance \"Alexa, turn on the AC\", \"turn on\" corresponds to a specific capability configured for the \"AC\" endpoint. Defining an endpoint declares a vehicle feature to be controllable, and defining capabilities on the endpoint declares how the endpoint can be controlled. Car Control supports four capability interfaces that can be declared alone or in combination for a particular endpoint to model its individual control experience: Power Controller controls the overall power state of an endpoint. For example, configuring an \"AC\" endpoint with a Power Controller capability enables utterances such as \"Alexa, turn on the AC\" and \"Alexa, power off the AC\". Toggle Controller controls a particular named property of an endpoint that can be turned on and off. For example, configuring a \"windshield\" endpoint with a \"defroster\" Toggle Controller capability instance enables utterances such as \"Alexa, turn on the windshield defroster.\" Mode Controller controls a particular named property of an endpoint that can be set to a discrete value from a defined set of values. For example, if an ambient light endpoint has red and green color settings, configuring an \"ambient light\" endpoint with a \"color\" Mode Controller capability instance enables utterances such as \"Alexa, set the ambient light color to red\" and \"Alexa, change the ambient light to green.\" Range Controller controls a particular named property of an endpoint that can be set to a numeric value within a range. For example, if a fan endpoint has a speed property with settings 1 through 3, configuring a \"fan\" endpoint with a \"speed\" Range Controller capability instance enables utterances such as \"Alexa, set the fan speed to 2.\" You can configure names, such as \"medium\", for a range value to enable additional utterances such as \"Alexa, set the fan to medium\" to set the fan speed setting to 2. Capability Primitives and Semantic Annotations \u00b6 Toggle Controller, Mode Controller, and Range Controller are known as \"capability primitives.\" You can use multiple instances of the same capability primitive interface on an endpoint under different instance names. For example, a heater endpoint might have intensity and position properties that are both best modeled as modes. You can declare an \"intensity\" Mode Controller instance and a \"position\" Mode Controller instance on the same \"heater\" endpoint so the user can target each property separately. To provide intuitive experiences for users, capability primitives offer \"semantic annotations\" for the devices to map specific utterances to the behaviors of capability instances. For example, if the vehicle uses a Range Controller to control a window, a user would prefer to say \"Alexa, open the window\" over the default utterances of the Range Controller such as \"Alexa, set the window height to 0\". For any endpoint to which the \"open\", \"close\", \"raise\", or \"lower\" concepts apply, you can configure the capability primitive instances of the endpoint with a \"semantics\" object that maps user utterances for these actions to the appropriate capability directives. Each action (e.g., \"open\") is allowed only once per endpoint since the action expresses intent to control the endpoint as a whole. The actions specified in configuration are action IDs rather than literal strings, which ensures Alexa recognizes all synonyms and translations for the action in the user utterance. The supported actions are \"Alexa.Actions.Open\", \"Alexa.Actions.Close\", \"Alexa.Actions.Raise\", and \"Alexa.Actions.Lower.\" Zones \u00b6 Each endpoint can belong to zero, one, or many \"zones.\" Zones, configured with member endpoints, define named regions of the vehicle and allow users to target endpoints by location. Zones are essential for unambiguous targeting of endpoints that have friendly names that overlap with other endpoints. For example, defining \"driver\" and \"passenger\" zones and assigning distinct \"seat\" endpoints to each allows proper control of the \"driver seat\" and the \"passenger seat\" independently. Assigning one zone in particular as the \"default\" enables endpoints in this zone to take precedence over endpoints sharing the same friendly name but not in the default zone when the user does not specify a zone in the utterance. This is useful for distinguishing \"zoneless\" endpoints from \"zoned\" endpoints with the same name when it is most likely that the user intends to target the \"zoneless\" one. For example, consider a vehicle with zone IDs \"zone.all\", \"zone.rear\", and \"zone.left\" with a distinct fan endpoint in each zone. If the user says \"Alexa, turn on the fan\", it is most likely that he wants to turn on the fan that refers to the vehicle as a whole because there is no natural way to specify its location. You can ensure that Alexa will resolve this utterance to the fan in the \"all\" zone by assigning \"zone.all\" as the default zone. Additionally, the default zone is useful for cases in which you have zoned endpoints with overlapping names, but one of the endpoints is a clear \"default\" to the user. For example, consider a vehicle with zones \"zone.all\" (assigned as default), \"zone.driver\", and \"zone.passenger\". The vehicle has a \"driver window\" in \"zone.driver\" and a \"passenger window\" in \"zone.passenger\", but Alexa cannot resolve which endpoint is the intended target of the user utterance \"Alexa, open the window.\" However, the user probably means \"Alexa, open the driver window\". You can ensure that Alexa considers the \"driver window\" as the \"default\" window by assigning it to \"zone.all\" as well. Assets \u00b6 The definitions of endpoints, capabilities, and zones include \"assets.\" Assets, identified by unique IDs, group a voice-accessible friendly name like \"air conditioner\" into a named group of synonyms and translations for all supported languages. For example, using the asset with ID \"Alexa.Automotive.DeviceName.AirConditioner\" in your car control module configuration for an AC endpoint not only enables the user to target the air conditioner with the default phrase \"air conditioner\", but also with phrases like \"air con\" and \"AC\" in English as well as synonyms in other supported locales. Using assets allows decoupling the many ways of identifying components from the core configuration of the components and enables de-duplication across different components that have overlapping ways to be identified. The Alexa Auto SDK provides a list of IDs for the \"default assets,\" which form an automotive-specific catalog. The catalog contains asset definitions for supported car control features, including endpoint names, zone names, and capability settings. Each default asset ID is prefixed with \"Alexa.Automotive.\" You can use these asset IDs in your Car Control module configuration without the corresponding definitions of friendly names, synonyms, and translations, because the definitions are specified in the Alexa cloud. Configuring the Car Control Module \u00b6 Car Control module configuration is vehicle-specific and tells the Auto SDK Engine which vehicle features to advertise to Alexa for control by the user. You must configure the Auto SDK Engine with an EngineConfiguration object that describes the vehicle. Like all Auto SDK Engine configuration, you can either define the JSON in a file and construct an EngineConfiguration from that file, or you can use the provided CarControlConfiguration class to programmatically construct the EngineConfiguration in the proper format. The following subsections describe the JSON schema. See the CarControlConfiguration class for details on how to build configuration programmatically. Configuration Format \u00b6 The Engine configuration for the Car Control module includes definitions of endpoints with their capabilities, zones with their member endpoints, and an optional path to a JSON file defining additional assets. Sample JSON Object { \"aace.carControl\": { \"endpoints\": [ { \"endpointId\": \"{{STRING}}\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"capabilities\": [ // list of capability definitions for this endpoint ] } ], \"zones\": [ { \"zoneID\": \"{{STRING}}\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] }, \"members\": [ { \"endpointId\": \"{{STRING}}\" } ] } ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Object Parameters Property Type Required Description aace.carControl. endpoints list Yes The list of connected endpoints for which the device implements capabilities. Each endpoint describes one controllable vehicle component. aace.carControl. endpoints[i]. endpointId string Yes The identifier for the endpoint, unique amongst all endpoints in the vehicle. The same endpointId is used to identify the endpoint targeted in an AASB message sent by the Engine. Note: Do not use this format for the endpointId : \\<clientId>::\\<productId>::\\<serialNumber>::[-\\<extEndpoint>] The Engine internally prepends the 3-part device prefix to your specified endpointId before sending the configuration to Alexa. Configuring the full ID directly results in duplication and excess characters. aace.carControl. endpoints[i]. endpointResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this endpoint. Note: Only \u201casset\u201d type labels are supported. aace.carControl. endpoints[i]. endpointResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to the endpoint. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. endpoints[i]. capabilities list Yes A list of capability definitions, representing capabilities implemented by the device on behalf of the endpoint, that define how the endpoint can be controlled by the user. Each object in this list must be a valid definition for one of the capabilities supported by the Car Control module: Alexa.PowerController , Alexa.ToggleController , Alexa.ModeController , and Alexa.RangeController aace.carControl. zones list No, but recommended A list of zone definitions for the named regions in the vehicle. aace.carControl. zones[i]. zoneId string Yes The identifier for the zone, unique amongst all zones in the vehicle. aace.carControl. zones[i]. zoneResources. friendlyNames list Yes A list of label objects that describe the possible ways to refer to this zone. Note: Only \u201casset\u201d type labels are supported. aace.carControl. zones[i]. zoneResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of strings used to refer to the zone in all supported locales. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. zones[i]. members list Yes A list of endpoints that belong to this zone. aace.carControl. zones[i]. members[j]. endpointId string Yes The endpointId for an endpoint that belongs to this zone. aace.carControl. defaultZoneId string No, but recommended The zoneId of the default zone. Endpoints in this zone take precedence when a user utterance does not specify a zone. It is recommended to use a zone that describes the whole vehicle as the default rather than a zone describing a specific region. aace.carControl. assets.customAssetsPath string (file path) No Specifies the path to a JSON file defining additional assets. Power Controller Capability Configuration \u00b6 Click to expand or collapse description See \"Alexa.PowerController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.PowerController\", \"version\": \"3\", \"properties\": { \"supported\": [ { \"name\": \"powerState\" } ], \"proactivelyReported\": false, \"retrievable\": false } } Object Parameters Property Type Required Description properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"powerState\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"powerState\") can be retrieved by Alexa. Accepted values: false Toggle Controller Capability Configuration \u00b6 Click to expand or collapse description See \"Alexa.ToggleController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ToggleController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"proactivelyReported\": false, \"retrievable\": false, \"supported\": [ { \"name\": \"toggleState\" } ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {} } }, ... ] } } Object Parameters Property Type Required Description instance string Yes The identifier of this instance of Alexa.ToggleController on this endpoint. capabilityResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only \u201casset\u201d type labels are supported. capabilityResources. friendlyNames[i]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"toggleState\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"toggleState\") can be retrieved by Alexa. Accepted values: false semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance. Note: semantics.stateMappings is not supported. semantics. actionMappings[i]. actions[j] string Yes, if semantics is present The identifiers of the utterances that should trigger the specified directive. Accepted values: \"Alexa.Actions.Open\" : \"open {endpoint}\" \"Alexa.Actions.Close\" : \"close {endpoint}\" \"Alexa.Actions.Raise\" : \"raise {endpoint}\" \"Alexa.Actions.Lower\" : \"lower {endpoint}\" semantics. actionMappings[i]. directive. name string Yes, if semantics is present Accepted values: \"TurnOn\" : The specified actions will trigger the \"TurnOn\" directive. The Engine will publish the SetToggleControllerValue message, with the turnOn attribute set to true . \"TurnOff\" : The specified actions will trigger the \"TurnOff\" directive. The Engine will publish the SetToggleControllerValue message, with the turnOn attribute set to false . Mode Controller Capability Configuration \u00b6 Click to expand or collapse description See \"Alexa.ModeController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ModeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"mode\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"ordered\": {{BOOLEAN}}, \"supportedModes\": [ { \"value\": \"{{STRING}}\", \"modeResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] } }, ... ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } Object Parameters Property Type Required Description instance string Yes The identifier of this instance of Alexa.ModeController on this endpoint. capabilityResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only \u201casset\u201d type labels are supported. capabilityResources. friendlyNames[i]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"mode\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"mode\") can be retrieved by Alexa. Accepted values: false configuration. ordered boolean Yes Whether the modes of this capability instance are ordered, enabling iteration through them using the \"AdjustMode\" directive. configuration. supportedModes list Yes A list of objects describing the available modes of this capability instance. If ordered is true, the order of the objects in this list implies the ordering of the modes. configuration. supportedModes[i]. value string Yes The identifier of this mode on this capability instance. configuration. supportedModes[i]. modeResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this mode. Note: Only \u201casset\u201d type labels are supported. semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance. Note: semantics.stateMappings is not supported. semantics. actionMappings[i]. actions[j] string Yes, if semantics is present The identifiers of the utterances that should trigger the specified directive. Accepted values: \"Alexa.Actions.Open\" : \"open {endpoint}\" \"Alexa.Actions.Close\" : \"close {endpoint}\" \"Alexa.Actions.Raise\" : \"raise {endpoint}\" \"Alexa.Actions.Lower\" : \"lower {endpoint}\" semantics. actionMappings[i]. directive. name string Yes, if semantics is present Accepted values: \"SetMode\" : The specified actions will trigger the \"SetMode\" directive with the specified payload . The Engine will publish the SetModeControllerValue message. \"AdjustMode\" : The specified actions will trigger the \"AdjustMode\" directive with the specified payload . The Engine will publish the AdjustModeControllerValue message. \"AdjustMode\" is accepted only if this capability instance is ordered . semantics. actionMappings[i]. directive. payload object Yes, if semantics is present If name is \u201cSetMode\u201d, this is the \u201cSetMode\u201d directive payload object that contains the \u201cmode\u201d property and the corresponding value from configuration.supportedModes[].value . If name is \u201cAdjustMode\u201d, this is the \u201cAdjustMode\u201d directive payload object that contains the \u201cmodeDelta\u201d field and the corresponding number of modes to advance. Range Controller Capability Configuration \u00b6 Click to expand or collapse description See \"Alexa.RangeController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.RangeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"rangeValue\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"supportedRange\": { \"minimumValue\": {{LONG}}, \"maximumValue\": {{LONG}}, \"precision\": {{LONG}} }, \"unitOfMeasure\": \"{{STRING}}\", \"presets\": [ { \"rangeValue\": {{LONG}}, \"presetResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] } }, ... ], \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } } Object Parameters Property Type Required Description instance string Yes The identifier of this instance of Alexa.RangeController on this endpoint. capabilityResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only \u201casset\u201d type labels are supported. capabilityResources. friendlyNames[i]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be retrieved by Alexa. Accepted values: false configuration. supportedRange. minimumValue long Yes The minimum value of the range this capability instance supports. configuration. supportedRange. maximumValue long Yes The maximum value of the range this capability instance supports. configuration. supportedRange. precision long Yes The amount by which the set value changes when iterating through the range. For example, if a user asks Alexa to increase the value but doesn't specify by how much, this value will be used. configuration. unitOfMeasure string No The unit of measure for the range. configuration. presets list Yes A list of objects describing values that can be invoked by name. For example, a rangeValue of 10 might be configured as the \"high\" preset. configuration. presets[i]. rangeValue long Yes The value within the supportedRange that has an associated named preset. configuration. presets[i]. presetResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this preset. Note: Only \u201casset\u201d type labels are supported. semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance. Note: semantics.stateMappings is not supported. semantics. actionMappings[i]. actions[j] string Yes, if semantics is present The identifiers of the utterances that should trigger the specified directive. Accepted values: \"Alexa.Actions.Open\" : \"open {endpoint}\" \"Alexa.Actions.Close\" : \"close {endpoint}\" \"Alexa.Actions.Raise\" : \"raise {endpoint}\" \"Alexa.Actions.Lower\" : \"lower {endpoint}\" semantics. actionMappings[i]. directive. name string Yes, if semantics is present Accepted values: \"SetRangeValue\" : The specified actions will trigger the \"SetRangeValue\" directive with the specified payload . The Engine will publish the SetRangeControllerValue message. \"AdjustRangeValue\" : The specified actions will trigger the \"AdjustRangeValue\" directive with the specified payload . The Engine will publish the AdjustRangeControllerValue message. semantics. actionMappings[i]. directive. payload object Yes, if semantics is present If name is \u201cSetRangeValue\u201d, this is the \u201cSetRangeValue\u201d directive payload object that contains the \"rangeValue\" property and the corresponding value between configuration.supportedRange.minumumValue and configuration.supportedRange.maximumValue . If name is \u201cAdjustRangeValue\u201d, this is the \u201cAdjustRangeValue\u201d directive payload object that contains the \u201crangeValueDelta\u201d field. Additional Notes about Assets \u00b6 The Car Control module provides the full list of asset IDs available in the default automotive catalog of assets in the CarControlAssets.h header file, which defines string constants for these asset IDs to be used when constructing configuration programmatically. The values of the constants are the same asset IDs that you should use if you construct your configuration in a JSON file. This module also provides a reference JSON file with sample definitions of the assets in the automotive catalog. Your implementation does not need to duplicate these asset definitions or specify the path to this file because the definitions also exist in the Alexa cloud. This copy of the file is a reference for you to see the synonyms and translations for the available assets. Note: Because the actual asset definitions are defined in the Alexa cloud, this reference file may be outdated or missing translations. The automotive catalog of assets defines assets for every feature officially supported by car control. The majority of your configuration will use these asset IDs. Amazon recommends that you not create new, custom assets for features that already exist in the default catalog. However, if your vehicle has a feature that cannot be described using the default assets (e.g., an endpoint with a proprietary name), create an additional JSON file defining a complementary set of assets to use alongside the default catalog. The format of this file must follow the same schema as the reference default assets JSON , and the definitions must include entries for each of the locales supported in the default catalog. Prefix every assetId in this file with \"My.\" , and specify the path to the file in the optional aace.carControl.assets.customAssetsPath field of configuration. Note for LVC: When using Local Voice Control and car control custom assets, there are two distinct configurations \u2014 the Auto SDK Engine and the LVC app \u2014 that require the path to the custom assets definition file. See the below subsections for details for this configuration on Linux or Android. (Local Voice Control) Custom Assets for Linux Integration \u00b6 The default LVC app configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the aace.carControl.assets.customAssetsPath field in the Car Control module configuration. (Local Voice Control) Custom Assets for Android Integration \u00b6 Local Voice Control Android integrations using the LVC APK implement the ILVCClient interface to configure Local Voice Control in the LVC APK (See the LVC extension documentation for more details). The \"CarControl.CustomAssetsFilePath\" field of the ILVCClient.getConfiguration() configuration schema specifies a path to the custom assets definition file, which must be accessible to the processes running the LVC APK services. When you integrate with AACS, you do not need to provide the CarControl.CustomAssetsFilePath field in any AACS configuration message; instead, your application should directly share permissions to the custom assets definition file using the AACS file sharing protocol. AACS will create a local copy of the file and use the path to its local copy to configure the LVC APK. Sample Configuration \u00b6 The Car Control module provides a sample JSON file to configure the Auto SDK Engine with a vehicle fully equipped for every use case officially supported for car control. This file models each supported endpoint with a configuration of capabilities and zones that ensures all supported utterances for that endpoint work as expected. It is recommended that you construct the configuration for your application by selecting the parts of this sample that describe features supported by your vehicle. Make adjustments to the endpoints, such as modifying modes and range settings, as needed. Configuration for Linux Integration \u00b6 If your implementation constructs the Car Control module EngineConfiguration programmatically rather than with a JSON file, see the following example usage of the aace::carControl::config::CarControlConfiguration builder class that produces the same fully-equipped vehicle as the sample file: Click to expand or collapse CarControlConfiguration C++ sample code #include <AACE/CarControl/CarControlAssets.h> using namespace aace :: carControl :: config ; using namespace aace :: carControl :: assets ; // Auto SDK Engine configuration std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configuration ; auto config = aace :: carControl :: config :: CarControlConfiguration :: create (); config -> createZone ( \"zone.default\" ) . addAssetId ( alexa :: location :: ALL ) . addMembers ({ \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }) . createZone ( \"zone.driver\" ) . addAssetId ( alexa :: location :: DRIVER ) . addAssetId ( alexa :: location :: FRONT_LEFT ) . addMembers ({ \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }) . createZone ( \"zone.passenger\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addAssetId ( alexa :: location :: FRONT_RIGHT ) . addMembers ({ \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }) . createZone ( \"zone.front\" ) . addAssetId ( alexa :: location :: FRONT ) . addMembers ({ \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }) . createZone ( \"zone.rear\" ) . addAssetId ( alexa :: location :: REAR ) . addMembers ({ \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }) . createZone ( \"zone.left\" ) . addAssetId ( alexa :: location :: LEFT ) . addMembers ({ \"left.heater\" , \"driver.seat\" , \"driver.vent\" }) . createZone ( \"zone.right\" ) . addAssetId ( alexa :: location :: RIGHT ) . addMembers ({ \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }) . createZone ( \"zone.rear.driver\" ) . addAssetId ( alexa :: location :: REAR_DRIVER ) . addAssetId ( alexa :: location :: REAR_LEFT ) . addMembers ({ \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }) . createZone ( \"zone.rear.passenger\" ) . addAssetId ( alexa :: location :: REAR_PASSENGER ) . addAssetId ( alexa :: location :: REAR_RIGHT ) . addMembers ({ \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }) . createZone ( \"zone.secondRow\" ) . addAssetId ( alexa :: location :: SECOND_ROW ) . addMembers ({ \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }) . createZone ( \"zone.thirdRow\" ) . addAssetId ( alexa :: location :: THIRD_ROW ) . addMembers ({ \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }) . setDefaultZone ( \"zone.default\" ) // \"Car\" . createEndpoint ( \"car\" ) . addAssetId ( alexa :: device :: CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( alexa :: value :: INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( alexa :: value :: OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( alexa :: setting :: CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( alexa :: setting :: DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( alexa :: value :: COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( alexa :: value :: SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( alexa :: value :: SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( alexa :: setting :: TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( alexa :: setting :: HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( alexa :: setting :: WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( alexa :: setting :: AUTO_BRAKE_HOLD ) // Ambient Light . createEndpoint ( \"ambient.light\" ) . addAssetId ( alexa :: device :: AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( alexa :: setting :: COLOR ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"RED\" ) . addAssetId ( alexa :: color :: RED ) . addValue ( \"BLUE\" ) . addAssetId ( alexa :: color :: BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( alexa :: color :: GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( alexa :: color :: WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( alexa :: color :: ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( alexa :: color :: YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( alexa :: color :: INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( alexa :: color :: VIOLET ) // Air Conditioner . createEndpoint ( \"default.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Air Conditioner . createEndpoint ( \"front.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Air Conditioner . createEndpoint ( \"rear.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Fan . createEndpoint ( \"default.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Fan . createEndpoint ( \"driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Fan . createEndpoint ( \"passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Fan . createEndpoint ( \"front.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Fan . createEndpoint ( \"rear.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Driver Fan . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Passenger Fan . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Fan . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Fan . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Vent . createEndpoint ( \"default.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Driver Vent . createEndpoint ( \"driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Passenger Vent . createEndpoint ( \"passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Front Vent . createEndpoint ( \"front.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Vent . createEndpoint ( \"rear.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Driver Vent . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Passenger Vent . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Second Row Vent . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Third Row Vent . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Climate Control . createEndpoint ( \"climatecontrol\" ) . addAssetId ( alexa :: device :: CLIMATE_CONTROL ) . addAssetId ( alexa :: setting :: AUTO ) . addPowerController ( false ) // Heater . createEndpoint ( \"default.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Heater . createEndpoint ( \"driver.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Heater . createEndpoint ( \"passenger.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Left Heater . createEndpoint ( \"left.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Right Heater . createEndpoint ( \"right.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Heater . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Heater . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Light . createEndpoint ( \"default.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Driver Light . createEndpoint ( \"driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Passenger Light . createEndpoint ( \"passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Front Light . createEndpoint ( \"front.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Light . createEndpoint ( \"rear.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Driver Light . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Passenger Light . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Second Row Light . createEndpoint ( \"secondRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Third Row Light . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Reading Light . createEndpoint ( \"default.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Reading Light . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Passenger Reading Light . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Front Reading Light . createEndpoint ( \"front.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Reading Light . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Driver Reading Light . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Passenger Reading Light . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Second Row Reading Light . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Third Row Reading Light . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Cupholder . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Passenger Cupholder . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Front Cupholder . createEndpoint ( \"front.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Cupholder . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Driver Cupholder . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Passenger Cupholder . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Second Row Cupholder . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Third Row Cupholder . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Driver Armrest . createEndpoint ( \"driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Passenger Armrest . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Front Armrest . createEndpoint ( \"front.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Armrest . createEndpoint ( \"rear.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Driver Armrest . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Passenger Armrest . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Second Row Armrest . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Third Row Armrest . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Driver Seat . createEndpoint ( \"driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Passenger Seat . createEndpoint ( \"passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Seat . createEndpoint ( \"front.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Seat . createEndpoint ( \"rear.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Driver Seat . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Passenger Seat . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Second Row Seat . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Third Row Seat . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Window . createEndpoint ( \"front.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Window . createEndpoint ( \"rear.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Driver Window . createEndpoint ( \"driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Passenger Window . createEndpoint ( \"passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Driver Window . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Passenger Window . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Second Row Window . createEndpoint ( \"secondRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Third Row Window . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Front Windshield . createEndpoint ( \"front.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Rear Windshield . createEndpoint ( \"rear.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Front Foglight . createEndpoint ( \"front.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Rear Foglight . createEndpoint ( \"rear.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Hazard Light . createEndpoint ( \"hazardlight\" ) . addAssetId ( alexa :: device :: HAZARD_LIGHTS ) . addAssetId ( alexa :: device :: PARKING_LIGHTS ) . addPowerController ( false ) // Front Wipers . createEndpoint ( \"front.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Wipers . createEndpoint ( \"rear.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Sunroof . createEndpoint ( \"sunroof\" ) . addAssetId ( alexa :: device :: SUNROOF ) . addAssetId ( alexa :: device :: MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // Sunshade . createEndpoint ( \"sunshade\" ) . addAssetId ( alexa :: device :: SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // HUD . createEndpoint ( \"hud\" ) . addAssetId ( alexa :: device :: HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: HUD ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // IVI . createEndpoint ( \"ivi\" ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( alexa :: value :: OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Dynamics Coordinator Page . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Performance Page . createEndpoint ( \"performancePage\" ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Home Page . createEndpoint ( \"homepage\" ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Bluetooth Page . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Radio Page . createEndpoint ( \"radioPage\" ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Settings Page . createEndpoint ( \"settingsPage\" ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Controls Page . createEndpoint ( \"controlsPage\" ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Navigation Page . createEndpoint ( \"navigationPage\" ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // GPS Page . createEndpoint ( \"gpsPage\" ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Service Page . createEndpoint ( \"servicePage\" ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Satellite Radio Page . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Information Page . createEndpoint ( \"informationPage\" ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Vehicle Status Page . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Multimedia Page . createEndpoint ( \"multimediaPage\" ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addAssetId ( alexa :: value :: MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Telephone Page . createEndpoint ( \"telephonePage\" ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Contacts Page . createEndpoint ( \"contactsPage\" ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Alerts Page . createEndpoint ( \"alertsPage\" ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Notifications Page . createEndpoint ( \"notificationsPage\" ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // 360 Camera . createEndpoint ( \"360Camera\" ) . addAssetId ( alexa :: device :: CAMERA_360 ) . addAssetId ( alexa :: device :: AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( alexa :: setting :: DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( alexa :: location :: FRONT ) . addValue ( \"REAR\" ) . addAssetId ( alexa :: location :: REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( alexa :: location :: DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Steering Wheel . createEndpoint ( \"steeringWheel\" ) . addAssetId ( alexa :: device :: STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Hood . createEndpoint ( \"hood\" ) . addAssetId ( alexa :: device :: HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Trunk . createEndpoint ( \"trunk\" ) . addAssetId ( alexa :: device :: TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Charge Door . createEndpoint ( \"chargedoor\" ) . addAssetId ( alexa :: device :: CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Gas Door . createEndpoint ( \"gasdoor\" ) . addAssetId ( alexa :: device :: GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ); configuration . push_back ( config ); Configuration for Android Integration \u00b6 To use the Car Control module Engine configuration with AACS, use \"aacs.carControl\" instead of \"aace.carControl\" in your AACS configuration file: { \"aacs.carControl\": { \"endpoints\": [ // list of endpoint definitions ], \"zones\": [ // list of zone definitions ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory class com.amazon.aace.carControl.CarControlConfiguration to programmatically construct the EngineConfiguration in the proper format, as shown in the example below. CarControlConfiguration Java sample code \u00b6 import com.amazon.aace.carControl.CarControlAssets ; import com.amazon.aace.carControl.CarControlConfiguration ; import com.amazon.aace.core.config.EngineConfiguration ; // Auto SDK Engine configuration List < EngineConfiguration > configuration = new ArrayList <> (); CarControlConfiguration config = CarControlConfiguration . create (); config . createZone ( \"zone.default\" ) . addAssetId ( CarControlAssets . Location . ALL ) . addMembers ( new String [] { \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }); config . createZone ( \"zone.driver\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addAssetId ( CarControlAssets . Location . FRONT_LEFT ) . addMembers ( new String [] { \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }); config . createZone ( \"zone.passenger\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addAssetId ( CarControlAssets . Location . FRONT_RIGHT ) . addMembers ( new String [] { \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }); config . createZone ( \"zone.front\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addMembers ( new String [] { \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }); config . createZone ( \"zone.rear\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addMembers ( new String [] { \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }); config . createZone ( \"zone.left\" ) . addAssetId ( CarControlAssets . Location . LEFT ) . addMembers ( new String [] { \"left.heater\" , \"driver.seat\" , \"driver.vent\" }); config . createZone ( \"zone.right\" ) . addAssetId ( CarControlAssets . Location . RIGHT ) . addMembers ( new String [] { \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }); config . createZone ( \"zone.rear.driver\" ) . addAssetId ( CarControlAssets . Location . REAR_DRIVER ) . addAssetId ( CarControlAssets . Location . REAR_LEFT ) . addMembers ( new String [] { \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }); config . createZone ( \"zone.rear.passenger\" ) . addAssetId ( CarControlAssets . Location . REAR_PASSENGER ) . addAssetId ( CarControlAssets . Location . REAR_RIGHT ) . addMembers ( new String [] { \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }); config . createZone ( \"zone.secondRow\" ) . addAssetId ( CarControlAssets . Location . SECOND_ROW ) . addMembers ( new String [] { \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }); config . createZone ( \"zone.thirdRow\" ) . addAssetId ( CarControlAssets . Location . THIRD_ROW ) . addMembers ( new String [] { \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }); config . setDefaultZone ( \"zone.default\" ); // \"Car\" config . createEndpoint ( \"car\" ) . addAssetId ( CarControlAssets . Device . CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( CarControlAssets . Value . INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( CarControlAssets . Value . OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( CarControlAssets . Setting . CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( CarControlAssets . Setting . DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( CarControlAssets . Value . COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( CarControlAssets . Value . SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( CarControlAssets . Value . SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( CarControlAssets . Setting . TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( CarControlAssets . Setting . HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( CarControlAssets . Setting . WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( CarControlAssets . Setting . AUTO_BRAKE_HOLD ); // Ambient Light config . createEndpoint ( \"ambient.light\" ) . addAssetId ( CarControlAssets . Device . AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( CarControlAssets . Setting . COLOR ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"RED\" ) . addAssetId ( CarControlAssets . Color . RED ) . addValue ( \"BLUE\" ) . addAssetId ( CarControlAssets . Color . BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( CarControlAssets . Color . GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( CarControlAssets . Color . WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( CarControlAssets . Color . ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( CarControlAssets . Color . YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( CarControlAssets . Color . INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( CarControlAssets . Color . VIOLET ); // Air Conditioner config . createEndpoint ( \"default.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Air Conditioner config . createEndpoint ( \"front.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Air Conditioner config . createEndpoint ( \"rear.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Fan config . createEndpoint ( \"default.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Fan config . createEndpoint ( \"driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Fan config . createEndpoint ( \"passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Fan config . createEndpoint ( \"front.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Fan config . createEndpoint ( \"rear.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Driver Fan config . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Passenger Fan config . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Fan config . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Fan config . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Vent config . createEndpoint ( \"default.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Driver Vent config . createEndpoint ( \"driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Passenger Vent config . createEndpoint ( \"passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Front Vent config . createEndpoint ( \"front.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Vent config . createEndpoint ( \"rear.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Driver Vent config . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Passenger Vent config . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Second Row Vent config . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Third Row Vent config . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Climate Control config . createEndpoint ( \"climatecontrol\" ) . addAssetId ( CarControlAssets . Device . CLIMATE_CONTROL ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addPowerController ( false ); // Heater config . createEndpoint ( \"default.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Heater config . createEndpoint ( \"driver.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Heater config . createEndpoint ( \"passenger.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Left Heater config . createEndpoint ( \"left.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Right Heater config . createEndpoint ( \"right.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Heater config . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Heater config . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Light config . createEndpoint ( \"default.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Driver Light config . createEndpoint ( \"driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Passenger Light config . createEndpoint ( \"passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Front Light config . createEndpoint ( \"front.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Light config . createEndpoint ( \"rear.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Driver Light config . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Passenger Light config . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Second Row Light config . createEndpoint ( \"secondRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Third Row Light config . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Reading Light config . createEndpoint ( \"default.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Reading Light config . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Passenger Reading Light config . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Front Reading Light config . createEndpoint ( \"front.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Reading Light config . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Driver Reading Light config . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Passenger Reading Light config . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Second Row Reading Light config . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Third Row Reading Light config . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Cupholder config . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Passenger Cupholder config . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Front Cupholder config . createEndpoint ( \"front.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Cupholder config . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Driver Cupholder config . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Passenger Cupholder config . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Second Row Cupholder config . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Third Row Cupholder config . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Driver Armrest config . createEndpoint ( \"driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Passenger Armrest config . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Front Armrest config . createEndpoint ( \"front.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Armrest config . createEndpoint ( \"rear.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Driver Armrest config . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Passenger Armrest config . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Second Row Armrest config . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Third Row Armrest config . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Driver Seat config . createEndpoint ( \"driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Passenger Seat config . createEndpoint ( \"passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Seat config . createEndpoint ( \"front.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Seat config . createEndpoint ( \"rear.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Driver Seat config . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Passenger Seat config . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Second Row Seat config . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Third Row Seat config . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Window config . createEndpoint ( \"front.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Window config . createEndpoint ( \"rear.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Driver Window config . createEndpoint ( \"driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Passenger Window config . createEndpoint ( \"passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Driver Window config . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Passenger Window config . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Second Row Window config . createEndpoint ( \"secondRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Third Row Window config . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Front Windshield config . createEndpoint ( \"front.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Rear Windshield config . createEndpoint ( \"rear.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Front Foglight config . createEndpoint ( \"front.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Rear Foglight config . createEndpoint ( \"rear.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Hazard Light config . createEndpoint ( \"hazardlight\" ) . addAssetId ( CarControlAssets . Device . HAZARD_LIGHTS ) . addAssetId ( CarControlAssets . Device . PARKING_LIGHTS ) . addPowerController ( false ); // Front Wipers config . createEndpoint ( \"front.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Wipers config . createEndpoint ( \"rear.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Sunroof config . createEndpoint ( \"sunroof\" ) . addAssetId ( CarControlAssets . Device . SUNROOF ) . addAssetId ( CarControlAssets . Device . MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // Sunshade config . createEndpoint ( \"sunshade\" ) . addAssetId ( CarControlAssets . Device . SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // HUD config . createEndpoint ( \"hud\" ) . addAssetId ( CarControlAssets . Device . HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . HUD ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // IVI config . createEndpoint ( \"ivi\" ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( CarControlAssets . Value . OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Dynamics Coordinator Page config . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Performance Page config . createEndpoint ( \"performancePage\" ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Home Page config . createEndpoint ( \"homepage\" ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Bluetooth Page config . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Radio Page config . createEndpoint ( \"radioPage\" ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Settings Page config . createEndpoint ( \"settingsPage\" ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Controls Page config . createEndpoint ( \"controlsPage\" ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Navigation Page config . createEndpoint ( \"navigationPage\" ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // GPS Page config . createEndpoint ( \"gpsPage\" ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Service Page config . createEndpoint ( \"servicePage\" ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Satellite Radio Page config . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Information Page config . createEndpoint ( \"informationPage\" ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Vehicle Status Page config . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Multimedia Page config . createEndpoint ( \"multimediaPage\" ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addAssetId ( CarControlAssets . Value . MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Telephone Page config . createEndpoint ( \"telephonePage\" ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Contacts Page config . createEndpoint ( \"contactsPage\" ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Alerts Page config . createEndpoint ( \"alertsPage\" ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Notifications Page config . createEndpoint ( \"notificationsPage\" ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // 360 Camera config . createEndpoint ( \"360Camera\" ) . addAssetId ( CarControlAssets . Device . CAMERA_360 ) . addAssetId ( CarControlAssets . Device . AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( CarControlAssets . Setting . DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addValue ( \"REAR\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Steering Wheel config . createEndpoint ( \"steeringWheel\" ) . addAssetId ( CarControlAssets . Device . STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Hood config . createEndpoint ( \"hood\" ) . addAssetId ( CarControlAssets . Device . HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Trunk config . createEndpoint ( \"trunk\" ) . addAssetId ( CarControlAssets . Device . TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Charge Door config . createEndpoint ( \"chargedoor\" ) . addAssetId ( CarControlAssets . Device . CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Gas Door config . createEndpoint ( \"gasdoor\" ) . addAssetId ( CarControlAssets . Device . GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); configuration . add ( config ); Using the Car Control Module AASB Messages \u00b6 The Auto SDK Engine provides an AASB message interface with topic CarControl for you to handle the car control directives from Alexa. The messages include an endpointId to identify the connected endpoint that Alexa identified to match the user's intent. For directives targeting primitive capability instances, the message includes the instanceId as well. The endpointId and instanceId match the configured IDs from aace.carControl.endpoints[i].endpointId and aace.carControl.endpoints[i].capabilities[j].instance , respectively. Changing the power state of an endpoint \u00b6 When the user requests Alexa to turn an endpoint on or off, the Engine publishes a SetControllerValue message for power state . Your application must power on or off the endpoint and publish SetControllerReply message in response. Click to expand or collapse sequence diagram: Turning on AC Click to expand or collapse sequence diagram: Turning off AC Toggling an endpoint property \u00b6 When the user requests Alexa to turn on or off a named property of an endpoint, the Engine publishes a SetControllerValue message for toggle of the setting . Your application must turn on or off the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Turning on the rear windshield defroster Click to expand or collapse sequence diagram: Turning off the rear windshield defroster Changing the mode of an endpoint property \u00b6 When the user requests Alexa to set the mode of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for mode of the setting . Your application must set the mode of the property and publish SetControllerValueReply` message in response. Click to expand or collapse sequence diagram: Setting the AC intensity to minimum When the user requests Alexa to increase or decrease the mode of a named property of an endpoint, the Engine publishes an AdjustControllerValue message for mode of the setting . Your application must adjust the mode of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the AC intensity Changing the numeric setting of an endpoint property \u00b6 When the user requests Alexa to set the numeric setting of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for the range setting . Your application must set the value of the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Setting the temperature to 70 When the user requests Alexa to adjust (increment or decrement) the numeric setting of a named property of an endpoint by a delta value, the Engine publishes a AdjustControllerValue message for the range setting . Your application must adjust the value of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the temperature by 4 Integrating the Car Control Module Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the Engine's MessageBroker to subscribe to \"CarControl\" AASB messages and publish replies. Click to expand or collapse C++ sample code #include <AACE/CarControl/CarControlConfiguration.h> #include <AACE/Core/MessageBroker.h> #include <AASB/Message/CarControl/CarControl/AdjustControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetPowerControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetToggleControllerValueMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyCarControlHandler { static const std :: string AASB_TOPIC_CAR_CONTROL ( \"CarControl\" ); static const std :: string AASB_ACTION_SET_CONTROLLER_VALUE ( \"SetControllerValue\" ); static const std :: string AASB_ACTION_ADJUST_CONTROLLER_VALUE ( \"AdjustControllerValue\" ); // Subscribe to \"CarControl\" messages from the Engine void MyCarControlHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_SET_CONTROLLER_VALUE ); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAdjustControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_ADJUST_CONTROLLER_VALUE ); } // Handle the messages from the Engine for \"SetControllerValue\" action void MyCarControlHandler::handleSetControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"POWER\" ) == 0 ) { SetPowerControllerValueMessage msg = json :: parse ( message ); setPowerControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"TOGGLE\" ) == 0 ) { SetToggleControllerValueMessage msg = json :: parse ( message ); setToggleControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { SetRangeControllerValueMessage msg = json :: parse ( message ); setRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { SetModeControllerValueMessage msg = json :: parse ( message ); setModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::setPowerControllerValue ( const std :: string & messageId , const std :: string & endpointId , bool turnOn ) { if ( turnOn ) { // Power on the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Power off the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setToggleControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , bool turnOn ) { if ( turnOn ) { // Turn on the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Turn off the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double value ) { // Set the numeric setting of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::setModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , const std :: string & value ) { // Set the mode of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendSetControllerValueMessageReply ( const std :: string & messageId , bool successful ) { SetControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); } // Handle the messages from the Engine for \"AdjustControllerValue\" action void MyCarControlHandler::handleAdjustControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { AdjustRangeControllerValueMessage msg = json :: parse ( message ); adjustRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { AdjustModeControllerValueMessage msg = json :: parse ( message ); adjustModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::adjustRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the numeric setting of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::adjustModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the mode of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendAdjustControllerValueMessageReply ( const std :: string & messageId , bool successful ) { AdjustControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); } AACS Android integration \u00b6 The Alexa Auto Client Service (AACS) provides the AACS Car Control Library to integrate the Auto SDK Car Control module on Android. See the AACS Car Control Library documentation for more information.","title":"Car Control Module"},{"location":"explore/features/car-control/#car-control-module","text":"","title":"Car Control Module"},{"location":"explore/features/car-control/#overview","text":"The Alexa Auto SDK Car Control module enables you to build a custom experience that allows users to use Alexa to voice-control vehicle features. The following concepts comprise the Car Control module APIs:","title":"Overview"},{"location":"explore/features/car-control/#endpoints","text":"The head unit device acting as an Alexa Auto SDK client is an \"endpoint\" that connects to the Alexa service. Other Auto SDK modules, such as Alexa , configure capabilities on this \"root\" or \"default\" endpoint because the capabilities pertain to the head unit itself. The Car Control module enables the default Auto SDK client endpoint to act as a proxy to receive events and directives on behalf of connected endpoints. You can configure a separate endpoint for every vehicle component that the head unit can control through device-level connections. This enables the user to target individual vehicle components directly with utterances like \"Alexa, turn on the AC\" or \"Alexa, set the temperature to 65.\"","title":"Endpoints"},{"location":"explore/features/car-control/#capabilities","text":"In the utterance \"Alexa, turn on the AC\", \"turn on\" corresponds to a specific capability configured for the \"AC\" endpoint. Defining an endpoint declares a vehicle feature to be controllable, and defining capabilities on the endpoint declares how the endpoint can be controlled. Car Control supports four capability interfaces that can be declared alone or in combination for a particular endpoint to model its individual control experience: Power Controller controls the overall power state of an endpoint. For example, configuring an \"AC\" endpoint with a Power Controller capability enables utterances such as \"Alexa, turn on the AC\" and \"Alexa, power off the AC\". Toggle Controller controls a particular named property of an endpoint that can be turned on and off. For example, configuring a \"windshield\" endpoint with a \"defroster\" Toggle Controller capability instance enables utterances such as \"Alexa, turn on the windshield defroster.\" Mode Controller controls a particular named property of an endpoint that can be set to a discrete value from a defined set of values. For example, if an ambient light endpoint has red and green color settings, configuring an \"ambient light\" endpoint with a \"color\" Mode Controller capability instance enables utterances such as \"Alexa, set the ambient light color to red\" and \"Alexa, change the ambient light to green.\" Range Controller controls a particular named property of an endpoint that can be set to a numeric value within a range. For example, if a fan endpoint has a speed property with settings 1 through 3, configuring a \"fan\" endpoint with a \"speed\" Range Controller capability instance enables utterances such as \"Alexa, set the fan speed to 2.\" You can configure names, such as \"medium\", for a range value to enable additional utterances such as \"Alexa, set the fan to medium\" to set the fan speed setting to 2.","title":"Capabilities"},{"location":"explore/features/car-control/#capability-primitives-and-semantic-annotations","text":"Toggle Controller, Mode Controller, and Range Controller are known as \"capability primitives.\" You can use multiple instances of the same capability primitive interface on an endpoint under different instance names. For example, a heater endpoint might have intensity and position properties that are both best modeled as modes. You can declare an \"intensity\" Mode Controller instance and a \"position\" Mode Controller instance on the same \"heater\" endpoint so the user can target each property separately. To provide intuitive experiences for users, capability primitives offer \"semantic annotations\" for the devices to map specific utterances to the behaviors of capability instances. For example, if the vehicle uses a Range Controller to control a window, a user would prefer to say \"Alexa, open the window\" over the default utterances of the Range Controller such as \"Alexa, set the window height to 0\". For any endpoint to which the \"open\", \"close\", \"raise\", or \"lower\" concepts apply, you can configure the capability primitive instances of the endpoint with a \"semantics\" object that maps user utterances for these actions to the appropriate capability directives. Each action (e.g., \"open\") is allowed only once per endpoint since the action expresses intent to control the endpoint as a whole. The actions specified in configuration are action IDs rather than literal strings, which ensures Alexa recognizes all synonyms and translations for the action in the user utterance. The supported actions are \"Alexa.Actions.Open\", \"Alexa.Actions.Close\", \"Alexa.Actions.Raise\", and \"Alexa.Actions.Lower.\"","title":"Capability Primitives and Semantic Annotations"},{"location":"explore/features/car-control/#zones","text":"Each endpoint can belong to zero, one, or many \"zones.\" Zones, configured with member endpoints, define named regions of the vehicle and allow users to target endpoints by location. Zones are essential for unambiguous targeting of endpoints that have friendly names that overlap with other endpoints. For example, defining \"driver\" and \"passenger\" zones and assigning distinct \"seat\" endpoints to each allows proper control of the \"driver seat\" and the \"passenger seat\" independently. Assigning one zone in particular as the \"default\" enables endpoints in this zone to take precedence over endpoints sharing the same friendly name but not in the default zone when the user does not specify a zone in the utterance. This is useful for distinguishing \"zoneless\" endpoints from \"zoned\" endpoints with the same name when it is most likely that the user intends to target the \"zoneless\" one. For example, consider a vehicle with zone IDs \"zone.all\", \"zone.rear\", and \"zone.left\" with a distinct fan endpoint in each zone. If the user says \"Alexa, turn on the fan\", it is most likely that he wants to turn on the fan that refers to the vehicle as a whole because there is no natural way to specify its location. You can ensure that Alexa will resolve this utterance to the fan in the \"all\" zone by assigning \"zone.all\" as the default zone. Additionally, the default zone is useful for cases in which you have zoned endpoints with overlapping names, but one of the endpoints is a clear \"default\" to the user. For example, consider a vehicle with zones \"zone.all\" (assigned as default), \"zone.driver\", and \"zone.passenger\". The vehicle has a \"driver window\" in \"zone.driver\" and a \"passenger window\" in \"zone.passenger\", but Alexa cannot resolve which endpoint is the intended target of the user utterance \"Alexa, open the window.\" However, the user probably means \"Alexa, open the driver window\". You can ensure that Alexa considers the \"driver window\" as the \"default\" window by assigning it to \"zone.all\" as well.","title":"Zones"},{"location":"explore/features/car-control/#assets","text":"The definitions of endpoints, capabilities, and zones include \"assets.\" Assets, identified by unique IDs, group a voice-accessible friendly name like \"air conditioner\" into a named group of synonyms and translations for all supported languages. For example, using the asset with ID \"Alexa.Automotive.DeviceName.AirConditioner\" in your car control module configuration for an AC endpoint not only enables the user to target the air conditioner with the default phrase \"air conditioner\", but also with phrases like \"air con\" and \"AC\" in English as well as synonyms in other supported locales. Using assets allows decoupling the many ways of identifying components from the core configuration of the components and enables de-duplication across different components that have overlapping ways to be identified. The Alexa Auto SDK provides a list of IDs for the \"default assets,\" which form an automotive-specific catalog. The catalog contains asset definitions for supported car control features, including endpoint names, zone names, and capability settings. Each default asset ID is prefixed with \"Alexa.Automotive.\" You can use these asset IDs in your Car Control module configuration without the corresponding definitions of friendly names, synonyms, and translations, because the definitions are specified in the Alexa cloud.","title":"Assets"},{"location":"explore/features/car-control/#configuring-the-car-control-module","text":"Car Control module configuration is vehicle-specific and tells the Auto SDK Engine which vehicle features to advertise to Alexa for control by the user. You must configure the Auto SDK Engine with an EngineConfiguration object that describes the vehicle. Like all Auto SDK Engine configuration, you can either define the JSON in a file and construct an EngineConfiguration from that file, or you can use the provided CarControlConfiguration class to programmatically construct the EngineConfiguration in the proper format. The following subsections describe the JSON schema. See the CarControlConfiguration class for details on how to build configuration programmatically.","title":"Configuring the Car Control Module"},{"location":"explore/features/car-control/#configuration-format","text":"The Engine configuration for the Car Control module includes definitions of endpoints with their capabilities, zones with their member endpoints, and an optional path to a JSON file defining additional assets. Sample JSON Object { \"aace.carControl\": { \"endpoints\": [ { \"endpointId\": \"{{STRING}}\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"capabilities\": [ // list of capability definitions for this endpoint ] } ], \"zones\": [ { \"zoneID\": \"{{STRING}}\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] }, \"members\": [ { \"endpointId\": \"{{STRING}}\" } ] } ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Object Parameters Property Type Required Description aace.carControl. endpoints list Yes The list of connected endpoints for which the device implements capabilities. Each endpoint describes one controllable vehicle component. aace.carControl. endpoints[i]. endpointId string Yes The identifier for the endpoint, unique amongst all endpoints in the vehicle. The same endpointId is used to identify the endpoint targeted in an AASB message sent by the Engine. Note: Do not use this format for the endpointId : \\<clientId>::\\<productId>::\\<serialNumber>::[-\\<extEndpoint>] The Engine internally prepends the 3-part device prefix to your specified endpointId before sending the configuration to Alexa. Configuring the full ID directly results in duplication and excess characters. aace.carControl. endpoints[i]. endpointResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this endpoint. Note: Only \u201casset\u201d type labels are supported. aace.carControl. endpoints[i]. endpointResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to the endpoint. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. endpoints[i]. capabilities list Yes A list of capability definitions, representing capabilities implemented by the device on behalf of the endpoint, that define how the endpoint can be controlled by the user. Each object in this list must be a valid definition for one of the capabilities supported by the Car Control module: Alexa.PowerController , Alexa.ToggleController , Alexa.ModeController , and Alexa.RangeController aace.carControl. zones list No, but recommended A list of zone definitions for the named regions in the vehicle. aace.carControl. zones[i]. zoneId string Yes The identifier for the zone, unique amongst all zones in the vehicle. aace.carControl. zones[i]. zoneResources. friendlyNames list Yes A list of label objects that describe the possible ways to refer to this zone. Note: Only \u201casset\u201d type labels are supported. aace.carControl. zones[i]. zoneResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of strings used to refer to the zone in all supported locales. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. zones[i]. members list Yes A list of endpoints that belong to this zone. aace.carControl. zones[i]. members[j]. endpointId string Yes The endpointId for an endpoint that belongs to this zone. aace.carControl. defaultZoneId string No, but recommended The zoneId of the default zone. Endpoints in this zone take precedence when a user utterance does not specify a zone. It is recommended to use a zone that describes the whole vehicle as the default rather than a zone describing a specific region. aace.carControl. assets.customAssetsPath string (file path) No Specifies the path to a JSON file defining additional assets.","title":"Configuration Format"},{"location":"explore/features/car-control/#power-controller-capability-configuration","text":"Click to expand or collapse description See \"Alexa.PowerController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.PowerController\", \"version\": \"3\", \"properties\": { \"supported\": [ { \"name\": \"powerState\" } ], \"proactivelyReported\": false, \"retrievable\": false } } Object Parameters Property Type Required Description properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"powerState\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"powerState\") can be retrieved by Alexa. Accepted values: false","title":"Power Controller Capability Configuration"},{"location":"explore/features/car-control/#toggle-controller-capability-configuration","text":"Click to expand or collapse description See \"Alexa.ToggleController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ToggleController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"proactivelyReported\": false, \"retrievable\": false, \"supported\": [ { \"name\": \"toggleState\" } ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {} } }, ... ] } } Object Parameters Property Type Required Description instance string Yes The identifier of this instance of Alexa.ToggleController on this endpoint. capabilityResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only \u201casset\u201d type labels are supported. capabilityResources. friendlyNames[i]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"toggleState\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"toggleState\") can be retrieved by Alexa. Accepted values: false semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance. Note: semantics.stateMappings is not supported. semantics. actionMappings[i]. actions[j] string Yes, if semantics is present The identifiers of the utterances that should trigger the specified directive. Accepted values: \"Alexa.Actions.Open\" : \"open {endpoint}\" \"Alexa.Actions.Close\" : \"close {endpoint}\" \"Alexa.Actions.Raise\" : \"raise {endpoint}\" \"Alexa.Actions.Lower\" : \"lower {endpoint}\" semantics. actionMappings[i]. directive. name string Yes, if semantics is present Accepted values: \"TurnOn\" : The specified actions will trigger the \"TurnOn\" directive. The Engine will publish the SetToggleControllerValue message, with the turnOn attribute set to true . \"TurnOff\" : The specified actions will trigger the \"TurnOff\" directive. The Engine will publish the SetToggleControllerValue message, with the turnOn attribute set to false .","title":"Toggle Controller Capability Configuration"},{"location":"explore/features/car-control/#mode-controller-capability-configuration","text":"Click to expand or collapse description See \"Alexa.ModeController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ModeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"mode\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"ordered\": {{BOOLEAN}}, \"supportedModes\": [ { \"value\": \"{{STRING}}\", \"modeResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] } }, ... ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } Object Parameters Property Type Required Description instance string Yes The identifier of this instance of Alexa.ModeController on this endpoint. capabilityResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only \u201casset\u201d type labels are supported. capabilityResources. friendlyNames[i]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"mode\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"mode\") can be retrieved by Alexa. Accepted values: false configuration. ordered boolean Yes Whether the modes of this capability instance are ordered, enabling iteration through them using the \"AdjustMode\" directive. configuration. supportedModes list Yes A list of objects describing the available modes of this capability instance. If ordered is true, the order of the objects in this list implies the ordering of the modes. configuration. supportedModes[i]. value string Yes The identifier of this mode on this capability instance. configuration. supportedModes[i]. modeResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this mode. Note: Only \u201casset\u201d type labels are supported. semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance. Note: semantics.stateMappings is not supported. semantics. actionMappings[i]. actions[j] string Yes, if semantics is present The identifiers of the utterances that should trigger the specified directive. Accepted values: \"Alexa.Actions.Open\" : \"open {endpoint}\" \"Alexa.Actions.Close\" : \"close {endpoint}\" \"Alexa.Actions.Raise\" : \"raise {endpoint}\" \"Alexa.Actions.Lower\" : \"lower {endpoint}\" semantics. actionMappings[i]. directive. name string Yes, if semantics is present Accepted values: \"SetMode\" : The specified actions will trigger the \"SetMode\" directive with the specified payload . The Engine will publish the SetModeControllerValue message. \"AdjustMode\" : The specified actions will trigger the \"AdjustMode\" directive with the specified payload . The Engine will publish the AdjustModeControllerValue message. \"AdjustMode\" is accepted only if this capability instance is ordered . semantics. actionMappings[i]. directive. payload object Yes, if semantics is present If name is \u201cSetMode\u201d, this is the \u201cSetMode\u201d directive payload object that contains the \u201cmode\u201d property and the corresponding value from configuration.supportedModes[].value . If name is \u201cAdjustMode\u201d, this is the \u201cAdjustMode\u201d directive payload object that contains the \u201cmodeDelta\u201d field and the corresponding number of modes to advance.","title":"Mode Controller Capability Configuration"},{"location":"explore/features/car-control/#range-controller-capability-configuration","text":"Click to expand or collapse description See \"Alexa.RangeController\" interface AVS documentation for additional details, but note that only features described in this document are supported for car control. Sample JSON Object { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.RangeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"rangeValue\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"supportedRange\": { \"minimumValue\": {{LONG}}, \"maximumValue\": {{LONG}}, \"precision\": {{LONG}} }, \"unitOfMeasure\": \"{{STRING}}\", \"presets\": [ { \"rangeValue\": {{LONG}}, \"presetResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] } }, ... ], \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } } Object Parameters Property Type Required Description instance string Yes The identifier of this instance of Alexa.RangeController on this endpoint. capabilityResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. Note: Only \u201casset\u201d type labels are supported. capabilityResources. friendlyNames[i]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. properties. proactivelyReported boolean Yes Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be proactively reported to Alexa via an event. Accepted values: false properties. retrievable boolean Yes Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be retrieved by Alexa. Accepted values: false configuration. supportedRange. minimumValue long Yes The minimum value of the range this capability instance supports. configuration. supportedRange. maximumValue long Yes The maximum value of the range this capability instance supports. configuration. supportedRange. precision long Yes The amount by which the set value changes when iterating through the range. For example, if a user asks Alexa to increase the value but doesn't specify by how much, this value will be used. configuration. unitOfMeasure string No The unit of measure for the range. configuration. presets list Yes A list of objects describing values that can be invoked by name. For example, a rangeValue of 10 might be configured as the \"high\" preset. configuration. presets[i]. rangeValue long Yes The value within the supportedRange that has an associated named preset. configuration. presets[i]. presetResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this preset. Note: Only \u201casset\u201d type labels are supported. semantics object No Semantic annotations that enable mapping user utterances with directives targeting this capability instance. Note: semantics.stateMappings is not supported. semantics. actionMappings[i]. actions[j] string Yes, if semantics is present The identifiers of the utterances that should trigger the specified directive. Accepted values: \"Alexa.Actions.Open\" : \"open {endpoint}\" \"Alexa.Actions.Close\" : \"close {endpoint}\" \"Alexa.Actions.Raise\" : \"raise {endpoint}\" \"Alexa.Actions.Lower\" : \"lower {endpoint}\" semantics. actionMappings[i]. directive. name string Yes, if semantics is present Accepted values: \"SetRangeValue\" : The specified actions will trigger the \"SetRangeValue\" directive with the specified payload . The Engine will publish the SetRangeControllerValue message. \"AdjustRangeValue\" : The specified actions will trigger the \"AdjustRangeValue\" directive with the specified payload . The Engine will publish the AdjustRangeControllerValue message. semantics. actionMappings[i]. directive. payload object Yes, if semantics is present If name is \u201cSetRangeValue\u201d, this is the \u201cSetRangeValue\u201d directive payload object that contains the \"rangeValue\" property and the corresponding value between configuration.supportedRange.minumumValue and configuration.supportedRange.maximumValue . If name is \u201cAdjustRangeValue\u201d, this is the \u201cAdjustRangeValue\u201d directive payload object that contains the \u201crangeValueDelta\u201d field.","title":"Range Controller Capability Configuration"},{"location":"explore/features/car-control/#additional-notes-about-assets","text":"The Car Control module provides the full list of asset IDs available in the default automotive catalog of assets in the CarControlAssets.h header file, which defines string constants for these asset IDs to be used when constructing configuration programmatically. The values of the constants are the same asset IDs that you should use if you construct your configuration in a JSON file. This module also provides a reference JSON file with sample definitions of the assets in the automotive catalog. Your implementation does not need to duplicate these asset definitions or specify the path to this file because the definitions also exist in the Alexa cloud. This copy of the file is a reference for you to see the synonyms and translations for the available assets. Note: Because the actual asset definitions are defined in the Alexa cloud, this reference file may be outdated or missing translations. The automotive catalog of assets defines assets for every feature officially supported by car control. The majority of your configuration will use these asset IDs. Amazon recommends that you not create new, custom assets for features that already exist in the default catalog. However, if your vehicle has a feature that cannot be described using the default assets (e.g., an endpoint with a proprietary name), create an additional JSON file defining a complementary set of assets to use alongside the default catalog. The format of this file must follow the same schema as the reference default assets JSON , and the definitions must include entries for each of the locales supported in the default catalog. Prefix every assetId in this file with \"My.\" , and specify the path to the file in the optional aace.carControl.assets.customAssetsPath field of configuration. Note for LVC: When using Local Voice Control and car control custom assets, there are two distinct configurations \u2014 the Auto SDK Engine and the LVC app \u2014 that require the path to the custom assets definition file. See the below subsections for details for this configuration on Linux or Android.","title":"Additional Notes about Assets"},{"location":"explore/features/car-control/#local-voice-control-custom-assets-for-linux-integration","text":"The default LVC app configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the aace.carControl.assets.customAssetsPath field in the Car Control module configuration.","title":"(Local Voice Control) Custom Assets for Linux Integration"},{"location":"explore/features/car-control/#local-voice-control-custom-assets-for-android-integration","text":"Local Voice Control Android integrations using the LVC APK implement the ILVCClient interface to configure Local Voice Control in the LVC APK (See the LVC extension documentation for more details). The \"CarControl.CustomAssetsFilePath\" field of the ILVCClient.getConfiguration() configuration schema specifies a path to the custom assets definition file, which must be accessible to the processes running the LVC APK services. When you integrate with AACS, you do not need to provide the CarControl.CustomAssetsFilePath field in any AACS configuration message; instead, your application should directly share permissions to the custom assets definition file using the AACS file sharing protocol. AACS will create a local copy of the file and use the path to its local copy to configure the LVC APK.","title":"(Local Voice Control) Custom Assets for Android Integration"},{"location":"explore/features/car-control/#sample-configuration","text":"The Car Control module provides a sample JSON file to configure the Auto SDK Engine with a vehicle fully equipped for every use case officially supported for car control. This file models each supported endpoint with a configuration of capabilities and zones that ensures all supported utterances for that endpoint work as expected. It is recommended that you construct the configuration for your application by selecting the parts of this sample that describe features supported by your vehicle. Make adjustments to the endpoints, such as modifying modes and range settings, as needed.","title":"Sample Configuration"},{"location":"explore/features/car-control/#configuration-for-linux-integration","text":"If your implementation constructs the Car Control module EngineConfiguration programmatically rather than with a JSON file, see the following example usage of the aace::carControl::config::CarControlConfiguration builder class that produces the same fully-equipped vehicle as the sample file: Click to expand or collapse CarControlConfiguration C++ sample code #include <AACE/CarControl/CarControlAssets.h> using namespace aace :: carControl :: config ; using namespace aace :: carControl :: assets ; // Auto SDK Engine configuration std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configuration ; auto config = aace :: carControl :: config :: CarControlConfiguration :: create (); config -> createZone ( \"zone.default\" ) . addAssetId ( alexa :: location :: ALL ) . addMembers ({ \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }) . createZone ( \"zone.driver\" ) . addAssetId ( alexa :: location :: DRIVER ) . addAssetId ( alexa :: location :: FRONT_LEFT ) . addMembers ({ \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }) . createZone ( \"zone.passenger\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addAssetId ( alexa :: location :: FRONT_RIGHT ) . addMembers ({ \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }) . createZone ( \"zone.front\" ) . addAssetId ( alexa :: location :: FRONT ) . addMembers ({ \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }) . createZone ( \"zone.rear\" ) . addAssetId ( alexa :: location :: REAR ) . addMembers ({ \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }) . createZone ( \"zone.left\" ) . addAssetId ( alexa :: location :: LEFT ) . addMembers ({ \"left.heater\" , \"driver.seat\" , \"driver.vent\" }) . createZone ( \"zone.right\" ) . addAssetId ( alexa :: location :: RIGHT ) . addMembers ({ \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }) . createZone ( \"zone.rear.driver\" ) . addAssetId ( alexa :: location :: REAR_DRIVER ) . addAssetId ( alexa :: location :: REAR_LEFT ) . addMembers ({ \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }) . createZone ( \"zone.rear.passenger\" ) . addAssetId ( alexa :: location :: REAR_PASSENGER ) . addAssetId ( alexa :: location :: REAR_RIGHT ) . addMembers ({ \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }) . createZone ( \"zone.secondRow\" ) . addAssetId ( alexa :: location :: SECOND_ROW ) . addMembers ({ \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }) . createZone ( \"zone.thirdRow\" ) . addAssetId ( alexa :: location :: THIRD_ROW ) . addMembers ({ \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }) . setDefaultZone ( \"zone.default\" ) // \"Car\" . createEndpoint ( \"car\" ) . addAssetId ( alexa :: device :: CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( alexa :: value :: INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( alexa :: value :: OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( alexa :: setting :: CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( alexa :: setting :: DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( alexa :: value :: COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( alexa :: value :: SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( alexa :: value :: SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( alexa :: setting :: TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( alexa :: setting :: HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( alexa :: setting :: WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( alexa :: setting :: AUTO_BRAKE_HOLD ) // Ambient Light . createEndpoint ( \"ambient.light\" ) . addAssetId ( alexa :: device :: AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( alexa :: setting :: COLOR ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"RED\" ) . addAssetId ( alexa :: color :: RED ) . addValue ( \"BLUE\" ) . addAssetId ( alexa :: color :: BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( alexa :: color :: GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( alexa :: color :: WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( alexa :: color :: ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( alexa :: color :: YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( alexa :: color :: INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( alexa :: color :: VIOLET ) // Air Conditioner . createEndpoint ( \"default.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Air Conditioner . createEndpoint ( \"front.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Air Conditioner . createEndpoint ( \"rear.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Fan . createEndpoint ( \"default.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Fan . createEndpoint ( \"driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Fan . createEndpoint ( \"passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Fan . createEndpoint ( \"front.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Fan . createEndpoint ( \"rear.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Driver Fan . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Passenger Fan . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Fan . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Fan . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Vent . createEndpoint ( \"default.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Driver Vent . createEndpoint ( \"driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Passenger Vent . createEndpoint ( \"passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Front Vent . createEndpoint ( \"front.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Vent . createEndpoint ( \"rear.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Driver Vent . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Passenger Vent . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Second Row Vent . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Third Row Vent . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Climate Control . createEndpoint ( \"climatecontrol\" ) . addAssetId ( alexa :: device :: CLIMATE_CONTROL ) . addAssetId ( alexa :: setting :: AUTO ) . addPowerController ( false ) // Heater . createEndpoint ( \"default.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Heater . createEndpoint ( \"driver.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Heater . createEndpoint ( \"passenger.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Left Heater . createEndpoint ( \"left.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Right Heater . createEndpoint ( \"right.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Heater . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Heater . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Light . createEndpoint ( \"default.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Driver Light . createEndpoint ( \"driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Passenger Light . createEndpoint ( \"passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Front Light . createEndpoint ( \"front.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Light . createEndpoint ( \"rear.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Driver Light . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Passenger Light . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Second Row Light . createEndpoint ( \"secondRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Third Row Light . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Reading Light . createEndpoint ( \"default.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Reading Light . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Passenger Reading Light . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Front Reading Light . createEndpoint ( \"front.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Reading Light . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Driver Reading Light . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Passenger Reading Light . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Second Row Reading Light . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Third Row Reading Light . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Cupholder . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Passenger Cupholder . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Front Cupholder . createEndpoint ( \"front.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Cupholder . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Driver Cupholder . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Passenger Cupholder . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Second Row Cupholder . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Third Row Cupholder . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Driver Armrest . createEndpoint ( \"driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Passenger Armrest . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Front Armrest . createEndpoint ( \"front.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Armrest . createEndpoint ( \"rear.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Driver Armrest . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Passenger Armrest . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Second Row Armrest . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Third Row Armrest . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Driver Seat . createEndpoint ( \"driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Passenger Seat . createEndpoint ( \"passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Seat . createEndpoint ( \"front.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Seat . createEndpoint ( \"rear.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Driver Seat . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Passenger Seat . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Second Row Seat . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Third Row Seat . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Window . createEndpoint ( \"front.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Window . createEndpoint ( \"rear.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Driver Window . createEndpoint ( \"driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Passenger Window . createEndpoint ( \"passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Driver Window . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Passenger Window . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Second Row Window . createEndpoint ( \"secondRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Third Row Window . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Front Windshield . createEndpoint ( \"front.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Rear Windshield . createEndpoint ( \"rear.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Front Foglight . createEndpoint ( \"front.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Rear Foglight . createEndpoint ( \"rear.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Hazard Light . createEndpoint ( \"hazardlight\" ) . addAssetId ( alexa :: device :: HAZARD_LIGHTS ) . addAssetId ( alexa :: device :: PARKING_LIGHTS ) . addPowerController ( false ) // Front Wipers . createEndpoint ( \"front.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Wipers . createEndpoint ( \"rear.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Sunroof . createEndpoint ( \"sunroof\" ) . addAssetId ( alexa :: device :: SUNROOF ) . addAssetId ( alexa :: device :: MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // Sunshade . createEndpoint ( \"sunshade\" ) . addAssetId ( alexa :: device :: SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // HUD . createEndpoint ( \"hud\" ) . addAssetId ( alexa :: device :: HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: HUD ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // IVI . createEndpoint ( \"ivi\" ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( alexa :: value :: OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Dynamics Coordinator Page . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Performance Page . createEndpoint ( \"performancePage\" ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Home Page . createEndpoint ( \"homepage\" ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Bluetooth Page . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Radio Page . createEndpoint ( \"radioPage\" ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Settings Page . createEndpoint ( \"settingsPage\" ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Controls Page . createEndpoint ( \"controlsPage\" ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Navigation Page . createEndpoint ( \"navigationPage\" ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // GPS Page . createEndpoint ( \"gpsPage\" ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Service Page . createEndpoint ( \"servicePage\" ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Satellite Radio Page . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Information Page . createEndpoint ( \"informationPage\" ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Vehicle Status Page . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Multimedia Page . createEndpoint ( \"multimediaPage\" ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addAssetId ( alexa :: value :: MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Telephone Page . createEndpoint ( \"telephonePage\" ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Contacts Page . createEndpoint ( \"contactsPage\" ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Alerts Page . createEndpoint ( \"alertsPage\" ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Notifications Page . createEndpoint ( \"notificationsPage\" ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // 360 Camera . createEndpoint ( \"360Camera\" ) . addAssetId ( alexa :: device :: CAMERA_360 ) . addAssetId ( alexa :: device :: AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( alexa :: setting :: DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( alexa :: location :: FRONT ) . addValue ( \"REAR\" ) . addAssetId ( alexa :: location :: REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( alexa :: location :: DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Steering Wheel . createEndpoint ( \"steeringWheel\" ) . addAssetId ( alexa :: device :: STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Hood . createEndpoint ( \"hood\" ) . addAssetId ( alexa :: device :: HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Trunk . createEndpoint ( \"trunk\" ) . addAssetId ( alexa :: device :: TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Charge Door . createEndpoint ( \"chargedoor\" ) . addAssetId ( alexa :: device :: CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Gas Door . createEndpoint ( \"gasdoor\" ) . addAssetId ( alexa :: device :: GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ); configuration . push_back ( config );","title":"Configuration for Linux Integration"},{"location":"explore/features/car-control/#configuration-for-android-integration","text":"To use the Car Control module Engine configuration with AACS, use \"aacs.carControl\" instead of \"aace.carControl\" in your AACS configuration file: { \"aacs.carControl\": { \"endpoints\": [ // list of endpoint definitions ], \"zones\": [ // list of zone definitions ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory class com.amazon.aace.carControl.CarControlConfiguration to programmatically construct the EngineConfiguration in the proper format, as shown in the example below.","title":"Configuration for Android Integration"},{"location":"explore/features/car-control/#carcontrolconfiguration-java-sample-code","text":"import com.amazon.aace.carControl.CarControlAssets ; import com.amazon.aace.carControl.CarControlConfiguration ; import com.amazon.aace.core.config.EngineConfiguration ; // Auto SDK Engine configuration List < EngineConfiguration > configuration = new ArrayList <> (); CarControlConfiguration config = CarControlConfiguration . create (); config . createZone ( \"zone.default\" ) . addAssetId ( CarControlAssets . Location . ALL ) . addMembers ( new String [] { \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }); config . createZone ( \"zone.driver\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addAssetId ( CarControlAssets . Location . FRONT_LEFT ) . addMembers ( new String [] { \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }); config . createZone ( \"zone.passenger\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addAssetId ( CarControlAssets . Location . FRONT_RIGHT ) . addMembers ( new String [] { \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }); config . createZone ( \"zone.front\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addMembers ( new String [] { \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }); config . createZone ( \"zone.rear\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addMembers ( new String [] { \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }); config . createZone ( \"zone.left\" ) . addAssetId ( CarControlAssets . Location . LEFT ) . addMembers ( new String [] { \"left.heater\" , \"driver.seat\" , \"driver.vent\" }); config . createZone ( \"zone.right\" ) . addAssetId ( CarControlAssets . Location . RIGHT ) . addMembers ( new String [] { \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }); config . createZone ( \"zone.rear.driver\" ) . addAssetId ( CarControlAssets . Location . REAR_DRIVER ) . addAssetId ( CarControlAssets . Location . REAR_LEFT ) . addMembers ( new String [] { \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }); config . createZone ( \"zone.rear.passenger\" ) . addAssetId ( CarControlAssets . Location . REAR_PASSENGER ) . addAssetId ( CarControlAssets . Location . REAR_RIGHT ) . addMembers ( new String [] { \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }); config . createZone ( \"zone.secondRow\" ) . addAssetId ( CarControlAssets . Location . SECOND_ROW ) . addMembers ( new String [] { \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }); config . createZone ( \"zone.thirdRow\" ) . addAssetId ( CarControlAssets . Location . THIRD_ROW ) . addMembers ( new String [] { \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }); config . setDefaultZone ( \"zone.default\" ); // \"Car\" config . createEndpoint ( \"car\" ) . addAssetId ( CarControlAssets . Device . CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( CarControlAssets . Value . INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( CarControlAssets . Value . OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( CarControlAssets . Setting . CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( CarControlAssets . Setting . DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( CarControlAssets . Value . COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( CarControlAssets . Value . SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( CarControlAssets . Value . SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( CarControlAssets . Setting . TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( CarControlAssets . Setting . HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( CarControlAssets . Setting . WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( CarControlAssets . Setting . AUTO_BRAKE_HOLD ); // Ambient Light config . createEndpoint ( \"ambient.light\" ) . addAssetId ( CarControlAssets . Device . AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( CarControlAssets . Setting . COLOR ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"RED\" ) . addAssetId ( CarControlAssets . Color . RED ) . addValue ( \"BLUE\" ) . addAssetId ( CarControlAssets . Color . BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( CarControlAssets . Color . GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( CarControlAssets . Color . WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( CarControlAssets . Color . ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( CarControlAssets . Color . YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( CarControlAssets . Color . INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( CarControlAssets . Color . VIOLET ); // Air Conditioner config . createEndpoint ( \"default.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Air Conditioner config . createEndpoint ( \"front.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Air Conditioner config . createEndpoint ( \"rear.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Fan config . createEndpoint ( \"default.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Fan config . createEndpoint ( \"driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Fan config . createEndpoint ( \"passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Fan config . createEndpoint ( \"front.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Fan config . createEndpoint ( \"rear.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Driver Fan config . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Passenger Fan config . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Fan config . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Fan config . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Vent config . createEndpoint ( \"default.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Driver Vent config . createEndpoint ( \"driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Passenger Vent config . createEndpoint ( \"passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Front Vent config . createEndpoint ( \"front.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Vent config . createEndpoint ( \"rear.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Driver Vent config . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Passenger Vent config . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Second Row Vent config . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Third Row Vent config . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Climate Control config . createEndpoint ( \"climatecontrol\" ) . addAssetId ( CarControlAssets . Device . CLIMATE_CONTROL ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addPowerController ( false ); // Heater config . createEndpoint ( \"default.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Heater config . createEndpoint ( \"driver.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Heater config . createEndpoint ( \"passenger.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Left Heater config . createEndpoint ( \"left.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Right Heater config . createEndpoint ( \"right.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Heater config . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Heater config . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Light config . createEndpoint ( \"default.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Driver Light config . createEndpoint ( \"driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Passenger Light config . createEndpoint ( \"passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Front Light config . createEndpoint ( \"front.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Light config . createEndpoint ( \"rear.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Driver Light config . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Passenger Light config . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Second Row Light config . createEndpoint ( \"secondRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Third Row Light config . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Reading Light config . createEndpoint ( \"default.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Reading Light config . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Passenger Reading Light config . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Front Reading Light config . createEndpoint ( \"front.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Reading Light config . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Driver Reading Light config . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Passenger Reading Light config . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Second Row Reading Light config . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Third Row Reading Light config . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Cupholder config . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Passenger Cupholder config . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Front Cupholder config . createEndpoint ( \"front.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Cupholder config . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Driver Cupholder config . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Passenger Cupholder config . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Second Row Cupholder config . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Third Row Cupholder config . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Driver Armrest config . createEndpoint ( \"driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Passenger Armrest config . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Front Armrest config . createEndpoint ( \"front.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Armrest config . createEndpoint ( \"rear.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Driver Armrest config . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Passenger Armrest config . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Second Row Armrest config . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Third Row Armrest config . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Driver Seat config . createEndpoint ( \"driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Passenger Seat config . createEndpoint ( \"passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Seat config . createEndpoint ( \"front.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Seat config . createEndpoint ( \"rear.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Driver Seat config . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Passenger Seat config . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Second Row Seat config . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Third Row Seat config . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Window config . createEndpoint ( \"front.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Window config . createEndpoint ( \"rear.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Driver Window config . createEndpoint ( \"driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Passenger Window config . createEndpoint ( \"passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Driver Window config . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Passenger Window config . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Second Row Window config . createEndpoint ( \"secondRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Third Row Window config . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Front Windshield config . createEndpoint ( \"front.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Rear Windshield config . createEndpoint ( \"rear.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Front Foglight config . createEndpoint ( \"front.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Rear Foglight config . createEndpoint ( \"rear.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Hazard Light config . createEndpoint ( \"hazardlight\" ) . addAssetId ( CarControlAssets . Device . HAZARD_LIGHTS ) . addAssetId ( CarControlAssets . Device . PARKING_LIGHTS ) . addPowerController ( false ); // Front Wipers config . createEndpoint ( \"front.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Wipers config . createEndpoint ( \"rear.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Sunroof config . createEndpoint ( \"sunroof\" ) . addAssetId ( CarControlAssets . Device . SUNROOF ) . addAssetId ( CarControlAssets . Device . MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // Sunshade config . createEndpoint ( \"sunshade\" ) . addAssetId ( CarControlAssets . Device . SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // HUD config . createEndpoint ( \"hud\" ) . addAssetId ( CarControlAssets . Device . HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . HUD ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // IVI config . createEndpoint ( \"ivi\" ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( CarControlAssets . Value . OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Dynamics Coordinator Page config . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Performance Page config . createEndpoint ( \"performancePage\" ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Home Page config . createEndpoint ( \"homepage\" ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Bluetooth Page config . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Radio Page config . createEndpoint ( \"radioPage\" ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Settings Page config . createEndpoint ( \"settingsPage\" ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Controls Page config . createEndpoint ( \"controlsPage\" ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Navigation Page config . createEndpoint ( \"navigationPage\" ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // GPS Page config . createEndpoint ( \"gpsPage\" ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Service Page config . createEndpoint ( \"servicePage\" ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Satellite Radio Page config . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Information Page config . createEndpoint ( \"informationPage\" ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Vehicle Status Page config . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Multimedia Page config . createEndpoint ( \"multimediaPage\" ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addAssetId ( CarControlAssets . Value . MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Telephone Page config . createEndpoint ( \"telephonePage\" ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Contacts Page config . createEndpoint ( \"contactsPage\" ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Alerts Page config . createEndpoint ( \"alertsPage\" ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Notifications Page config . createEndpoint ( \"notificationsPage\" ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // 360 Camera config . createEndpoint ( \"360Camera\" ) . addAssetId ( CarControlAssets . Device . CAMERA_360 ) . addAssetId ( CarControlAssets . Device . AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( CarControlAssets . Setting . DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addValue ( \"REAR\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Steering Wheel config . createEndpoint ( \"steeringWheel\" ) . addAssetId ( CarControlAssets . Device . STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Hood config . createEndpoint ( \"hood\" ) . addAssetId ( CarControlAssets . Device . HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Trunk config . createEndpoint ( \"trunk\" ) . addAssetId ( CarControlAssets . Device . TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Charge Door config . createEndpoint ( \"chargedoor\" ) . addAssetId ( CarControlAssets . Device . CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Gas Door config . createEndpoint ( \"gasdoor\" ) . addAssetId ( CarControlAssets . Device . GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); configuration . add ( config );","title":"CarControlConfiguration Java sample code"},{"location":"explore/features/car-control/#using-the-car-control-module-aasb-messages","text":"The Auto SDK Engine provides an AASB message interface with topic CarControl for you to handle the car control directives from Alexa. The messages include an endpointId to identify the connected endpoint that Alexa identified to match the user's intent. For directives targeting primitive capability instances, the message includes the instanceId as well. The endpointId and instanceId match the configured IDs from aace.carControl.endpoints[i].endpointId and aace.carControl.endpoints[i].capabilities[j].instance , respectively.","title":"Using the Car Control Module AASB Messages"},{"location":"explore/features/car-control/#changing-the-power-state-of-an-endpoint","text":"When the user requests Alexa to turn an endpoint on or off, the Engine publishes a SetControllerValue message for power state . Your application must power on or off the endpoint and publish SetControllerReply message in response. Click to expand or collapse sequence diagram: Turning on AC Click to expand or collapse sequence diagram: Turning off AC","title":"Changing the power state of an endpoint"},{"location":"explore/features/car-control/#toggling-an-endpoint-property","text":"When the user requests Alexa to turn on or off a named property of an endpoint, the Engine publishes a SetControllerValue message for toggle of the setting . Your application must turn on or off the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Turning on the rear windshield defroster Click to expand or collapse sequence diagram: Turning off the rear windshield defroster","title":"Toggling an endpoint property"},{"location":"explore/features/car-control/#changing-the-mode-of-an-endpoint-property","text":"When the user requests Alexa to set the mode of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for mode of the setting . Your application must set the mode of the property and publish SetControllerValueReply` message in response. Click to expand or collapse sequence diagram: Setting the AC intensity to minimum When the user requests Alexa to increase or decrease the mode of a named property of an endpoint, the Engine publishes an AdjustControllerValue message for mode of the setting . Your application must adjust the mode of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the AC intensity","title":"Changing the mode of an endpoint property"},{"location":"explore/features/car-control/#changing-the-numeric-setting-of-an-endpoint-property","text":"When the user requests Alexa to set the numeric setting of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for the range setting . Your application must set the value of the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Setting the temperature to 70 When the user requests Alexa to adjust (increment or decrement) the numeric setting of a named property of an endpoint by a delta value, the Engine publishes a AdjustControllerValue message for the range setting . Your application must adjust the value of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the temperature by 4","title":"Changing the numeric setting of an endpoint property"},{"location":"explore/features/car-control/#integrating-the-car-control-module-into-your-application","text":"","title":"Integrating the Car Control Module Into Your Application"},{"location":"explore/features/car-control/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to subscribe to \"CarControl\" AASB messages and publish replies. Click to expand or collapse C++ sample code #include <AACE/CarControl/CarControlConfiguration.h> #include <AACE/Core/MessageBroker.h> #include <AASB/Message/CarControl/CarControl/AdjustControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetPowerControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetToggleControllerValueMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyCarControlHandler { static const std :: string AASB_TOPIC_CAR_CONTROL ( \"CarControl\" ); static const std :: string AASB_ACTION_SET_CONTROLLER_VALUE ( \"SetControllerValue\" ); static const std :: string AASB_ACTION_ADJUST_CONTROLLER_VALUE ( \"AdjustControllerValue\" ); // Subscribe to \"CarControl\" messages from the Engine void MyCarControlHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_SET_CONTROLLER_VALUE ); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAdjustControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_ADJUST_CONTROLLER_VALUE ); } // Handle the messages from the Engine for \"SetControllerValue\" action void MyCarControlHandler::handleSetControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"POWER\" ) == 0 ) { SetPowerControllerValueMessage msg = json :: parse ( message ); setPowerControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"TOGGLE\" ) == 0 ) { SetToggleControllerValueMessage msg = json :: parse ( message ); setToggleControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { SetRangeControllerValueMessage msg = json :: parse ( message ); setRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { SetModeControllerValueMessage msg = json :: parse ( message ); setModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::setPowerControllerValue ( const std :: string & messageId , const std :: string & endpointId , bool turnOn ) { if ( turnOn ) { // Power on the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Power off the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setToggleControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , bool turnOn ) { if ( turnOn ) { // Turn on the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Turn off the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double value ) { // Set the numeric setting of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::setModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , const std :: string & value ) { // Set the mode of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendSetControllerValueMessageReply ( const std :: string & messageId , bool successful ) { SetControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); } // Handle the messages from the Engine for \"AdjustControllerValue\" action void MyCarControlHandler::handleAdjustControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { AdjustRangeControllerValueMessage msg = json :: parse ( message ); adjustRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { AdjustModeControllerValueMessage msg = json :: parse ( message ); adjustModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::adjustRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the numeric setting of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::adjustModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the mode of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendAdjustControllerValueMessageReply ( const std :: string & messageId , bool successful ) { AdjustControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); }","title":"C++ MessageBroker Integration"},{"location":"explore/features/car-control/#aacs-android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS Car Control Library to integrate the Auto SDK Car Control module on Android. See the AACS Car Control Library documentation for more information.","title":"AACS Android integration"},{"location":"explore/features/cbl/","text":"Code-Based Linking (CBL) Module \u00b6 Overview \u00b6 Every request to Alexa Voice Service (AVS) requires a Login with Amazon (LWA) access token. The Alexa Auto SDK CBL module implements the CBL mechanism of acquiring such tokens. Use the Authorization AASB message interface to start, cancel, and log out of CBL authorization. For more information about how the Engine manages authorization, see the Authorization interface documentation. Important!: This document is not yet updated is updated to reflect the Auto SDK 4.0 MessageBroker message API. Some sections still include text, code samples, or diagrams that show the deprecated Authorization platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analogous Authorization AASB messages with the MessageBroker. The concepts are the same between the two interfaces. This document will be fully updated in the next Auto SDK version. Using the Authorization Platform Interface to Carry out CBL Authorization \u00b6 This section describes how an application uses the Authorization platform interface to carry out CBL authorization. The service name used by Authorization for CBL authorization is alexa:cbl . Starting Authorization \u00b6 This section describes how the startAuthorization API is used for starting authorization. The data parameter in the request has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The following list describes what value to pass for the data parameter: If the application is starting a new CBL authorization session, pass an empty string as the data parameter. The following syntax shows how to start a new authorization: startAuthorization( \"alexa:cbl\", \"\") If the application is starting a CBL authorization session with an existing refresh token, it provides the refresh token obtained previously from setAuthorizationData() , with the key as refreshToken . The following example shows how to start authorization and pass the refresh token: startAuthorization( \u201calexa:cbl\u201d, \"{\"refreshToken\":\u201cAtzr|IQEBLzAtAhRP\u201d}\") Note: With the Authorization platform interface, it is the responsibility of the application to start authorization at every Engine start. Each time the Engine is restarted, it does not automatically start the authorization that was previously in effect before the Engine restart. Receiving Events from Engine \u00b6 This section describes the protocol for getting the code pair and user profile data by using the eventReceived API. The Engine passes the code pair to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"cbl-code\", \"payload\": { \"code\":\"{STRING}\", \"url\":\"{STRING}\" } } The following example provides the application with the CBL code and URL: eventReceived( \"alexa:cbl\", \"{\"type\":\"cbl-code\", \"payload\":{\"code\":\"OC2EFA\",\"url\":\"some-url\"}}\" ) The Engine passes the user profile data to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"user-profile\", \"payload\": { \"name\": \"{STRING}\", \"email\": \"{STRING}\" } } The following example provides the user profile data for an application to use the logged-in user's name and email: eventReceived( \"alexa:cbl\", \"{\"type\":\"user-profile\",\"payload\":{\"name\":\"some-name\",\"email\":\"some-email\"}}\" ) Setting Authorization Data \u00b6 This section describes the protocol for storing the refresh token by using the setAuthorizationData API. The Engine passes the refresh token to the application by using the refreshToken parameter, as shown in the following example: setAuthorizationData( \"alexa:cbl\", \"refreshToken\", \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\" ); Note : It is the responsibility of the application to securely store authorization data, such as the refresh token, on the device. Getting Authorization Data \u00b6 This section describes the protocol for the Engine to get the refresh token from the application using the getAuthorizationData API. The Engine asks the application to provide the refresh token previously obtained from setAuthorizationData . If this is the first time the application tries to authorize the device, pass an empty string. The string returned for this API has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The Engine calls the getAuthorizationData method as follows: getAuthorizationData(\"alexa:cbl\",\"refreshToken\") The application returns the refresh token as in the following example: \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\" Canceling Authorization \u00b6 This section describes how the application cancels an authorization. The API to use is cancelAuthorization , which can cancel the authorization and stop the CBL work flow at any time. For example, cancellation can happen when the application is waiting for the user to enter the code pair or when the access token is being refreshed. If the device is already authorized, the API cancels the token refreshing process. Canceling authorization does not affect the device authorization state. Logging Out \u00b6 The API to use is logout . The application makes this API call to the Engine to log out. Handling Errors \u00b6 This section describes the errors reported by the Engine. The following list describes possible errors during authorization: UNKNOWN_ERROR is an unrecoverable error in the authorization process. TIMEOUT happens when the application's attempt to get the code pair from the LWA Service times out. CODE_PAIR_EXPIRED is caused by an expired code pair. The application must restart the authorization process and request a new code pair. AUTHORIZATION_EXPIRED is caused by an expired or a revoked refresh token. LOGOUT_FAILED happens when a logout attempt fails. START_AUTHORIZATION_FAILED happens when the authorization flow cannot start. The Engine notifies the application about any error during authorization. The following example shows how the Engine notifies the application when a code pair expires: authorizationError( \"alexa:cbl\", \"CODE_PAIR_EXPIRED\", \"\" ) Enabling User Profile \u00b6 If you want the Engine to pass information about logged-in users to the application, include the following code in the Engine configuration: { \"aace.cbl\": { \"enableUserProfile\": true } } You can also generate the configuration programmatically by using the following method: auto userProfileConfig = aace :: cbl :: config :: CBLConfiguration :: createCBLUserProfileConfig ( true ); engine -> configure ( { //other config objects..., userProfileConfig, ... } ); The user profile is passed via the eventReceived API as described in this section . Sequence Diagrams for CBL \u00b6 The following diagram illustrates the flow when authorization starts. The following diagram illustrates how the Authorization platform interface handles a refresh token. The following diagram illustrates the flow when authorization is canceled. The following diagram illustrates the flow when the application logs out of the authorization.","title":"Code-Based Linking (CBL) Module"},{"location":"explore/features/cbl/#code-based-linking-cbl-module","text":"","title":"Code-Based Linking (CBL) Module"},{"location":"explore/features/cbl/#overview","text":"Every request to Alexa Voice Service (AVS) requires a Login with Amazon (LWA) access token. The Alexa Auto SDK CBL module implements the CBL mechanism of acquiring such tokens. Use the Authorization AASB message interface to start, cancel, and log out of CBL authorization. For more information about how the Engine manages authorization, see the Authorization interface documentation. Important!: This document is not yet updated is updated to reflect the Auto SDK 4.0 MessageBroker message API. Some sections still include text, code samples, or diagrams that show the deprecated Authorization platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analogous Authorization AASB messages with the MessageBroker. The concepts are the same between the two interfaces. This document will be fully updated in the next Auto SDK version.","title":"Overview"},{"location":"explore/features/cbl/#using-the-authorization-platform-interface-to-carry-out-cbl-authorization","text":"This section describes how an application uses the Authorization platform interface to carry out CBL authorization. The service name used by Authorization for CBL authorization is alexa:cbl .","title":"Using the Authorization Platform Interface to Carry out CBL Authorization"},{"location":"explore/features/cbl/#starting-authorization","text":"This section describes how the startAuthorization API is used for starting authorization. The data parameter in the request has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The following list describes what value to pass for the data parameter: If the application is starting a new CBL authorization session, pass an empty string as the data parameter. The following syntax shows how to start a new authorization: startAuthorization( \"alexa:cbl\", \"\") If the application is starting a CBL authorization session with an existing refresh token, it provides the refresh token obtained previously from setAuthorizationData() , with the key as refreshToken . The following example shows how to start authorization and pass the refresh token: startAuthorization( \u201calexa:cbl\u201d, \"{\"refreshToken\":\u201cAtzr|IQEBLzAtAhRP\u201d}\") Note: With the Authorization platform interface, it is the responsibility of the application to start authorization at every Engine start. Each time the Engine is restarted, it does not automatically start the authorization that was previously in effect before the Engine restart.","title":"Starting Authorization"},{"location":"explore/features/cbl/#receiving-events-from-engine","text":"This section describes the protocol for getting the code pair and user profile data by using the eventReceived API. The Engine passes the code pair to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"cbl-code\", \"payload\": { \"code\":\"{STRING}\", \"url\":\"{STRING}\" } } The following example provides the application with the CBL code and URL: eventReceived( \"alexa:cbl\", \"{\"type\":\"cbl-code\", \"payload\":{\"code\":\"OC2EFA\",\"url\":\"some-url\"}}\" ) The Engine passes the user profile data to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"user-profile\", \"payload\": { \"name\": \"{STRING}\", \"email\": \"{STRING}\" } } The following example provides the user profile data for an application to use the logged-in user's name and email: eventReceived( \"alexa:cbl\", \"{\"type\":\"user-profile\",\"payload\":{\"name\":\"some-name\",\"email\":\"some-email\"}}\" )","title":"Receiving Events from Engine"},{"location":"explore/features/cbl/#setting-authorization-data","text":"This section describes the protocol for storing the refresh token by using the setAuthorizationData API. The Engine passes the refresh token to the application by using the refreshToken parameter, as shown in the following example: setAuthorizationData( \"alexa:cbl\", \"refreshToken\", \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\" ); Note : It is the responsibility of the application to securely store authorization data, such as the refresh token, on the device.","title":"Setting Authorization Data"},{"location":"explore/features/cbl/#getting-authorization-data","text":"This section describes the protocol for the Engine to get the refresh token from the application using the getAuthorizationData API. The Engine asks the application to provide the refresh token previously obtained from setAuthorizationData . If this is the first time the application tries to authorize the device, pass an empty string. The string returned for this API has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The Engine calls the getAuthorizationData method as follows: getAuthorizationData(\"alexa:cbl\",\"refreshToken\") The application returns the refresh token as in the following example: \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\"","title":"Getting Authorization Data"},{"location":"explore/features/cbl/#canceling-authorization","text":"This section describes how the application cancels an authorization. The API to use is cancelAuthorization , which can cancel the authorization and stop the CBL work flow at any time. For example, cancellation can happen when the application is waiting for the user to enter the code pair or when the access token is being refreshed. If the device is already authorized, the API cancels the token refreshing process. Canceling authorization does not affect the device authorization state.","title":"Canceling Authorization"},{"location":"explore/features/cbl/#logging-out","text":"The API to use is logout . The application makes this API call to the Engine to log out.","title":"Logging Out"},{"location":"explore/features/cbl/#handling-errors","text":"This section describes the errors reported by the Engine. The following list describes possible errors during authorization: UNKNOWN_ERROR is an unrecoverable error in the authorization process. TIMEOUT happens when the application's attempt to get the code pair from the LWA Service times out. CODE_PAIR_EXPIRED is caused by an expired code pair. The application must restart the authorization process and request a new code pair. AUTHORIZATION_EXPIRED is caused by an expired or a revoked refresh token. LOGOUT_FAILED happens when a logout attempt fails. START_AUTHORIZATION_FAILED happens when the authorization flow cannot start. The Engine notifies the application about any error during authorization. The following example shows how the Engine notifies the application when a code pair expires: authorizationError( \"alexa:cbl\", \"CODE_PAIR_EXPIRED\", \"\" )","title":"Handling Errors"},{"location":"explore/features/cbl/#enabling-user-profile","text":"If you want the Engine to pass information about logged-in users to the application, include the following code in the Engine configuration: { \"aace.cbl\": { \"enableUserProfile\": true } } You can also generate the configuration programmatically by using the following method: auto userProfileConfig = aace :: cbl :: config :: CBLConfiguration :: createCBLUserProfileConfig ( true ); engine -> configure ( { //other config objects..., userProfileConfig, ... } ); The user profile is passed via the eventReceived API as described in this section .","title":"Enabling User Profile"},{"location":"explore/features/cbl/#sequence-diagrams-for-cbl","text":"The following diagram illustrates the flow when authorization starts. The following diagram illustrates how the Authorization platform interface handles a refresh token. The following diagram illustrates the flow when authorization is canceled. The following diagram illustrates the flow when the application logs out of the authorization.","title":"Sequence Diagrams for CBL"},{"location":"explore/features/connectivity/","text":"Connectivity Module \u00b6 Overview \u00b6 The Connectivity module for the Alexa Auto SDK creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. This module allows the automaker to create tiered access to Alexa for customers and offer up-sell opportunities to subscribe to a full connectivity plan. A customer who purchases an Alexa-enabled vehicle typically has to subscribe to the automaker\u2019s connectivity plans and accept the automaker's and network provider's terms and conditions to access Alexa. Without the Connectivity module, if the customer declines the terms and conditions, or does not have a data plan (for example, due to plan expiration), the customer loses access to Alexa. The Connectivity module, however, provides an option that allows the automaker to offer a reduced set of Alexa functionality and limited bandwidth consumption for little or no cost. In this low data consumption mode, utterances sent to the cloud are filtered by feature, because the Connectivity module offers a restricted set of features. For example, when a user accesses Alexa through the Connectivity module, an utterance requesting music streaming does not start the streaming but turns on the FM radio station that was last played. Features such as weather and traffic remain accessible. Your application's Connectivity module integration is responsible for: Providing the network identifier for Alexa to send to the mobile network operator (MNO) Providing the vehicle's connection properties and configurations to Alexa Configuring the Connectivity Module \u00b6 The Connectivity module does not require Engine configuration. Using the Connectivity AASB Messages \u00b6 Providing the Network Identifier \u00b6 The network identifier is agnostic of the data plan and is assigned when initially integrated into the vehicle. It links the device with the network provider and enables the network provider to identify and provide device connectivity. Examples of the network identifier are the Embedded SIM ID (eSIM ID) and a globally unique ID (GUID). Which ID to use depends on the implementation determined in agreement with Amazon, OEM, and MNO. Note: The network identifier is optional. If it is missing, the Engine will use vehicleIdentifier in the Engine configuration as the network identifier. To learn more about vehicle information in the Engine configuration, see the Core module documentation. During device discovery the Engine publishes the GetIdentifier message . To report the network identifier to Alexa, publish the GetIdentifierReply message . Click to expand or collapse sequence diagram: Providing the Network Identifier Providing the Connectivity Status \u00b6 When a client application initiates connection with Alexa or when Alexa requests a report of the current connectivity state, publish the ConnectivityStateChange message . In response, the Engine will publish the GetConnectivityState message to which your application must publish the GetConnectivityStateReply message containing the connectivity state. The Engine will then publish the ConnectivityStateChangeReply message to indicate if the connectivity state was processed successfully. Alexa parses the internet connectivity information from the vehicle and determines whether the customer is eligible for the full or partial Alexa experience. The connectivityState obtained in the GetConnectivityState reply payload has the following schema: { \"managedProvider\": { \"type\": \"{{STRING_ENUM}}\", \"id\": \"{{STRING}}\" }, \"termStatus\": \"{{STRING_ENUM}}\", \"termsVersion\": \"{{STRING}}\", \"dataPlan\": { \"type\": \"{{STRING_ENUM}}\", \"endDate\": \"{{STRING}}\" }, \"dataPlansAvailable\": [\"{{STRING}}\", \"{{STRING}}\", ...] } Click to expand or collapse details about the objects in the payload Property Type Description Required dataPlan Object It provides the active data plan type and end date. Yes (only when managedProvider.type is MANAGED ) dataPlan.type String Accepted values: PAID indicates that the device has an active data plan paid for by the customer. TRIAL indicates that the device has an active data plan which has been provided to the customer as a promotional event. AMAZON_SPONSORED indicates that the customer has not paid for a data plan or signed up for a free trial. The customer can connect to the internet via a plan sponsored by Amazon and can access a limited number of Alexa features. A customer with either of PAID or TRIAL data plan has unrestricted access to all Alexa features. Yes dataPlan.endDate String It specifies the date on which the trial data plan ends. If it is not set, there is no end date for the plan. The value is in the RFC 3339 format. Yes (only when dataPlan.type is TRIAL ) termsStatus String It indicates whether the customer has accepted the terms and conditions of the OEM and MNO. If it is not set, the behavior is the same as when it is set to DECLINED . Accepted values : ACCEPTED means that the customer has agreed to receive voice messages from Alexa, which enable the customer to use voice to purchase a data plan. DECLINED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. DEFERRED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. However, Alexa might remind the user to respond to the terms and conditions again. No, but recommended termsVersion String It indicates the version of the terms and conditions presented to the user. Do not use termsVersion if you do not use termsStatus . Maximum length is 250 characters. Note: If you implemented Auto SDK 3.1 with the Connectivity module, a default value is automatically assigned to termsVersion . For Auto SDK 3.2 or later, be sure to specify termsVersion . Otherwise, the MNO is not notified of the correct version of the terms and conditions presented to the user. Yes (only when termsStatus is provided) dataPlansAvailable String array It indicates the data plans that can be activated. Accepted values are PAID , AMAZON_SPONSORED , and TRIAL . For example, if the array is [\"TRIAL\", \"AMAZON_SPONSORED\", \"PAID\"] , Alexa encourages the user to upgrade from an AMAZON_SPONSORED plan to a TRIAL plan or from a TRIAL plan to a PAID plan. No managedProvider Object It provides information about the type of network connectivity that the device has. Yes managedProvider.type String Accepted Values: MANAGED means the device's internet connectivity is managed by a provider. The only possible provider that manages connectivity is Amazon. The Alexa experience is affected by the current connectivity state in the following ways: If the customer is on a paid or trial data plan, MANAGED has no effect on the customer's Alexa experience. If the customer does not have a paid or trial data plan, the customer, through the AlexaConnectivity platform interface, can access a limited number of Alexa features. NOT_MANAGED means the device's internet connectivity is not managed by a provider. For example, assign this value if the customer accesses the internet via a WiFi network or mobile hotspot. The customer can access all Alexa features, regardless of the current connectivity state. Yes managedProvider.id String It specifies the name of the provider that manages connectivity. The only accepted value is AMAZON . Yes (only when managedProvider.type is MANAGED ) Click to expand or collapse sequence diagram: Connectivity Report Activating Voice Up-Sell Conversation \u00b6 To activate the voice up-sell conversation with Alexa (e.g., to activate the trial or paid plan subscription), publish the SendConnectivityEvent message . The Engine publishes the SendConnectivityEventReply message specifying the delivery status of the event. The event sent in the SendConnectivityEvent message payload has the following schema: { \"type\": \"{{STRING}}\" } Note: Alexa requires the customer to have accepted the OEM and network provider's terms and conditions before starting the voice conversation. Click to expand or collapse details about the objects in the payload Property Type Description Required type String Represents the type of the connectivity event to Alexa. Accepted Values : ACTIVATE_TRIAL for Alexa to begin the trial data plan activation (if available). Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Note: If the platform implementation cannot determine the data plan type, use this event type. Alexa would first check the trial eligibility. If the customer is not eligible, Alexa begins the paid plan voice conversation. ACTIVATE_PAID_PLAN for Alexa to begin the paid data plan activation. Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Yes Click to expand or collapse sequence diagram: Send Connectivity Event Integrating the Connectivity Module Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the Engine's MessageBroker to publish \"Connectivity\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Connectivity/AlexaConnectivity/StatusCode.h> #include <AASB/Message/Connectivity/AlexaConnectivity/ConnectivityStateChangeMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetConnectivityStateMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetIdentifierMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/SendConnectivityEventMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAlexaConnectivityHandler { // Subscribe to messages from the Engine void MyAlexaConnectivityHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetConnectivityStateMessage ( message ); }, GetConnectivityStateMessage :: topic (), GetConnectivityStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetIdentifierMessage ( message ); }, GetIdentifierMessage :: topic (), GetIdentifierMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleConnectivityStateChangeReplyMessage ( message ); }, ConnectivityStateChangeMessageReply :: topic (), ConnectivityStateChangeMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendConnectivityEventReplyMessage ( message ); }, SendConnectivityEventMessageReply :: topic (), SendConnectivityEventMessageReply :: action ()); } // Handle the ConnectivityStateChange reply message from the Engine void MyAlexaConnectivityHandler::handleConnectivityStateChangeReplyMessage ( const std :: string & message ) { ConnectivityStateChangeMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; // ...Handle change in the connectivity state... } // Handle the SendConnectivityEvent reply message from the Engine void MyAlexaConnectivityHandler::handleSendConnectivityEventReplyMessage ( const std :: string & message ) { SendConnectivityEventMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; StatusCode statusCode = msg . payload . statusCode ; // ...Handle delivery status of the event... } // Handle the GetConnectivityState message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetConnectivityStateMessage ( const std :: string & message ) { GetConnectivityStateMessage msg = json :: parse ( message ); GetConnectivityStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . connectivityState = getConnectivityState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the GetIdentifier message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetIdentifierMessage ( const std :: string & message ) { GetIdentifierMessage msg = json :: parse ( message ); GetIdentifierMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . identifier = getIdentifier (); m_messageBroker -> publish ( replyMsg . toString ()); } // To report a connectivity status change to Alexa, publish a ConnectivityStateChange message to the Engine bool MyAlexaConnectivityHandler::connectivityStateChange () { ConnectivityStateChangeMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the ConnectivityStateChangeReply message // Return the success status from reply message payload } // To activate a voice up-sell conversation with Alexa, publish a SendConnectivityEvent message to the Engine StatusCode MyAlexaConnectivityHandler::sendConnectivityEvent ( const std :: string & event ) { SendConnectivityEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the SendConnectivityEventReply message // Return the statusCode from reply message payload } // Implement to retrieve the connectivity state std :: string MyAlexaConnectivityHandler::getConnectivityState (); // Implement to retrieve the identifier std :: string MyAlexaConnectivityHandler::getIdentifier (); }; Android Integration \u00b6 This lower data consumption mode for Alexa is not available in the Alexa Auto Client Service (AACS). If you are interested in creating tiered access to Alexa for customers you are required to implement it independently using AASB Messages.","title":"Connectivity Module"},{"location":"explore/features/connectivity/#connectivity-module","text":"","title":"Connectivity Module"},{"location":"explore/features/connectivity/#overview","text":"The Connectivity module for the Alexa Auto SDK creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. This module allows the automaker to create tiered access to Alexa for customers and offer up-sell opportunities to subscribe to a full connectivity plan. A customer who purchases an Alexa-enabled vehicle typically has to subscribe to the automaker\u2019s connectivity plans and accept the automaker's and network provider's terms and conditions to access Alexa. Without the Connectivity module, if the customer declines the terms and conditions, or does not have a data plan (for example, due to plan expiration), the customer loses access to Alexa. The Connectivity module, however, provides an option that allows the automaker to offer a reduced set of Alexa functionality and limited bandwidth consumption for little or no cost. In this low data consumption mode, utterances sent to the cloud are filtered by feature, because the Connectivity module offers a restricted set of features. For example, when a user accesses Alexa through the Connectivity module, an utterance requesting music streaming does not start the streaming but turns on the FM radio station that was last played. Features such as weather and traffic remain accessible. Your application's Connectivity module integration is responsible for: Providing the network identifier for Alexa to send to the mobile network operator (MNO) Providing the vehicle's connection properties and configurations to Alexa","title":"Overview"},{"location":"explore/features/connectivity/#configuring-the-connectivity-module","text":"The Connectivity module does not require Engine configuration.","title":"Configuring the Connectivity Module"},{"location":"explore/features/connectivity/#using-the-connectivity-aasb-messages","text":"","title":"Using the Connectivity AASB Messages"},{"location":"explore/features/connectivity/#providing-the-network-identifier","text":"The network identifier is agnostic of the data plan and is assigned when initially integrated into the vehicle. It links the device with the network provider and enables the network provider to identify and provide device connectivity. Examples of the network identifier are the Embedded SIM ID (eSIM ID) and a globally unique ID (GUID). Which ID to use depends on the implementation determined in agreement with Amazon, OEM, and MNO. Note: The network identifier is optional. If it is missing, the Engine will use vehicleIdentifier in the Engine configuration as the network identifier. To learn more about vehicle information in the Engine configuration, see the Core module documentation. During device discovery the Engine publishes the GetIdentifier message . To report the network identifier to Alexa, publish the GetIdentifierReply message . Click to expand or collapse sequence diagram: Providing the Network Identifier","title":"Providing the Network Identifier"},{"location":"explore/features/connectivity/#providing-the-connectivity-status","text":"When a client application initiates connection with Alexa or when Alexa requests a report of the current connectivity state, publish the ConnectivityStateChange message . In response, the Engine will publish the GetConnectivityState message to which your application must publish the GetConnectivityStateReply message containing the connectivity state. The Engine will then publish the ConnectivityStateChangeReply message to indicate if the connectivity state was processed successfully. Alexa parses the internet connectivity information from the vehicle and determines whether the customer is eligible for the full or partial Alexa experience. The connectivityState obtained in the GetConnectivityState reply payload has the following schema: { \"managedProvider\": { \"type\": \"{{STRING_ENUM}}\", \"id\": \"{{STRING}}\" }, \"termStatus\": \"{{STRING_ENUM}}\", \"termsVersion\": \"{{STRING}}\", \"dataPlan\": { \"type\": \"{{STRING_ENUM}}\", \"endDate\": \"{{STRING}}\" }, \"dataPlansAvailable\": [\"{{STRING}}\", \"{{STRING}}\", ...] } Click to expand or collapse details about the objects in the payload Property Type Description Required dataPlan Object It provides the active data plan type and end date. Yes (only when managedProvider.type is MANAGED ) dataPlan.type String Accepted values: PAID indicates that the device has an active data plan paid for by the customer. TRIAL indicates that the device has an active data plan which has been provided to the customer as a promotional event. AMAZON_SPONSORED indicates that the customer has not paid for a data plan or signed up for a free trial. The customer can connect to the internet via a plan sponsored by Amazon and can access a limited number of Alexa features. A customer with either of PAID or TRIAL data plan has unrestricted access to all Alexa features. Yes dataPlan.endDate String It specifies the date on which the trial data plan ends. If it is not set, there is no end date for the plan. The value is in the RFC 3339 format. Yes (only when dataPlan.type is TRIAL ) termsStatus String It indicates whether the customer has accepted the terms and conditions of the OEM and MNO. If it is not set, the behavior is the same as when it is set to DECLINED . Accepted values : ACCEPTED means that the customer has agreed to receive voice messages from Alexa, which enable the customer to use voice to purchase a data plan. DECLINED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. DEFERRED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. However, Alexa might remind the user to respond to the terms and conditions again. No, but recommended termsVersion String It indicates the version of the terms and conditions presented to the user. Do not use termsVersion if you do not use termsStatus . Maximum length is 250 characters. Note: If you implemented Auto SDK 3.1 with the Connectivity module, a default value is automatically assigned to termsVersion . For Auto SDK 3.2 or later, be sure to specify termsVersion . Otherwise, the MNO is not notified of the correct version of the terms and conditions presented to the user. Yes (only when termsStatus is provided) dataPlansAvailable String array It indicates the data plans that can be activated. Accepted values are PAID , AMAZON_SPONSORED , and TRIAL . For example, if the array is [\"TRIAL\", \"AMAZON_SPONSORED\", \"PAID\"] , Alexa encourages the user to upgrade from an AMAZON_SPONSORED plan to a TRIAL plan or from a TRIAL plan to a PAID plan. No managedProvider Object It provides information about the type of network connectivity that the device has. Yes managedProvider.type String Accepted Values: MANAGED means the device's internet connectivity is managed by a provider. The only possible provider that manages connectivity is Amazon. The Alexa experience is affected by the current connectivity state in the following ways: If the customer is on a paid or trial data plan, MANAGED has no effect on the customer's Alexa experience. If the customer does not have a paid or trial data plan, the customer, through the AlexaConnectivity platform interface, can access a limited number of Alexa features. NOT_MANAGED means the device's internet connectivity is not managed by a provider. For example, assign this value if the customer accesses the internet via a WiFi network or mobile hotspot. The customer can access all Alexa features, regardless of the current connectivity state. Yes managedProvider.id String It specifies the name of the provider that manages connectivity. The only accepted value is AMAZON . Yes (only when managedProvider.type is MANAGED ) Click to expand or collapse sequence diagram: Connectivity Report","title":"Providing the Connectivity Status"},{"location":"explore/features/connectivity/#activating-voice-up-sell-conversation","text":"To activate the voice up-sell conversation with Alexa (e.g., to activate the trial or paid plan subscription), publish the SendConnectivityEvent message . The Engine publishes the SendConnectivityEventReply message specifying the delivery status of the event. The event sent in the SendConnectivityEvent message payload has the following schema: { \"type\": \"{{STRING}}\" } Note: Alexa requires the customer to have accepted the OEM and network provider's terms and conditions before starting the voice conversation. Click to expand or collapse details about the objects in the payload Property Type Description Required type String Represents the type of the connectivity event to Alexa. Accepted Values : ACTIVATE_TRIAL for Alexa to begin the trial data plan activation (if available). Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Note: If the platform implementation cannot determine the data plan type, use this event type. Alexa would first check the trial eligibility. If the customer is not eligible, Alexa begins the paid plan voice conversation. ACTIVATE_PAID_PLAN for Alexa to begin the paid data plan activation. Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Yes Click to expand or collapse sequence diagram: Send Connectivity Event","title":"Activating Voice Up-Sell Conversation"},{"location":"explore/features/connectivity/#integrating-the-connectivity-module-into-your-application","text":"","title":"Integrating the Connectivity Module Into Your Application"},{"location":"explore/features/connectivity/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to publish \"Connectivity\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Connectivity/AlexaConnectivity/StatusCode.h> #include <AASB/Message/Connectivity/AlexaConnectivity/ConnectivityStateChangeMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetConnectivityStateMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetIdentifierMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/SendConnectivityEventMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAlexaConnectivityHandler { // Subscribe to messages from the Engine void MyAlexaConnectivityHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetConnectivityStateMessage ( message ); }, GetConnectivityStateMessage :: topic (), GetConnectivityStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetIdentifierMessage ( message ); }, GetIdentifierMessage :: topic (), GetIdentifierMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleConnectivityStateChangeReplyMessage ( message ); }, ConnectivityStateChangeMessageReply :: topic (), ConnectivityStateChangeMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendConnectivityEventReplyMessage ( message ); }, SendConnectivityEventMessageReply :: topic (), SendConnectivityEventMessageReply :: action ()); } // Handle the ConnectivityStateChange reply message from the Engine void MyAlexaConnectivityHandler::handleConnectivityStateChangeReplyMessage ( const std :: string & message ) { ConnectivityStateChangeMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; // ...Handle change in the connectivity state... } // Handle the SendConnectivityEvent reply message from the Engine void MyAlexaConnectivityHandler::handleSendConnectivityEventReplyMessage ( const std :: string & message ) { SendConnectivityEventMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; StatusCode statusCode = msg . payload . statusCode ; // ...Handle delivery status of the event... } // Handle the GetConnectivityState message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetConnectivityStateMessage ( const std :: string & message ) { GetConnectivityStateMessage msg = json :: parse ( message ); GetConnectivityStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . connectivityState = getConnectivityState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the GetIdentifier message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetIdentifierMessage ( const std :: string & message ) { GetIdentifierMessage msg = json :: parse ( message ); GetIdentifierMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . identifier = getIdentifier (); m_messageBroker -> publish ( replyMsg . toString ()); } // To report a connectivity status change to Alexa, publish a ConnectivityStateChange message to the Engine bool MyAlexaConnectivityHandler::connectivityStateChange () { ConnectivityStateChangeMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the ConnectivityStateChangeReply message // Return the success status from reply message payload } // To activate a voice up-sell conversation with Alexa, publish a SendConnectivityEvent message to the Engine StatusCode MyAlexaConnectivityHandler::sendConnectivityEvent ( const std :: string & event ) { SendConnectivityEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the SendConnectivityEventReply message // Return the statusCode from reply message payload } // Implement to retrieve the connectivity state std :: string MyAlexaConnectivityHandler::getConnectivityState (); // Implement to retrieve the identifier std :: string MyAlexaConnectivityHandler::getIdentifier (); };","title":"C++ MessageBroker Integration"},{"location":"explore/features/connectivity/#android-integration","text":"This lower data consumption mode for Alexa is not available in the Alexa Auto Client Service (AACS). If you are interested in creating tiered access to Alexa for customers you are required to implement it independently using AASB Messages.","title":"Android Integration"},{"location":"explore/features/core/","text":"Core Module \u00b6 Overview \u00b6 The Core module is the heart of the Alexa Auto SDK. The Core module provides the following elements that are the foundation for all Auto SDK features: Defining core API for your application to access the features of Auto SDK\u2014 Core defines the Engine and MessageBroker components. Alongside the Alexa Auto Services Bridge (AASB) messages defined by each Auto SDK module, these components comprise the core API for your application to access the features of Auto SDK. To learn about the API, see Auto SDK Core API Overview . Providing an infrastructure to other modules\u2014 Core provides the base infrastructure of the Engine, which each Auto SDK module extends to add module-specific features. Providing core services to other modules\u2014 Core defines the common Engine services and corresponding AASB message interfaces for logging, audio I/O, authorization, device settings, network info, and more. Each module uses these Engine services to provide its own module-specific features. Configure the Core module \u00b6 The Core module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programmatically with the relevant configuration factory functions. (Required) Vehicle info configuration \u00b6 Your application must provide the aace.vehicle configuration specified below. Amazon uses the vehicle configuration properties for analytics. { \"aace.vehicle\": { \"info\": { \"make\": {{STRING}}, \"model\": {{STRING}}, \"year\": {{STRING}}, \"trim\": {{STRING}}, \"geography\": {{STRING}}, \"version\": {{STRING}}, \"os\": {{STRING}}, \"arch\": {{STRING}}, \"language\": {{STRING}}, \"microphone\": {{STRING}}, \"vehicleIdentifier\": {{STRING}}, \"engineType\": {{STRING}}, \"rseEmbeddedFireTvs\": {{STRING}} } } } The following table describes the properties in the configuration: Property Type Required Description Example make String Yes The make of the vehicle \u2014 model String Yes The model of the vehicle \u2014 year Integer as a string Yes The model year of the vehicle. The value must be an integer in the range 1900-2100. \"2019\" trim String No The trim package of the vehicle, identifying the vehicle's level of equipment or special features \"Sport\" geography String No The location of the vehicle \"US\", \"US-North\", \"WA\" version String No The client software version \"4.0\" os String No The operating system used by the head unit \"AndroidOreo_8.1\" arch String No The hardware architecture used by the head unit \"x86_64\" language String No The language or locale selected for Alexa by the vehicle owner \"en-US\", \"fr-CA\" microphone String No The type and arrangement of microphone used in the vehicle \"7 mic array, centrally mounted\" vehicleIdentifier String Yes An identifier for the vehicle \"1234abcd\" engineType String No The engine type of the vehicle. Accepted values: \"GAS\" \"ELECTRIC\" \"HYBRID\" \"GAS\" rseEmbeddedFireTvs Integer as a string No The number of RSE embedded FireTVs installed in the vehicle \"1\" Important! To pass the Amazon certification process, the vehicleIdentifier value you provide must NOT be the vehicle identification number (VIN). Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the VehicleConfiguration::createVehicleInfoConfig() factory function to generate the configuration programmatically. #include <AACE/Vehicle/VehicleConfiguration.h> std :: vector < aace :: vehicle :: config :: VehicleConfiguration :: VehicleProperty > vehicleProperties = { { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: MAKE , \"SampleMake\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: MODEL , \"SampleModel\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: YEAR , \"2020\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: TRIM , \"Sport\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: GEOGRAPHY , \"US\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: VERSION , \"4.0\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: OPERATING_SYSTEM , \"AndroidOreo_8.1\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: HARDWARE_ARCH , \"x86_64\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: MICROPHONE , \"7 mic array, centrally mounted\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: LANGUAGE , \"en-US\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: VEHICLE_IDENTIFIER , \"1234abcd\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: ENGINE_TYPE , \"GAS\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: RSE_EMBEDDED_FIRETVS , \"1\" } }; auto vehicleConfig = aace :: vehicle :: config :: VehicleConfiguration :: createVehicleInfoConfig ( vehicleProperties ); engine -> configure ( { // ...other config objects..., vehicleConfig } ); (Required) Storage configuration \u00b6 Your application must provide the aace.storage configuration specified below. The Engine uses the configured path to create a database to persist data across device reboots. { \"aace.storage\": { \"localStoragePath\": {{STRING}}, \"storageType\": \"sqlite\" } } The following table describes the properties in the configuration: Property Type Required Description Example localStoragePath String Yes The absolute path where the Engine will create the local storage database, including the database name \"/opt/AAC/data/aace-storage.db\" storageType String Yes The type of storage to use \"sqlite\" Note: This database is not the only one used by the Engine. For example, components in the Alexa module have similar configuration to store feature-specific data. See Configure the Alexa module for details. Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the StorageConfiguration::createLocalStorageConfig() factory function to generate the configuration programmatically. #include <AACE/Storage/StorageConfiguration.h> auto storageConfig = aace :: storage :: config :: StorageConfiguration :: createLocalStorageConfig ( \"/opt/AAC/data/storage.db\" ); engine -> configure ( { // ...other config objects..., storageConfig } ); (Required) cURL configuration \u00b6 The Auto SDK uses cURL for network connections. Your application can provide Engine configuration to specify the cURL configuration: { \"aace.alexa\": { \"avsDeviceSDK\": { \"libcurlUtils\" { \"CURLOPT_CAPATH\": {{STRING}}, \"CURLOPT_INTERFACE\": {{STRING}}, \"CURLOPT_PROXY\": {{STRING}} } } } } The following table describes the properties in the configuration: Property Type Required Description Example CURLOPT_CAPATH String Yes The path to the directory containing the CA certificates \"/opt/AAC/certs\" CURLOPT_INTERFACE String Yes The outgoing network interface. Can be a network interface name, an IP address, or a host name \"wlan0\" CURLOPT_PROXY String No The address of the HTTP proxy \"http://127.0.0.1:8888\" Note: If the HTTP proxy requires credentials in HTTP headers to authenticate a user agent, you can specify the headers at runtime with the PropertyManager interface by using the aace.network.httpProxyHeaders property name. You can also change the network interface at runtime with the aace.network.networkInterface property name. Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the AlexaConfiguration::createCurlConfig() factory function to generate the configuration programmatically. #include <AACE/Alexa/AlexaConfiguration.h> auto curlConfig = aace :: alexa :: config :: AlexaConfiguration :: createCurlConfig ( \"/opt/AAC/etc/certs\" ); engine -> configure ( { // ...other config objects..., curlConfig } ); (Optional) Logger configuration \u00b6 By default, the Engine writes Auto SDK logs to the following places: The console, for C++ native applications Logcat, for Android applications You can configure the Engine to save logs to a file with the aace.logger configuration: { \"aace.logger\": { \"sinks\": [ { \"id\": {{STRING}}, \"type\": \"aace.logger.sink.file\", \"config\": { \"path\": {{STRING}}, \"prefix\": {{STRING}}, \"maxSize\": {{INTEGER}}, \"maxFiles\": {{INTEGER}}, \"append\": {{BOOLEAN}} }, \"rules\": [ { \"level\": {{STRING}} } ] } ] } The following table describes the properties in the configuration: Property Type Required Description Example aace.logger. sinks[i]. id String Yes A unique identifier for the log sink. \"debug-logs\" aace.logger. sinks[i]. type String Yes The type of the log sink. Use \"aace.logger.sink.file\" to write logs to a file. \"aace.logger.sink.file\" aace.logger. sinks[i]. config. path String Yes An absolute path to a directory where the Engine creates the log file. \"/opt/AAC/data\" aace.logger. sinks[i]. config. prefix String Yes The prefix for the log file. \"auto-sdk-logs\" aace.logger. sinks[i]. config. maxSize Integer Yes The maximum size of the log file in bytes. 5242880 aace.logger. sinks[i]. config. maxFiles Integer Yes The maximum number of log files. 5 aace.logger. sinks[i]. config. append Boolean Yes Whether the Engine should overwrite log files. Use true to append logs to the existing file. Use false to overwrite the log files. false aace.logger. sinks[i]. rules[j]. level Enum string Yes The log level filter the Engine uses when writing logs to the sink. Accepted values: \"VERBOSE\" \"INFO\" \"WARN\" \"ERROR\" \"CRITICAL\" \"METRIC\" \"VERBOSE\" Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the LoggerConfiguration::createFileSinkConfig() factory function to generate the configuration programmatically. #include \"AACE/Logger/Logger.h\" #include \"AACE/Logger/LoggerConfiguration.h\" auto fileSinkConfig = aace :: logger :: config :: LoggerConfiguration :: createFileSinkConfig ( \"debug-logs\" , aace :: logger :: LoggerEngineInterface :: Level :: VERBOSE , \"opt/AAC/data\" , \"auto-sdk-logs\" , 5242880 , 5 , false ); engine -> configure ( { // ...other config objects..., fileSinkConfig } ); (Optional) AASB and MessageBroker configuration \u00b6 Configure enabled interfaces \u00b6 When you use a module, the Engine services of that module enable every interface the module defines. This means that for every interface in a module you use, if your application does not subscribe to the AASB messages of the interface, the Engine performs default handling (typically no-op) for the messages you do not handle. To disable this setting, provide the following aace.messageBroker configuration object in your Engine configuration: { \"aace.messageBroker\": { \"autoEnableInterfaces\": false } } You can also configure the enablement on a per-interface basis. If you don't want the Engine to provide a default handler for a particular interface, you can disable the interface using the following configuration that specifies the name of the interface and the Engine service that owns it: { \"aasb.<engine_service_ID>\": { \"<interface_name>\": { \"enabled\": {{BOOLEAN}} } } } For example, the following configuration disables the TemplateRuntime interface from the Alexa module's alexa Engine service and the LocationProvider interface from Core module's location Engine service: { \"aasb.alexa\": { \"TemplateRuntime\": { \"enabled\": false } }, \"aasb.location\": { \"LocationProvider\": { \"enabled\": false } } } Configure the synchronous message timeout \u00b6 All the messages published by the Engine through the Message Broker are asynchronous; however, certain messages require your application to respond with a special synchronous-style Reply message. Your application must publish the reply quickly because the Engine blocks its execution thread while waiting for the response, and the Message Broker cannot dispatch more messages while waiting. The following messages are examples of the LocationProvider.GetLocation message and its reply message: LocationProvider.GetLocation message: { \"header\": { \"id\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\", \"messageType\": \"Publish\", \"version\": \"4.0\", \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\" } } } LocationProvider.GetLocation reply message: { \"header\": { \"id\": \"4c4d13b6-6a8d-445b-931a-a3feb0878311\", \"messageType\": \"Reply\", \"version\": \"4.0\", \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\", \"replyToId\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\" } }, \"payload\": { \"location\": { \"latitude\": 37.410, \"longitude\": -122.025 } } } The AASB message documentation for each interface specifies whether the interface requires any Reply messages. However, not every Reply message is synchronous-style. To avoid waiting indefinitely for \"synchronous\" replies, the Engine uses a timeout when waiting for these reply messages. If your application does not publish a reply before the timeout elapses, the Message Broker proceeds to avoid waiting, but the relevant Engine operation won't execute properly. The default timeout value for reply messages is 500 milliseconds. In a busy system, the default timeout might not be long enough. You can configure this value by adding the optional field defaultMessageTimeout to the aace.messageBroker JSON object in your Engine configuration. The following example configuration sets the reply timeout to 1000 ms: { \"aace.messageBroker\": { \"defaultMessageTimeout\": 1000 } } Important! Since increasing the timeout increases the Engine's message processing time, use this configuration carefully. Consult with your Amazon Solutions Architect (SA) as needed. Use the Core module interfaces \u00b6 The following list describes the AASB message interfaces provided by the Core module: (Required) Provide access tokens with Authorization \u00b6 The Authorization interface specifies messages for your application to initiate device authorization, terminate device authorization, or provide authorization data, such as Alexa access tokens, to the Engine. >> Authorization interface (Required) Provide audio channels with AudioInput and AudioOutput \u00b6 The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each component that requests an audio channel specifies its audio channel type so your application can provide different microphone and media player implementations for each channel. >> AudioInput interface >> AudioOutput interface (Required) Manage runtime properties with PropertyManager \u00b6 Different Auto SDK modules define properties based on their supported features. For example, the Alexa module requires a locale setting to notify Alexa which language to use when interacting with the user. The Core module provides a mechanism for Engine services to register properties they manage and listen to changes in properties managed by other modules. The PropertyManager interface specifies messages for your application and the Engine to query and update these properties. >> PropertyManager interface (Optional) Report location with LocationProvider \u00b6 For an accurate and personalized user experience, the Engine uses the vehicle's location from LocationProvider . >> LocationProvider interface (Optional) Report network status changes with NetworkInfoProvider \u00b6 To adapt the Engine behavior dynamically based on the state of the head unit's network connection, provide network connection reporting through NetworkInfoProvider . >> NetworkInfoProvider interface (Optional) Report data usage with DeviceUsage \u00b6 Report metrics about the head unit's data usage with DeviceUsage . >> DeviceUsage interface","title":"Core Module"},{"location":"explore/features/core/#core-module","text":"","title":"Core Module"},{"location":"explore/features/core/#overview","text":"The Core module is the heart of the Alexa Auto SDK. The Core module provides the following elements that are the foundation for all Auto SDK features: Defining core API for your application to access the features of Auto SDK\u2014 Core defines the Engine and MessageBroker components. Alongside the Alexa Auto Services Bridge (AASB) messages defined by each Auto SDK module, these components comprise the core API for your application to access the features of Auto SDK. To learn about the API, see Auto SDK Core API Overview . Providing an infrastructure to other modules\u2014 Core provides the base infrastructure of the Engine, which each Auto SDK module extends to add module-specific features. Providing core services to other modules\u2014 Core defines the common Engine services and corresponding AASB message interfaces for logging, audio I/O, authorization, device settings, network info, and more. Each module uses these Engine services to provide its own module-specific features.","title":"Overview"},{"location":"explore/features/core/#configure-the-core-module","text":"The Core module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programmatically with the relevant configuration factory functions.","title":"Configure the Core module"},{"location":"explore/features/core/#required-vehicle-info-configuration","text":"Your application must provide the aace.vehicle configuration specified below. Amazon uses the vehicle configuration properties for analytics. { \"aace.vehicle\": { \"info\": { \"make\": {{STRING}}, \"model\": {{STRING}}, \"year\": {{STRING}}, \"trim\": {{STRING}}, \"geography\": {{STRING}}, \"version\": {{STRING}}, \"os\": {{STRING}}, \"arch\": {{STRING}}, \"language\": {{STRING}}, \"microphone\": {{STRING}}, \"vehicleIdentifier\": {{STRING}}, \"engineType\": {{STRING}}, \"rseEmbeddedFireTvs\": {{STRING}} } } } The following table describes the properties in the configuration: Property Type Required Description Example make String Yes The make of the vehicle \u2014 model String Yes The model of the vehicle \u2014 year Integer as a string Yes The model year of the vehicle. The value must be an integer in the range 1900-2100. \"2019\" trim String No The trim package of the vehicle, identifying the vehicle's level of equipment or special features \"Sport\" geography String No The location of the vehicle \"US\", \"US-North\", \"WA\" version String No The client software version \"4.0\" os String No The operating system used by the head unit \"AndroidOreo_8.1\" arch String No The hardware architecture used by the head unit \"x86_64\" language String No The language or locale selected for Alexa by the vehicle owner \"en-US\", \"fr-CA\" microphone String No The type and arrangement of microphone used in the vehicle \"7 mic array, centrally mounted\" vehicleIdentifier String Yes An identifier for the vehicle \"1234abcd\" engineType String No The engine type of the vehicle. Accepted values: \"GAS\" \"ELECTRIC\" \"HYBRID\" \"GAS\" rseEmbeddedFireTvs Integer as a string No The number of RSE embedded FireTVs installed in the vehicle \"1\" Important! To pass the Amazon certification process, the vehicleIdentifier value you provide must NOT be the vehicle identification number (VIN). Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the VehicleConfiguration::createVehicleInfoConfig() factory function to generate the configuration programmatically. #include <AACE/Vehicle/VehicleConfiguration.h> std :: vector < aace :: vehicle :: config :: VehicleConfiguration :: VehicleProperty > vehicleProperties = { { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: MAKE , \"SampleMake\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: MODEL , \"SampleModel\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: YEAR , \"2020\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: TRIM , \"Sport\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: GEOGRAPHY , \"US\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: VERSION , \"4.0\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: OPERATING_SYSTEM , \"AndroidOreo_8.1\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: HARDWARE_ARCH , \"x86_64\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: MICROPHONE , \"7 mic array, centrally mounted\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: LANGUAGE , \"en-US\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: VEHICLE_IDENTIFIER , \"1234abcd\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: ENGINE_TYPE , \"GAS\" }, { aace :: vehicle :: config :: VehicleConfiguration :: VehiclePropertyType :: RSE_EMBEDDED_FIRETVS , \"1\" } }; auto vehicleConfig = aace :: vehicle :: config :: VehicleConfiguration :: createVehicleInfoConfig ( vehicleProperties ); engine -> configure ( { // ...other config objects..., vehicleConfig } );","title":"(Required) Vehicle info configuration"},{"location":"explore/features/core/#required-storage-configuration","text":"Your application must provide the aace.storage configuration specified below. The Engine uses the configured path to create a database to persist data across device reboots. { \"aace.storage\": { \"localStoragePath\": {{STRING}}, \"storageType\": \"sqlite\" } } The following table describes the properties in the configuration: Property Type Required Description Example localStoragePath String Yes The absolute path where the Engine will create the local storage database, including the database name \"/opt/AAC/data/aace-storage.db\" storageType String Yes The type of storage to use \"sqlite\" Note: This database is not the only one used by the Engine. For example, components in the Alexa module have similar configuration to store feature-specific data. See Configure the Alexa module for details. Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the StorageConfiguration::createLocalStorageConfig() factory function to generate the configuration programmatically. #include <AACE/Storage/StorageConfiguration.h> auto storageConfig = aace :: storage :: config :: StorageConfiguration :: createLocalStorageConfig ( \"/opt/AAC/data/storage.db\" ); engine -> configure ( { // ...other config objects..., storageConfig } );","title":"(Required) Storage configuration"},{"location":"explore/features/core/#required-curl-configuration","text":"The Auto SDK uses cURL for network connections. Your application can provide Engine configuration to specify the cURL configuration: { \"aace.alexa\": { \"avsDeviceSDK\": { \"libcurlUtils\" { \"CURLOPT_CAPATH\": {{STRING}}, \"CURLOPT_INTERFACE\": {{STRING}}, \"CURLOPT_PROXY\": {{STRING}} } } } } The following table describes the properties in the configuration: Property Type Required Description Example CURLOPT_CAPATH String Yes The path to the directory containing the CA certificates \"/opt/AAC/certs\" CURLOPT_INTERFACE String Yes The outgoing network interface. Can be a network interface name, an IP address, or a host name \"wlan0\" CURLOPT_PROXY String No The address of the HTTP proxy \"http://127.0.0.1:8888\" Note: If the HTTP proxy requires credentials in HTTP headers to authenticate a user agent, you can specify the headers at runtime with the PropertyManager interface by using the aace.network.httpProxyHeaders property name. You can also change the network interface at runtime with the aace.network.networkInterface property name. Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the AlexaConfiguration::createCurlConfig() factory function to generate the configuration programmatically. #include <AACE/Alexa/AlexaConfiguration.h> auto curlConfig = aace :: alexa :: config :: AlexaConfiguration :: createCurlConfig ( \"/opt/AAC/etc/certs\" ); engine -> configure ( { // ...other config objects..., curlConfig } );","title":"(Required) cURL configuration"},{"location":"explore/features/core/#optional-logger-configuration","text":"By default, the Engine writes Auto SDK logs to the following places: The console, for C++ native applications Logcat, for Android applications You can configure the Engine to save logs to a file with the aace.logger configuration: { \"aace.logger\": { \"sinks\": [ { \"id\": {{STRING}}, \"type\": \"aace.logger.sink.file\", \"config\": { \"path\": {{STRING}}, \"prefix\": {{STRING}}, \"maxSize\": {{INTEGER}}, \"maxFiles\": {{INTEGER}}, \"append\": {{BOOLEAN}} }, \"rules\": [ { \"level\": {{STRING}} } ] } ] } The following table describes the properties in the configuration: Property Type Required Description Example aace.logger. sinks[i]. id String Yes A unique identifier for the log sink. \"debug-logs\" aace.logger. sinks[i]. type String Yes The type of the log sink. Use \"aace.logger.sink.file\" to write logs to a file. \"aace.logger.sink.file\" aace.logger. sinks[i]. config. path String Yes An absolute path to a directory where the Engine creates the log file. \"/opt/AAC/data\" aace.logger. sinks[i]. config. prefix String Yes The prefix for the log file. \"auto-sdk-logs\" aace.logger. sinks[i]. config. maxSize Integer Yes The maximum size of the log file in bytes. 5242880 aace.logger. sinks[i]. config. maxFiles Integer Yes The maximum number of log files. 5 aace.logger. sinks[i]. config. append Boolean Yes Whether the Engine should overwrite log files. Use true to append logs to the existing file. Use false to overwrite the log files. false aace.logger. sinks[i]. rules[j]. level Enum string Yes The log level filter the Engine uses when writing logs to the sink. Accepted values: \"VERBOSE\" \"INFO\" \"WARN\" \"ERROR\" \"CRITICAL\" \"METRIC\" \"VERBOSE\" Click to expand or collapse details\u2014 Generate the configuration programmatically with the C++ factory function Auto SDK provides the LoggerConfiguration::createFileSinkConfig() factory function to generate the configuration programmatically. #include \"AACE/Logger/Logger.h\" #include \"AACE/Logger/LoggerConfiguration.h\" auto fileSinkConfig = aace :: logger :: config :: LoggerConfiguration :: createFileSinkConfig ( \"debug-logs\" , aace :: logger :: LoggerEngineInterface :: Level :: VERBOSE , \"opt/AAC/data\" , \"auto-sdk-logs\" , 5242880 , 5 , false ); engine -> configure ( { // ...other config objects..., fileSinkConfig } );","title":"(Optional) Logger configuration"},{"location":"explore/features/core/#optional-aasb-and-messagebroker-configuration","text":"","title":"(Optional) AASB and MessageBroker configuration"},{"location":"explore/features/core/#configure-enabled-interfaces","text":"When you use a module, the Engine services of that module enable every interface the module defines. This means that for every interface in a module you use, if your application does not subscribe to the AASB messages of the interface, the Engine performs default handling (typically no-op) for the messages you do not handle. To disable this setting, provide the following aace.messageBroker configuration object in your Engine configuration: { \"aace.messageBroker\": { \"autoEnableInterfaces\": false } } You can also configure the enablement on a per-interface basis. If you don't want the Engine to provide a default handler for a particular interface, you can disable the interface using the following configuration that specifies the name of the interface and the Engine service that owns it: { \"aasb.<engine_service_ID>\": { \"<interface_name>\": { \"enabled\": {{BOOLEAN}} } } } For example, the following configuration disables the TemplateRuntime interface from the Alexa module's alexa Engine service and the LocationProvider interface from Core module's location Engine service: { \"aasb.alexa\": { \"TemplateRuntime\": { \"enabled\": false } }, \"aasb.location\": { \"LocationProvider\": { \"enabled\": false } } }","title":"Configure enabled interfaces"},{"location":"explore/features/core/#configure-the-synchronous-message-timeout","text":"All the messages published by the Engine through the Message Broker are asynchronous; however, certain messages require your application to respond with a special synchronous-style Reply message. Your application must publish the reply quickly because the Engine blocks its execution thread while waiting for the response, and the Message Broker cannot dispatch more messages while waiting. The following messages are examples of the LocationProvider.GetLocation message and its reply message: LocationProvider.GetLocation message: { \"header\": { \"id\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\", \"messageType\": \"Publish\", \"version\": \"4.0\", \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\" } } } LocationProvider.GetLocation reply message: { \"header\": { \"id\": \"4c4d13b6-6a8d-445b-931a-a3feb0878311\", \"messageType\": \"Reply\", \"version\": \"4.0\", \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\", \"replyToId\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\" } }, \"payload\": { \"location\": { \"latitude\": 37.410, \"longitude\": -122.025 } } } The AASB message documentation for each interface specifies whether the interface requires any Reply messages. However, not every Reply message is synchronous-style. To avoid waiting indefinitely for \"synchronous\" replies, the Engine uses a timeout when waiting for these reply messages. If your application does not publish a reply before the timeout elapses, the Message Broker proceeds to avoid waiting, but the relevant Engine operation won't execute properly. The default timeout value for reply messages is 500 milliseconds. In a busy system, the default timeout might not be long enough. You can configure this value by adding the optional field defaultMessageTimeout to the aace.messageBroker JSON object in your Engine configuration. The following example configuration sets the reply timeout to 1000 ms: { \"aace.messageBroker\": { \"defaultMessageTimeout\": 1000 } } Important! Since increasing the timeout increases the Engine's message processing time, use this configuration carefully. Consult with your Amazon Solutions Architect (SA) as needed.","title":"Configure the synchronous message timeout"},{"location":"explore/features/core/#use-the-core-module-interfaces","text":"The following list describes the AASB message interfaces provided by the Core module:","title":"Use the Core module interfaces"},{"location":"explore/features/core/#required-provide-access-tokens-with-authorization","text":"The Authorization interface specifies messages for your application to initiate device authorization, terminate device authorization, or provide authorization data, such as Alexa access tokens, to the Engine. >> Authorization interface","title":"(Required) Provide access tokens with Authorization"},{"location":"explore/features/core/#required-provide-audio-channels-with-audioinput-and-audiooutput","text":"The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each component that requests an audio channel specifies its audio channel type so your application can provide different microphone and media player implementations for each channel. >> AudioInput interface >> AudioOutput interface","title":"(Required) Provide audio channels with AudioInput and AudioOutput"},{"location":"explore/features/core/#required-manage-runtime-properties-with-propertymanager","text":"Different Auto SDK modules define properties based on their supported features. For example, the Alexa module requires a locale setting to notify Alexa which language to use when interacting with the user. The Core module provides a mechanism for Engine services to register properties they manage and listen to changes in properties managed by other modules. The PropertyManager interface specifies messages for your application and the Engine to query and update these properties. >> PropertyManager interface","title":"(Required) Manage runtime properties with PropertyManager"},{"location":"explore/features/core/#optional-report-location-with-locationprovider","text":"For an accurate and personalized user experience, the Engine uses the vehicle's location from LocationProvider . >> LocationProvider interface","title":"(Optional) Report location with LocationProvider"},{"location":"explore/features/core/#optional-report-network-status-changes-with-networkinfoprovider","text":"To adapt the Engine behavior dynamically based on the state of the head unit's network connection, provide network connection reporting through NetworkInfoProvider . >> NetworkInfoProvider interface","title":"(Optional) Report network status changes with NetworkInfoProvider"},{"location":"explore/features/core/#optional-report-data-usage-with-deviceusage","text":"Report metrics about the head unit's data usage with DeviceUsage . >> DeviceUsage interface","title":"(Optional) Report data usage with DeviceUsage"},{"location":"explore/features/core/AudioInput/","text":"AudioInput Interface \u00b6 Overview \u00b6 The core audio Engine service provides a mechanism for Engine components of any module to open audio input channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide a microphone implementation specific to the channel type. The AudioInput interface provides AASB messages for your application to share audio data with the Engine when the Engine needs it. Understand AudioInput \u00b6 Your application subscribes to the outgoing AudioInput AASB messages published by the Engine. When some Engine component requests audio input (for example, when the user presses the tap-to-talk button from SpeechRecognizer ), the Engine publishes a StartAudioInput message that specifies the audioType and streamId . The Engine defines the following audio types for which it requests AudioInput streams: VOICE\u2014 This audio input type provides user speech audio data. COMMUNICATION\u2014 This audio input type provides user speech audio data specific to Alexa-to-Alexa calling. For example, the Alexa Comms module Engine components request audio input with this type. LOOPBACK\u2014 This audio input type provides audio data recorded from the device's own speakers. For example, the Loopback Detector module Engine components request audio input with this type to detect Alexa saying her own name in the audio output. Regardless of the audio type, your application writes audio data to the stream with the specified ID until the Engine publishes a StopAudioInput message for the same stream ID. The audio data you provide must use the following format: 16bit Linear PCM 16kHz sample rate Single channel Signed, little endian byte order The core audio Engine service enables multiple Engine components to share single producer, multi-consumer audio input in two key ways: Multiple Engine components might request audio input of the same type. For example, the Alexa module and Amazonlite module Engine components both want VOICE audio input. When the first component requests to open a VOICE stream, your application receives a StartAudioInput message requesting to open a stream for the VOICE type. When the second Engine component needs the voice audio type, the Engine won't ask your application for voice audio again because your application is already providing it. The Engine takes care of providing the same audio data to both consumers. Similarly, your application will only receive a StopAudioInput message for the voice stream when the last Engine component has canceled its request to receive this type of audio. Multiple Engine components might request audio input of \"different\" types that your application considers the same. For example, the Alexa module and Alexa Comms module want VOICE and COMMUNICATION audio input, respectively. Your application's specific integration might have one implementation for producing the user speech audio data. In this case, your application takes care of providing the same audio data to both consumers in different streams opened by the Engine. Use the AudioInput interface in a native C++ application \u00b6 To write the audio data to the Engine after receiving a StartAudioInput message, use the MessageBroker::openStream() function, specifying the same streamId from the StartAudioInput message and the operation mode MessageStream::Mode::WRITE . The openStream() call returns a MessageStream object. Provide audio data in repeated calls to MessageStream::write() until the Engine publishes a StopAudioInput message for the stream ID. The following C++ example code demonstrates how your application subscribes to AudioInput AASB messages, opens an input stream to provide audio when requested, and stops providing audio when requested. #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> class MyAudioInputHandler { // Call this during the \"subscribe to AASB messages\" phase of the Engine lifecycle void MyAudioInputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartAudioInputMessage ( message ); }, StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopAudioInputMessage ( message ); }, StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); } void MyAudioInputHandler::handleStartAudioInputMessage ( const std :: string & message ) { StartAudioInputMessage msg = json :: parse ( message ); // open the stream for writing auto streamId = msg . payload . streamId ; auto stream = m_messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); if ( stream == nullptr ) { // handle the error condition return ; } startAudioInput ( streamId , stream ) } void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same \"streamId\" // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! return ; } void MyAudioInputHandler::handleStopAudioInputMessage ( const std :: string & message ) { StopAudioInputMessage msg = json :: parse ( message ); auto streamId = msg . payload . streamId ; stopAudioInput ( streamId ); } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream identified by \"streamId\" // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! return ; } } Use the AudioInput interface in an Android application \u00b6 Alexa Auto Client Service (AACS) provides a default implementation of AudioInput . You can use the default implementation in your application instead of integrating directly with the AudioInput AASB messages yourself. See the Android documentation for details about using the default implementation.","title":"AudioInput"},{"location":"explore/features/core/AudioInput/#audioinput-interface","text":"","title":"AudioInput Interface "},{"location":"explore/features/core/AudioInput/#overview","text":"The core audio Engine service provides a mechanism for Engine components of any module to open audio input channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide a microphone implementation specific to the channel type. The AudioInput interface provides AASB messages for your application to share audio data with the Engine when the Engine needs it.","title":"Overview"},{"location":"explore/features/core/AudioInput/#understand-audioinput","text":"Your application subscribes to the outgoing AudioInput AASB messages published by the Engine. When some Engine component requests audio input (for example, when the user presses the tap-to-talk button from SpeechRecognizer ), the Engine publishes a StartAudioInput message that specifies the audioType and streamId . The Engine defines the following audio types for which it requests AudioInput streams: VOICE\u2014 This audio input type provides user speech audio data. COMMUNICATION\u2014 This audio input type provides user speech audio data specific to Alexa-to-Alexa calling. For example, the Alexa Comms module Engine components request audio input with this type. LOOPBACK\u2014 This audio input type provides audio data recorded from the device's own speakers. For example, the Loopback Detector module Engine components request audio input with this type to detect Alexa saying her own name in the audio output. Regardless of the audio type, your application writes audio data to the stream with the specified ID until the Engine publishes a StopAudioInput message for the same stream ID. The audio data you provide must use the following format: 16bit Linear PCM 16kHz sample rate Single channel Signed, little endian byte order The core audio Engine service enables multiple Engine components to share single producer, multi-consumer audio input in two key ways: Multiple Engine components might request audio input of the same type. For example, the Alexa module and Amazonlite module Engine components both want VOICE audio input. When the first component requests to open a VOICE stream, your application receives a StartAudioInput message requesting to open a stream for the VOICE type. When the second Engine component needs the voice audio type, the Engine won't ask your application for voice audio again because your application is already providing it. The Engine takes care of providing the same audio data to both consumers. Similarly, your application will only receive a StopAudioInput message for the voice stream when the last Engine component has canceled its request to receive this type of audio. Multiple Engine components might request audio input of \"different\" types that your application considers the same. For example, the Alexa module and Alexa Comms module want VOICE and COMMUNICATION audio input, respectively. Your application's specific integration might have one implementation for producing the user speech audio data. In this case, your application takes care of providing the same audio data to both consumers in different streams opened by the Engine.","title":"Understand AudioInput"},{"location":"explore/features/core/AudioInput/#use-the-audioinput-interface-in-a-native-c-application","text":"To write the audio data to the Engine after receiving a StartAudioInput message, use the MessageBroker::openStream() function, specifying the same streamId from the StartAudioInput message and the operation mode MessageStream::Mode::WRITE . The openStream() call returns a MessageStream object. Provide audio data in repeated calls to MessageStream::write() until the Engine publishes a StopAudioInput message for the stream ID. The following C++ example code demonstrates how your application subscribes to AudioInput AASB messages, opens an input stream to provide audio when requested, and stops providing audio when requested. #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> class MyAudioInputHandler { // Call this during the \"subscribe to AASB messages\" phase of the Engine lifecycle void MyAudioInputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartAudioInputMessage ( message ); }, StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopAudioInputMessage ( message ); }, StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); } void MyAudioInputHandler::handleStartAudioInputMessage ( const std :: string & message ) { StartAudioInputMessage msg = json :: parse ( message ); // open the stream for writing auto streamId = msg . payload . streamId ; auto stream = m_messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); if ( stream == nullptr ) { // handle the error condition return ; } startAudioInput ( streamId , stream ) } void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same \"streamId\" // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! return ; } void MyAudioInputHandler::handleStopAudioInputMessage ( const std :: string & message ) { StopAudioInputMessage msg = json :: parse ( message ); auto streamId = msg . payload . streamId ; stopAudioInput ( streamId ); } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream identified by \"streamId\" // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! return ; } }","title":"Use the AudioInput interface in a native C++ application"},{"location":"explore/features/core/AudioInput/#use-the-audioinput-interface-in-an-android-application","text":"Alexa Auto Client Service (AACS) provides a default implementation of AudioInput . You can use the default implementation in your application instead of integrating directly with the AudioInput AASB messages yourself. See the Android documentation for details about using the default implementation.","title":"Use the AudioInput interface in an Android application"},{"location":"explore/features/core/AudioOutput/","text":"AudioOutput Interface \u00b6 Overview \u00b6 The core audio Engine service provides a mechanism for Engine components of any module to open audio output channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide a media player implementation specific to the channel type. The AudioOutput interface provides AASB messages for the Engine to request your application to play or perform other operations on audio output data. Understand AudioOutput \u00b6 Your application subscribes to the outgoing AudioOutput AASB messages published by the Engine. When some Engine component needs to play audio, the Engine publishes AudioOutput messages that specify content to play with a token uniquely identifying the content. To set up content for playback, the Engine includes an audioType in an AudioOutput.Prepare message. The Engine defines the following audio types for which it requests playback via AudioOutput : TTS\u2014 This audio output type plays speech audio data. For example, Alexa's speech responses from the SpeechSynthesizer interface MUSIC\u2014 This audio output type plays media. For example, Amazon Music or other streaming content from the AudioPlayer interface NOTIFICATION\u2014 This audio output type plays notification audio cues. For example, short cues from the Notifications interface ALARM\u2014 This audio output type plays alarms. For example, repeating alarm audio from the Alerts interface EARCON\u2014 This audio output type plays Alexa attention state audio cues. For example, the audio cue to indicate Alexa started listening COMMUNICATION\u2014 This audio output type plays the audio for Alexa-to-Alexa calling. For example, the \"other side\" of the user's Alexa-to-Alexa call placed using the Alexa Comms module. RINGTONE\u2014 This audio output type plays ringtones. For example, the inbound or outbound ringing tone of the user's Alexa-to-Alexa call placed using the Alexa Comms module. Your application determines how to handle each different audio type. The simplest integration, for example, might play all audio output types with multiple instances of the same underlying media player implementation. A more sophisticated integration might provide different media player implementations depending on the audio type\u2014 for example, using a low-level audio implementation for NOTIFICATION and EARCON types, and a high-level implementation for TTS and MUSIC . The best approach depends on your system-specific use cases. Important! Even though your application might use the same media player implementation for multiple audio output types, the actual integration must be able to handle the Engine having multiple channels open at the same time; for example, there might be music buffered in the MUSIC channel media player while the user makes a quick Alexa-to-Alexa call using the RINGTONE and COMMUNICATION channels. The Engine is agnostic to how you buffer and control the audio, but it does require your integration to be capable of keeping the right state of all channels that are active at the same time. I.e., starting RINGTONE audio playback is not allowed to override your active MUSIC playback buffer. After preparing an appropriate media player implementation with content specified in a Prepare message, the Engine will publish additional messages with the same token instructing your application to perform additional operations on the content, such as starting playback, pausing, stopping, or querying data about the content. Messages that request data require your application to publish a synchronous-style reply message, and messages that request playback operations require your application to asynchronously respond with a message when the media state has changed. See the AudioOutput AASB message reference for complete details about which messages require which responses. Enable music ducking \u00b6 The AudioOutput interface allows audio ducking for the MUSIC audio type. Your application can duck music playback when a higher priority Alexa audio channel acquires foreground focus or when any external application's audio channel acquires foreground focus. To enable music audio ducking, provide the following JSON in your Engine configuration: { \"aace.alexa\" : { \"audio\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } } } Alternatively, use the AlexaConfiguration::createDuckingConfig() factory function to generate the EngineConfiguration object. auto audioDuckingConfig = aace :: alexa :: config :: AlexaConfiguration :: createDuckingConfig ( true ); This Engine configuration is required in order for you to use the AudioFocusEvent message to report externally-initiated audio ducking events on the music channel. The configuration is also required to enable the Engine to publish StartDucking and StopDucking messages to your application. See Duck audio for additional details about using these messages. Use the AudioOutput interface in a native C++ application \u00b6 This section describes how to integrate the AudioOutput AASB messages in your application. Prepare content for playback \u00b6 When your application receives a Prepare message, use the audioType value in the payload to determine which of your media player implementations will handle the content (if your application manages multiple player types). There are two flavors of content that a Prepare message might use: If the Prepare message includes a url in its payload, begin downloading the content at the URL and preparing your media player for playback when the Engine requests it. URL-based content is used by the Alexa module's AudioPlayer interface, for example, to specify content provided by Amazon Music, Flash Briefing, Audible, TuneIn, and other media streaming skills. If the Prepare message includes a streamId , the Engine will write the audio data directly to a MessageStream object that you retrieve through MessageBroker . Call MessageBroker::openStream() , specifying the streamId from the Prepare message and the operation mode MessageStream::Mode::READ . To retrieve the audio data for your buffer, repeatedly call MessageStream::read() on the stream object until MessageStream::isClosed() returns true, indicating the Engine has no more data to add to the stream. Important!: Your application should use a separate thread to read the content from the stream into your media player's buffer. For some types of audio, the Engine can continuously write data to the stream for a long time and may request operations on the content playback in parallel. Your application may not block MessageBroker's outgoing thread or block operations on the content (such as play or pause) from happening immediately when requested. Keep track of the token and channel from the Prepare message since these values are used in further messages to and from the Engine for the content. After publishing a Prepare message, the Engine can optionally publish a MayDuck message to indicate if your application is allowed to duck this particular audio item during its playback (for example, when an external application temporarily takes foreground audio focus but allows your Alexa app audio to play at a ducked volume). If you receive this message, your player is allowed to duck the audio during its playback any time the system requests it and report the ducking as outlined in Duck audio . If you do not receive a MayDuck message before receiving a Play message for the audio item, your application is not allowed to duck this audio content. Start playback \u00b6 Begin playback of the buffered content only after you receive a Play message with matching token . Your media player might take a moment to start playback (for instance, if there is not enough content buffered), so publish the asynchronous MediaStateChanged message with state set to PLAYING when your player begins to play. Specify the cached token and channel for the content in this message. Unless you receive another message with matching token , such as a request from the Engine to pause or stop the playback, your player should continue to play back all of the content for this audio item until there is no more content to play. Publish the MediaStateChanged message with state set to STOPPED to tell the Engine when the content is finished. The Engine will not send any further AASB messages for this particular audio item (identified by the token ), and it may or may not tell your player to prepare new content (such as another track in a playlist) with a fresh Prepare message. Set the playback position \u00b6 If the Engine needs your player to seek to a particular position in the media stream, your application receives a SetPosition message. Your player must update its playback position to the offset specified in the position parameter. Respond to queries about the playback \u00b6 The Engine might need to query your implementation for information about the active playback. Publish the reply messages quickly so you don't delay the user's interactions with Alexa. If you receive a GetPosition message, use the synchronous-style reply message to notify the Engine of the current playback offset in the media stream (or the most recent offset if the stream isn't currently playing). The Engine will query the position any time the user makes a request to Alexa as well as various other times during playback. If you receive a GetNumBytesBuffered message, use the synchronous-style reply message to notify the Engine how many bytes your player has buffered for the current audio item. If you receive a GetDuration message, use the synchronous-style reply message to notify the Engine of the duration of the current audio item Handle a buffer underrun during playback \u00b6 If your player encounters a buffer underrun during playback (i.e., your playback buffer has run out and is refilling slower than the rate needed for playback), you can notify the Engine by publishing a MediaStateChanged message with state set to BUFFERING . Publish another MediaStateChanged message with state set to PLAYING when the buffer is refilled. Handle an error during playback \u00b6 If your player encounters an error during playback, notify the Engine by publishing a MediaError message. Publishing this message indicates to the Engine that the player has stopped playback due to an error and cannot resume, so ensure you do not begin playback for this audio item after publishing a MediaError message. After receiving MediaError for an audio item, the Engine will not request any more playback operations, such as play, pause, or resume, for this audio item. However, it is possible that the Engine can still query data about the audio item (see Respond to queries about the playback ). The Engine expects the most recently known state of the audio in this case, so cache any retrievable data until the Engine prepares a new audio item with the same audio type. Pause and resume playback \u00b6 The Engine can request your player to pause the content playback by publishing a Pause message. When you receive this message, you must pause playback and preserve the state of the audio in the buffer. Publish a MediaStateChanged message with state set to STOPPED to indicate to the Engine that your player has paused as requested. Your player will remain paused until you receive a Resume message for the same audio item. Publish a MediaStateChanged message with state set to PLAYING to indicate to the Engine that your player has resumed as requested. Note: The Engine uses the Pause and Resume messages for temporary operations, typically related to higher priority Alexa channels taking over. For example, the Engine will temporarily pause audio playing from the AudioPlayer channel when the SpeechSynthesizer channel needs to play Alexa speech. The Engine resumes the AudioPlayer audio when the SpeechSynthesizer audio is finished. For cases in which a user presses a pause button or makes a voice request to pause AudioPlayer streaming content, the Engine typically uses the Stop message for this sort of pause operation. When the user resumes the playback with the button or voice, the Engine will Prepare and Play a new audio item even though the content is the same. Important! Do not publish a MediaStateChanged message with state set to STOPPED in an attempt to notify the Engine of some locally-initiated pause or stop operation. The STOPPED state has three interpretations in the Engine, and which one the Engine uses depends on its state prior to receiving the STOPPED state from your application. If you publish the STOPPED state after the Engine published Pause for the audio item, the Engine interprets the STOPPED as a successful pause. The Engine will Resume the audio when it needs to. If you publish the STOPPED state after the Engine published Stop for the audio item, the Engine interprets the STOPPED as a successful stop. The Engine considers this media item complete and flushed from the buffer. The audio item is not resumable any more. If you publish the STOPPED state proactively (i.e., not after a Pause or Stop request from the Engine), the Engine interprets this as meaning that the content is finished playing. If the Engine has more content in its queue, such as a subsequent track in a playlist, the Engine will continue to Prepare and Play the next item automatically. If you need to pause or stop audio playback for the MUSIC audio type due to a user button press or some system audio focus event, you must use the PlaybackController interface from the Alexa module to request the Engine to halt the playback. There is no AASB message to pause other audio types. Stop playback \u00b6 The Engine can request your player to stop the content playback by publishing a Stop message. When you receive this message, you must stop playback and publish a MediaStateChanged message with state set to STOPPED to indicate to the Engine that your player has stopped as requested. The Engine considers this media item complete and non-operable any more, so you will not receive further requests for playback operations, such as play, pause, or resume, for this audio item. However, it is possible that the Engine can still query data about the audio item (see Respond to queries about the playback ). The Engine expects the most recently known state of the audio in this case, so cache any retrievable data until the Engine prepares a new audio item with the same audio type. Duck audio \u00b6 Engine-initiated \u00b6 If your application has enabled audio ducking for the music channel , the Engine can request your application to duck audio playback when a higher priority Alexa audio source temporarily needs the foreground audio focus rather than using the default behavior in which the Engine pauses and resumes the content. For example, sometimes the AudioPlayer channel is streaming media when the user interrupts to ask Alexa a question. Without ducking enabled, the Engine requests your application to pause the active audio output on the music channel. When the user and Alexa finish their interaction, the Engine requests your application to resume the audio. With ducking enabled, the Engine requests your application to start ducking the music channel content for the duration of the user's interaction with Alexa and then restores the original volume of the music when the interaction is over. When the Engine needs your application to duck the volume of the music content, the Engine publishes the StartDucking message. When you receive this message, you must reduce the playback volume, preserve the state of the audio, and continue playback. When you receive a StopDucking message, restore the audio playback to its original volume prior to ducking and continue playback. Externally-initiated \u00b6 If audio is active on the music channel and the Engine permitted the audio source to duck with the MayDuck message (see Prepare content for playback ), your application is allowed to duck audio when external audio sources on the system overtake foreground audio focus. If this happens, you must report to the Engine that your media player implementation proactively ducked its own audio by publishing an AudioFocusEvent message with focusAction set to REPORT_DUCKING_STARTED . When your implementation regains foreground audio focus on the system and restores the volume to the original level, publish another AudioFocusEvent message with focusAction set to REPORT_DUCKING_STOPPED . Mute audio \u00b6 The Engine can request your player to mute or unmute the content playback by publishing a MutedStateChanged message. When you receive a MutedStateChanged message with state set to MUTED , you must mute the playback volume, preserving the state of the audio and continuing playback. When you receive a MutedStateChanged message with state set to UNMUTED , you must restore the playback volume, preserving the state of the audio and continuing playback. Change audio volume \u00b6 The Engine can request your player to change the volume of the content playback by publishing a VolumeChanged message. When you receive a VolumeChanged message, use the value of the volume parameter to adjust the volume of the audio source. The volume is a float in the range 0-1, so you can use it as a scaling factor for the actual volume range used by your media player. Example code \u00b6 The following example code demonstrates how your application subscribes to the AudioOutput AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioOutput/GetDurationMessage.h> #include <AASB/Message/Audio/AudioOutput/GetNumBytesBufferedMessage.h> #include <AASB/Message/Audio/AudioOutput/GetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/MayDuckMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaErrorMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/MutedStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/PauseMessage.h> #include <AASB/Message/Audio/AudioOutput/PlayMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareStreamMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareURLMessage.h> #include <AASB/Message/Audio/AudioOutput/ResumeMessage.h> #include <AASB/Message/Audio/AudioOutput/SetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/StartDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopMessage.h> #include <AASB/Message/Audio/AudioOutput/VolumeChangedMessage.h> class MyAudioOutputHandler { // Call this during the \"subscribe to AASB messages\" phase of the Engine lifecycle void MyAudioOutputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMutedStateChangedMessage ( message ); }, MutedStateChangedMessage :: topic (), MutedStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePauseMessage ( message ); }, PauseMessage :: topic (), PauseMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePlayMessage ( message ); }, PlayMessage :: topic (), PlayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareStreamMessage ( message ); }, PrepareStreamMessage :: topic (), PrepareStreamMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareURLMessage ( message ); }, PrepareURLMessage :: topic (), PrepareURLMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMayDuckMessage ( message ); }, MayDuckMessage :: topic (), MayDuckMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleResumeMessage ( message ); }, ResumeMessage :: topic (), ResumeMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetPositionMessage ( message ); }, SetPositionMessage :: topic (), SetPositionMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleVolumeChangedMessage ( message ); }, VolumeChangedMessage :: topic (), VolumeChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartDuckingMessage ( message ); }, StartDuckingMessage :: topic (), StartDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopDuckingMessage ( message ); }, StopDuckingMessage :: topic (), StopDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetDurationMessage ( message ); }, GetDurationMessage :: topic (), GetDurationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNumBytesBufferedMessage ( message ); }, GetNumBytesBufferedMessage :: topic (), GetNumBytesBufferedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPositionMessage ( message ); }, GetPositionMessage :: topic (), GetPositionMessage :: action ()); } void MyAudioOutputHandler::handleMutedStateChangedMessage ( const std :: string & message ) { // Implement this stub to mute the audio } void MyAudioOutputHandler::handlePauseMessage ( const std :: string & message ) { // Implement this stub to pause the audio } void MyAudioOutputHandler::handlePlayMessage ( const std :: string & message ) { // Implement this stub to play the audio } void MyAudioOutputHandler::handlePrepareStreamMessage ( const std :: string & message ) { PrepareStreamMessage msg = json :: parse ( message ); auto stream = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // Implement this stub to read the stream content into the media player buffer // Use a separate thread! } void MyAudioOutputHandler::handlePrepareURLMessage ( const std :: string & message ) { // Implement this stub to download the URL contents into the media player buffer // Use a separate thread! } void MyAudioOutputHandler::handleMayDuckMessage ( const std :: string & message ) { // Implement this stub to set the prepared content as duck-able } void MyAudioOutputHandler::handleResumeMessage ( const std :: string & message ) { // Implement this stub to resume the audio } void MyAudioOutputHandler::handleSetPositionMessage ( const std :: string & message ) { // Implement this stub to set the audio playback position } void MyAudioOutputHandler::handleStopMessage ( const std :: string & message ) { // Implement this stub to stop the audio playback } void MyAudioOutputHandler::handleVolumeChangedMessage ( const std :: string & message ) { // Implement this stub to change the volume of the audio stream } void MyAudioOutputHandler::handleStartDuckingMessage ( const std :: string & message ) { // Implement this stub to duck the audio stream volume // Alternatively, you can pause the audio stream if more suitable - just don't publish MediaStateChanged in this case } void MyAudioOutputHandler::handleStopDuckingMessage ( const std :: string & message ) { // Implement this stub to restore the audio stream volume from the ducked state // You can resume the playback if you paused instead of ducking - just don't publish MediaStateChanged in this case } void MyAudioOutputHandler::handleGetDurationMessage ( const std :: string & message ) { GetDurationMessage msg = json :: parse ( message ); // Implement this stub to get the duration // Perform this operation quickly and publish the sync-style reply message } void MyAudioOutputHandler::handleGetNumBytesBufferedMessage ( const std :: string & message ) { GetNumBytesBufferedMessage msg = json :: parse ( message ); // Implement this stub to get the number of bytes buffered // Perform this operation quickly and publish the sync-style reply message } void MyAudioOutputHandler::handleGetPositionMessage ( const std :: string & message ) { GetPositionMessage msg = json :: parse ( message ); // Implement this stub to get the current playback offset (or the most recent offset if nothing is playing) // Perform this operation quickly and publish the sync-style reply message } // Call this function when you need to publish a MediaError message void MyAudioOutputHandler::publishMediaError ( const std :: string & token , MediaError error , const std :: string & description ) { MediaErrorMessage msg ; msg . payload . token = token ; msg . payload . error = error ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } // Call this function when you need to publish a MediaStateChanged message void MyAudioOutputHandler::publishMediaStateChanged ( const std :: string & channel , const std :: string & token , MediaState state ) { MediaStateChangedMessage msg ; msg . payload . channel = channel ; msg . payload . token = token ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } } Sequence diagrams \u00b6 Note: The following diagrams show sequences using the deprecated AudioOutput platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analogous AudioOutput AASB messages with the MessageBroker. The concepts are the same between the two interfaces. Duck music volume when Alexa dialog or alerts take foreground focus \u00b6 Duck music volume when an external audio source takes foreground focus \u00b6 Use the AudioOutput interface in an Android application \u00b6 Alexa Auto Client Service (AACS) provides a default implementation of AudioOutput for the audio types TTS and MUSIC . You can use the default implementation in your application instead of integrating directly with the AudioInput AASB messages yourself for these particular audio types. See the Android documentation for details about using the default implementation. For the remaining audio types, integrate with the AACS intents corresponding to the AudioOutput AASB messages in a similar manner to the description in Use the AudioOutput interface in a native C++ application .","title":"AudioOutput"},{"location":"explore/features/core/AudioOutput/#audiooutput-interface","text":"","title":"AudioOutput Interface "},{"location":"explore/features/core/AudioOutput/#overview","text":"The core audio Engine service provides a mechanism for Engine components of any module to open audio output channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide a media player implementation specific to the channel type. The AudioOutput interface provides AASB messages for the Engine to request your application to play or perform other operations on audio output data.","title":"Overview"},{"location":"explore/features/core/AudioOutput/#understand-audiooutput","text":"Your application subscribes to the outgoing AudioOutput AASB messages published by the Engine. When some Engine component needs to play audio, the Engine publishes AudioOutput messages that specify content to play with a token uniquely identifying the content. To set up content for playback, the Engine includes an audioType in an AudioOutput.Prepare message. The Engine defines the following audio types for which it requests playback via AudioOutput : TTS\u2014 This audio output type plays speech audio data. For example, Alexa's speech responses from the SpeechSynthesizer interface MUSIC\u2014 This audio output type plays media. For example, Amazon Music or other streaming content from the AudioPlayer interface NOTIFICATION\u2014 This audio output type plays notification audio cues. For example, short cues from the Notifications interface ALARM\u2014 This audio output type plays alarms. For example, repeating alarm audio from the Alerts interface EARCON\u2014 This audio output type plays Alexa attention state audio cues. For example, the audio cue to indicate Alexa started listening COMMUNICATION\u2014 This audio output type plays the audio for Alexa-to-Alexa calling. For example, the \"other side\" of the user's Alexa-to-Alexa call placed using the Alexa Comms module. RINGTONE\u2014 This audio output type plays ringtones. For example, the inbound or outbound ringing tone of the user's Alexa-to-Alexa call placed using the Alexa Comms module. Your application determines how to handle each different audio type. The simplest integration, for example, might play all audio output types with multiple instances of the same underlying media player implementation. A more sophisticated integration might provide different media player implementations depending on the audio type\u2014 for example, using a low-level audio implementation for NOTIFICATION and EARCON types, and a high-level implementation for TTS and MUSIC . The best approach depends on your system-specific use cases. Important! Even though your application might use the same media player implementation for multiple audio output types, the actual integration must be able to handle the Engine having multiple channels open at the same time; for example, there might be music buffered in the MUSIC channel media player while the user makes a quick Alexa-to-Alexa call using the RINGTONE and COMMUNICATION channels. The Engine is agnostic to how you buffer and control the audio, but it does require your integration to be capable of keeping the right state of all channels that are active at the same time. I.e., starting RINGTONE audio playback is not allowed to override your active MUSIC playback buffer. After preparing an appropriate media player implementation with content specified in a Prepare message, the Engine will publish additional messages with the same token instructing your application to perform additional operations on the content, such as starting playback, pausing, stopping, or querying data about the content. Messages that request data require your application to publish a synchronous-style reply message, and messages that request playback operations require your application to asynchronously respond with a message when the media state has changed. See the AudioOutput AASB message reference for complete details about which messages require which responses.","title":"Understand AudioOutput"},{"location":"explore/features/core/AudioOutput/#enable-music-ducking","text":"The AudioOutput interface allows audio ducking for the MUSIC audio type. Your application can duck music playback when a higher priority Alexa audio channel acquires foreground focus or when any external application's audio channel acquires foreground focus. To enable music audio ducking, provide the following JSON in your Engine configuration: { \"aace.alexa\" : { \"audio\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } } } Alternatively, use the AlexaConfiguration::createDuckingConfig() factory function to generate the EngineConfiguration object. auto audioDuckingConfig = aace :: alexa :: config :: AlexaConfiguration :: createDuckingConfig ( true ); This Engine configuration is required in order for you to use the AudioFocusEvent message to report externally-initiated audio ducking events on the music channel. The configuration is also required to enable the Engine to publish StartDucking and StopDucking messages to your application. See Duck audio for additional details about using these messages.","title":"Enable music ducking"},{"location":"explore/features/core/AudioOutput/#use-the-audiooutput-interface-in-a-native-c-application","text":"This section describes how to integrate the AudioOutput AASB messages in your application.","title":"Use the AudioOutput interface in a native C++ application"},{"location":"explore/features/core/AudioOutput/#prepare-content-for-playback","text":"When your application receives a Prepare message, use the audioType value in the payload to determine which of your media player implementations will handle the content (if your application manages multiple player types). There are two flavors of content that a Prepare message might use: If the Prepare message includes a url in its payload, begin downloading the content at the URL and preparing your media player for playback when the Engine requests it. URL-based content is used by the Alexa module's AudioPlayer interface, for example, to specify content provided by Amazon Music, Flash Briefing, Audible, TuneIn, and other media streaming skills. If the Prepare message includes a streamId , the Engine will write the audio data directly to a MessageStream object that you retrieve through MessageBroker . Call MessageBroker::openStream() , specifying the streamId from the Prepare message and the operation mode MessageStream::Mode::READ . To retrieve the audio data for your buffer, repeatedly call MessageStream::read() on the stream object until MessageStream::isClosed() returns true, indicating the Engine has no more data to add to the stream. Important!: Your application should use a separate thread to read the content from the stream into your media player's buffer. For some types of audio, the Engine can continuously write data to the stream for a long time and may request operations on the content playback in parallel. Your application may not block MessageBroker's outgoing thread or block operations on the content (such as play or pause) from happening immediately when requested. Keep track of the token and channel from the Prepare message since these values are used in further messages to and from the Engine for the content. After publishing a Prepare message, the Engine can optionally publish a MayDuck message to indicate if your application is allowed to duck this particular audio item during its playback (for example, when an external application temporarily takes foreground audio focus but allows your Alexa app audio to play at a ducked volume). If you receive this message, your player is allowed to duck the audio during its playback any time the system requests it and report the ducking as outlined in Duck audio . If you do not receive a MayDuck message before receiving a Play message for the audio item, your application is not allowed to duck this audio content.","title":"Prepare content for playback"},{"location":"explore/features/core/AudioOutput/#start-playback","text":"Begin playback of the buffered content only after you receive a Play message with matching token . Your media player might take a moment to start playback (for instance, if there is not enough content buffered), so publish the asynchronous MediaStateChanged message with state set to PLAYING when your player begins to play. Specify the cached token and channel for the content in this message. Unless you receive another message with matching token , such as a request from the Engine to pause or stop the playback, your player should continue to play back all of the content for this audio item until there is no more content to play. Publish the MediaStateChanged message with state set to STOPPED to tell the Engine when the content is finished. The Engine will not send any further AASB messages for this particular audio item (identified by the token ), and it may or may not tell your player to prepare new content (such as another track in a playlist) with a fresh Prepare message.","title":"Start playback"},{"location":"explore/features/core/AudioOutput/#set-the-playback-position","text":"If the Engine needs your player to seek to a particular position in the media stream, your application receives a SetPosition message. Your player must update its playback position to the offset specified in the position parameter.","title":"Set the playback position"},{"location":"explore/features/core/AudioOutput/#respond-to-queries-about-the-playback","text":"The Engine might need to query your implementation for information about the active playback. Publish the reply messages quickly so you don't delay the user's interactions with Alexa. If you receive a GetPosition message, use the synchronous-style reply message to notify the Engine of the current playback offset in the media stream (or the most recent offset if the stream isn't currently playing). The Engine will query the position any time the user makes a request to Alexa as well as various other times during playback. If you receive a GetNumBytesBuffered message, use the synchronous-style reply message to notify the Engine how many bytes your player has buffered for the current audio item. If you receive a GetDuration message, use the synchronous-style reply message to notify the Engine of the duration of the current audio item","title":"Respond to queries about the playback"},{"location":"explore/features/core/AudioOutput/#handle-a-buffer-underrun-during-playback","text":"If your player encounters a buffer underrun during playback (i.e., your playback buffer has run out and is refilling slower than the rate needed for playback), you can notify the Engine by publishing a MediaStateChanged message with state set to BUFFERING . Publish another MediaStateChanged message with state set to PLAYING when the buffer is refilled.","title":"Handle a buffer underrun during playback"},{"location":"explore/features/core/AudioOutput/#handle-an-error-during-playback","text":"If your player encounters an error during playback, notify the Engine by publishing a MediaError message. Publishing this message indicates to the Engine that the player has stopped playback due to an error and cannot resume, so ensure you do not begin playback for this audio item after publishing a MediaError message. After receiving MediaError for an audio item, the Engine will not request any more playback operations, such as play, pause, or resume, for this audio item. However, it is possible that the Engine can still query data about the audio item (see Respond to queries about the playback ). The Engine expects the most recently known state of the audio in this case, so cache any retrievable data until the Engine prepares a new audio item with the same audio type.","title":"Handle an error during playback"},{"location":"explore/features/core/AudioOutput/#pause-and-resume-playback","text":"The Engine can request your player to pause the content playback by publishing a Pause message. When you receive this message, you must pause playback and preserve the state of the audio in the buffer. Publish a MediaStateChanged message with state set to STOPPED to indicate to the Engine that your player has paused as requested. Your player will remain paused until you receive a Resume message for the same audio item. Publish a MediaStateChanged message with state set to PLAYING to indicate to the Engine that your player has resumed as requested. Note: The Engine uses the Pause and Resume messages for temporary operations, typically related to higher priority Alexa channels taking over. For example, the Engine will temporarily pause audio playing from the AudioPlayer channel when the SpeechSynthesizer channel needs to play Alexa speech. The Engine resumes the AudioPlayer audio when the SpeechSynthesizer audio is finished. For cases in which a user presses a pause button or makes a voice request to pause AudioPlayer streaming content, the Engine typically uses the Stop message for this sort of pause operation. When the user resumes the playback with the button or voice, the Engine will Prepare and Play a new audio item even though the content is the same. Important! Do not publish a MediaStateChanged message with state set to STOPPED in an attempt to notify the Engine of some locally-initiated pause or stop operation. The STOPPED state has three interpretations in the Engine, and which one the Engine uses depends on its state prior to receiving the STOPPED state from your application. If you publish the STOPPED state after the Engine published Pause for the audio item, the Engine interprets the STOPPED as a successful pause. The Engine will Resume the audio when it needs to. If you publish the STOPPED state after the Engine published Stop for the audio item, the Engine interprets the STOPPED as a successful stop. The Engine considers this media item complete and flushed from the buffer. The audio item is not resumable any more. If you publish the STOPPED state proactively (i.e., not after a Pause or Stop request from the Engine), the Engine interprets this as meaning that the content is finished playing. If the Engine has more content in its queue, such as a subsequent track in a playlist, the Engine will continue to Prepare and Play the next item automatically. If you need to pause or stop audio playback for the MUSIC audio type due to a user button press or some system audio focus event, you must use the PlaybackController interface from the Alexa module to request the Engine to halt the playback. There is no AASB message to pause other audio types.","title":"Pause and resume playback"},{"location":"explore/features/core/AudioOutput/#stop-playback","text":"The Engine can request your player to stop the content playback by publishing a Stop message. When you receive this message, you must stop playback and publish a MediaStateChanged message with state set to STOPPED to indicate to the Engine that your player has stopped as requested. The Engine considers this media item complete and non-operable any more, so you will not receive further requests for playback operations, such as play, pause, or resume, for this audio item. However, it is possible that the Engine can still query data about the audio item (see Respond to queries about the playback ). The Engine expects the most recently known state of the audio in this case, so cache any retrievable data until the Engine prepares a new audio item with the same audio type.","title":"Stop playback"},{"location":"explore/features/core/AudioOutput/#duck-audio","text":"","title":"Duck audio"},{"location":"explore/features/core/AudioOutput/#engine-initiated","text":"If your application has enabled audio ducking for the music channel , the Engine can request your application to duck audio playback when a higher priority Alexa audio source temporarily needs the foreground audio focus rather than using the default behavior in which the Engine pauses and resumes the content. For example, sometimes the AudioPlayer channel is streaming media when the user interrupts to ask Alexa a question. Without ducking enabled, the Engine requests your application to pause the active audio output on the music channel. When the user and Alexa finish their interaction, the Engine requests your application to resume the audio. With ducking enabled, the Engine requests your application to start ducking the music channel content for the duration of the user's interaction with Alexa and then restores the original volume of the music when the interaction is over. When the Engine needs your application to duck the volume of the music content, the Engine publishes the StartDucking message. When you receive this message, you must reduce the playback volume, preserve the state of the audio, and continue playback. When you receive a StopDucking message, restore the audio playback to its original volume prior to ducking and continue playback.","title":"Engine-initiated"},{"location":"explore/features/core/AudioOutput/#externally-initiated","text":"If audio is active on the music channel and the Engine permitted the audio source to duck with the MayDuck message (see Prepare content for playback ), your application is allowed to duck audio when external audio sources on the system overtake foreground audio focus. If this happens, you must report to the Engine that your media player implementation proactively ducked its own audio by publishing an AudioFocusEvent message with focusAction set to REPORT_DUCKING_STARTED . When your implementation regains foreground audio focus on the system and restores the volume to the original level, publish another AudioFocusEvent message with focusAction set to REPORT_DUCKING_STOPPED .","title":"Externally-initiated"},{"location":"explore/features/core/AudioOutput/#mute-audio","text":"The Engine can request your player to mute or unmute the content playback by publishing a MutedStateChanged message. When you receive a MutedStateChanged message with state set to MUTED , you must mute the playback volume, preserving the state of the audio and continuing playback. When you receive a MutedStateChanged message with state set to UNMUTED , you must restore the playback volume, preserving the state of the audio and continuing playback.","title":"Mute audio"},{"location":"explore/features/core/AudioOutput/#change-audio-volume","text":"The Engine can request your player to change the volume of the content playback by publishing a VolumeChanged message. When you receive a VolumeChanged message, use the value of the volume parameter to adjust the volume of the audio source. The volume is a float in the range 0-1, so you can use it as a scaling factor for the actual volume range used by your media player.","title":"Change audio volume"},{"location":"explore/features/core/AudioOutput/#example-code","text":"The following example code demonstrates how your application subscribes to the AudioOutput AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioOutput/GetDurationMessage.h> #include <AASB/Message/Audio/AudioOutput/GetNumBytesBufferedMessage.h> #include <AASB/Message/Audio/AudioOutput/GetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/MayDuckMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaErrorMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/MutedStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/PauseMessage.h> #include <AASB/Message/Audio/AudioOutput/PlayMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareStreamMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareURLMessage.h> #include <AASB/Message/Audio/AudioOutput/ResumeMessage.h> #include <AASB/Message/Audio/AudioOutput/SetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/StartDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopMessage.h> #include <AASB/Message/Audio/AudioOutput/VolumeChangedMessage.h> class MyAudioOutputHandler { // Call this during the \"subscribe to AASB messages\" phase of the Engine lifecycle void MyAudioOutputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMutedStateChangedMessage ( message ); }, MutedStateChangedMessage :: topic (), MutedStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePauseMessage ( message ); }, PauseMessage :: topic (), PauseMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePlayMessage ( message ); }, PlayMessage :: topic (), PlayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareStreamMessage ( message ); }, PrepareStreamMessage :: topic (), PrepareStreamMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareURLMessage ( message ); }, PrepareURLMessage :: topic (), PrepareURLMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMayDuckMessage ( message ); }, MayDuckMessage :: topic (), MayDuckMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleResumeMessage ( message ); }, ResumeMessage :: topic (), ResumeMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetPositionMessage ( message ); }, SetPositionMessage :: topic (), SetPositionMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleVolumeChangedMessage ( message ); }, VolumeChangedMessage :: topic (), VolumeChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartDuckingMessage ( message ); }, StartDuckingMessage :: topic (), StartDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopDuckingMessage ( message ); }, StopDuckingMessage :: topic (), StopDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetDurationMessage ( message ); }, GetDurationMessage :: topic (), GetDurationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNumBytesBufferedMessage ( message ); }, GetNumBytesBufferedMessage :: topic (), GetNumBytesBufferedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPositionMessage ( message ); }, GetPositionMessage :: topic (), GetPositionMessage :: action ()); } void MyAudioOutputHandler::handleMutedStateChangedMessage ( const std :: string & message ) { // Implement this stub to mute the audio } void MyAudioOutputHandler::handlePauseMessage ( const std :: string & message ) { // Implement this stub to pause the audio } void MyAudioOutputHandler::handlePlayMessage ( const std :: string & message ) { // Implement this stub to play the audio } void MyAudioOutputHandler::handlePrepareStreamMessage ( const std :: string & message ) { PrepareStreamMessage msg = json :: parse ( message ); auto stream = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // Implement this stub to read the stream content into the media player buffer // Use a separate thread! } void MyAudioOutputHandler::handlePrepareURLMessage ( const std :: string & message ) { // Implement this stub to download the URL contents into the media player buffer // Use a separate thread! } void MyAudioOutputHandler::handleMayDuckMessage ( const std :: string & message ) { // Implement this stub to set the prepared content as duck-able } void MyAudioOutputHandler::handleResumeMessage ( const std :: string & message ) { // Implement this stub to resume the audio } void MyAudioOutputHandler::handleSetPositionMessage ( const std :: string & message ) { // Implement this stub to set the audio playback position } void MyAudioOutputHandler::handleStopMessage ( const std :: string & message ) { // Implement this stub to stop the audio playback } void MyAudioOutputHandler::handleVolumeChangedMessage ( const std :: string & message ) { // Implement this stub to change the volume of the audio stream } void MyAudioOutputHandler::handleStartDuckingMessage ( const std :: string & message ) { // Implement this stub to duck the audio stream volume // Alternatively, you can pause the audio stream if more suitable - just don't publish MediaStateChanged in this case } void MyAudioOutputHandler::handleStopDuckingMessage ( const std :: string & message ) { // Implement this stub to restore the audio stream volume from the ducked state // You can resume the playback if you paused instead of ducking - just don't publish MediaStateChanged in this case } void MyAudioOutputHandler::handleGetDurationMessage ( const std :: string & message ) { GetDurationMessage msg = json :: parse ( message ); // Implement this stub to get the duration // Perform this operation quickly and publish the sync-style reply message } void MyAudioOutputHandler::handleGetNumBytesBufferedMessage ( const std :: string & message ) { GetNumBytesBufferedMessage msg = json :: parse ( message ); // Implement this stub to get the number of bytes buffered // Perform this operation quickly and publish the sync-style reply message } void MyAudioOutputHandler::handleGetPositionMessage ( const std :: string & message ) { GetPositionMessage msg = json :: parse ( message ); // Implement this stub to get the current playback offset (or the most recent offset if nothing is playing) // Perform this operation quickly and publish the sync-style reply message } // Call this function when you need to publish a MediaError message void MyAudioOutputHandler::publishMediaError ( const std :: string & token , MediaError error , const std :: string & description ) { MediaErrorMessage msg ; msg . payload . token = token ; msg . payload . error = error ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } // Call this function when you need to publish a MediaStateChanged message void MyAudioOutputHandler::publishMediaStateChanged ( const std :: string & channel , const std :: string & token , MediaState state ) { MediaStateChangedMessage msg ; msg . payload . channel = channel ; msg . payload . token = token ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } }","title":"Example code"},{"location":"explore/features/core/AudioOutput/#sequence-diagrams","text":"Note: The following diagrams show sequences using the deprecated AudioOutput platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analogous AudioOutput AASB messages with the MessageBroker. The concepts are the same between the two interfaces.","title":"Sequence diagrams"},{"location":"explore/features/core/AudioOutput/#duck-music-volume-when-alexa-dialog-or-alerts-take-foreground-focus","text":"","title":"Duck music volume when Alexa dialog or alerts take foreground focus"},{"location":"explore/features/core/AudioOutput/#duck-music-volume-when-an-external-audio-source-takes-foreground-focus","text":"","title":"Duck music volume when an external audio source takes foreground focus"},{"location":"explore/features/core/AudioOutput/#use-the-audiooutput-interface-in-an-android-application","text":"Alexa Auto Client Service (AACS) provides a default implementation of AudioOutput for the audio types TTS and MUSIC . You can use the default implementation in your application instead of integrating directly with the AudioInput AASB messages yourself for these particular audio types. See the Android documentation for details about using the default implementation. For the remaining audio types, integrate with the AACS intents corresponding to the AudioOutput AASB messages in a similar manner to the description in Use the AudioOutput interface in a native C++ application .","title":"Use the AudioOutput interface in an Android application"},{"location":"explore/features/core/Authorization/","text":"Authorization Interface \u00b6 Overview \u00b6 To make requests to services such as Alexa, the Auto SDK Engine requires authorization. For example, the Engine includes a Login with Amazon (LWA) access token in every request to Alexa. The access token authorizes the Engine to interact with Alexa on behalf of the user. A service that requires authorization might have more than one method of performing the authorization; for instance, there are multiple methods to acquire an LWA token that authorizes access to Alexa. See the Authorize an AVS Device for details of each method. The Auto SDK Core module provides an Engine service and Authorization interface for your application to initiate, terminate, or provide data for an authorization session with an authorization provider. The following sections describe the Auto SDK Authorization interface and details to use the Authorization interface for LWA Alexa authorization in your application. Understand the Authorization interface \u00b6 The Authorization interface specifies generic messages to support authorization to any cloud service using any valid authorization method for that service. The actions the Engine takes in response to an Authorization message from your application depend on the provider to which the message corresponds, as well as the specific responsibilities of each software component involved in the authorization method. For example, in your Alexa integration, your application might use the method in which the Engine acquires LWA Alexa access tokens, so at first time user sign-in, your application requests the Engine to fetch a code for your application UI to display to the user. Alternatively, you might use the method in which your application provides its own implementation to acquire LWA Alexa access tokens, so at first time user sign-in, your application notifies the Engine that your application will will soon provide an access token that it acquires on its own. In either case, your application interacts with the same Authorization interface messages; only the protocol in the message payload varies. Each authorization provider that the Engine supports corresponds to a protocol that your application uses in Authorization message payloads. See the Authorization message reference for details about the messages and provider-specific documentation for details about the specific protocol to use with the messages. Regardless of the authorization provider you choose, your application does the following general steps: Before starting the Engine, subscribe to the following messages: SetAuthorizationData \u2014 Requests your application to store provider-specific data. GetAuthorizationData \u2014 Requests your application to share provider-specific data. Your application publishes the synchronous-style reply message in response. EventReceived \u2014 Notifies your application of provider-specific events during the authorization flow. AuthorizationStateChanged \u2014 Notifies your application of status changes during the authorization flow. AuthorizationError \u2014 Notifies your application of errors during the authorization flow. At runtime, publish the following messages: StartAuthorization \u2014 Tells the Engine to start the authorization flow. Depending on the provider in use, this could be a request to the Engine to start fetching authorization data or a notification that your application is ready for authorization and will fetch or refresh authorization data on its own. SendEvent \u2014 Notifies the Engine about a provider-specific event. CancelAuthorization \u2014 Tells the Engine to cancel the authorization flow. Depending on the provider in use, this could be a request to the Engine to cancel fetching authorization data while in progress or a notification that your application is canceling its own data fetching. Logout \u2014 Notifies the Engine that the user signed out of your application. Authorize for Alexa \u00b6 To simplify your Alexa authorization implementation, the Engine provides an implementation of the code-based linking (CBL) LWA authorization method, which you can use in your application by integrating with the CBL module . Alternatively, your application can provide the implementation to fetch access tokens through any method you choose . The different authorization providers for Alexa access tokens are mutually exclusive, so the Engine only allows one active provider session at a time. If your application has an active authorization session using the CBL module, for example, and switches to an application-provided authorization implementation, the Engine terminates the session with the CBL module provider prior to accepting further updates from the application-provided provider. Important!: Logging out from the CBL module or application-provided authorization clears the Auto SDK databases that store user data, such as alerts and settings. For example, when the user logs out, the Alexa module Engine components clear pending alerts in the alerts database to ensure that the next user who logs in does not receive any alerts set by another user. However, the Alexa module Engine components also clear the locale setting at log out and reset the setting to the default value from the Engine configuration. Therefore, if the device locale setting is different from the default locale when the next user signs in, you must set the locale before starting an authorization flow. Use the CBL module \u00b6 The Engine provides an implementation of the code-based linking method of acquiring LWA access tokens. To use the implementation, build the Auto SDK with the CBL module, link the library in your application, and follow the Authorization protocol specified in the CBL module documentation . Use an application-provided method \u00b6 If you want your application to provide the implementation for fetching and refreshing Alexa access tokens, use the application-provided authorization method according to the following specification. Use alexa:auth-provider for the service parameter in Authorization messages. Initialize the active authorization provider \u00b6 When your application is ready to start an authorization session for alexa:auth-provider , publish the StartAuthorization message with empty data parameter. This StartAuthorization message notifies the Engine that your application-provided component is the active authorization provider. This allows the Engine to clear any previously active authorization provider sessions and ready itself to expect further state change notifications and access tokens from your application. Click to expand or collapse example StartAuthorization message { \"header\": { \"id\": \"7b388b36-6843-4f63-b3ad-ec69c16a518e\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"StartAuthorization\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"\", \"service\": \"alexa:auth-provider\" } } In response to the StartAuthorization message that requests to initialize alexa:auth-provider , the Engine will publish one or more AuthorizationStateChanged messages. The state parameter indicates the Engine's internal view of the authorization state for the provider specified in the service parameter. If a different provider was used more recently than alexa:auth-provider , the Engine un-initializes that provider and sets its state to UNAUTHORIZED . Click to expand or collapse example AuthorizationStateChanged message { \"header\": { \"id\": \"56f4fdb1-2174-44ba-850e-e46ae10488e6\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:cbl\", \"state\": \"UNAUTHORIZED\" } } Once any previously active authorization session is cleared, the Engine notifies your application that alexa:auth-provider is AUTHORIZING . The Engine does not consider your application-provided authorization component to be the active authorization provider until you receive this message. Click to expand or collapse example AuthorizationStateChanged message { \"header\": { \"id\": \"5d163203-2ebc-4169-ac45-e840fc125ad2\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\", \"state\": \"AUTHORIZING\" } } Once alexa:auth-provider reaches the AUTHORIZING state, the Engine needs to know whether there is an access token. It publishes the EventReceived message to request your application to publish its authorization state. The data parameter is a serialized JSON string with the following structure: { \"type\": \"requestAuthorization\" } Click to expand or collapse example EventReceived message { \"header\": { \"id\": \"9fac0f24-779b-4e69-91db-317c8988eedc\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"EventReceived\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"{\\\"type\\\":\\\"requestAuthorization\\\"}\", \"service\": \"alexa:auth-provider\" } } The Engine can also publish this EventReceived message at any point later in the application run time. Publish the SendEvent message in response to this EventReceived message. The event parameter is a serialized JSON string with the following structure: { \"type\":\"authStateChangeEvent\", \"payload\": { \"state\": {{STRING}} } } The accepted values for state are AUTHORIZED and UNAUTHORIZED . Set state to AUTHORIZED if your application has an access token or UNAUTHORIZED if it does not have an access token yet. Click to expand or collapse example SendEvent message { \"header\": { \"id\": \"6f6baa3c-0de7-439d-aa67-c9b7ad858894\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SendEvent\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"{\\\"type\\\":\\\"authStateChangeEvent\\\",\\\"payload\\\":{\\\"state\\\":\\\"AUTHORIZED\\\"}}\", \"service\": \"alexa:auth-provider\" } } Your application can also proactively publish this SendEvent message when its authorization state changes. For example, if the state was initially AUTHORIZED but later your application fails to refresh an expired token, publish SendEvent as specified above and use the state UNAUTHORIZED . If the application later recovers and acquires a new token, publish another SendEvent message with state AUTHORIZED . The Engine acknowledges the authorization state from your application by publishing an AuthorizationStateChanged message with its updated internal state. Click to expand or collapse example AuthorizationStateChanged message { \"header\": { \"id\": \"1a91c0ab-053e-4884-a275-ff5caf3207b8\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\", \"state\": \"AUTHORIZED\" } } The following diagram illustrates the sequence for your application to set the application-provided component as the active authorization provider. Provide an access token \u00b6 When your application is in the AUTHORIZED state, the Engine will request your application to provide the access token by publishing a GetAuthorizationData message with the key parameter set to accessToken . The Engine will publish GetAuthorizationData messages throughout the application run time, such as when the user invokes Alexa. Click to expand or collapse example GetAuthorizationData message { \"header\": { \"id\": \"5b6e905a-9def-411c-806d-7ef8fa1ad0a9\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"key\": \"accessToken\", \"service\": \"alexa:auth-provider\" } } Your application includes the access token in the synchronous-style GetAuthorizationData reply message. The data parameter is a serialized JSON string with the following structure: { \"accessToken\": {{STRING}} } Click to expand or collapse example GetAuthorizationData reply message { \"header\": { \"id\": \"a680da01-8046-4401-9ab6-a8d6120f0814\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\", \"replyToId\": \"5b6e905a-9def-411c-806d-7ef8fa1ad0a9\" }, \"messageType\": \"Reply\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"{\\\"accessToken\\\":\\\"Atza|AAAAAABBBBBBCCCCCC\\\"}\" } } The following diagram illustrates an example sequence for your application to provide an access token to the Engine. Cancel authorization \u00b6 If your application needs to cancel an in-progress authorization initialization, you can publish a CancelAuthorization message prior to publishing SendEvent containing an access token. The Engine acknowledges this message from your application by publishing an AuthorizationStateChanged message with its updated internal state. Click to expand or collapse example CancelAuthorization message { \"header\": { \"id\": \"329ac412-82e2-46be-8c67-fd965dfe3dc6\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"CancelAuthorization\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\" } } Note: If you need to terminate the authorization session when the auth state is AUTHORIZED , use the Logout message instead. The following diagram illustrates an example sequence for your application to cancel authorization. Log out \u00b6 When the user signs out of your application, publish a Logout message and delete any stored access or refresh tokens. The user must sign in to their Amazon account in order to use Alexa with your application again. Click to expand or collapse example Logout message { \"header\": { \"id\": \"a9e28b9a-6f9d-45b5-999a-19a421431af4\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"Logout\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\" } } The Engine acknowledges the Logout message from your application by publishing an EventReceived message with type set to logout and an AuthorizationStateChanged message with its updated internal state. The following diagram illustrates an example sequence when the user signs out of your application. Handle errors \u00b6 If the Engine encounters an error during the authorization flow, it publishes an AuthorizationError message to your application. The error parameter specifies which issue the Engine encountered. The following list describes the values: START_AUTHORIZATION_FAILED : The Engine could not start the authorization flow. LOGOUT_FAILED : The Engine could not complete the logout flow. AUTH_FAILURE : The application provided an invalid or expired access token. UNKNOWN_ERROR : The Engine encountered any other type of unrecoverable error in the authorization flow. Click to expand or collapse example AuthorizationError message { \"header\": { \"id\": \"c7e93ab5-2509-4f0e-b421-32d0b5991279\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationError\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\", \"error\": \"UNKNOWN_ERROR\", \"message\": \"\" } } The following diagram illustrates an example error scenario in which the user de-registers their car from their Alexa account using the Alexa companion app while the car's Alexa application is running. (Optional) Configure the Engine for multiple providers \u00b6 By default, the Engine supports one application-provided authorization provider. However, if your application supports more than one, include the following JSON object in your Engine configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [<LIST_OF_PROVIDER_NAME_STRINGS>] } } } For example, if your application supports providers \"serviceA\" and \"serviceB,\" provide the following configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [\"serviceA\" , \"serviceB\"] } } } With this configuration, the Engine uses the service names serviceA and serviceB with the Authorization interface messages instead of using the default service name alexa:auth-provider . The rest of the sequence is the same as alexa:auth-provider .","title":"Authorization"},{"location":"explore/features/core/Authorization/#authorization-interface","text":"","title":"Authorization Interface"},{"location":"explore/features/core/Authorization/#overview","text":"To make requests to services such as Alexa, the Auto SDK Engine requires authorization. For example, the Engine includes a Login with Amazon (LWA) access token in every request to Alexa. The access token authorizes the Engine to interact with Alexa on behalf of the user. A service that requires authorization might have more than one method of performing the authorization; for instance, there are multiple methods to acquire an LWA token that authorizes access to Alexa. See the Authorize an AVS Device for details of each method. The Auto SDK Core module provides an Engine service and Authorization interface for your application to initiate, terminate, or provide data for an authorization session with an authorization provider. The following sections describe the Auto SDK Authorization interface and details to use the Authorization interface for LWA Alexa authorization in your application.","title":"Overview"},{"location":"explore/features/core/Authorization/#understand-the-authorization-interface","text":"The Authorization interface specifies generic messages to support authorization to any cloud service using any valid authorization method for that service. The actions the Engine takes in response to an Authorization message from your application depend on the provider to which the message corresponds, as well as the specific responsibilities of each software component involved in the authorization method. For example, in your Alexa integration, your application might use the method in which the Engine acquires LWA Alexa access tokens, so at first time user sign-in, your application requests the Engine to fetch a code for your application UI to display to the user. Alternatively, you might use the method in which your application provides its own implementation to acquire LWA Alexa access tokens, so at first time user sign-in, your application notifies the Engine that your application will will soon provide an access token that it acquires on its own. In either case, your application interacts with the same Authorization interface messages; only the protocol in the message payload varies. Each authorization provider that the Engine supports corresponds to a protocol that your application uses in Authorization message payloads. See the Authorization message reference for details about the messages and provider-specific documentation for details about the specific protocol to use with the messages. Regardless of the authorization provider you choose, your application does the following general steps: Before starting the Engine, subscribe to the following messages: SetAuthorizationData \u2014 Requests your application to store provider-specific data. GetAuthorizationData \u2014 Requests your application to share provider-specific data. Your application publishes the synchronous-style reply message in response. EventReceived \u2014 Notifies your application of provider-specific events during the authorization flow. AuthorizationStateChanged \u2014 Notifies your application of status changes during the authorization flow. AuthorizationError \u2014 Notifies your application of errors during the authorization flow. At runtime, publish the following messages: StartAuthorization \u2014 Tells the Engine to start the authorization flow. Depending on the provider in use, this could be a request to the Engine to start fetching authorization data or a notification that your application is ready for authorization and will fetch or refresh authorization data on its own. SendEvent \u2014 Notifies the Engine about a provider-specific event. CancelAuthorization \u2014 Tells the Engine to cancel the authorization flow. Depending on the provider in use, this could be a request to the Engine to cancel fetching authorization data while in progress or a notification that your application is canceling its own data fetching. Logout \u2014 Notifies the Engine that the user signed out of your application.","title":"Understand the Authorization interface"},{"location":"explore/features/core/Authorization/#authorize-for-alexa","text":"To simplify your Alexa authorization implementation, the Engine provides an implementation of the code-based linking (CBL) LWA authorization method, which you can use in your application by integrating with the CBL module . Alternatively, your application can provide the implementation to fetch access tokens through any method you choose . The different authorization providers for Alexa access tokens are mutually exclusive, so the Engine only allows one active provider session at a time. If your application has an active authorization session using the CBL module, for example, and switches to an application-provided authorization implementation, the Engine terminates the session with the CBL module provider prior to accepting further updates from the application-provided provider. Important!: Logging out from the CBL module or application-provided authorization clears the Auto SDK databases that store user data, such as alerts and settings. For example, when the user logs out, the Alexa module Engine components clear pending alerts in the alerts database to ensure that the next user who logs in does not receive any alerts set by another user. However, the Alexa module Engine components also clear the locale setting at log out and reset the setting to the default value from the Engine configuration. Therefore, if the device locale setting is different from the default locale when the next user signs in, you must set the locale before starting an authorization flow.","title":"Authorize for Alexa"},{"location":"explore/features/core/Authorization/#use-the-cbl-module","text":"The Engine provides an implementation of the code-based linking method of acquiring LWA access tokens. To use the implementation, build the Auto SDK with the CBL module, link the library in your application, and follow the Authorization protocol specified in the CBL module documentation .","title":"Use the CBL module"},{"location":"explore/features/core/Authorization/#use-an-application-provided-method","text":"If you want your application to provide the implementation for fetching and refreshing Alexa access tokens, use the application-provided authorization method according to the following specification. Use alexa:auth-provider for the service parameter in Authorization messages.","title":"Use an application-provided method"},{"location":"explore/features/core/Authorization/#initialize-the-active-authorization-provider","text":"When your application is ready to start an authorization session for alexa:auth-provider , publish the StartAuthorization message with empty data parameter. This StartAuthorization message notifies the Engine that your application-provided component is the active authorization provider. This allows the Engine to clear any previously active authorization provider sessions and ready itself to expect further state change notifications and access tokens from your application. Click to expand or collapse example StartAuthorization message { \"header\": { \"id\": \"7b388b36-6843-4f63-b3ad-ec69c16a518e\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"StartAuthorization\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"\", \"service\": \"alexa:auth-provider\" } } In response to the StartAuthorization message that requests to initialize alexa:auth-provider , the Engine will publish one or more AuthorizationStateChanged messages. The state parameter indicates the Engine's internal view of the authorization state for the provider specified in the service parameter. If a different provider was used more recently than alexa:auth-provider , the Engine un-initializes that provider and sets its state to UNAUTHORIZED . Click to expand or collapse example AuthorizationStateChanged message { \"header\": { \"id\": \"56f4fdb1-2174-44ba-850e-e46ae10488e6\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:cbl\", \"state\": \"UNAUTHORIZED\" } } Once any previously active authorization session is cleared, the Engine notifies your application that alexa:auth-provider is AUTHORIZING . The Engine does not consider your application-provided authorization component to be the active authorization provider until you receive this message. Click to expand or collapse example AuthorizationStateChanged message { \"header\": { \"id\": \"5d163203-2ebc-4169-ac45-e840fc125ad2\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\", \"state\": \"AUTHORIZING\" } } Once alexa:auth-provider reaches the AUTHORIZING state, the Engine needs to know whether there is an access token. It publishes the EventReceived message to request your application to publish its authorization state. The data parameter is a serialized JSON string with the following structure: { \"type\": \"requestAuthorization\" } Click to expand or collapse example EventReceived message { \"header\": { \"id\": \"9fac0f24-779b-4e69-91db-317c8988eedc\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"EventReceived\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"{\\\"type\\\":\\\"requestAuthorization\\\"}\", \"service\": \"alexa:auth-provider\" } } The Engine can also publish this EventReceived message at any point later in the application run time. Publish the SendEvent message in response to this EventReceived message. The event parameter is a serialized JSON string with the following structure: { \"type\":\"authStateChangeEvent\", \"payload\": { \"state\": {{STRING}} } } The accepted values for state are AUTHORIZED and UNAUTHORIZED . Set state to AUTHORIZED if your application has an access token or UNAUTHORIZED if it does not have an access token yet. Click to expand or collapse example SendEvent message { \"header\": { \"id\": \"6f6baa3c-0de7-439d-aa67-c9b7ad858894\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SendEvent\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"{\\\"type\\\":\\\"authStateChangeEvent\\\",\\\"payload\\\":{\\\"state\\\":\\\"AUTHORIZED\\\"}}\", \"service\": \"alexa:auth-provider\" } } Your application can also proactively publish this SendEvent message when its authorization state changes. For example, if the state was initially AUTHORIZED but later your application fails to refresh an expired token, publish SendEvent as specified above and use the state UNAUTHORIZED . If the application later recovers and acquires a new token, publish another SendEvent message with state AUTHORIZED . The Engine acknowledges the authorization state from your application by publishing an AuthorizationStateChanged message with its updated internal state. Click to expand or collapse example AuthorizationStateChanged message { \"header\": { \"id\": \"1a91c0ab-053e-4884-a275-ff5caf3207b8\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\", \"state\": \"AUTHORIZED\" } } The following diagram illustrates the sequence for your application to set the application-provided component as the active authorization provider.","title":"Initialize the active authorization provider"},{"location":"explore/features/core/Authorization/#provide-an-access-token","text":"When your application is in the AUTHORIZED state, the Engine will request your application to provide the access token by publishing a GetAuthorizationData message with the key parameter set to accessToken . The Engine will publish GetAuthorizationData messages throughout the application run time, such as when the user invokes Alexa. Click to expand or collapse example GetAuthorizationData message { \"header\": { \"id\": \"5b6e905a-9def-411c-806d-7ef8fa1ad0a9\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"key\": \"accessToken\", \"service\": \"alexa:auth-provider\" } } Your application includes the access token in the synchronous-style GetAuthorizationData reply message. The data parameter is a serialized JSON string with the following structure: { \"accessToken\": {{STRING}} } Click to expand or collapse example GetAuthorizationData reply message { \"header\": { \"id\": \"a680da01-8046-4401-9ab6-a8d6120f0814\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\", \"replyToId\": \"5b6e905a-9def-411c-806d-7ef8fa1ad0a9\" }, \"messageType\": \"Reply\", \"version\": \"4.0\" }, \"payload\": { \"data\": \"{\\\"accessToken\\\":\\\"Atza|AAAAAABBBBBBCCCCCC\\\"}\" } } The following diagram illustrates an example sequence for your application to provide an access token to the Engine.","title":"Provide an access token"},{"location":"explore/features/core/Authorization/#cancel-authorization","text":"If your application needs to cancel an in-progress authorization initialization, you can publish a CancelAuthorization message prior to publishing SendEvent containing an access token. The Engine acknowledges this message from your application by publishing an AuthorizationStateChanged message with its updated internal state. Click to expand or collapse example CancelAuthorization message { \"header\": { \"id\": \"329ac412-82e2-46be-8c67-fd965dfe3dc6\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"CancelAuthorization\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\" } } Note: If you need to terminate the authorization session when the auth state is AUTHORIZED , use the Logout message instead. The following diagram illustrates an example sequence for your application to cancel authorization.","title":"Cancel authorization"},{"location":"explore/features/core/Authorization/#log-out","text":"When the user signs out of your application, publish a Logout message and delete any stored access or refresh tokens. The user must sign in to their Amazon account in order to use Alexa with your application again. Click to expand or collapse example Logout message { \"header\": { \"id\": \"a9e28b9a-6f9d-45b5-999a-19a421431af4\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"Logout\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\" } } The Engine acknowledges the Logout message from your application by publishing an EventReceived message with type set to logout and an AuthorizationStateChanged message with its updated internal state. The following diagram illustrates an example sequence when the user signs out of your application.","title":"Log out"},{"location":"explore/features/core/Authorization/#handle-errors","text":"If the Engine encounters an error during the authorization flow, it publishes an AuthorizationError message to your application. The error parameter specifies which issue the Engine encountered. The following list describes the values: START_AUTHORIZATION_FAILED : The Engine could not start the authorization flow. LOGOUT_FAILED : The Engine could not complete the logout flow. AUTH_FAILURE : The application provided an invalid or expired access token. UNKNOWN_ERROR : The Engine encountered any other type of unrecoverable error in the authorization flow. Click to expand or collapse example AuthorizationError message { \"header\": { \"id\": \"c7e93ab5-2509-4f0e-b421-32d0b5991279\", \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationError\" }, \"messageType\": \"Publish\", \"version\": \"4.0\" }, \"payload\": { \"service\": \"alexa:auth-provider\", \"error\": \"UNKNOWN_ERROR\", \"message\": \"\" } } The following diagram illustrates an example error scenario in which the user de-registers their car from their Alexa account using the Alexa companion app while the car's Alexa application is running.","title":"Handle errors"},{"location":"explore/features/core/Authorization/#optional-configure-the-engine-for-multiple-providers","text":"By default, the Engine supports one application-provided authorization provider. However, if your application supports more than one, include the following JSON object in your Engine configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [<LIST_OF_PROVIDER_NAME_STRINGS>] } } } For example, if your application supports providers \"serviceA\" and \"serviceB,\" provide the following configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [\"serviceA\" , \"serviceB\"] } } } With this configuration, the Engine uses the service names serviceA and serviceB with the Authorization interface messages instead of using the default service name alexa:auth-provider . The rest of the sequence is the same as alexa:auth-provider .","title":"(Optional) Configure the Engine for multiple providers"},{"location":"explore/features/core/DeviceUsage/","text":"DeviceUsage Interface \u00b6 Periodically publish the DeviceUsage.ReportNetworkDataUsage message (for example, at five minute intervals) to report network data usage to the Engine. If your application uses the Device Client Metrics (DCM) extension, the Engine records metrics with this information. The usage field in the payload is a JSON object as a string. The format of the JSON is the following: { \"startTimeStamp\" : {{LONG}}, \"endTimeStamp\" : {{LONG}}, \"networkInterfaceType\": \"{{STRING}}\", \"dataPlanType\" : \"{{STRING}}\", \"bytesUsage\" :{ \"rxBytes\" : {{LONG}}, \"txBytes\" : {{LONG}} } } The following table describes the properties in the JSON: Property Type Required Description Example startTimeStamp Long Yes The starting timestamp in milliseconds for this network usage datapoint \u2014 endTimeStamp Long Yes The ending timestamp in milliseconds for this network usage datapoint \u2014 networkInterfaceType String Yes The name of the network interface over which the data is recorded \"WIFI\", \"MOBILE\" dataPlanType String No The type of data plan the device is subscribed to. This is an optional field and should be provided if your application uses the AlexaConnectivity module. See AlexaConnectivity bytesUsage .rxBytes Long Yes The number of bytes received over the network interface during the time range represented by this datapoint \u2014 bytesUsage .txBytes Long Yes The number of bytes transmitted over the network interface during the time range represented by this datapoint \u2014","title":"DeviceUsage"},{"location":"explore/features/core/DeviceUsage/#deviceusage-interface","text":"Periodically publish the DeviceUsage.ReportNetworkDataUsage message (for example, at five minute intervals) to report network data usage to the Engine. If your application uses the Device Client Metrics (DCM) extension, the Engine records metrics with this information. The usage field in the payload is a JSON object as a string. The format of the JSON is the following: { \"startTimeStamp\" : {{LONG}}, \"endTimeStamp\" : {{LONG}}, \"networkInterfaceType\": \"{{STRING}}\", \"dataPlanType\" : \"{{STRING}}\", \"bytesUsage\" :{ \"rxBytes\" : {{LONG}}, \"txBytes\" : {{LONG}} } } The following table describes the properties in the JSON: Property Type Required Description Example startTimeStamp Long Yes The starting timestamp in milliseconds for this network usage datapoint \u2014 endTimeStamp Long Yes The ending timestamp in milliseconds for this network usage datapoint \u2014 networkInterfaceType String Yes The name of the network interface over which the data is recorded \"WIFI\", \"MOBILE\" dataPlanType String No The type of data plan the device is subscribed to. This is an optional field and should be provided if your application uses the AlexaConnectivity module. See AlexaConnectivity bytesUsage .rxBytes Long Yes The number of bytes received over the network interface during the time range represented by this datapoint \u2014 bytesUsage .txBytes Long Yes The number of bytes transmitted over the network interface during the time range represented by this datapoint \u2014","title":"DeviceUsage Interface"},{"location":"explore/features/core/LocationProvider/","text":"LocationProvider Interface \u00b6 Sometimes the user asks Alexa a question that requires she know the location in order to answer properly. For example, a user in San Francisco, California might say \"Alexa, what's the weather?\" . This user probably wants to hear Alexa say something like \"The weather in San Francisco is sixty-five degrees and overcast...\" rather than something like \"I can't find your exact location right now...\" . Similarly, the user might say \"Alexa, take me to the nearest Whole Foods\" and wants Alexa to start navigation to a Whole Foods that is actually nearby. To provide the user with accurate responses to local search commands, weather questions, and more, obtain the user's consent to share their location with Alexa and use the LocationProvider interface. Note: For Android applications, AACS provides a default implementation of LocationProvider . See the AACS Default Implementation documentation for more information. Your application should subscribe to the LocationProvider.GetLocation and LocationProvider.GetCountry messages to provide location data, such as geographic coordinates and vehicle operating country, when the Engine requests it. These messages are synchronous-style and require your application to send the corresponding reply messages right away. To avoid blocking the MessageBroker outgoing thread and delaying user requests to Alexa, your application should keep the location data in a cache that you update frequently. Pull the location from the cache when the Engine requests it. The Engine won't publish the GetLocation message if it knows your application has lost access to the location data. Keep the Engine in sync with the state of your application's location provider availability by proactively publishing the LocationServiceAccessChanged message at startup and each time the state changes. For example, your application might publish this message with access set to DISABLED if the system revokes your application's access to location or if GPS turns off. Note: The Engine does not persist this state across device reboots. To ensure the Engine always knows the initial state of location availability, publish a LocationServiceAccessChanged message each time you start the Engine. This includes notifying the Engine that access is ENABLED . Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Location/LocationProvider/GetCountryMessage.h> #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> #include <AASB/Message/Location/LocationProvider/LocationServiceAccessChangedMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyLocationProviderHandler { // Call before you start the Engine void MyLocationProviderHandler::subscribeToAASBMessages () { messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCountryMessage ( message ); }, GetCountryMessage :: topic (), GetCountryMessage :: action ()); messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetLocationMessage ( message ); }, GetLocationMessage :: topic (), GetLocationMessage :: action ()); } void MyLocationProviderHandler::handleGetCountryMessage ( const std :: string & message ) { GetCountryMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto country = getCountryFromCache (); // implement this stub GetCountryMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . country = country ; messageBroker -> publish ( replyMsg . toString ()); } void MyLocationProviderHandler::handleGetLocationMessage ( const std :: string & message ) { GetLocationMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto location = getLocationFromCache (); // implement this stub GetLocationMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // parse \"location\" and populate the fields of the reply message aasb :: message :: location :: locationProvider :: Location replyLocation ; replyLocation . latitude = ... ; // the latitude from \"location\"; replyLocation . longitude = ... ; // the longitude from \"location\"; replyMsg . payload . location = replyLocation ; messageBroker -> publish ( replyMsg . toString ()); } // Call when the application access to location data changes // and after starting the Engine void MyLocationProviderHandler::locationServiceAccessChanged ( bool hasAccess ) { LocationServiceAccessChangedMessage msg ; if ( hasAccess ) { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: ENABLED ; } else { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: DISABLED ; } messageBroker -> publish ( msg . toString ()); } }","title":"LocationProvider"},{"location":"explore/features/core/LocationProvider/#locationprovider-interface","text":"Sometimes the user asks Alexa a question that requires she know the location in order to answer properly. For example, a user in San Francisco, California might say \"Alexa, what's the weather?\" . This user probably wants to hear Alexa say something like \"The weather in San Francisco is sixty-five degrees and overcast...\" rather than something like \"I can't find your exact location right now...\" . Similarly, the user might say \"Alexa, take me to the nearest Whole Foods\" and wants Alexa to start navigation to a Whole Foods that is actually nearby. To provide the user with accurate responses to local search commands, weather questions, and more, obtain the user's consent to share their location with Alexa and use the LocationProvider interface. Note: For Android applications, AACS provides a default implementation of LocationProvider . See the AACS Default Implementation documentation for more information. Your application should subscribe to the LocationProvider.GetLocation and LocationProvider.GetCountry messages to provide location data, such as geographic coordinates and vehicle operating country, when the Engine requests it. These messages are synchronous-style and require your application to send the corresponding reply messages right away. To avoid blocking the MessageBroker outgoing thread and delaying user requests to Alexa, your application should keep the location data in a cache that you update frequently. Pull the location from the cache when the Engine requests it. The Engine won't publish the GetLocation message if it knows your application has lost access to the location data. Keep the Engine in sync with the state of your application's location provider availability by proactively publishing the LocationServiceAccessChanged message at startup and each time the state changes. For example, your application might publish this message with access set to DISABLED if the system revokes your application's access to location or if GPS turns off. Note: The Engine does not persist this state across device reboots. To ensure the Engine always knows the initial state of location availability, publish a LocationServiceAccessChanged message each time you start the Engine. This includes notifying the Engine that access is ENABLED . Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Location/LocationProvider/GetCountryMessage.h> #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> #include <AASB/Message/Location/LocationProvider/LocationServiceAccessChangedMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyLocationProviderHandler { // Call before you start the Engine void MyLocationProviderHandler::subscribeToAASBMessages () { messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCountryMessage ( message ); }, GetCountryMessage :: topic (), GetCountryMessage :: action ()); messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetLocationMessage ( message ); }, GetLocationMessage :: topic (), GetLocationMessage :: action ()); } void MyLocationProviderHandler::handleGetCountryMessage ( const std :: string & message ) { GetCountryMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto country = getCountryFromCache (); // implement this stub GetCountryMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . country = country ; messageBroker -> publish ( replyMsg . toString ()); } void MyLocationProviderHandler::handleGetLocationMessage ( const std :: string & message ) { GetLocationMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto location = getLocationFromCache (); // implement this stub GetLocationMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // parse \"location\" and populate the fields of the reply message aasb :: message :: location :: locationProvider :: Location replyLocation ; replyLocation . latitude = ... ; // the latitude from \"location\"; replyLocation . longitude = ... ; // the longitude from \"location\"; replyMsg . payload . location = replyLocation ; messageBroker -> publish ( replyMsg . toString ()); } // Call when the application access to location data changes // and after starting the Engine void MyLocationProviderHandler::locationServiceAccessChanged ( bool hasAccess ) { LocationServiceAccessChangedMessage msg ; if ( hasAccess ) { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: ENABLED ; } else { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: DISABLED ; } messageBroker -> publish ( msg . toString ()); } }","title":"LocationProvider Interface"},{"location":"explore/features/core/NetworkInfoProvider/","text":"NetworkInfoProvider Interface \u00b6 Your application should monitor the internet connection and notify the Engine of changes in the status using the NetworkInfoProvider interface. The Engine uses this information to adjust its behavior, including tearing down the connection to Alexa cloud when your application reports that it has no connection to the internet. Although using NetworkInfoProvider is optional, you should use it so the Engine can avoid undesirable behavior; for instance, attempting to send events to Alexa when the lack of connectivity means the events are bound to fail. Note: You must use the NetworkInfoProvider interface if your application uses the Local Voice Control (LVC) extension. Note: For Android applications, AACS provides a default implementation of NetworkInfoProvider . See the AACS Default Implementation documentation for more information. Various Engine components want the initial network status at startup so they can adapt their initial behavior accordingly. Your application should subscribe to the NetworkInfoProvider.GetNetworkStatus and NetworkInfoProvider.GetWifiSignalStrength messages to answer the initial query from the Engine. These messages are synchronous-style and require your application to send the corresponding reply messages right away. At runtime, publish the NetworkInfoProvider.NetworkStatusChanged message to notify the Engine of any status changes.","title":"NetworkInfoProvider"},{"location":"explore/features/core/NetworkInfoProvider/#networkinfoprovider-interface","text":"Your application should monitor the internet connection and notify the Engine of changes in the status using the NetworkInfoProvider interface. The Engine uses this information to adjust its behavior, including tearing down the connection to Alexa cloud when your application reports that it has no connection to the internet. Although using NetworkInfoProvider is optional, you should use it so the Engine can avoid undesirable behavior; for instance, attempting to send events to Alexa when the lack of connectivity means the events are bound to fail. Note: You must use the NetworkInfoProvider interface if your application uses the Local Voice Control (LVC) extension. Note: For Android applications, AACS provides a default implementation of NetworkInfoProvider . See the AACS Default Implementation documentation for more information. Various Engine components want the initial network status at startup so they can adapt their initial behavior accordingly. Your application should subscribe to the NetworkInfoProvider.GetNetworkStatus and NetworkInfoProvider.GetWifiSignalStrength messages to answer the initial query from the Engine. These messages are synchronous-style and require your application to send the corresponding reply messages right away. At runtime, publish the NetworkInfoProvider.NetworkStatusChanged message to notify the Engine of any status changes.","title":"NetworkInfoProvider Interface"},{"location":"explore/features/core/PropertyManager/","text":"PropertyManager Interface \u00b6 Overview \u00b6 Certain modules in the Auto SDK define constants (for example FIRMWARE_VERSION and LOCALE ) that are used to get and set the values of runtime properties in the Engine. Changes to property values may also be initiated from the Alexa Voice Service (AVS). For example, the TIMEZONE property may be changed through AVS when the user changes the timezone setting in the Alexa Companion App. The Auto SDK Core module provides the Property Manager service with corresponding AASB interface PropertyManager . Property Manager maintains the runtime properties by storing properties and listeners to the properties and delegating the SetProperty and GetProperty messages calls from your application to the respective Engine services. The Engine also publishes PropertyChanged and PropertyStateChanged messages to notify your application about property value changes originating in the Engine. Use the Property Manager AASB messages \u00b6 To change a property value, publish a SetProperty message. The Engine publishes a PropertyStateChanged message indicating the success or failure of the request. To retrieve a property value, publish a GetProperty message. The Engine publishes synchronous-style a GetProperty reply with the value of the property. When a change in a property value occurs in the Engine that is not initiated by your application, the Engine publishes a PropertyChanged message. Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PropertyManager/PropertyManager/GetPropertyMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/PropertyChangedMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/SetPropertyMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPropertyManagerHandler { // Subscribe to messages from the engine void MyPropertyManagerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyChangedMessage ( message ); }, PropertyChangedMessage :: topic (), PropertyChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyStateChangedMessage ( message ); }, PropertyStateChangedMessage :: topic (), PropertyStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); } void MyPropertyManagerHandler::handlePropertyChangedMessage ( const std :: string & message ) { PropertyChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string newValue = msg . payload . newValue ; // ...Handle property changed... } void MyPropertyManagerHandler::handlePropertyStateChangedMessage ( const std :: string & message ) { PropertyStateChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string value = msg . payload . value ; std :: string state = msg . payload . state // ...Handle property state changed... } void MyPropertyManagerHandler::handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string value = msg . payload . value ; // ...Handle the value for the message... } // Call to set a property void MyPropertyManagerHandler::setProperty ( const std :: string & name , const std :: string & value ) { ] SetPropertyMessage msg ; msg . payload . name = name ; msg . payload . value = value ; m_messageBroker -> publish ( msg . toString ()); } // Call to get a property std :: string MyPropertyManagerHandler::getProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetProperty reply message // Return the value from reply message payload } } Property Definitions \u00b6 The definitions of the properties used with the SetProperty and GetProperty messages are defined by the Auto SDK modules that manage the properties. Alexa \u00b6 The Alexa module provides the following properties: \"aace.alexa.wakewordSupported\" This read-only property is used with GetProperty to check if wake word support is enabled in the Engine. If wake word is not supported in the Engine, attempts to enable wake word with the SpeechRecognizer will fail. \"aace.alexa.system.firmwareVersion\" This property is used with SetProperty to change the firmware version that is reported to AVS. The value must be a positive, 32-bit signed integer represented as a string. \"aace.alexa.setting.locale\" This property is used with SetProperty to change the current locale setting for Alexa. The value must be one of the following: A valid locale accepted by AVS as a string. E.g. \"en-US\" A valid locale pair. The format is a string containing two valid locales separated with a forward slash. E.g. \"en-US/es-US\" Note: For a list of the Alexa Voice Service (AVS) supported locales, see the Alexa Voice Service (AVS) documentation \"aace.alexa.countrySupported\" This read-only property is used with GetProperty to check if the vehicle's country is supported. \"aace.alexa.wakewordEnabled\" This property is used with SetProperty to change the current wake word enabled setting. The value must be a boolean represented as a string, i.e. \"true\" or \"false\". Use GetProperty with this property to check whether wake word is enabled. Note: The Engine does not persist this setting across device reboots. \"aace.alexa.timezone\" This property is used with SetProperty to change the current timezone setting of the device. The value must be a valid timezone accepted by AVS. Use GetProperty to get the Engine's current timezone setting. Core \u00b6 The Core module provides the following properties: \"aace.core.version\" This property is used with GetProperty to return the Auto SDK version. \"aace.vehicle.operatingCountry\" This property is used with SetProperty to change the current operating country. The value must be a valid 2-letter ISO country code. \"aace.network.networkInterface\" This property is used with SetProperty to set the network interface for the network connection. The value must be an IP address or network interface name. \"aace.network.httpProxyHeaders\" This property is used with SetProperty to set the custom HTTP header to pass in the HTTP request sent to a proxy. The headers should be \\n separated. For example, \"Proxy-Authorization: Bearer 1234\" (should not be CRLF-terminated) Note: To apply the custom headers you are required to specify the CURLOPT_PROXY in the Engine configuration. The specified headers will be applied to all subsequent requests sent to a proxy.","title":"PropertyManager"},{"location":"explore/features/core/PropertyManager/#propertymanager-interface","text":"","title":"PropertyManager Interface "},{"location":"explore/features/core/PropertyManager/#overview","text":"Certain modules in the Auto SDK define constants (for example FIRMWARE_VERSION and LOCALE ) that are used to get and set the values of runtime properties in the Engine. Changes to property values may also be initiated from the Alexa Voice Service (AVS). For example, the TIMEZONE property may be changed through AVS when the user changes the timezone setting in the Alexa Companion App. The Auto SDK Core module provides the Property Manager service with corresponding AASB interface PropertyManager . Property Manager maintains the runtime properties by storing properties and listeners to the properties and delegating the SetProperty and GetProperty messages calls from your application to the respective Engine services. The Engine also publishes PropertyChanged and PropertyStateChanged messages to notify your application about property value changes originating in the Engine.","title":"Overview"},{"location":"explore/features/core/PropertyManager/#use-the-property-manager-aasb-messages","text":"To change a property value, publish a SetProperty message. The Engine publishes a PropertyStateChanged message indicating the success or failure of the request. To retrieve a property value, publish a GetProperty message. The Engine publishes synchronous-style a GetProperty reply with the value of the property. When a change in a property value occurs in the Engine that is not initiated by your application, the Engine publishes a PropertyChanged message. Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PropertyManager/PropertyManager/GetPropertyMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/PropertyChangedMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/SetPropertyMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPropertyManagerHandler { // Subscribe to messages from the engine void MyPropertyManagerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyChangedMessage ( message ); }, PropertyChangedMessage :: topic (), PropertyChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyStateChangedMessage ( message ); }, PropertyStateChangedMessage :: topic (), PropertyStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); } void MyPropertyManagerHandler::handlePropertyChangedMessage ( const std :: string & message ) { PropertyChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string newValue = msg . payload . newValue ; // ...Handle property changed... } void MyPropertyManagerHandler::handlePropertyStateChangedMessage ( const std :: string & message ) { PropertyStateChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string value = msg . payload . value ; std :: string state = msg . payload . state // ...Handle property state changed... } void MyPropertyManagerHandler::handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string value = msg . payload . value ; // ...Handle the value for the message... } // Call to set a property void MyPropertyManagerHandler::setProperty ( const std :: string & name , const std :: string & value ) { ] SetPropertyMessage msg ; msg . payload . name = name ; msg . payload . value = value ; m_messageBroker -> publish ( msg . toString ()); } // Call to get a property std :: string MyPropertyManagerHandler::getProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetProperty reply message // Return the value from reply message payload } }","title":"Use the Property Manager AASB messages"},{"location":"explore/features/core/PropertyManager/#property-definitions","text":"The definitions of the properties used with the SetProperty and GetProperty messages are defined by the Auto SDK modules that manage the properties.","title":"Property Definitions"},{"location":"explore/features/core/PropertyManager/#alexa","text":"The Alexa module provides the following properties: \"aace.alexa.wakewordSupported\" This read-only property is used with GetProperty to check if wake word support is enabled in the Engine. If wake word is not supported in the Engine, attempts to enable wake word with the SpeechRecognizer will fail. \"aace.alexa.system.firmwareVersion\" This property is used with SetProperty to change the firmware version that is reported to AVS. The value must be a positive, 32-bit signed integer represented as a string. \"aace.alexa.setting.locale\" This property is used with SetProperty to change the current locale setting for Alexa. The value must be one of the following: A valid locale accepted by AVS as a string. E.g. \"en-US\" A valid locale pair. The format is a string containing two valid locales separated with a forward slash. E.g. \"en-US/es-US\" Note: For a list of the Alexa Voice Service (AVS) supported locales, see the Alexa Voice Service (AVS) documentation \"aace.alexa.countrySupported\" This read-only property is used with GetProperty to check if the vehicle's country is supported. \"aace.alexa.wakewordEnabled\" This property is used with SetProperty to change the current wake word enabled setting. The value must be a boolean represented as a string, i.e. \"true\" or \"false\". Use GetProperty with this property to check whether wake word is enabled. Note: The Engine does not persist this setting across device reboots. \"aace.alexa.timezone\" This property is used with SetProperty to change the current timezone setting of the device. The value must be a valid timezone accepted by AVS. Use GetProperty to get the Engine's current timezone setting.","title":"Alexa"},{"location":"explore/features/core/PropertyManager/#core","text":"The Core module provides the following properties: \"aace.core.version\" This property is used with GetProperty to return the Auto SDK version. \"aace.vehicle.operatingCountry\" This property is used with SetProperty to change the current operating country. The value must be a valid 2-letter ISO country code. \"aace.network.networkInterface\" This property is used with SetProperty to set the network interface for the network connection. The value must be an IP address or network interface name. \"aace.network.httpProxyHeaders\" This property is used with SetProperty to set the custom HTTP header to pass in the HTTP request sent to a proxy. The headers should be \\n separated. For example, \"Proxy-Authorization: Bearer 1234\" (should not be CRLF-terminated) Note: To apply the custom headers you are required to specify the CURLOPT_PROXY in the Engine configuration. The specified headers will be applied to all subsequent requests sent to a proxy.","title":"Core"},{"location":"explore/features/custom-domain/","text":"Custom Domain Module \u00b6 Overview \u00b6 The Alexa Auto SDK Custom Domain module creates a bi-directional communication channel between your device and your cloud custom skills, allowing you to build customized experience with your in-vehicle Alexa Custom Assistant. By using this module, you can instruct Auto SDK to send data (in Events and Contexts) from your device to your cloud custom skills that can consume the data, and also receive the data (in Directives) dispatched by the skills to the device. Custom Domain provides an AASB message interface that you can integrate with to enable the bi-directional communication between your device and your custom skills in the cloud. Since Auto SDK is built on top of Alexa Voice Service (AVS) Device SDK which utilizes directives and events to achieve the communication with Alexa Cloud, this module enables your device to receive custom directives from your skills and send custom events, contexts to your skills that can process them. Prerequisites \u00b6 To use Custom Domain module, please contact your Solution Architect to onboard your device type, vendor ID, custom skill IDs, custom interface names, etc. Auto SDK Custom Domain Sequence Diagrams \u00b6 This diagram illustrates the sequence of receiving custom directives and sending custom events. This diagram illustrates the sequence of providing custom states in the context when required. The event that requires context could be from the device, Auto SDK, or AVS itself and it could be custom or non-custom ones. For any AVS event, as long as it requires context, which is queried by the ContextManager , the Auto SDK Engine publishes GetContext message, and the registered custom states should be provided by replying the message. Required Engine Configuration \u00b6 The Custom Domain module requires proper Engine Configuration for your custom interfaces. Below is the expected configuration format. Sample JSON Object \"aace.customDomain\" : { \"interfaces\": [ { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\" \"states\": [\"{{String}}\", \"{{String}}\", ...] }, { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\", \"states\": [\"{{String}}\", \"{{String}}\", ...] }, ... ] } Object Parameters Field Type Required Description aace.customDomain. interfaces list Yes The list of custom interfaces for the communication between your device and skills. aace.customDomain. interfaces[i].namespace string Yes The namespace of the custom interface. The string must follow the convention Custom.<vendorId>.<customInterfaceName> , where the vendorId must match your actual vendorId that should be onboarded and allow-listed, and the customInterfaceName is a string of your own choice based on the responsibility of the interface. The namespace must match with the one you specified in your Skill Manifest. aace.customDomain. interfaces[i].version string Yes The version of the custom interface in string. The version should follow the versioning convention <major>.<minor> . e.g. \"1.0\". aace.customDomain. interfaces[i].states list No Optional. The list of the custom state names for a custom interface. It must be provided if custom states are available for this interface. The custom state names must match with the ones you specified in your Skill Manifest. Note: On AACS and AACS Sample App, this module is disabled by default. Please refer to AACS Configuration documentation to enable the module through AACS configuration file. If your product does not use AACS but uses AASB messages and if you do not intend to enable the communication between the vehicle and your cloud Alexa skills, you can disable this module by providing the block below in the Engine Configuration. \"aasb.customDomain\": { \"CustomDomain\": { \"enabled\": false } } Using the Custom Domain Module AASB Messages \u00b6 Receiving and handling a custom directive \u00b6 Custom directives carry the information from your custom skills to the device. When a new directive arrives, the Engine publishes HandleDirective message with directive metadata including namespace, name, payload, etc. Only directives with custom namespaces configured in the Engine Configuration will be received. Reporting a directive handling result \u00b6 After handling a directive, your application is responsible for reporting the directive handling result by publishing ReportDirectiveHandlingResult message with the necessary directive metadata. When a directive is cancelled \u00b6 It is possible that the arrived directive is cancelled by AVS due to associated directives (e.g. a Speak directive) is not handled properly or an error occurs. In this case, the Engine publishes CancelDirective message to inform your application that a directive is cancelled. Depending on the use case, your application might need to process the cancellation accordingly and inform the user that a previous directive is cancelled. Sending a custom event \u00b6 Custom events carry the information from your application to your skills. Your application can inform the Engine to send a custom event to the Alexa cloud by publishing SendEvent message with required event metadata. Only custom events with configured custom namespaces in the Engine Configuration will be sent to the Alexa cloud, and only events with custom namespaces registered and onboarded with the cloud services can be received by your skill. If the custom event should be sent with context, set requiresContext to true in the AASB message payload. Optionally, you can also include the custom context (if available) for the custom event's namespace in the SendEvent message, and it's recommended to do so to avoid the unnecessary GetContext messages from the Engine. If the custom event is in response to a custom directive, make sure the correlationToken for the event matches with the one the directive has. Your application can also send proactive events, which can trigger a skill session without user interaction. correlationToken is not required for proactive events. Providing custom states in Context \u00b6 Context communicates the state of the device client components to AVS. A context object reflects the state of client components immediately before its associated event is sent. Please refer to AVS documentation for more information on Context. The Engine publishes GetContext message to query the custom context with a specific configured custom namespace. Your device is expected to reply back the custom context quickly, and should provide the custom context in a String representation of a JSON object in GetContextReply message . Below is the expected JSON structure for the custom context, which needs to be serialized to a single String to be included in the GetContext message reply. The context states should match the ones specified in the Custom Domain Engine Configuration. { \"context\": [ { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, ... ] } Object Parameters Field Type Required Description context list Yes List of custom states to be reported. context[i].name string Yes The name of the custom context property state. context[i].value string/object/number Yes The value of the context property state. context[i].timeOfSample string No The time at which the property value was recorded in ISO-8601 representation. If omitted, the default value is the current time recorded when AVS constructs the context. context[i].uncertaintyInMilliseconds integer No The number of milliseconds that have elapsed since the property value was last confirmed. If omitted, the default value is 0.","title":"Custom Domain Module"},{"location":"explore/features/custom-domain/#custom-domain-module","text":"","title":"Custom Domain Module"},{"location":"explore/features/custom-domain/#overview","text":"The Alexa Auto SDK Custom Domain module creates a bi-directional communication channel between your device and your cloud custom skills, allowing you to build customized experience with your in-vehicle Alexa Custom Assistant. By using this module, you can instruct Auto SDK to send data (in Events and Contexts) from your device to your cloud custom skills that can consume the data, and also receive the data (in Directives) dispatched by the skills to the device. Custom Domain provides an AASB message interface that you can integrate with to enable the bi-directional communication between your device and your custom skills in the cloud. Since Auto SDK is built on top of Alexa Voice Service (AVS) Device SDK which utilizes directives and events to achieve the communication with Alexa Cloud, this module enables your device to receive custom directives from your skills and send custom events, contexts to your skills that can process them.","title":"Overview"},{"location":"explore/features/custom-domain/#prerequisites","text":"To use Custom Domain module, please contact your Solution Architect to onboard your device type, vendor ID, custom skill IDs, custom interface names, etc.","title":"Prerequisites"},{"location":"explore/features/custom-domain/#auto-sdk-custom-domain-sequence-diagrams","text":"This diagram illustrates the sequence of receiving custom directives and sending custom events. This diagram illustrates the sequence of providing custom states in the context when required. The event that requires context could be from the device, Auto SDK, or AVS itself and it could be custom or non-custom ones. For any AVS event, as long as it requires context, which is queried by the ContextManager , the Auto SDK Engine publishes GetContext message, and the registered custom states should be provided by replying the message.","title":"Auto SDK Custom Domain Sequence Diagrams"},{"location":"explore/features/custom-domain/#required-engine-configuration","text":"The Custom Domain module requires proper Engine Configuration for your custom interfaces. Below is the expected configuration format. Sample JSON Object \"aace.customDomain\" : { \"interfaces\": [ { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\" \"states\": [\"{{String}}\", \"{{String}}\", ...] }, { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\", \"states\": [\"{{String}}\", \"{{String}}\", ...] }, ... ] } Object Parameters Field Type Required Description aace.customDomain. interfaces list Yes The list of custom interfaces for the communication between your device and skills. aace.customDomain. interfaces[i].namespace string Yes The namespace of the custom interface. The string must follow the convention Custom.<vendorId>.<customInterfaceName> , where the vendorId must match your actual vendorId that should be onboarded and allow-listed, and the customInterfaceName is a string of your own choice based on the responsibility of the interface. The namespace must match with the one you specified in your Skill Manifest. aace.customDomain. interfaces[i].version string Yes The version of the custom interface in string. The version should follow the versioning convention <major>.<minor> . e.g. \"1.0\". aace.customDomain. interfaces[i].states list No Optional. The list of the custom state names for a custom interface. It must be provided if custom states are available for this interface. The custom state names must match with the ones you specified in your Skill Manifest. Note: On AACS and AACS Sample App, this module is disabled by default. Please refer to AACS Configuration documentation to enable the module through AACS configuration file. If your product does not use AACS but uses AASB messages and if you do not intend to enable the communication between the vehicle and your cloud Alexa skills, you can disable this module by providing the block below in the Engine Configuration. \"aasb.customDomain\": { \"CustomDomain\": { \"enabled\": false } }","title":"Required Engine Configuration"},{"location":"explore/features/custom-domain/#using-the-custom-domain-module-aasb-messages","text":"","title":"Using the Custom Domain Module AASB Messages"},{"location":"explore/features/custom-domain/#receiving-and-handling-a-custom-directive","text":"Custom directives carry the information from your custom skills to the device. When a new directive arrives, the Engine publishes HandleDirective message with directive metadata including namespace, name, payload, etc. Only directives with custom namespaces configured in the Engine Configuration will be received.","title":"Receiving and handling a custom directive"},{"location":"explore/features/custom-domain/#reporting-a-directive-handling-result","text":"After handling a directive, your application is responsible for reporting the directive handling result by publishing ReportDirectiveHandlingResult message with the necessary directive metadata.","title":"Reporting a directive handling result"},{"location":"explore/features/custom-domain/#when-a-directive-is-cancelled","text":"It is possible that the arrived directive is cancelled by AVS due to associated directives (e.g. a Speak directive) is not handled properly or an error occurs. In this case, the Engine publishes CancelDirective message to inform your application that a directive is cancelled. Depending on the use case, your application might need to process the cancellation accordingly and inform the user that a previous directive is cancelled.","title":"When a directive is cancelled"},{"location":"explore/features/custom-domain/#sending-a-custom-event","text":"Custom events carry the information from your application to your skills. Your application can inform the Engine to send a custom event to the Alexa cloud by publishing SendEvent message with required event metadata. Only custom events with configured custom namespaces in the Engine Configuration will be sent to the Alexa cloud, and only events with custom namespaces registered and onboarded with the cloud services can be received by your skill. If the custom event should be sent with context, set requiresContext to true in the AASB message payload. Optionally, you can also include the custom context (if available) for the custom event's namespace in the SendEvent message, and it's recommended to do so to avoid the unnecessary GetContext messages from the Engine. If the custom event is in response to a custom directive, make sure the correlationToken for the event matches with the one the directive has. Your application can also send proactive events, which can trigger a skill session without user interaction. correlationToken is not required for proactive events.","title":"Sending a custom event"},{"location":"explore/features/custom-domain/#providing-custom-states-in-context","text":"Context communicates the state of the device client components to AVS. A context object reflects the state of client components immediately before its associated event is sent. Please refer to AVS documentation for more information on Context. The Engine publishes GetContext message to query the custom context with a specific configured custom namespace. Your device is expected to reply back the custom context quickly, and should provide the custom context in a String representation of a JSON object in GetContextReply message . Below is the expected JSON structure for the custom context, which needs to be serialized to a single String to be included in the GetContext message reply. The context states should match the ones specified in the Custom Domain Engine Configuration. { \"context\": [ { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, ... ] } Object Parameters Field Type Required Description context list Yes List of custom states to be reported. context[i].name string Yes The name of the custom context property state. context[i].value string/object/number Yes The value of the context property state. context[i].timeOfSample string No The time at which the property value was recorded in ISO-8601 representation. If omitted, the default value is the current time recorded when AVS constructs the context. context[i].uncertaintyInMilliseconds integer No The number of milliseconds that have elapsed since the property value was last confirmed. If omitted, the default value is 0.","title":"Providing custom states in Context"},{"location":"explore/features/loopback-detector/","text":"Loopback Detector Module \u00b6 Overview \u00b6 The Loopback Detector module enables your Alexa Auto SDK client application to monitor wake word detection to cancel out self references. In some environments where acoustic echo cancellation capabilities are limited, the microphone may pick up the wake word from speakers, which will cause false wake word detection. For example, if the user says \"Alexa, what's your name?\", Alexa responds with \"My name is Alexa\", which may cause false wake word detection and interrupt the current speech output. The Loopback Detector module solves this issue by capturing speaker reference \"loopback\" audio and trying to detect the wake word at the same time. Configuring the Loopback Detector Module \u00b6 The Loopback Detector module can be optionally configured with the following configuration structure: { \"aace.loopbackDetector\" : { \"wakewordEngine\" : \"<WAKEWORD ENGINE NAME>\" } } Setting up the Loopback Detector Module \u00b6 Providing Audio \u00b6 The Loopback Detector module requests audio through the StartAudioInput AASB message. The StartAudioInput message payload contains a field audioType set to LOOPBACK . The StopAudioInput AASB message is sent to request that audio input be stopped. The example below shows how to handle the StartAudioInput and StopAudioInput messages. #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; // Loopback stream id std :: string m_streamId ; // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); m_streamId = _msg . payload . streamId ; auto audioType = _msg . payload . audioType ; if ( audioType == \"LOOPBACK\" ) { // open the stream for writing auto stream = messageBroker -> openStream ( m_streamId , MessageStream :: Mode :: WRITE ); if ( stream != nullptr ) startAudioInput ( m_streamId , stream ) } }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; if ( streamId == m_streamId ) { stopAudioInput ( streamId ); m_streamId = \"\" ; } }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } This audio source should be the final mix of audio output (i.e. speaker reference/monitor). Note: If you are using the System Audio module, see the System Audio module documentation for details about how to specify LOOPBACK audio input provider. Building with the Loopback Detector Module \u00b6 To build the Alexa Auto SDK with the Loopback Detector module, simply include the module when running the Auto SDK builder: $ builder/build.py -m loopback-detector Note: Additionally include any other modules you want to use in the same command. Example Setup in Ubuntu Linux \u00b6 Here is an example of how to provide loopback audio into the Alexa Auto SDK. You will need the following software running on a Linux system: PulseAudio GStreamer Advanced Linux Sound Architecture (ALSA) snd_aloop module If you are using the System Audio module , the Auto SDK (and all other applications on Linux) will use PulseAudio to output audio by default. PulseAudio mixes all audio then plays it through a hardware device. We need to capture this \"final mix result\" into the GStreamer pipeline and pass it through directly into the ALSA loopback device so the Auto SDK can capture this audio. To do this, follow these steps: Make sure the snd_aloop module is loaded into kernel by running sudo modprobe snd_aloop . Use this command to launch the GStreamer pipeline: gst-launch-1.0 -v autoaudiosrc ! audio/x-raw,format=S16LE,channels=1,rate=16000,layout=interleaved ! audioconvert ! audioresample ! alsasink device=hw:Loopback,0,0 Note: You need to keep this process throughout the testing. Open the PulseAudio control panel ( pavucontrol ), and go to the Recording panel. You will see that the gst-launch-1.0 process is capturing the audio. Change the audio source to Monitor of Built-in Audio Analog Stereo . Set the SampleApp Record Stream to microphone device . At this point, all speaker outputs (through PulseAudio) will be eventually routed to the ALSA loopback device. If you are using the System Audio module, ensure the LOOPBACK type and loopback device are configured correctly. \"aace.systemAudio\": { \"AudioInputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" }, \"loopback\": { \"module\": \"GStreamer\", \"card\": \"hw:Loopback,1,0\", \"shared\": true } }, \"types\": { \"LOOPBACK\": \"loopback\" } }, \"AudioOutputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" } } } } After this, the Auto SDK can capture audio loopback from the hw:Loopback,1,0 device. The following diagram illustrates how the audio output data is routed to the Loopback Detector on Linux:","title":"Loopback Detector Module"},{"location":"explore/features/loopback-detector/#loopback-detector-module","text":"","title":"Loopback Detector Module"},{"location":"explore/features/loopback-detector/#overview","text":"The Loopback Detector module enables your Alexa Auto SDK client application to monitor wake word detection to cancel out self references. In some environments where acoustic echo cancellation capabilities are limited, the microphone may pick up the wake word from speakers, which will cause false wake word detection. For example, if the user says \"Alexa, what's your name?\", Alexa responds with \"My name is Alexa\", which may cause false wake word detection and interrupt the current speech output. The Loopback Detector module solves this issue by capturing speaker reference \"loopback\" audio and trying to detect the wake word at the same time.","title":"Overview"},{"location":"explore/features/loopback-detector/#configuring-the-loopback-detector-module","text":"The Loopback Detector module can be optionally configured with the following configuration structure: { \"aace.loopbackDetector\" : { \"wakewordEngine\" : \"<WAKEWORD ENGINE NAME>\" } }","title":"Configuring the Loopback Detector Module"},{"location":"explore/features/loopback-detector/#setting-up-the-loopback-detector-module","text":"","title":"Setting up the Loopback Detector Module"},{"location":"explore/features/loopback-detector/#providing-audio","text":"The Loopback Detector module requests audio through the StartAudioInput AASB message. The StartAudioInput message payload contains a field audioType set to LOOPBACK . The StopAudioInput AASB message is sent to request that audio input be stopped. The example below shows how to handle the StartAudioInput and StopAudioInput messages. #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; // Loopback stream id std :: string m_streamId ; // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); m_streamId = _msg . payload . streamId ; auto audioType = _msg . payload . audioType ; if ( audioType == \"LOOPBACK\" ) { // open the stream for writing auto stream = messageBroker -> openStream ( m_streamId , MessageStream :: Mode :: WRITE ); if ( stream != nullptr ) startAudioInput ( m_streamId , stream ) } }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; if ( streamId == m_streamId ) { stopAudioInput ( streamId ); m_streamId = \"\" ; } }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } This audio source should be the final mix of audio output (i.e. speaker reference/monitor). Note: If you are using the System Audio module, see the System Audio module documentation for details about how to specify LOOPBACK audio input provider.","title":"Providing Audio"},{"location":"explore/features/loopback-detector/#building-with-the-loopback-detector-module","text":"To build the Alexa Auto SDK with the Loopback Detector module, simply include the module when running the Auto SDK builder: $ builder/build.py -m loopback-detector Note: Additionally include any other modules you want to use in the same command.","title":"Building with the Loopback Detector Module"},{"location":"explore/features/loopback-detector/#example-setup-in-ubuntu-linux","text":"Here is an example of how to provide loopback audio into the Alexa Auto SDK. You will need the following software running on a Linux system: PulseAudio GStreamer Advanced Linux Sound Architecture (ALSA) snd_aloop module If you are using the System Audio module , the Auto SDK (and all other applications on Linux) will use PulseAudio to output audio by default. PulseAudio mixes all audio then plays it through a hardware device. We need to capture this \"final mix result\" into the GStreamer pipeline and pass it through directly into the ALSA loopback device so the Auto SDK can capture this audio. To do this, follow these steps: Make sure the snd_aloop module is loaded into kernel by running sudo modprobe snd_aloop . Use this command to launch the GStreamer pipeline: gst-launch-1.0 -v autoaudiosrc ! audio/x-raw,format=S16LE,channels=1,rate=16000,layout=interleaved ! audioconvert ! audioresample ! alsasink device=hw:Loopback,0,0 Note: You need to keep this process throughout the testing. Open the PulseAudio control panel ( pavucontrol ), and go to the Recording panel. You will see that the gst-launch-1.0 process is capturing the audio. Change the audio source to Monitor of Built-in Audio Analog Stereo . Set the SampleApp Record Stream to microphone device . At this point, all speaker outputs (through PulseAudio) will be eventually routed to the ALSA loopback device. If you are using the System Audio module, ensure the LOOPBACK type and loopback device are configured correctly. \"aace.systemAudio\": { \"AudioInputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" }, \"loopback\": { \"module\": \"GStreamer\", \"card\": \"hw:Loopback,1,0\", \"shared\": true } }, \"types\": { \"LOOPBACK\": \"loopback\" } }, \"AudioOutputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" } } } } After this, the Auto SDK can capture audio loopback from the hw:Loopback,1,0 device. The following diagram illustrates how the audio output data is routed to the Loopback Detector on Linux:","title":"Example Setup in Ubuntu Linux"},{"location":"explore/features/messaging/","text":"Messaging Module \u00b6 Overview \u00b6 The Alexa Auto SDK Messaging module enables your Alexa Auto SDK client application to use the Short Message Service (SMS) capabilities of Alexa, independent of the messaging device's connection mechanism. The SMS features of this module include reading messages, sending messages, and replying to messages as they are read. The user must connect their device and consent to allow Alexa to read and send SMS messages through the messaging device. The Messaging feature can use phone numbers directly or use phone contacts uploaded via the Address Book module. Managing Messaging Sessions \u00b6 The application is responsible for managing the life cycle of the messaging session, including enhancing the end user experience by: Uploading unread SMS messages when the messaging device is connected, so they are ready for readout. Uploading new SMS messages when they are received on the messaging device. Updating the status of messages when notified to do so. Responding to messaging requests with appropriate successful or failure responses. Alexa will not notify the user when new SMS messages are available, your implementation is responsible for providing new message notifications. Configuring the Messaging Module \u00b6 The Messaging module does not require Engine configuration. Using the Messaging Module AASB Messages \u00b6 Sending Messages \u00b6 When Alexa sends a request to the Engine to deliver a message, the Engine publishes the SendMessage message including the text and URL for the audio from which the message was created. Publish either the SendMessageSucceeded message or SendMessageFailed message indicating either the success or failure of the request. Click to expand or collapse sequence diagram: Sending Messages Reading Messages \u00b6 When a user requests for Alexa to read messages, your application's Messaging module integration must upload a conversation report containing all unread messages. Once Alexa requests a conversation report upload, the Engine publishes the UploadConversations message . Publish the ConversationsReport message to notify the Engine to upload a conversation report to the cloud. Note: Messages are grouped by conversation, each given a unique identifier. Conversations also have unique identifiers and contain the list of recipient phone numbers included in the conversation, but not the phone number of the messaging device. After Alexa reads a message, it notifies the application that the message was read and should exclude the read message in subsequent conversation report uploads. The Engine publishes the UpdateMessagesStatus message to update the status of the SMS messages. Publish either the UpdateMessagesStatusSucceeded message or UpdateMessageStatusFailed message indicating the success of the message status update. After Alexa reads all messages, or if message readout is interrupted, Alexa requests the upload of a new conversation report. In this way, Alexa stays in sync with unread messages on the messaging device. Note: Unread messages are stored in the cloud for 12 hours before being deleted. By design Alexa will read a limited number of unread messages with a 'read messages' utterance. Therefore, it may be necessary to issue additional read messages requests to head all messages. Click to expand or collapse sequence diagram: Reading Messages and Replying Replying to Message \u00b6 The user can request to reply to a message after Alexa reads the message or as it is being read. Replying is always done within the context of the currently read message. Click to expand or collapse sequence diagram: Replying to Message Updating Messaging Endpoint State \u00b6 When connection to a calling device is established or broken and/or the user grants or denies permissions to read and send messages, publish the UpdateMessagingEndpointState message to update Alexa with the state of the messaging device. Click to expand or collapse sequence diagram: Connecting/Disconnecting Calling Device Click to expand or collapse sequence diagram: Granting/Denying Permissions to Read and Send Messages Integrating the Messaging Module Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the Engine's MessageBroker to subscribe to and publish \"Messaging\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Messaging/Messaging/ConnectionState.h> #include <AASB/Message/Messaging/Messaging/ErrorCode.h> #include <AASB/Message/Messaging/Messaging/PermissionState.h> #include <AASB/Message/Messaging/Messaging/ConversationsReportMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageFailedMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusFailedMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagingEndpointStateMessage.h> #include <AASB/Message/Messaging/Messaging/UploadConversationsMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyMessagingHandler { // Subscribe to messages from the Engine void MyMessagingHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendMessageMessage ( message ); }, SendMessageMessage :: topic (), SendMessageMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUpdateMessagesStatusMessage ( message ); }, UpdateMessagesStatusMessage :: topic (), UpdateMessagesStatusMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUploadConversationsMessage ( message ); }, UploadConversationsMessage :: topic (), UploadConversationsMessage :: action ()); } // Handle the SendMessage message from the Engine void MyMessagingHandler::handleSendMessageMessage ( const std :: string & message ) { SendMessageMessage msg = json :: parse ( message ); sendMessage ( msg . payload . token , msg . payload . message , msg . payload . recipients ); } // Handle the UpdateMessagesStatus message from the Engine void MyMessagingHandler::handleUpdateMessagesStatusMessage ( const std :: string & message ) { UpdateMessagesStatusMessage msg = json :: parse ( message ); updateMessagesStatus ( msg . payload . token , msg . payload . conversationId , msg . payload . status ); } // Handle the UploadConversations message from the Engine void MyMessagingHandler::handleUploadConversationsMessage ( const std :: string & message ) { UploadConversationsMessage msg = json :: parse ( message ); uploadConversations ( msg . payload . token ); } // To upload a conversations report to Alexa, publish a ConversationsReport message to the Engine void MyMessagingHandler::conversationsReport ( const std :: string & token , const std :: string & conversations ) { ConversationsReportMessage msg ; msg . payload . token = token ; msg . payload . conversations = conversations ; m_messageBroker -> publish ( msg . toString ()); } // When the message fails to send, publish a SendMessageFailed message to the Engine void MyMessagingHandler::sendMessageFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { SendMessageFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message is successfully sent, publish a SendMessageSucceeded message to the Engine void MyMessagingHandler::sendMessageSucceeded ( const std :: string & token ) { SendMessageSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update fails, publish a UpdateMessagesStatusFailed message to the Engine void MyMessagingHandler::updateMessagesStatusFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { UpdateMessagesStatusFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update succeeds, publish an UpdateMessagesStatusSucceeded message to the Engine void MyMessagingHandler::updateMessagesStatusSucceeded ( const std :: string & token ) { UpdateMessagesStatusSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // To update the messaging endpoint state, publish an UpdateMessagingEndpointState message to the Engine void MyMessagingHandler::updateMessagingEndpointState ( ConnectionState connectionState , PermissionState sendPermission , PermissionState readPermission ) { UpdateMessagingEndpointStateMessage msg ; msg . payload . connectionState = connectionState ; msg . payload . sendPermission = sendPermission ; msg . payload . readPermission = readPermission ; m_messageBroker -> publish ( msg . toString ()); } void MyMessagingHandler::sendMessage ( const std :: string & token , const std :: string & message , const std :: string & recipients ) { // Parse list of recipients to extract the phone number(s) // Send message using the connected messaging device // Send response of the result using the received token // If message was sent successfully then call sendMessageSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message sendMessageFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to send message\" ); } void MyMessagingHandler::updateMessagesStatus ( const std :: string & token , const std :: string & conversationId , const std :: string & status ) { // Remove unread messages specified in 'status' from the conversation that matches the 'conversationId' // Send response of the result using the received token // If messages status was updated successfully then call updateMessagesStatusSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message updateMessagesStatusFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to update message status\" ); } // Alexa is requesting that a conversation report is uploaded so it can sync up the // status of messages on the cloud void MyMessagingHandler::uploadConversations ( const std :: string & token ) { conversationsReport ( token , storedConversations ); } }; Android Integration \u00b6 Short Message Service (SMS) support is not yet available in the Alexa Auto Client Service (AACS). If you are interested in using the SMS capabilities of Alexa you are required to implement it independently using AASB Messages.","title":"Messaging Module"},{"location":"explore/features/messaging/#messaging-module","text":"","title":"Messaging Module"},{"location":"explore/features/messaging/#overview","text":"The Alexa Auto SDK Messaging module enables your Alexa Auto SDK client application to use the Short Message Service (SMS) capabilities of Alexa, independent of the messaging device's connection mechanism. The SMS features of this module include reading messages, sending messages, and replying to messages as they are read. The user must connect their device and consent to allow Alexa to read and send SMS messages through the messaging device. The Messaging feature can use phone numbers directly or use phone contacts uploaded via the Address Book module.","title":"Overview"},{"location":"explore/features/messaging/#managing-messaging-sessions","text":"The application is responsible for managing the life cycle of the messaging session, including enhancing the end user experience by: Uploading unread SMS messages when the messaging device is connected, so they are ready for readout. Uploading new SMS messages when they are received on the messaging device. Updating the status of messages when notified to do so. Responding to messaging requests with appropriate successful or failure responses. Alexa will not notify the user when new SMS messages are available, your implementation is responsible for providing new message notifications.","title":"Managing Messaging Sessions"},{"location":"explore/features/messaging/#configuring-the-messaging-module","text":"The Messaging module does not require Engine configuration.","title":"Configuring the Messaging Module"},{"location":"explore/features/messaging/#using-the-messaging-module-aasb-messages","text":"","title":"Using the Messaging Module AASB Messages"},{"location":"explore/features/messaging/#sending-messages","text":"When Alexa sends a request to the Engine to deliver a message, the Engine publishes the SendMessage message including the text and URL for the audio from which the message was created. Publish either the SendMessageSucceeded message or SendMessageFailed message indicating either the success or failure of the request. Click to expand or collapse sequence diagram: Sending Messages","title":"Sending Messages"},{"location":"explore/features/messaging/#reading-messages","text":"When a user requests for Alexa to read messages, your application's Messaging module integration must upload a conversation report containing all unread messages. Once Alexa requests a conversation report upload, the Engine publishes the UploadConversations message . Publish the ConversationsReport message to notify the Engine to upload a conversation report to the cloud. Note: Messages are grouped by conversation, each given a unique identifier. Conversations also have unique identifiers and contain the list of recipient phone numbers included in the conversation, but not the phone number of the messaging device. After Alexa reads a message, it notifies the application that the message was read and should exclude the read message in subsequent conversation report uploads. The Engine publishes the UpdateMessagesStatus message to update the status of the SMS messages. Publish either the UpdateMessagesStatusSucceeded message or UpdateMessageStatusFailed message indicating the success of the message status update. After Alexa reads all messages, or if message readout is interrupted, Alexa requests the upload of a new conversation report. In this way, Alexa stays in sync with unread messages on the messaging device. Note: Unread messages are stored in the cloud for 12 hours before being deleted. By design Alexa will read a limited number of unread messages with a 'read messages' utterance. Therefore, it may be necessary to issue additional read messages requests to head all messages. Click to expand or collapse sequence diagram: Reading Messages and Replying","title":"Reading Messages"},{"location":"explore/features/messaging/#replying-to-message","text":"The user can request to reply to a message after Alexa reads the message or as it is being read. Replying is always done within the context of the currently read message. Click to expand or collapse sequence diagram: Replying to Message","title":"Replying to Message"},{"location":"explore/features/messaging/#updating-messaging-endpoint-state","text":"When connection to a calling device is established or broken and/or the user grants or denies permissions to read and send messages, publish the UpdateMessagingEndpointState message to update Alexa with the state of the messaging device. Click to expand or collapse sequence diagram: Connecting/Disconnecting Calling Device Click to expand or collapse sequence diagram: Granting/Denying Permissions to Read and Send Messages","title":"Updating Messaging Endpoint State"},{"location":"explore/features/messaging/#integrating-the-messaging-module-into-your-application","text":"","title":"Integrating the Messaging Module Into Your Application"},{"location":"explore/features/messaging/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to subscribe to and publish \"Messaging\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Messaging/Messaging/ConnectionState.h> #include <AASB/Message/Messaging/Messaging/ErrorCode.h> #include <AASB/Message/Messaging/Messaging/PermissionState.h> #include <AASB/Message/Messaging/Messaging/ConversationsReportMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageFailedMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusFailedMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagingEndpointStateMessage.h> #include <AASB/Message/Messaging/Messaging/UploadConversationsMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyMessagingHandler { // Subscribe to messages from the Engine void MyMessagingHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendMessageMessage ( message ); }, SendMessageMessage :: topic (), SendMessageMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUpdateMessagesStatusMessage ( message ); }, UpdateMessagesStatusMessage :: topic (), UpdateMessagesStatusMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUploadConversationsMessage ( message ); }, UploadConversationsMessage :: topic (), UploadConversationsMessage :: action ()); } // Handle the SendMessage message from the Engine void MyMessagingHandler::handleSendMessageMessage ( const std :: string & message ) { SendMessageMessage msg = json :: parse ( message ); sendMessage ( msg . payload . token , msg . payload . message , msg . payload . recipients ); } // Handle the UpdateMessagesStatus message from the Engine void MyMessagingHandler::handleUpdateMessagesStatusMessage ( const std :: string & message ) { UpdateMessagesStatusMessage msg = json :: parse ( message ); updateMessagesStatus ( msg . payload . token , msg . payload . conversationId , msg . payload . status ); } // Handle the UploadConversations message from the Engine void MyMessagingHandler::handleUploadConversationsMessage ( const std :: string & message ) { UploadConversationsMessage msg = json :: parse ( message ); uploadConversations ( msg . payload . token ); } // To upload a conversations report to Alexa, publish a ConversationsReport message to the Engine void MyMessagingHandler::conversationsReport ( const std :: string & token , const std :: string & conversations ) { ConversationsReportMessage msg ; msg . payload . token = token ; msg . payload . conversations = conversations ; m_messageBroker -> publish ( msg . toString ()); } // When the message fails to send, publish a SendMessageFailed message to the Engine void MyMessagingHandler::sendMessageFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { SendMessageFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message is successfully sent, publish a SendMessageSucceeded message to the Engine void MyMessagingHandler::sendMessageSucceeded ( const std :: string & token ) { SendMessageSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update fails, publish a UpdateMessagesStatusFailed message to the Engine void MyMessagingHandler::updateMessagesStatusFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { UpdateMessagesStatusFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update succeeds, publish an UpdateMessagesStatusSucceeded message to the Engine void MyMessagingHandler::updateMessagesStatusSucceeded ( const std :: string & token ) { UpdateMessagesStatusSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // To update the messaging endpoint state, publish an UpdateMessagingEndpointState message to the Engine void MyMessagingHandler::updateMessagingEndpointState ( ConnectionState connectionState , PermissionState sendPermission , PermissionState readPermission ) { UpdateMessagingEndpointStateMessage msg ; msg . payload . connectionState = connectionState ; msg . payload . sendPermission = sendPermission ; msg . payload . readPermission = readPermission ; m_messageBroker -> publish ( msg . toString ()); } void MyMessagingHandler::sendMessage ( const std :: string & token , const std :: string & message , const std :: string & recipients ) { // Parse list of recipients to extract the phone number(s) // Send message using the connected messaging device // Send response of the result using the received token // If message was sent successfully then call sendMessageSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message sendMessageFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to send message\" ); } void MyMessagingHandler::updateMessagesStatus ( const std :: string & token , const std :: string & conversationId , const std :: string & status ) { // Remove unread messages specified in 'status' from the conversation that matches the 'conversationId' // Send response of the result using the received token // If messages status was updated successfully then call updateMessagesStatusSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message updateMessagesStatusFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to update message status\" ); } // Alexa is requesting that a conversation report is uploaded so it can sync up the // status of messages on the cloud void MyMessagingHandler::uploadConversations ( const std :: string & token ) { conversationsReport ( token , storedConversations ); } };","title":"C++ MessageBroker Integration"},{"location":"explore/features/messaging/#android-integration","text":"Short Message Service (SMS) support is not yet available in the Alexa Auto Client Service (AACS). If you are interested in using the SMS capabilities of Alexa you are required to implement it independently using AASB Messages.","title":"Android Integration"},{"location":"explore/features/navigation/","text":"Navigation Module \u00b6 Overview \u00b6 The Navigation module enables your Alexa Auto SDK client application to use the navigation capabilities of Alexa and provides support for Alexa to interface with the onboard navigation system. Your integration is responsible for handling navigation actions when notified to do so by the Engine. How these requests are handled is based on your navigation provider. Configuring the Navigation Module \u00b6 To inform Alexa which navigation provider is used on the head unit, configure the Navigation module. Sometimes Alexa needs to query a cloud navigation provider API to fulfill a user request. Knowing which provider is used on the device allows for better customer experience because Alexa's results can more closely match what the user sees on the screen in the navigation app. To configure the Navigation module, use the \"aace.navigation\" JSON object specified below in your Engine configuration: { \"aace.navigation\": { \"providerName\": \"{{STRING}}\" } } Property Type Required Description Example aace.navigation.providerName string No The navigation service provider name. Accepted values: \"HERE\" (default) \"TOMTOM\" \"TELENAV\" \"HERE\" Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::navigation::config::NavigationConfiguration::createNavigationConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse NavigationConfiguration C++ sample code #include <AACE/Navigation/NavigationConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto navigationConfig = aace :: navigation :: config :: NavigationConfiguration :: createNavigationConfig ( \"HERE\" ); configurations . push_back ( navigationConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Android Integration \u00b6 To use the Navigation module Engine configuration with AACS, use \"aacs.navigation\" instead of \"aace.navigation\" in your AACS configuration file: { \"aacs.navigation\": { \"providerName\": \"{{STRING}}\" } } Using the Navigation AASB Messages \u00b6 Providing the Current Navigation State \u00b6 The navigation state context informs Alexa whether the device is navigating and provides Alexa with the user's routing information or the destination set by the user. Such information is necessary for Alexa to respond to route-based utterances, allowing the user to use the following features: Adding or removing waypoints Obtaining Estimated Time of Arrival (ETA) Obtaining Distance To Arrival (DTA) When the user requests navigation information based on the current route, the Engine publishes the GetNavigationState message . The implementation should respond with the GetNavigationStateReply message containing the navigation state passed as a JSON string payload. Note: Returning the navigation state must be quick. If querying the navigation provider for state information takes significant time, Amazon recommends that the application periodically query the provider to update the state in a cache. Then the application can obtain the information each time the Engine requests the navigation state. The following table explains the properties in the JSON. Property Type Required Description state String Yes The navigation device state. Accepted values: \"NAVIGATING\" : Navigation engine is navigating to a predefined destination set. \"NOT_NAVIGATING\" : Navigation is not in progress. shapes Array of double arrays Yes The array contains an ordered list of coordinates depicting the route from the source to the destination. The coordinate is a latitude-longitude pair (in that order) specified as an array of doubles. The array can be empty. The maximum number of coordinates is 100. Special considerations: The set of coordinates might not represent the complete route. Shapes are provider specific. The shape of a route can correspond to one of these versions: a complete route, a route for a viewport, or a route defined for a certain distance. One mile spacing between each coordinate in the shapes array is recommended. The coordinates in the array are ordered in the same direction as the user is driving. waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. Expand the section below for more information. Note: Can be empty except when state is \"NAVIGATING\" . Click to expand or collapse the properties of waypoints object Property Type Required Description type String Yes Type of the location on the route. Accepted values: SOURCE : The location from which the user starts driving. DESTINATION : Final location to which the user wants to navigate to. INTERIM : Intermediate stop where the user wants to navigate to before reaching the destination. estimatedTimeOfArrival Object Yes (Applicable only if type is \"DESTINATION\" or \"INTERIM\" .) Time of arrival at the waypoint, specified in the ISO-8601 time format. estimatedTimeOfArrival.ideal String No Expected arrival time without considering traffic, diversions, etc. estimatedTimeOfArrival.predicted String Yes Expected arrival time, after considering traffic conditions. If the ideal ETA and predicted ETA match, only the predicted ETA will be populated. address Object No Address of the waypoint specified in multiple string fields, such as addressLine1 , city , etc. Note: countryCode is a 3-letter country code in ISO 3166-1 alpha-3 format. name String No Name of the waypoint (e.g., \"work\" or \"Starbucks\"). coordinate Array Yes An array consisting of the waypoint's latitude and longitude (in that order). The data type of latitude and longitude is double. pointOfInterest Object No Information about the waypoint if the waypoint is also a point of interest (POI). Expand the section below for more information. Click to expand or collapse the properties of pointOfInterest object Property Type Required Description id String No (recommended if available) ID for the POI known to Alexa. If id is provided, you can omit other properties of pointOfInterest . If the waypoint is added by the user via the navigation app, omit id because Alexa cannot recognize any ID assigned by the app. You can specify the ID if the waypoint is added by Alexa (e.g., by the utterance \"Alexa, navigate to Whole Foods along the way\"). It is specified in the StartNavigation message payload received from Alexa. hoursOfOperation Array No Hours of operation for the POI. hoursOfOperation.dayOfWeek String Y Day of week for this day. Accepted values: \"MONDAY\" , \"TUESDAY\" , \"WEDNESDAY\" , \"THURSDAY\" , \"FRIDAY\" , \"SATURDAY\" , \"SUNDAY\" . hoursOfOperation.hours Array Yes List of times when the POI is open or closed for the day, specified in ISO 8601 format with the timezone offset (time difference from UTC). Properties in the array are: open : Time at which the POI is open. close : Time at which the POI is closed. Timezone considerations: If the user and the POI are in different timezones, hours are converted to the timezone of the POI. If timezone offset is omitted, the time is assumed to be a UTC time and then converted to the POI's timezone. Note: Hours for the next 7 days are provided by the data provider. hoursOfOperation.type String Yes Status of the current operation. Accepted values: \"OPEN_DURING_HOURS\" , \"OPEN_24_HOURS\" , \"CLOSED\" , \"UNKNOWN\" , \"HOLIDAY\" . phoneNumber String No Phone number of the POI in E.164 format. Examples of Navigation State Payload \u00b6 Click to expand or collapse example Navigation State payload when navigation is in progress { \"state\" : \"NAVIGATING\" , \"waypoints\" : [ { \"type\" : \"SOURCE\" , \"address\" : { \"addressLine1\" : \"2795 Augustine Drive\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Santa Clara\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"95054\" }, \"name\" : \"work\" , \"coordinate\" : [ 37.3809462 , -121.9794846 ] }, { \"type\" : \"INTERIM\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:00:00-08:00\" , \"predicted\" : \"2019-12-09T17:10:00-08:00\" }, \"address\" : { \"addressLine1\" : \"750 Castro Street\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Mountain View\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"94041\" }, \"name\" : \"Starbucks\" , \"coordinate\" : [ 37.3809461 , -122.0830221 ], \"pointOfInterest\" : { \"id\" : \"AlexaLocalSearch:eyJpZCI6InllbHA6OnRGV01ySS1VWERGa09FcnZ6eXJ0clEiLCJjb3ZlcnMiOnsiUExBQ0VTX1JFUE8iOiJ5ZWxwOjp0RldNckktVVhERmtPRXJ2enlydHJRIn0sInF1ZXJ5SWQiOiItNjYxMzI1NTYxIiwiZGRiVGFibGVOYW1lIjoiZXMtbHNzLTIwMjEwNjE2Iiwid2VibGFiQWxsb2NhdGlvbnMiOnsiQUxTU19XRUJMQUJfT05CT0FSRF9URVNUSU5HXzI4MDI4NiI6IlQxIiwiQUxFWEFfTE9DQUxTRUFSQ0hfUExBQ0VUWVBFX0NMQVNTSUZJRVJfMzA4MTY5IjoiQyIsIkFMRVhBX0xPQ0FMX1NFQVJDSF9MMlJfRU5USVRZX1NIQURPV18yOTA5MDUiOiJDIiwiQUxFWEFfTE9DQUxfU0VBUkNIX1RSSUdHRVJfQU1CSUdVT1VTX1FVRVJZX0lERU5USUZJQ0FUSU9OXzMyNjMxNSI6IlQxIn19\" , \"phoneNumber\" : \"+14084968523\" } }, { \"type\" : \"DESTINATION\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:30:00-08:00\" , \"predicted\" : \"2019-12-09T17:40:00-08:00\" }, \"address\" : { \"addressLine1\" : \"4800 El Camino Real\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Los Altos\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"\" , \"postalCode\" : \"94022\" }, \"name\" : \"Whole Foods Market\" , \"coordinate\" : [ 37.3991897 , -122.1106268 ], \"pointOfInterest\" : { \"hoursOfOperation\" : [ { \"dayOfWeek\" : \"MONDAY\" , \"hours\" : [ { \"open\" : \"08:00:00-08:00\" , \"close\" : \"22:00:00-08:00\" } ], \"type\" : \"OPEN_DURING_HOURS\" } ] } } ], \"shapes\" : [ [ 37.380946 , -121.9794846 ], [ 37.380545 , -122.073252 ], ... ] } Click to expand or collapse example Navigation State payload when navigation no navigation is in progress { \"state\" : \"NOT_NAVIGATING\" , \"waypoints\" :[], \"shapes\" :[] } Starting Navigation \u00b6 To start navigation, the Engine publishes the StartNavigation message passing a JSON string payload containing the destination information. The following table explains the properties in the JSON. Property Type Required Description transportationMode String No The mode of transportation. Accepted Values: \"BIKING\" \"DRIVING\" \"TRANSIT\" \"WALKING\" waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. The properties use the same schema used for state reporting. See the Providing the Current Navigation State section. Click to expand or collapse the StartNavigation message payload schema { \"transportationMode\": \"DRIVING\", \"waypoints\":[ { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\" }, { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\":\"{{STRING}}\", \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\", \"pointOfInterest\":{ \"id\":\"{{STRING}}\", \"hoursOfOperation\":[ { \"dayOfWeek\":\"{{STRING}}\", \"hours\":[ { \"open\":\"{{STRING}}\", \"close\":\"{{STRING}}\" } ], \"type\":\"{{STRING}}\" } ], \"phoneNumber\":\"{{STRING}}\" } } ] } } Note: The waypoints in the route are determined by Alexa either through a proximity search or by resolving the user's uploaded navigation favorite name to its location. Your implementation should calculate the route from the SOURCE waypoint to the DESTINATION waypoint, with stops along the way at INTERIM waypoints in the order in which they appear in the payload. If there are multiple routes, your implementation should either pick the fastest route if no user interaction is possible, or let the user choose the route. After the route is chosen, your implementation should start navigation. If navigation starts successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Starting Navigation Stopping Navigation \u00b6 To stop navigation, the Engine publishes the CancelNavigation message . Consequently, when the Engine publishes the next GetNavigationState message the state should be NOT_NAVIGATING . Click to expand or collapse sequence diagram: Stopping Navigation Adding a Waypoint \u00b6 If the user wants to add a waypoint, the Engine publishes the StartNavigation message . If navigation is in progress or route is present, the route to the final destination is changed by including the additional waypoint. Your implementation should calculate or re-calculate the route with the information of the waypoint. If the waypoint is added successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Adding a Waypoint Canceling a Waypoint \u00b6 If the user wants to cancel a waypoint, the Engine publishes the StartNavigation message after receiving the directive from Alexa with the updated waypoints. Your implementation should start navigation using the updated waypoints. If navigation is started successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Canceling a Waypoint Showing Previous Waypoints \u00b6 If the user wants to display previous waypoints, the Engine publishes the ShowPreviousWaypoints message . Each waypoint displayed includes at least the address. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_WAYPOINTS_SHOWN event. Otherwise, it should publish the NavigationError message with the SHOW_PREVIOUS_WAYPOINTS_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Note: It is the responsibility of the navigation provider to store and provide the previous destination list to the user. Click to expand or collapse sequence diagram: Showing Previous Waypoints Navigating to a Previous Waypoint \u00b6 If the user wants to navigate to a previous waypoint, the Engine publishes the NavigateToPreviousWaypoint message . The navigation app retrieves the most recently used destination, calculates a route from the current location, selects the fastest route or a route preferred by the user, and starts navigation. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the PREVIOUS_NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Click to expand or collapse sequence diagram: Navigating to a Previous Waypoint Getting Turn and Lane Guidance Information \u00b6 If the user wants to get turn and lane guidance, the Engine publishes the AnnounceManeuver message , passing a JSON string payload containing the manueuver information. The following table explains the properties in the JSON. Property Type Required Description type String Yes Specifies the type of information requested. Accepted values: \"TURN\" : The user asks about a turn. (e.g., \"What's my next turn?\") \"EXIT\" : The user asks about a freeway exit. (e.g., \"What's my next exit?\") \"ENTER\" : The user asks about how to get onto a street. (e.g., \"Which lane should I be to get onto the US-101?\") \"MERGE\" : The user asks about the merge onto a street. (e.g., \"Alexa, which lane do i need to merge onto the highway?\") \"LANE\" : The user asks for lane guidance. (e.g., \"Alexa, which lane to take?\") targetLocation Object No Describes the location for which maneuver information is requested. If the target location is a POI, user place, or street address, Alexa provides at least one field in this object. If the utterance does not include a location (e.g., \"Alexa, what's my next turn?\"), targetLocation is omitted. targetLocation.name String No Specifies the name of the location (e.g., \"HOME\" or \"WORK\") for which the user requests the maneuver instruction. targetLocation.address Object No Specifies the address for which the user requests the maneuver instruction. The object contains multiple string fields, which together form the complete address. targetLocation.coordinate Array No The array value specifies the latitude and longitude of the target location. Data type for the values in the array is double. Click to expand or collapse the AnnounceManeuver message schema { \"type\": \"{{STRING}}\", \"targetLocation\" : { \"name\": \"{{STRING}}\", \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\": [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ] } } Your implementation should provide the navigation instruction as follows: If targetLocation is omitted, announce the next maneuver along the route. If targetLocation is specified and the location is along the route, announce the maneuver about the location. If targetLocation is specified but the location is not along the route, calculate the route to the location, announce maneuver from the user's current location to the target location, and inform the user the target location is NOT along the current route. If the device can provide the maneuver instruction successfully, your implementation should publish the NavigationEvent message with one of the following events: events: TURN_GUIDANCE_ANNOUNCED , EXIT_GUIDANCE_ANNOUNCED , ENTER_GUIDANCE_ANNOUNCED , MERGE_GUIDANCE_ANNOUNCED , LANE_GUIDANCE_ANNOUNCED Otherwise, your implementation should publish the NavigationError message with a type and code from the following: types: TURN_GUIDANCE_FAILED , EXIT_GUIDANCE_FAILED , ENTER_GUIDANCE_FAILED , MERGE_GUIDANCE_FAILED , LANE_GUIDANCE_FAILED codes: INTERNAL_SERVICE_ERROR , ROUTE_NOT_FOUND , NOT_SUPPORTED , NOT_NAVIGATING Click to expand or collapse sequence diagram: Getting Turn and Lane Guidance Information Getting Road Regulation Information \u00b6 If the user wants to get road regulation information, the Engine publishes the AnnounceRoadRegulation message , which passes a payload with the following schema: { \"type\": \"{{STRING}}\" } Property Type Required Description type String Yes Type of road regulation requested. Accepted values: \"SPEED_LIMIT\" specifies the speed limit at the current position (e.g., when the user asks, \"Alexa, what is the speed limit?\"). \"CARPOOL_RULES\" specifies the carpool regulations on the current highway (e.g., when the user asks, \"Alexa, is carpool free now?\"). If the device can provide the road regulation information successfully, your implementation should publish the NavigationEvent message with a SPEED_LIMIT_REGULATION_ANNOUNCED or CARPOOL_RULES_REGULATION_ANNOUNCED event. Otherwise, it should publish the NavigationError message with a type and code from the following: types: SPEED_LIMIT_REGULATION_FAILED , CARPOOL_RULES_REGULATION_FAILED codes: INTERNAL_SERVICE_ERROR , ROUTE_NOT_FOUND , NOT_SUPPORTED , NOT_NAVIGATING Click to expand or collapse sequence diagram: Getting Road Regulation Information Controlling the Display \u00b6 If the user wants to control the map display on the screen, the Engine publishes the ControlDisplay message . If the device can adjust the display successfully, your implementation should publish the NavigationEvent message with one of the following event: events: ROUTE_OVERVIEW_SHOWN , DIRECTIONS_LIST_SHOWN , ZOOMED_IN , ZOOMED_OUT , MAP_CENTERED , ORIENTED_NORTH , SCROLLED_NORTH , SCROLLED_UP , SCROLLED_EAST , SCROLLED_RIGHT , SCROLLED_SOUTH , SCROLLED_DOWN , SCROLLED_WEST , SCROLLED_LEFT , ROUTE_GUIDANCE_MUTED , ROUTE_GUIDANCE_UNMUTED Otherwise, your implementation should publish the NavigationError message with a type and code from the following: types: ROUTE_OVERVIEW_FAILED , DIRECTIONS_LIST_FAILED , ZOOMED_IN_FAILED , ZOOMED_OUT_FAILED , MAP_CENTERED_FAILED , ORIENTED_NORTH_FAILED , SCROLLED_NORTH_FAILED , SCROLLED_UP_FAILED , SCROLLED_EAST_FAILED , SCROLLED_RIGHT_FAILED , SCROLLED_SOUTH_FAILED , SCROLLED_DOWN_FAILED , SCROLLED_WEST_FAILED , SCROLLED_LEFT_FAILED , ROUTE_GUIDANCE_MUTED_FAILED , ROUTE_GUIDANCE_UNMUTED_FAILED codes: INTERNAL_SERVICE_ERROR , NOT_NAVIGATING , NOT_SUPPORTED , NOT_ALLOWED Click to expand or collapse sequence diagram: Controlling the Display Showing Alternative Routes \u00b6 If the user wants to display alternative routes, the Engine publishes the ShowAlternativeRoutes message , which passes the type of alternate route to be displayed. If the device can display the alternative route successfully, your implementation should publish the ShowAlternativeRoutesSucceeded message with a payload containing information about the alternative route. The following table explains the properties in the JSON. Property Type Required Description inquiryType String Yes The type of alternative routes based on the user's preference. Accepted values: \"DEFAULT\" , which means there is no preference as to whether the alternate route saves time or distance. \"SHORTER_TIME\" , which means the alternate route saves time. \"SHORTER_DISTANCE\" , which means the alternate route saves distance. alternateRoute Object Yes Information about the best route that matches the preference specified by inquiryType . alternateRoute.labels Array of strings Yes Unique names within a route (e.g., names of highways) used to distinguish between alternative routes. Each label might contain the direction of the route. alternateRoute.savings Array No List of savings achieved by the route. alternateRoute.savings.type String Yes The type of savings. Accepted values: \"DISTANCE\" or \"TIME\" . alternateRoute.savings.amount Float Yes The amount of savings achieved by the route. Alexa uses prescribed unit to convert the amount of savings to improve user experience, if needed. alternateRoute.savings.unit String Yes Measurement unit of the savings. Accepted values: \"MINUTE\" , \"HOUR\" , \"YARD\" , \"FOOT\" , \"MILE\" , \"METER\" , or \"KILOMETER\" . Click to expand or collapse the ShowAlternativeRoutesSucceeded message schema { \"inquiryType\": \"{{STRING}}\", \"alternateRoute\": { \"labels\": [\"{{STRING}}\"], \"savings\": [ { \"type\": \"{{STRING}}\", \"amount\": {{FLOAT}}, \"unit\": \"{{STRING}}\" } ] } } Otherwise, your implementation should publish the NavigationError message with a type and code from the following: types: DEFAULT_ALTERNATE_ROUTES_FAILED , SHORTER_TIME_ROUTES_FAILED , SHORTER_DISTANCE_ROUTES_FAILED codes: INTERNAL_SERVICE_ERROR , ROUTE_NOT_FOUND , NOT_SUPPORTED , NOT_NAVIGATING Click to expand or collapse sequence diagram: Showing Alternative Routes Integrating the Navigation Module Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the Engine's MessageBroker to subscribe to and publish \"Navigation\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Navigation/Navigation/AlternateRouteType.h> #include <AASB/Message/Navigation/Navigation/ControlDisplay.h> #include <AASB/Message/Navigation/Navigation/ErrorCode.h> #include <AASB/Message/Navigation/Navigation/ErrorType.h> #include <AASB/Message/Navigation/Navigation/EventName.h> #include <AASB/Message/Navigation/Navigation/RoadRegulation.h> #include <AASB/Message/Navigation/Navigation/AnnounceManeuverMessage.h> #include <AASB/Message/Navigation/Navigation/AnnounceRoadRegulationMessage.h> #include <AASB/Message/Navigation/Navigation/CancelNavigationMessage.h> #include <AASB/Message/Navigation/Navigation/ControlDisplayMessage.h> #include <AASB/Message/Navigation/Navigation/GetNavigationStateMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationErrorMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationEventMessage.h> #include <AASB/Message/Navigation/Navigation/NavigateToPreviousWaypointMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesSucceededMessage.h> #include <AASB/Message/Navigation/Navigation/ShowPreviousWaypointsMessage.h> #include <AASB/Message/Navigation/Navigation/StartNavigationMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyNavigationHandler { void MyNavigationHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceManeuverMessage ( message ); }, AnnounceManeuverMessage :: topic (), AnnounceManeuverMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceRoadRegulationMessage ( message ); }, AnnounceRoadRegulationMessage :: topic (), AnnounceRoadRegulationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCancelNavigationMessage ( message ); }, CancelNavigationMessage :: topic (), CancelNavigationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleControlDisplayMessage ( message ); }, ControlDisplayMessage :: topic (), ControlDisplayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNavigationStateMessage ( message ); }, GetNavigationStateMessage :: topic (), GetNavigationStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleNavigateToPreviousWaypointMessage ( message ); }, NavigateToPreviousWaypointMessage :: topic (), NavigateToPreviousWaypointMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowAlternativeRoutesMessage ( message ); }, ShowAlternativeRoutesMessage :: topic (), ShowAlternativeRoutesMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowPreviousWaypointsMessage ( message ); }, ShowPreviousWaypointsMessage :: topic (), ShowPreviousWaypointsMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartNavigationMessage ( message ); }, StartNavigationMessage :: topic (), StartNavigationMessage :: action ()); } // Handle the AnnounceManeuver message from the Engine void MyNavigationHandler::handleAnnounceManeuverMessage ( const std :: string & message ) { AnnounceManeuverMessage msg = json :: parse ( message ); announceManeuver ( msg . payload . payload ); } // Handle the AnnounceRoadRegulation message from the Engine void MyNavigationHandler::handleAnnounceRoadRegulationMessage ( const std :: string & message ) { AnnounceRoadRegulationMessage msg = json :: parse ( message ); announceRoadRegulation ( msg . payload . roadRegulation ); } // Handle the CancelNavigation message from the Engine void MyNavigationHandler::handleCancelNavigationMessage ( const std :: string & message ) { cancelNavigation (); } // Handle the ControlDisplay message from the Engine void MyNavigationHandler::handleControlDisplayMessage ( const std :: string & message ) { ControlDisplayMessage msg = json :: parse ( message ); controlDisplay ( msg . payload . controlDisplay ); } // Handle the GetNavigationState message from the Engine and publish the // reply message containing the current navigation state void MyNavigationHandler::handleGetNavigationStateMessage ( const std :: string & message ) { GetNavigationStateMessage msg = json :: parse ( message ); GetNavigationStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . navigationState = getNavigationState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the NavigateToPreviousWaypoint message from the Engine void MyNavigationHandler::handleNavigateToPreviousWaypointMessage ( const std :: string & message ) { navigateToPreviousWaypoint (); } // Handle the ShowAlternativeRoutes message from the Engine void MyNavigationHandler::handleShowAlternativeRoutesMessage ( const std :: string & message ) { ShowAlternativeRoutesMessage msg = json :: parse ( message ); showAlternativeRoutes ( msg . payload . alternateRouteType ); } // Handle the ShowPreviousWaypoints message from the Engine void MyNavigationHandler::handleShowPreviousWaypointsMessage ( const std :: string & message ) { showPreviousWaypoints (); } // Handle the StartNavigation message from the Engine void MyNavigationHandler::handleStartNavigationMessage ( const std :: string & message ) { StartNavigationMessage msg = json :: parse ( message ); startNavigation ( msg . payload . payload ); } void MyNavigationHandler::navigationError ( ErrorType type , ErrorCode code , const std :: string & description ) { NavigationErrorMessage msg ; msg . payload . type = type ; msg . payload . code = code ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::navigationEvent ( EventName event ) { NavigationEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::showAlternativeRoutesSucceeded ( const std :: string & payload ) { ShowAlternativeRoutesSucceededMessage msg ; msg . payload . payload = payload ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::startNavigation ( const std :: string & payload ) { // Update the previous destinations list // Call navigationEvent(EventName::NAVIGATION_STARTED) // If error occurs call navigationError() with ErrorType::NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void MyNavigationHandler::navigateToPreviousWaypoint () { // Call navigationEvent(EventName::PREVIOUS_NAVIGATION_STARTED) // If any error occurs call navigationError() with ErrorType::PREVIOUS_NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showPreviousWaypoints () { // Call navigationEvent(EventName::PREVIOUS_WAYPOINTS_SHOWN) // If error occurs call navigationError() with ErrorType::SHOW_PREVIOUS_WAYPOINTS_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showAlternativeRoutes ( AlternateRouteType alternateRouteType ) { // Based on the AlternativeRouteType obtain the alternative route information // Call showAlternativeRoutesSucceeded() // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::controlDisplay ( ControlDisplay controlDisplay ) { // Call navigationEvent() for the requested map control request // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceManeuver ( const std :: string & payload ) { // Call navigationEvent() for the requested manueuver instruction // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceRoadRegulation ( RoadRegulation roadRegulation ) { // Call navigationEvent() for the requested road regulation // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } bool NavigationHandler::cancelNavigation () { // Clear the navigation state } std :: string NavigationHandler::getNavigationState () { // Return current navigation state } }; Android Integration \u00b6 The Alexa Auto Client Service (AACS) provides the Navigation App Component to integrate the Auto SDK Navigation module on Android. See the AACS Navigation App Component documentation for more information.","title":"Navigation Module"},{"location":"explore/features/navigation/#navigation-module","text":"","title":"Navigation Module"},{"location":"explore/features/navigation/#overview","text":"The Navigation module enables your Alexa Auto SDK client application to use the navigation capabilities of Alexa and provides support for Alexa to interface with the onboard navigation system. Your integration is responsible for handling navigation actions when notified to do so by the Engine. How these requests are handled is based on your navigation provider.","title":"Overview"},{"location":"explore/features/navigation/#configuring-the-navigation-module","text":"To inform Alexa which navigation provider is used on the head unit, configure the Navigation module. Sometimes Alexa needs to query a cloud navigation provider API to fulfill a user request. Knowing which provider is used on the device allows for better customer experience because Alexa's results can more closely match what the user sees on the screen in the navigation app. To configure the Navigation module, use the \"aace.navigation\" JSON object specified below in your Engine configuration: { \"aace.navigation\": { \"providerName\": \"{{STRING}}\" } } Property Type Required Description Example aace.navigation.providerName string No The navigation service provider name. Accepted values: \"HERE\" (default) \"TOMTOM\" \"TELENAV\" \"HERE\" Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::navigation::config::NavigationConfiguration::createNavigationConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse NavigationConfiguration C++ sample code #include <AACE/Navigation/NavigationConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto navigationConfig = aace :: navigation :: config :: NavigationConfiguration :: createNavigationConfig ( \"HERE\" ); configurations . push_back ( navigationConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations );","title":"Configuring the Navigation Module"},{"location":"explore/features/navigation/#android-integration","text":"To use the Navigation module Engine configuration with AACS, use \"aacs.navigation\" instead of \"aace.navigation\" in your AACS configuration file: { \"aacs.navigation\": { \"providerName\": \"{{STRING}}\" } }","title":"Android Integration"},{"location":"explore/features/navigation/#using-the-navigation-aasb-messages","text":"","title":"Using the Navigation AASB Messages"},{"location":"explore/features/navigation/#providing-the-current-navigation-state","text":"The navigation state context informs Alexa whether the device is navigating and provides Alexa with the user's routing information or the destination set by the user. Such information is necessary for Alexa to respond to route-based utterances, allowing the user to use the following features: Adding or removing waypoints Obtaining Estimated Time of Arrival (ETA) Obtaining Distance To Arrival (DTA) When the user requests navigation information based on the current route, the Engine publishes the GetNavigationState message . The implementation should respond with the GetNavigationStateReply message containing the navigation state passed as a JSON string payload. Note: Returning the navigation state must be quick. If querying the navigation provider for state information takes significant time, Amazon recommends that the application periodically query the provider to update the state in a cache. Then the application can obtain the information each time the Engine requests the navigation state. The following table explains the properties in the JSON. Property Type Required Description state String Yes The navigation device state. Accepted values: \"NAVIGATING\" : Navigation engine is navigating to a predefined destination set. \"NOT_NAVIGATING\" : Navigation is not in progress. shapes Array of double arrays Yes The array contains an ordered list of coordinates depicting the route from the source to the destination. The coordinate is a latitude-longitude pair (in that order) specified as an array of doubles. The array can be empty. The maximum number of coordinates is 100. Special considerations: The set of coordinates might not represent the complete route. Shapes are provider specific. The shape of a route can correspond to one of these versions: a complete route, a route for a viewport, or a route defined for a certain distance. One mile spacing between each coordinate in the shapes array is recommended. The coordinates in the array are ordered in the same direction as the user is driving. waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. Expand the section below for more information. Note: Can be empty except when state is \"NAVIGATING\" . Click to expand or collapse the properties of waypoints object Property Type Required Description type String Yes Type of the location on the route. Accepted values: SOURCE : The location from which the user starts driving. DESTINATION : Final location to which the user wants to navigate to. INTERIM : Intermediate stop where the user wants to navigate to before reaching the destination. estimatedTimeOfArrival Object Yes (Applicable only if type is \"DESTINATION\" or \"INTERIM\" .) Time of arrival at the waypoint, specified in the ISO-8601 time format. estimatedTimeOfArrival.ideal String No Expected arrival time without considering traffic, diversions, etc. estimatedTimeOfArrival.predicted String Yes Expected arrival time, after considering traffic conditions. If the ideal ETA and predicted ETA match, only the predicted ETA will be populated. address Object No Address of the waypoint specified in multiple string fields, such as addressLine1 , city , etc. Note: countryCode is a 3-letter country code in ISO 3166-1 alpha-3 format. name String No Name of the waypoint (e.g., \"work\" or \"Starbucks\"). coordinate Array Yes An array consisting of the waypoint's latitude and longitude (in that order). The data type of latitude and longitude is double. pointOfInterest Object No Information about the waypoint if the waypoint is also a point of interest (POI). Expand the section below for more information. Click to expand or collapse the properties of pointOfInterest object Property Type Required Description id String No (recommended if available) ID for the POI known to Alexa. If id is provided, you can omit other properties of pointOfInterest . If the waypoint is added by the user via the navigation app, omit id because Alexa cannot recognize any ID assigned by the app. You can specify the ID if the waypoint is added by Alexa (e.g., by the utterance \"Alexa, navigate to Whole Foods along the way\"). It is specified in the StartNavigation message payload received from Alexa. hoursOfOperation Array No Hours of operation for the POI. hoursOfOperation.dayOfWeek String Y Day of week for this day. Accepted values: \"MONDAY\" , \"TUESDAY\" , \"WEDNESDAY\" , \"THURSDAY\" , \"FRIDAY\" , \"SATURDAY\" , \"SUNDAY\" . hoursOfOperation.hours Array Yes List of times when the POI is open or closed for the day, specified in ISO 8601 format with the timezone offset (time difference from UTC). Properties in the array are: open : Time at which the POI is open. close : Time at which the POI is closed. Timezone considerations: If the user and the POI are in different timezones, hours are converted to the timezone of the POI. If timezone offset is omitted, the time is assumed to be a UTC time and then converted to the POI's timezone. Note: Hours for the next 7 days are provided by the data provider. hoursOfOperation.type String Yes Status of the current operation. Accepted values: \"OPEN_DURING_HOURS\" , \"OPEN_24_HOURS\" , \"CLOSED\" , \"UNKNOWN\" , \"HOLIDAY\" . phoneNumber String No Phone number of the POI in E.164 format.","title":"Providing the Current Navigation State"},{"location":"explore/features/navigation/#examples-of-navigation-state-payload","text":"Click to expand or collapse example Navigation State payload when navigation is in progress { \"state\" : \"NAVIGATING\" , \"waypoints\" : [ { \"type\" : \"SOURCE\" , \"address\" : { \"addressLine1\" : \"2795 Augustine Drive\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Santa Clara\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"95054\" }, \"name\" : \"work\" , \"coordinate\" : [ 37.3809462 , -121.9794846 ] }, { \"type\" : \"INTERIM\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:00:00-08:00\" , \"predicted\" : \"2019-12-09T17:10:00-08:00\" }, \"address\" : { \"addressLine1\" : \"750 Castro Street\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Mountain View\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"94041\" }, \"name\" : \"Starbucks\" , \"coordinate\" : [ 37.3809461 , -122.0830221 ], \"pointOfInterest\" : { \"id\" : \"AlexaLocalSearch:eyJpZCI6InllbHA6OnRGV01ySS1VWERGa09FcnZ6eXJ0clEiLCJjb3ZlcnMiOnsiUExBQ0VTX1JFUE8iOiJ5ZWxwOjp0RldNckktVVhERmtPRXJ2enlydHJRIn0sInF1ZXJ5SWQiOiItNjYxMzI1NTYxIiwiZGRiVGFibGVOYW1lIjoiZXMtbHNzLTIwMjEwNjE2Iiwid2VibGFiQWxsb2NhdGlvbnMiOnsiQUxTU19XRUJMQUJfT05CT0FSRF9URVNUSU5HXzI4MDI4NiI6IlQxIiwiQUxFWEFfTE9DQUxTRUFSQ0hfUExBQ0VUWVBFX0NMQVNTSUZJRVJfMzA4MTY5IjoiQyIsIkFMRVhBX0xPQ0FMX1NFQVJDSF9MMlJfRU5USVRZX1NIQURPV18yOTA5MDUiOiJDIiwiQUxFWEFfTE9DQUxfU0VBUkNIX1RSSUdHRVJfQU1CSUdVT1VTX1FVRVJZX0lERU5USUZJQ0FUSU9OXzMyNjMxNSI6IlQxIn19\" , \"phoneNumber\" : \"+14084968523\" } }, { \"type\" : \"DESTINATION\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:30:00-08:00\" , \"predicted\" : \"2019-12-09T17:40:00-08:00\" }, \"address\" : { \"addressLine1\" : \"4800 El Camino Real\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Los Altos\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"\" , \"postalCode\" : \"94022\" }, \"name\" : \"Whole Foods Market\" , \"coordinate\" : [ 37.3991897 , -122.1106268 ], \"pointOfInterest\" : { \"hoursOfOperation\" : [ { \"dayOfWeek\" : \"MONDAY\" , \"hours\" : [ { \"open\" : \"08:00:00-08:00\" , \"close\" : \"22:00:00-08:00\" } ], \"type\" : \"OPEN_DURING_HOURS\" } ] } } ], \"shapes\" : [ [ 37.380946 , -121.9794846 ], [ 37.380545 , -122.073252 ], ... ] } Click to expand or collapse example Navigation State payload when navigation no navigation is in progress { \"state\" : \"NOT_NAVIGATING\" , \"waypoints\" :[], \"shapes\" :[] }","title":"Examples of Navigation State Payload"},{"location":"explore/features/navigation/#starting-navigation","text":"To start navigation, the Engine publishes the StartNavigation message passing a JSON string payload containing the destination information. The following table explains the properties in the JSON. Property Type Required Description transportationMode String No The mode of transportation. Accepted Values: \"BIKING\" \"DRIVING\" \"TRANSIT\" \"WALKING\" waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. The properties use the same schema used for state reporting. See the Providing the Current Navigation State section. Click to expand or collapse the StartNavigation message payload schema { \"transportationMode\": \"DRIVING\", \"waypoints\":[ { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\" }, { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\":\"{{STRING}}\", \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\", \"pointOfInterest\":{ \"id\":\"{{STRING}}\", \"hoursOfOperation\":[ { \"dayOfWeek\":\"{{STRING}}\", \"hours\":[ { \"open\":\"{{STRING}}\", \"close\":\"{{STRING}}\" } ], \"type\":\"{{STRING}}\" } ], \"phoneNumber\":\"{{STRING}}\" } } ] } } Note: The waypoints in the route are determined by Alexa either through a proximity search or by resolving the user's uploaded navigation favorite name to its location. Your implementation should calculate the route from the SOURCE waypoint to the DESTINATION waypoint, with stops along the way at INTERIM waypoints in the order in which they appear in the payload. If there are multiple routes, your implementation should either pick the fastest route if no user interaction is possible, or let the user choose the route. After the route is chosen, your implementation should start navigation. If navigation starts successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Starting Navigation","title":"Starting Navigation"},{"location":"explore/features/navigation/#stopping-navigation","text":"To stop navigation, the Engine publishes the CancelNavigation message . Consequently, when the Engine publishes the next GetNavigationState message the state should be NOT_NAVIGATING . Click to expand or collapse sequence diagram: Stopping Navigation","title":"Stopping Navigation"},{"location":"explore/features/navigation/#adding-a-waypoint","text":"If the user wants to add a waypoint, the Engine publishes the StartNavigation message . If navigation is in progress or route is present, the route to the final destination is changed by including the additional waypoint. Your implementation should calculate or re-calculate the route with the information of the waypoint. If the waypoint is added successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Adding a Waypoint","title":"Adding a Waypoint"},{"location":"explore/features/navigation/#canceling-a-waypoint","text":"If the user wants to cancel a waypoint, the Engine publishes the StartNavigation message after receiving the directive from Alexa with the updated waypoints. Your implementation should start navigation using the updated waypoints. If navigation is started successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Canceling a Waypoint","title":"Canceling a Waypoint"},{"location":"explore/features/navigation/#showing-previous-waypoints","text":"If the user wants to display previous waypoints, the Engine publishes the ShowPreviousWaypoints message . Each waypoint displayed includes at least the address. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_WAYPOINTS_SHOWN event. Otherwise, it should publish the NavigationError message with the SHOW_PREVIOUS_WAYPOINTS_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Note: It is the responsibility of the navigation provider to store and provide the previous destination list to the user. Click to expand or collapse sequence diagram: Showing Previous Waypoints","title":"Showing Previous Waypoints"},{"location":"explore/features/navigation/#navigating-to-a-previous-waypoint","text":"If the user wants to navigate to a previous waypoint, the Engine publishes the NavigateToPreviousWaypoint message . The navigation app retrieves the most recently used destination, calculates a route from the current location, selects the fastest route or a route preferred by the user, and starts navigation. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the PREVIOUS_NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Click to expand or collapse sequence diagram: Navigating to a Previous Waypoint","title":"Navigating to a Previous Waypoint"},{"location":"explore/features/navigation/#getting-turn-and-lane-guidance-information","text":"If the user wants to get turn and lane guidance, the Engine publishes the AnnounceManeuver message , passing a JSON string payload containing the manueuver information. The following table explains the properties in the JSON. Property Type Required Description type String Yes Specifies the type of information requested. Accepted values: \"TURN\" : The user asks about a turn. (e.g., \"What's my next turn?\") \"EXIT\" : The user asks about a freeway exit. (e.g., \"What's my next exit?\") \"ENTER\" : The user asks about how to get onto a street. (e.g., \"Which lane should I be to get onto the US-101?\") \"MERGE\" : The user asks about the merge onto a street. (e.g., \"Alexa, which lane do i need to merge onto the highway?\") \"LANE\" : The user asks for lane guidance. (e.g., \"Alexa, which lane to take?\") targetLocation Object No Describes the location for which maneuver information is requested. If the target location is a POI, user place, or street address, Alexa provides at least one field in this object. If the utterance does not include a location (e.g., \"Alexa, what's my next turn?\"), targetLocation is omitted. targetLocation.name String No Specifies the name of the location (e.g., \"HOME\" or \"WORK\") for which the user requests the maneuver instruction. targetLocation.address Object No Specifies the address for which the user requests the maneuver instruction. The object contains multiple string fields, which together form the complete address. targetLocation.coordinate Array No The array value specifies the latitude and longitude of the target location. Data type for the values in the array is double. Click to expand or collapse the AnnounceManeuver message schema { \"type\": \"{{STRING}}\", \"targetLocation\" : { \"name\": \"{{STRING}}\", \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\": [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ] } } Your implementation should provide the navigation instruction as follows: If targetLocation is omitted, announce the next maneuver along the route. If targetLocation is specified and the location is along the route, announce the maneuver about the location. If targetLocation is specified but the location is not along the route, calculate the route to the location, announce maneuver from the user's current location to the target location, and inform the user the target location is NOT along the current route. If the device can provide the maneuver instruction successfully, your implementation should publish the NavigationEvent message with one of the following events: events: TURN_GUIDANCE_ANNOUNCED , EXIT_GUIDANCE_ANNOUNCED , ENTER_GUIDANCE_ANNOUNCED , MERGE_GUIDANCE_ANNOUNCED , LANE_GUIDANCE_ANNOUNCED Otherwise, your implementation should publish the NavigationError message with a type and code from the following: types: TURN_GUIDANCE_FAILED , EXIT_GUIDANCE_FAILED , ENTER_GUIDANCE_FAILED , MERGE_GUIDANCE_FAILED , LANE_GUIDANCE_FAILED codes: INTERNAL_SERVICE_ERROR , ROUTE_NOT_FOUND , NOT_SUPPORTED , NOT_NAVIGATING Click to expand or collapse sequence diagram: Getting Turn and Lane Guidance Information","title":"Getting Turn and Lane Guidance Information"},{"location":"explore/features/navigation/#getting-road-regulation-information","text":"If the user wants to get road regulation information, the Engine publishes the AnnounceRoadRegulation message , which passes a payload with the following schema: { \"type\": \"{{STRING}}\" } Property Type Required Description type String Yes Type of road regulation requested. Accepted values: \"SPEED_LIMIT\" specifies the speed limit at the current position (e.g., when the user asks, \"Alexa, what is the speed limit?\"). \"CARPOOL_RULES\" specifies the carpool regulations on the current highway (e.g., when the user asks, \"Alexa, is carpool free now?\"). If the device can provide the road regulation information successfully, your implementation should publish the NavigationEvent message with a SPEED_LIMIT_REGULATION_ANNOUNCED or CARPOOL_RULES_REGULATION_ANNOUNCED event. Otherwise, it should publish the NavigationError message with a type and code from the following: types: SPEED_LIMIT_REGULATION_FAILED , CARPOOL_RULES_REGULATION_FAILED codes: INTERNAL_SERVICE_ERROR , ROUTE_NOT_FOUND , NOT_SUPPORTED , NOT_NAVIGATING Click to expand or collapse sequence diagram: Getting Road Regulation Information","title":"Getting Road Regulation Information"},{"location":"explore/features/navigation/#controlling-the-display","text":"If the user wants to control the map display on the screen, the Engine publishes the ControlDisplay message . If the device can adjust the display successfully, your implementation should publish the NavigationEvent message with one of the following event: events: ROUTE_OVERVIEW_SHOWN , DIRECTIONS_LIST_SHOWN , ZOOMED_IN , ZOOMED_OUT , MAP_CENTERED , ORIENTED_NORTH , SCROLLED_NORTH , SCROLLED_UP , SCROLLED_EAST , SCROLLED_RIGHT , SCROLLED_SOUTH , SCROLLED_DOWN , SCROLLED_WEST , SCROLLED_LEFT , ROUTE_GUIDANCE_MUTED , ROUTE_GUIDANCE_UNMUTED Otherwise, your implementation should publish the NavigationError message with a type and code from the following: types: ROUTE_OVERVIEW_FAILED , DIRECTIONS_LIST_FAILED , ZOOMED_IN_FAILED , ZOOMED_OUT_FAILED , MAP_CENTERED_FAILED , ORIENTED_NORTH_FAILED , SCROLLED_NORTH_FAILED , SCROLLED_UP_FAILED , SCROLLED_EAST_FAILED , SCROLLED_RIGHT_FAILED , SCROLLED_SOUTH_FAILED , SCROLLED_DOWN_FAILED , SCROLLED_WEST_FAILED , SCROLLED_LEFT_FAILED , ROUTE_GUIDANCE_MUTED_FAILED , ROUTE_GUIDANCE_UNMUTED_FAILED codes: INTERNAL_SERVICE_ERROR , NOT_NAVIGATING , NOT_SUPPORTED , NOT_ALLOWED Click to expand or collapse sequence diagram: Controlling the Display","title":"Controlling the Display"},{"location":"explore/features/navigation/#showing-alternative-routes","text":"If the user wants to display alternative routes, the Engine publishes the ShowAlternativeRoutes message , which passes the type of alternate route to be displayed. If the device can display the alternative route successfully, your implementation should publish the ShowAlternativeRoutesSucceeded message with a payload containing information about the alternative route. The following table explains the properties in the JSON. Property Type Required Description inquiryType String Yes The type of alternative routes based on the user's preference. Accepted values: \"DEFAULT\" , which means there is no preference as to whether the alternate route saves time or distance. \"SHORTER_TIME\" , which means the alternate route saves time. \"SHORTER_DISTANCE\" , which means the alternate route saves distance. alternateRoute Object Yes Information about the best route that matches the preference specified by inquiryType . alternateRoute.labels Array of strings Yes Unique names within a route (e.g., names of highways) used to distinguish between alternative routes. Each label might contain the direction of the route. alternateRoute.savings Array No List of savings achieved by the route. alternateRoute.savings.type String Yes The type of savings. Accepted values: \"DISTANCE\" or \"TIME\" . alternateRoute.savings.amount Float Yes The amount of savings achieved by the route. Alexa uses prescribed unit to convert the amount of savings to improve user experience, if needed. alternateRoute.savings.unit String Yes Measurement unit of the savings. Accepted values: \"MINUTE\" , \"HOUR\" , \"YARD\" , \"FOOT\" , \"MILE\" , \"METER\" , or \"KILOMETER\" . Click to expand or collapse the ShowAlternativeRoutesSucceeded message schema { \"inquiryType\": \"{{STRING}}\", \"alternateRoute\": { \"labels\": [\"{{STRING}}\"], \"savings\": [ { \"type\": \"{{STRING}}\", \"amount\": {{FLOAT}}, \"unit\": \"{{STRING}}\" } ] } } Otherwise, your implementation should publish the NavigationError message with a type and code from the following: types: DEFAULT_ALTERNATE_ROUTES_FAILED , SHORTER_TIME_ROUTES_FAILED , SHORTER_DISTANCE_ROUTES_FAILED codes: INTERNAL_SERVICE_ERROR , ROUTE_NOT_FOUND , NOT_SUPPORTED , NOT_NAVIGATING Click to expand or collapse sequence diagram: Showing Alternative Routes","title":"Showing Alternative Routes"},{"location":"explore/features/navigation/#integrating-the-navigation-module-into-your-application","text":"","title":"Integrating the Navigation Module Into Your Application "},{"location":"explore/features/navigation/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to subscribe to and publish \"Navigation\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Navigation/Navigation/AlternateRouteType.h> #include <AASB/Message/Navigation/Navigation/ControlDisplay.h> #include <AASB/Message/Navigation/Navigation/ErrorCode.h> #include <AASB/Message/Navigation/Navigation/ErrorType.h> #include <AASB/Message/Navigation/Navigation/EventName.h> #include <AASB/Message/Navigation/Navigation/RoadRegulation.h> #include <AASB/Message/Navigation/Navigation/AnnounceManeuverMessage.h> #include <AASB/Message/Navigation/Navigation/AnnounceRoadRegulationMessage.h> #include <AASB/Message/Navigation/Navigation/CancelNavigationMessage.h> #include <AASB/Message/Navigation/Navigation/ControlDisplayMessage.h> #include <AASB/Message/Navigation/Navigation/GetNavigationStateMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationErrorMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationEventMessage.h> #include <AASB/Message/Navigation/Navigation/NavigateToPreviousWaypointMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesSucceededMessage.h> #include <AASB/Message/Navigation/Navigation/ShowPreviousWaypointsMessage.h> #include <AASB/Message/Navigation/Navigation/StartNavigationMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyNavigationHandler { void MyNavigationHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceManeuverMessage ( message ); }, AnnounceManeuverMessage :: topic (), AnnounceManeuverMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceRoadRegulationMessage ( message ); }, AnnounceRoadRegulationMessage :: topic (), AnnounceRoadRegulationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCancelNavigationMessage ( message ); }, CancelNavigationMessage :: topic (), CancelNavigationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleControlDisplayMessage ( message ); }, ControlDisplayMessage :: topic (), ControlDisplayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNavigationStateMessage ( message ); }, GetNavigationStateMessage :: topic (), GetNavigationStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleNavigateToPreviousWaypointMessage ( message ); }, NavigateToPreviousWaypointMessage :: topic (), NavigateToPreviousWaypointMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowAlternativeRoutesMessage ( message ); }, ShowAlternativeRoutesMessage :: topic (), ShowAlternativeRoutesMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowPreviousWaypointsMessage ( message ); }, ShowPreviousWaypointsMessage :: topic (), ShowPreviousWaypointsMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartNavigationMessage ( message ); }, StartNavigationMessage :: topic (), StartNavigationMessage :: action ()); } // Handle the AnnounceManeuver message from the Engine void MyNavigationHandler::handleAnnounceManeuverMessage ( const std :: string & message ) { AnnounceManeuverMessage msg = json :: parse ( message ); announceManeuver ( msg . payload . payload ); } // Handle the AnnounceRoadRegulation message from the Engine void MyNavigationHandler::handleAnnounceRoadRegulationMessage ( const std :: string & message ) { AnnounceRoadRegulationMessage msg = json :: parse ( message ); announceRoadRegulation ( msg . payload . roadRegulation ); } // Handle the CancelNavigation message from the Engine void MyNavigationHandler::handleCancelNavigationMessage ( const std :: string & message ) { cancelNavigation (); } // Handle the ControlDisplay message from the Engine void MyNavigationHandler::handleControlDisplayMessage ( const std :: string & message ) { ControlDisplayMessage msg = json :: parse ( message ); controlDisplay ( msg . payload . controlDisplay ); } // Handle the GetNavigationState message from the Engine and publish the // reply message containing the current navigation state void MyNavigationHandler::handleGetNavigationStateMessage ( const std :: string & message ) { GetNavigationStateMessage msg = json :: parse ( message ); GetNavigationStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . navigationState = getNavigationState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the NavigateToPreviousWaypoint message from the Engine void MyNavigationHandler::handleNavigateToPreviousWaypointMessage ( const std :: string & message ) { navigateToPreviousWaypoint (); } // Handle the ShowAlternativeRoutes message from the Engine void MyNavigationHandler::handleShowAlternativeRoutesMessage ( const std :: string & message ) { ShowAlternativeRoutesMessage msg = json :: parse ( message ); showAlternativeRoutes ( msg . payload . alternateRouteType ); } // Handle the ShowPreviousWaypoints message from the Engine void MyNavigationHandler::handleShowPreviousWaypointsMessage ( const std :: string & message ) { showPreviousWaypoints (); } // Handle the StartNavigation message from the Engine void MyNavigationHandler::handleStartNavigationMessage ( const std :: string & message ) { StartNavigationMessage msg = json :: parse ( message ); startNavigation ( msg . payload . payload ); } void MyNavigationHandler::navigationError ( ErrorType type , ErrorCode code , const std :: string & description ) { NavigationErrorMessage msg ; msg . payload . type = type ; msg . payload . code = code ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::navigationEvent ( EventName event ) { NavigationEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::showAlternativeRoutesSucceeded ( const std :: string & payload ) { ShowAlternativeRoutesSucceededMessage msg ; msg . payload . payload = payload ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::startNavigation ( const std :: string & payload ) { // Update the previous destinations list // Call navigationEvent(EventName::NAVIGATION_STARTED) // If error occurs call navigationError() with ErrorType::NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void MyNavigationHandler::navigateToPreviousWaypoint () { // Call navigationEvent(EventName::PREVIOUS_NAVIGATION_STARTED) // If any error occurs call navigationError() with ErrorType::PREVIOUS_NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showPreviousWaypoints () { // Call navigationEvent(EventName::PREVIOUS_WAYPOINTS_SHOWN) // If error occurs call navigationError() with ErrorType::SHOW_PREVIOUS_WAYPOINTS_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showAlternativeRoutes ( AlternateRouteType alternateRouteType ) { // Based on the AlternativeRouteType obtain the alternative route information // Call showAlternativeRoutesSucceeded() // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::controlDisplay ( ControlDisplay controlDisplay ) { // Call navigationEvent() for the requested map control request // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceManeuver ( const std :: string & payload ) { // Call navigationEvent() for the requested manueuver instruction // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceRoadRegulation ( RoadRegulation roadRegulation ) { // Call navigationEvent() for the requested road regulation // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } bool NavigationHandler::cancelNavigation () { // Clear the navigation state } std :: string NavigationHandler::getNavigationState () { // Return current navigation state } };","title":"C++ MessageBroker Integration"},{"location":"explore/features/navigation/#android-integration_1","text":"The Alexa Auto Client Service (AACS) provides the Navigation App Component to integrate the Auto SDK Navigation module on Android. See the AACS Navigation App Component documentation for more information.","title":"Android Integration"},{"location":"explore/features/phone-control/","text":"Phone Control Module \u00b6 Overview \u00b6 The Phone Control module enables your Alexa Auto SDK client application to use the phone call control capabilities of Alexa, independent of the connection mechanism to the calling device. By using the PhoneCallController interface in your application, you allow the end user to interact with new or ongoing calls using Alexa, and you provide Alexa with the state of the calling device. The Phone Control module uses phone contacts uploaded via the Address Book module. Your application's PhoneCallController integration is responsible for managing the lifecycle of the call session, including enhancing the end user experience by: Preventing Alexa Text To Speech (TTS) from being fed back into the microphone when the user triggers Alexa during a call. To accomplish this, your implementation should stop feeding the microphone input into the call channel until Alexa returns to the idle state, and it should also specify strong echo cancellation. Lowering the audio level of previous media in response to an incoming call until the call is answered or declined (if ducking is supported) and pausing the media if the call is answered. Maintaining the last dialed number to support redialing. Configuring the Phone Control Module \u00b6 The Phone Control module does not require Engine configuration. Using the Phone Call Controller AASB Messages \u00b6 Changing Connection State \u00b6 When connection to a calling device is established or terminated, publish the ConnectionStateChanged message . Click to expand or collapse sequence diagram: Connection State Changed Updating Device Configuration \u00b6 To update the device configuration of the connected calling device, publish the DeviceConfigurationUpdated message . Note: The Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Click to expand or collapse sequence diagram: Device Configuration Updated Calling \u00b6 Whether the call is initiated by Alexa or by the user, during the call session your application is responsible for publishing CallStateChanged messages to inform the Engine of the progression of the call (e.g., call is answered, call ended) while the Engine publishes messages to the application in order to handle user interactions with the call (e.g., answer, dial, stop). Regardless of whether the call is inbound or outbound: During a call if the user asks Alexa to press the keypad, the Engine publishes the SendDTMF message . Your application must handle this message and publish either the SendDTMFSucceeded message or SendDTMFFailed message to indicate its completion or failure, respectively. If an error occurrs during an active call or call setup, publish the CallFailed message specifying the error. When the user asks Alexa to hang up a call, cancel a call setup, or decline an incoming call the Engine publishes the Stop message . Inbound Calling \u00b6 When an inbound call is detected, publish the CreateCallId message . In response, the Engine will publish the CreateCallId reply containing a unique identifier for the call. Once an inbound call alert is received, your application must publish the CallStateChanged message indicating the call is now in the CALL_RECEIVED state. When the inbound call begins ringing, publish the CallStateChanged message, this time specifying the INBOUND_RINGING call state. If the user asks Alexa to answer the inbound call, the Engine publishes the Answer message . Publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Note: When a caller id is received for an inbound call, publish the CallerIdReceived message . Click to expand or collapse sequence diagram: Inbound Calling Outbound Calling \u00b6 When a user asks Alexa to dial a number or call an uploaded contact, the Engine publishes the Dial message . Alternatively, if the user asks Alexa to redial the last dialed number, the Engine publishes the Redial message . In both cases, your application must publish the CallStateChanged message indicating the call is now in the DIALING state. Once the outgoing call setup is complete and outbound ringing has started, publish the CallStateChanged message specifying the OUTBOUND_RINGING call state. If the call is answered and in progress, publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Click to expand or collapse sequence diagram: Outbound Calling Integrating the Phone Call Controller Module Into Your Application \u00b6 Use the MessageBroker to subscribe to and publish PhoneCallController AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallingDeviceConfigurationProperty.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DTMFError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/AnswerMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallerIdReceivedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CreateCallIdMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DeviceConfigurationUpdatedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/RedialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFSucceededMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/StopMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPhoneCallControllerHandler { // Subscribe to messages from the Engine void MyPhoneCallControllerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnswerMessage ( message ); }, AnswerMessage :: topic (), AnswerMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleDialMessage ( message ); }, DialMessage :: topic (), DialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRedialMessage ( message ); }, RedialMessage :: topic (), RedialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendDMTFMessage ( message ); }, SendDTMFMessage :: topic (), SendDTMFMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCreateCallIdReplyMessage ( message ); }, CreateCallIdMessageReply :: topic (), CreateCallIdMessageReply :: action ()); } // Handle the Answer message from the Engine void MyPhoneCallControllerHandler::handleAnswerMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); answer ( msg . payload . payload ); } // Handle the Dial message from the Engine void MyPhoneCallControllerHandler::handleDialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); std :: string payload = msg . payload . payload ; dial ( msg . payload . payload ); } // Handle the Redial message from the Engine void MyPhoneCallControllerHandler::handleRedialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); redial ( msg . payload . payload ); } // Handle the SendDTMF message from the Engine void MyPhoneCallControllerHandler::handleSendDMTFMessage ( const std :: string & message ) { SendDTMFMessage msg = json :: parse ( message ); sendDTMF ( msg . payload . payload ); } // Handle the Stop message from the Engine void MyPhoneCallControllerHandler::handleStopMessage ( const std :: string & message ) { StopMessage msg = json :: parse ( message ); stop ( msg . payload . payload ); } // Handle the CreateCallId reply message from the Engine void MyPhoneCallControllerHandler::handleCreateCallIdReplyMessage ( const std :: string & message ) { CreateCallIdMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string callId = msg . payload . callId ; // ...Handle the generated call id... } // When an error occurrs during an active call or call setup, publish a CallFailed // message to the Engine void MyPhoneCallControllerHandler::callFailed ( const std :: string & callId , CallError code , const std :: string & message ) { CallFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the call state changes, publish a CallStateChanged message to the Engine void MyPhoneCallControllerHandler::callStateChanged ( CallState state , const std :: string & callId , const std :: string & callerId ) { CallStateChangedMessage msg ; msg . payload . state = state ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When a caller id is received for an inbound call, publish a CallerIdReceived // message to the Engine void MyPhoneCallControllerHandler::callerIdReceived ( const std :: string & callId , const std :: string & callerId ) { CallerIdReceivedMessage msg ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When connection to a calling device is established or broken, publish a // ConnectionStateChanged message to the Engine void MyPhoneCallControllerHandler::connectionStateChanged ( ConnectionState state ) { ConnectionStateChangedMessage msg ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } // To generate an identifier for a call, publish a CreateCallId message to the Engine std :: string MyPhoneCallControllerHandler::createCallId () { CreateCallIdMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the CreateCallIdReply message // Return the unique identifier from reply message payload } // When a feature of the calling device changes, publish a // DeviceConfigurationUpdated message to the Engine void MyPhoneCallControllerHandler::deviceConfigurationUpdated ( std :: unordered_map < CallingDeviceConfigurationProperty , bool > configurationMap ) { json configuration ; for ( auto it : configurationMap ) { configuration [ configurationFeatureToString ( it . first )] = it . second ; } DeviceConfigurationUpdatedMessage msg ; msg . payload . configurationMap = configuration . dump (); m_messageBroker -> publish ( msg . toString ()); } // When the DTMF signal is delivered, publish a SendDTMFSucceeded message to the Engine void MyPhoneCallControllerHandler::sendDTMFSucceeded ( const std :: string & callId ) { SendDTMFSucceededMessage msg ; msg . payload . callId = callId ; m_messageBroker -> publish ( msg . toString ()); } // When sending the DTMF signal failed, publish a SendDTMFFailed message to the Engine void MyPhoneCallControllerHandler::sendDTMFFailed ( const std :: string & callId , DTMFError code , const std :: string & message ) { SendDTMFFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } void MyPhoneCallControllerHandler::answer ( const std :: string & payload ) { // Answer the inbound call } void MyPhoneCallControllerHandler::dial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::redial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::stop ( const std :: string & payload ) { // Stop the call } void MyPhoneCallControllerHandler::sendDTMF ( const std :: string & payload ) { // Send a DTMF signal } // Implement to convert CallingDeviceConfigurationProperty to string std :: string MyPhoneCallControllerHandler::configurationFeatureToString ( CallingDeviceConfigurationProperty feature ); }; Android Integration \u00b6 The Alexa Auto Client Service (AACS) provides the AACS Telephony Library to integrate the Auto SDK Phone Control module on Android. See the AACS Telephony Library documentation for more information.","title":"Phone Control Module"},{"location":"explore/features/phone-control/#phone-control-module","text":"","title":"Phone Control Module"},{"location":"explore/features/phone-control/#overview","text":"The Phone Control module enables your Alexa Auto SDK client application to use the phone call control capabilities of Alexa, independent of the connection mechanism to the calling device. By using the PhoneCallController interface in your application, you allow the end user to interact with new or ongoing calls using Alexa, and you provide Alexa with the state of the calling device. The Phone Control module uses phone contacts uploaded via the Address Book module. Your application's PhoneCallController integration is responsible for managing the lifecycle of the call session, including enhancing the end user experience by: Preventing Alexa Text To Speech (TTS) from being fed back into the microphone when the user triggers Alexa during a call. To accomplish this, your implementation should stop feeding the microphone input into the call channel until Alexa returns to the idle state, and it should also specify strong echo cancellation. Lowering the audio level of previous media in response to an incoming call until the call is answered or declined (if ducking is supported) and pausing the media if the call is answered. Maintaining the last dialed number to support redialing.","title":"Overview"},{"location":"explore/features/phone-control/#configuring-the-phone-control-module","text":"The Phone Control module does not require Engine configuration.","title":"Configuring the Phone Control Module"},{"location":"explore/features/phone-control/#using-the-phone-call-controller-aasb-messages","text":"","title":"Using the Phone Call Controller AASB Messages"},{"location":"explore/features/phone-control/#changing-connection-state","text":"When connection to a calling device is established or terminated, publish the ConnectionStateChanged message . Click to expand or collapse sequence diagram: Connection State Changed","title":"Changing Connection State"},{"location":"explore/features/phone-control/#updating-device-configuration","text":"To update the device configuration of the connected calling device, publish the DeviceConfigurationUpdated message . Note: The Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Click to expand or collapse sequence diagram: Device Configuration Updated","title":"Updating Device Configuration"},{"location":"explore/features/phone-control/#calling","text":"Whether the call is initiated by Alexa or by the user, during the call session your application is responsible for publishing CallStateChanged messages to inform the Engine of the progression of the call (e.g., call is answered, call ended) while the Engine publishes messages to the application in order to handle user interactions with the call (e.g., answer, dial, stop). Regardless of whether the call is inbound or outbound: During a call if the user asks Alexa to press the keypad, the Engine publishes the SendDTMF message . Your application must handle this message and publish either the SendDTMFSucceeded message or SendDTMFFailed message to indicate its completion or failure, respectively. If an error occurrs during an active call or call setup, publish the CallFailed message specifying the error. When the user asks Alexa to hang up a call, cancel a call setup, or decline an incoming call the Engine publishes the Stop message .","title":"Calling"},{"location":"explore/features/phone-control/#inbound-calling","text":"When an inbound call is detected, publish the CreateCallId message . In response, the Engine will publish the CreateCallId reply containing a unique identifier for the call. Once an inbound call alert is received, your application must publish the CallStateChanged message indicating the call is now in the CALL_RECEIVED state. When the inbound call begins ringing, publish the CallStateChanged message, this time specifying the INBOUND_RINGING call state. If the user asks Alexa to answer the inbound call, the Engine publishes the Answer message . Publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Note: When a caller id is received for an inbound call, publish the CallerIdReceived message . Click to expand or collapse sequence diagram: Inbound Calling","title":"Inbound Calling"},{"location":"explore/features/phone-control/#outbound-calling","text":"When a user asks Alexa to dial a number or call an uploaded contact, the Engine publishes the Dial message . Alternatively, if the user asks Alexa to redial the last dialed number, the Engine publishes the Redial message . In both cases, your application must publish the CallStateChanged message indicating the call is now in the DIALING state. Once the outgoing call setup is complete and outbound ringing has started, publish the CallStateChanged message specifying the OUTBOUND_RINGING call state. If the call is answered and in progress, publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Click to expand or collapse sequence diagram: Outbound Calling","title":"Outbound Calling"},{"location":"explore/features/phone-control/#integrating-the-phone-call-controller-module-into-your-application","text":"Use the MessageBroker to subscribe to and publish PhoneCallController AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallingDeviceConfigurationProperty.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DTMFError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/AnswerMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallerIdReceivedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CreateCallIdMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DeviceConfigurationUpdatedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/RedialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFSucceededMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/StopMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPhoneCallControllerHandler { // Subscribe to messages from the Engine void MyPhoneCallControllerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnswerMessage ( message ); }, AnswerMessage :: topic (), AnswerMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleDialMessage ( message ); }, DialMessage :: topic (), DialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRedialMessage ( message ); }, RedialMessage :: topic (), RedialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendDMTFMessage ( message ); }, SendDTMFMessage :: topic (), SendDTMFMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCreateCallIdReplyMessage ( message ); }, CreateCallIdMessageReply :: topic (), CreateCallIdMessageReply :: action ()); } // Handle the Answer message from the Engine void MyPhoneCallControllerHandler::handleAnswerMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); answer ( msg . payload . payload ); } // Handle the Dial message from the Engine void MyPhoneCallControllerHandler::handleDialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); std :: string payload = msg . payload . payload ; dial ( msg . payload . payload ); } // Handle the Redial message from the Engine void MyPhoneCallControllerHandler::handleRedialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); redial ( msg . payload . payload ); } // Handle the SendDTMF message from the Engine void MyPhoneCallControllerHandler::handleSendDMTFMessage ( const std :: string & message ) { SendDTMFMessage msg = json :: parse ( message ); sendDTMF ( msg . payload . payload ); } // Handle the Stop message from the Engine void MyPhoneCallControllerHandler::handleStopMessage ( const std :: string & message ) { StopMessage msg = json :: parse ( message ); stop ( msg . payload . payload ); } // Handle the CreateCallId reply message from the Engine void MyPhoneCallControllerHandler::handleCreateCallIdReplyMessage ( const std :: string & message ) { CreateCallIdMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string callId = msg . payload . callId ; // ...Handle the generated call id... } // When an error occurrs during an active call or call setup, publish a CallFailed // message to the Engine void MyPhoneCallControllerHandler::callFailed ( const std :: string & callId , CallError code , const std :: string & message ) { CallFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the call state changes, publish a CallStateChanged message to the Engine void MyPhoneCallControllerHandler::callStateChanged ( CallState state , const std :: string & callId , const std :: string & callerId ) { CallStateChangedMessage msg ; msg . payload . state = state ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When a caller id is received for an inbound call, publish a CallerIdReceived // message to the Engine void MyPhoneCallControllerHandler::callerIdReceived ( const std :: string & callId , const std :: string & callerId ) { CallerIdReceivedMessage msg ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When connection to a calling device is established or broken, publish a // ConnectionStateChanged message to the Engine void MyPhoneCallControllerHandler::connectionStateChanged ( ConnectionState state ) { ConnectionStateChangedMessage msg ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } // To generate an identifier for a call, publish a CreateCallId message to the Engine std :: string MyPhoneCallControllerHandler::createCallId () { CreateCallIdMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the CreateCallIdReply message // Return the unique identifier from reply message payload } // When a feature of the calling device changes, publish a // DeviceConfigurationUpdated message to the Engine void MyPhoneCallControllerHandler::deviceConfigurationUpdated ( std :: unordered_map < CallingDeviceConfigurationProperty , bool > configurationMap ) { json configuration ; for ( auto it : configurationMap ) { configuration [ configurationFeatureToString ( it . first )] = it . second ; } DeviceConfigurationUpdatedMessage msg ; msg . payload . configurationMap = configuration . dump (); m_messageBroker -> publish ( msg . toString ()); } // When the DTMF signal is delivered, publish a SendDTMFSucceeded message to the Engine void MyPhoneCallControllerHandler::sendDTMFSucceeded ( const std :: string & callId ) { SendDTMFSucceededMessage msg ; msg . payload . callId = callId ; m_messageBroker -> publish ( msg . toString ()); } // When sending the DTMF signal failed, publish a SendDTMFFailed message to the Engine void MyPhoneCallControllerHandler::sendDTMFFailed ( const std :: string & callId , DTMFError code , const std :: string & message ) { SendDTMFFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } void MyPhoneCallControllerHandler::answer ( const std :: string & payload ) { // Answer the inbound call } void MyPhoneCallControllerHandler::dial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::redial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::stop ( const std :: string & payload ) { // Stop the call } void MyPhoneCallControllerHandler::sendDTMF ( const std :: string & payload ) { // Send a DTMF signal } // Implement to convert CallingDeviceConfigurationProperty to string std :: string MyPhoneCallControllerHandler::configurationFeatureToString ( CallingDeviceConfigurationProperty feature ); };","title":"Integrating the Phone Call Controller Module Into Your Application"},{"location":"explore/features/phone-control/#android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS Telephony Library to integrate the Auto SDK Phone Control module on Android. See the AACS Telephony Library documentation for more information.","title":"Android Integration"},{"location":"explore/features/system-audio/","text":"Alexa Auto SDK System Audio Module \u00b6 The System Audio module provides the default audio capturing and playback functionality for macOS, Linux, and QNX. What's Included \u00b6 The System Audio module contains the platform implementations of: aace::audio::AudioOutput and aace::audio::AudioOutputProvider for audio playback capability aace::audio::AudioInput and aace::audio::AudioInputProvider for audio capturing capability Supported Audio Backends \u00b6 Currently the System Audio module supports: GStreamer tested on: Ubuntu Linux (18.04 and 20.04) Note: Ensure installing at least gstreamer1.0-plugins-base and gstreamer1.0-plugins-good . It is recommended to install gstreamer1.0-plugins-bad for playing content from Amazon Music (which uses HLS) and other Music Service Providers. Refer to https://gstreamer.freedesktop.org/documentation/installing/on-linux.html for instructions. Note: GStreamer on Poky Linux for iMX8 does not support Audible or Amazon Music playback. Automotive Grade Linux with 4A framework support (FF or GG) Poky Linux armv7hf and armv8 macOS x86_64 with GStreamer installed by Homebrew OpenMAX AL (Encoded audio playback only) tested with: QNX Multimedia Suite 2.0 on QNX 7.0.0 armv8 QNX Sound Architecture (QSA) (Raw audio only) tested with: QNX 7.0.0 armv8 Note: You'll need a QNX Multimedia Suite license to use OpenMAX AL, and both OpenMAX AL and QSA are required in order to enable full functionality on QNX. Getting Started \u00b6 Prerequisites \u00b6 You'll need GStreamer development packages such as libgstreamer1.0-dev and libgstreamer-plugins-base1.0-dev . Building the Alexa Auto SDK with the System Audio Module \u00b6 The Alexa Auto SDK Builder Tool automatically includes the System Audio module when you build the C++ sample app. You can include it explicitly by specifying -o aac_modules=aac-module-system-audio,... to the build command. Running the C++ Sample App with the Audio Configuration \u00b6 When you run the C++ Sample App, a config-system-audio.json file with default audio settings for Linux platforms is provided under shared/system-audio/config . Changing the Default Audio Settings for Linux (required for Poky 32) \u00b6 If you need to modify the configuration defined in the config-system-audio.json file for your Linux platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/linux directory) as necessary. Note: For Poky 32 boards, you must set \"shared\" to \"true\" in the \"default\" node. Save the config-system-audio.json file to the same directory other config files reside. Include a --config path/to/config-system-audio.json line when you run the C++ Sample App. Changing the Default Audio Settings for QNX (required) \u00b6 The default audio settings will not work for QNX. To modify the configuration defined in the config-system-audio.json file for your QNX platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/neutrino directory) as necessary. See the default QNX configuration for guidance. Save the config-system-audio.json file to the same directory other config files reside. Include a --config /opt/AAC/etc/config-system-audio.json line when you run the C++ Sample App. Note: You may need to set the AAL_CAPATH system environment value to specify which path should OpenMAX AL used for CURLOPT_CAPATH internally. If you don't set the AAL_CAPATH system environment variable, /etc/ssl/certs will be used by default. Configuring System Audio \u00b6 For complex audio setup, you may need to write your own config file. To use this file, save it as config-system-audio.json and include a --config path/to/config-system-audio.json line when you run the C++ Sample App. Here is the config file template: { \"aace.systemAudio\": { \"<provider>\": { \"enabled\": {{BOOLEAN}}, \"devices\": { \"<device-name>\": { \"module\": \"<module-name>\", \"card\": \"<id>\", \"rate\": \"<sample-rate>\", \"shared\": {{BOOLEAN}} } }, \"types\": { \"<type>\": \"<device-name>\" } } } } aace.systemAudio.<provider> : Set to AudioInputProvider or AudioOutputProvider . You can write a configuration for each <provider> , depending on the direction (input or output). aace.systemAudio.<provider>.enabled : Set to true or false . Setting this parameter to false disables the registration of the <provider> platform implementation. The default setting is true . aace.systemAudio.<provider>.devices.<device-name> : Set to any \"<device-name>\" or to default . If you set the \"<device-name>\" to \"default\" audio will be routed by default if there is no explicit \"<device-name> \" available for the configured \"<type>\" . You can configure multiple devices, depending on your platform. \"module\" : Specify a \"<module-name>\" to explicitly define which audio backend to use. By default, \"module\" is set to an empty string, which configures the system audio module to use whatever backend is available. \"card\" : Specify the card id for the specific audio backend you defined with the \"<module-name>\" parameter. By default, \"card\" is set to an empty string since by default \"<module-name>\" is not defined. \"rate\" : Specify the sample rate of audio input. By default the \"rate\" is set to 0 . \"shared\" (AudioInputProvider only) : Set to true or false . Set \"shared\" to true for Poky 32 boards or in cases where the device should be shared within the Auto SDK Engine; otherwise, the System Audio module will try to open the device for every audio input type. The \"shared\" option is useful when the underlying backend doesn't support the input splitter. By default \"shared\" is set to false . aace.systemAudio.<provider>.types.<type> : Use the \"type\" option to specify which device should be used for various types of audio. If you do not explicitly specify a device, the default type is used. See aace::audio::AudioInputProvider::AudioInputType and aace::audio::AudioOutputProvider::AudioOutputType for the possible \"<type>\" values. Default QNX Configuration \u00b6 Here is the default configuration for QNX platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"QSA\" , \"shared\" : true } } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"OpenMAX AL\" }, \"raw\" : { \"module\" : \"QSA\" } }, \"types\" : { \"COMMUNICATION\" : \"raw\" } } } } If you use this configuration: The audio capturing for all types will use QSA , but it will be shared. This means that only a single PCM channel will be opened by the Engine. The audio playback for all types except COMMUNICATION will use OpenMAX AL . COMMUNICATION audio will use QSA instead. Note that the multiple PCM channels will be opened for each types. Linux Configuration Example \u00b6 Here is a configuration example for Linux platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" }, \"loopback\" : { \"module\" : \"GStreamer\" , \"card\" : \"hw:Loopback,1,0\" , \"shared\" : true } }, \"types\" : { \"LOOPBACK\" : \"loopback\" } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" } } } } } The above example shows how you could provide \"Speaker reference\" into the engine. Specifying Input and Output Device \u00b6 The card field specifies the audio input source and audio output sink. For devices using module GStreamer , the card field can be one of the following values: If the card field is an empty string or not specified at all, the input device will be decided by GStreamer autoaudiosrc plugin and the output device will be decided by GStreamer autoaudiosink plugin automatically. If the the card field starts with bin: , the input and output device can be specified with a GStreamer bin description. For example, setting card of an audio input device to bin:udpsrc port=5000 caps=\\\"application/x-rtp,channels=(int)1,format=(string)S16LE,media=(string)audio,payload=(int)96,clock-rate=(int)16000,encoding-name=(string)L16\\\" ! rtpL16depay will receive audio from local UDP port 5000. See Pipeline Description for details. If the card field starts with element: , the input and output device can be specified with a GStreamer element. For example, setting card of an audio output device to element:pulsesink will deliver the output audio to the PulseAudio server. See Plugins for the list of GStreamer plugins. If none of the above matches, the string will be treated as an Advanced Linux Sound Architecture (ALSA) device name. You can use aplay -L or arecord -L to list available audio output and input devices. One practical use of the card field is to specify virtual audio input/output for the following devices: The target device does not have audio input/output hardware. The target device is remotely located. Here is an example to use local microphone and speaker and run C++ sample app on a remote device: Local macOS/Linux device Deliver audio from local microphone to remote UDP port 5000 by running gst-launch-1.0 -v autoaudiosrc ! \"audio/x-raw, format=(string)S16LE, channels=(int)1, layout=(string)interleaved\" ! audioresample ! audio/x-raw, rate=16000 ! audioconvert ! rtpL16pay ! udpsink host=your.remote.device port=5000 . Build a reverse SSH tunnel by running ssh -R 24713:localhost:4713 your.remote.device . Play audio output received from remote device by running pulseaudio --load=module-native-protocol-tcp --exit-idle-time=-1 --daemon . Remote device Receive audio input from UDP port 5000 by specifying card of audio input device to bin:udpsrc port=5000 caps=\\\"application/x-rtp,channels=(int)1,format=(string)S16LE,media=(string)audio,payload=(int)96,clock-rate=(int)16000,encoding-name=(string)L16\\\" ! rtpL16depay . Send audio output to local device by specifying card of audio output device to element:pulsesink and export PULSE_SERVER environment variable to tcp:localhost:24713 before running C++ sample app. Playlist URL Support \u00b6 The System Audio module supports playback of playlist URL from media streaming services (such as TuneIn) based on PlaylistParser provided by AVS Device SDK. The current supported formats include M3U and PLS. Note that only the first playable entry will be played in the current implementation. Choosing a variant based on stream information or continuing playback of the second or later entry is not supported right now. After the user asks Alexa to play on TuneIn, if Alexa acknowledges the request but says TuneIn is not available, the parser displays the following error: 2021-03-02 05:04:25.745 [AVS] E PlaylistParser:doDepthFirstSearch:url=http\\://www.podtrac.com/pts/redirect.mp3/chtbl.com/track/5899E/traffic.megaphone.fm/HSW1953246087.mp3:getHeaderFailed To avoid this error, provide a valid cacert.pem to CURLOPT_CAINFO in the Auto SDK configuration. Download the cacert.pem file from here . \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"/path/to/certs\", \"CURLOPT_CAINFO\": \"/path/to/cacert.pem\" }","title":"Alexa Auto SDK System Audio Module"},{"location":"explore/features/system-audio/#alexa-auto-sdk-system-audio-module","text":"The System Audio module provides the default audio capturing and playback functionality for macOS, Linux, and QNX.","title":"Alexa Auto SDK System Audio Module"},{"location":"explore/features/system-audio/#whats-included","text":"The System Audio module contains the platform implementations of: aace::audio::AudioOutput and aace::audio::AudioOutputProvider for audio playback capability aace::audio::AudioInput and aace::audio::AudioInputProvider for audio capturing capability","title":"What's Included"},{"location":"explore/features/system-audio/#supported-audio-backends","text":"Currently the System Audio module supports: GStreamer tested on: Ubuntu Linux (18.04 and 20.04) Note: Ensure installing at least gstreamer1.0-plugins-base and gstreamer1.0-plugins-good . It is recommended to install gstreamer1.0-plugins-bad for playing content from Amazon Music (which uses HLS) and other Music Service Providers. Refer to https://gstreamer.freedesktop.org/documentation/installing/on-linux.html for instructions. Note: GStreamer on Poky Linux for iMX8 does not support Audible or Amazon Music playback. Automotive Grade Linux with 4A framework support (FF or GG) Poky Linux armv7hf and armv8 macOS x86_64 with GStreamer installed by Homebrew OpenMAX AL (Encoded audio playback only) tested with: QNX Multimedia Suite 2.0 on QNX 7.0.0 armv8 QNX Sound Architecture (QSA) (Raw audio only) tested with: QNX 7.0.0 armv8 Note: You'll need a QNX Multimedia Suite license to use OpenMAX AL, and both OpenMAX AL and QSA are required in order to enable full functionality on QNX.","title":"Supported Audio Backends"},{"location":"explore/features/system-audio/#getting-started","text":"","title":"Getting Started"},{"location":"explore/features/system-audio/#prerequisites","text":"You'll need GStreamer development packages such as libgstreamer1.0-dev and libgstreamer-plugins-base1.0-dev .","title":"Prerequisites"},{"location":"explore/features/system-audio/#building-the-alexa-auto-sdk-with-the-system-audio-module","text":"The Alexa Auto SDK Builder Tool automatically includes the System Audio module when you build the C++ sample app. You can include it explicitly by specifying -o aac_modules=aac-module-system-audio,... to the build command.","title":"Building the Alexa Auto SDK with the System Audio Module"},{"location":"explore/features/system-audio/#running-the-c-sample-app-with-the-audio-configuration","text":"When you run the C++ Sample App, a config-system-audio.json file with default audio settings for Linux platforms is provided under shared/system-audio/config .","title":"Running the C++ Sample App with the Audio Configuration"},{"location":"explore/features/system-audio/#changing-the-default-audio-settings-for-linux-required-for-poky-32","text":"If you need to modify the configuration defined in the config-system-audio.json file for your Linux platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/linux directory) as necessary. Note: For Poky 32 boards, you must set \"shared\" to \"true\" in the \"default\" node. Save the config-system-audio.json file to the same directory other config files reside. Include a --config path/to/config-system-audio.json line when you run the C++ Sample App.","title":"Changing the Default Audio Settings for Linux (required for Poky 32)"},{"location":"explore/features/system-audio/#changing-the-default-audio-settings-for-qnx-required","text":"The default audio settings will not work for QNX. To modify the configuration defined in the config-system-audio.json file for your QNX platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/neutrino directory) as necessary. See the default QNX configuration for guidance. Save the config-system-audio.json file to the same directory other config files reside. Include a --config /opt/AAC/etc/config-system-audio.json line when you run the C++ Sample App. Note: You may need to set the AAL_CAPATH system environment value to specify which path should OpenMAX AL used for CURLOPT_CAPATH internally. If you don't set the AAL_CAPATH system environment variable, /etc/ssl/certs will be used by default.","title":"Changing the Default Audio Settings for QNX (required)"},{"location":"explore/features/system-audio/#configuring-system-audio","text":"For complex audio setup, you may need to write your own config file. To use this file, save it as config-system-audio.json and include a --config path/to/config-system-audio.json line when you run the C++ Sample App. Here is the config file template: { \"aace.systemAudio\": { \"<provider>\": { \"enabled\": {{BOOLEAN}}, \"devices\": { \"<device-name>\": { \"module\": \"<module-name>\", \"card\": \"<id>\", \"rate\": \"<sample-rate>\", \"shared\": {{BOOLEAN}} } }, \"types\": { \"<type>\": \"<device-name>\" } } } } aace.systemAudio.<provider> : Set to AudioInputProvider or AudioOutputProvider . You can write a configuration for each <provider> , depending on the direction (input or output). aace.systemAudio.<provider>.enabled : Set to true or false . Setting this parameter to false disables the registration of the <provider> platform implementation. The default setting is true . aace.systemAudio.<provider>.devices.<device-name> : Set to any \"<device-name>\" or to default . If you set the \"<device-name>\" to \"default\" audio will be routed by default if there is no explicit \"<device-name> \" available for the configured \"<type>\" . You can configure multiple devices, depending on your platform. \"module\" : Specify a \"<module-name>\" to explicitly define which audio backend to use. By default, \"module\" is set to an empty string, which configures the system audio module to use whatever backend is available. \"card\" : Specify the card id for the specific audio backend you defined with the \"<module-name>\" parameter. By default, \"card\" is set to an empty string since by default \"<module-name>\" is not defined. \"rate\" : Specify the sample rate of audio input. By default the \"rate\" is set to 0 . \"shared\" (AudioInputProvider only) : Set to true or false . Set \"shared\" to true for Poky 32 boards or in cases where the device should be shared within the Auto SDK Engine; otherwise, the System Audio module will try to open the device for every audio input type. The \"shared\" option is useful when the underlying backend doesn't support the input splitter. By default \"shared\" is set to false . aace.systemAudio.<provider>.types.<type> : Use the \"type\" option to specify which device should be used for various types of audio. If you do not explicitly specify a device, the default type is used. See aace::audio::AudioInputProvider::AudioInputType and aace::audio::AudioOutputProvider::AudioOutputType for the possible \"<type>\" values.","title":"Configuring System Audio"},{"location":"explore/features/system-audio/#default-qnx-configuration","text":"Here is the default configuration for QNX platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"QSA\" , \"shared\" : true } } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"OpenMAX AL\" }, \"raw\" : { \"module\" : \"QSA\" } }, \"types\" : { \"COMMUNICATION\" : \"raw\" } } } } If you use this configuration: The audio capturing for all types will use QSA , but it will be shared. This means that only a single PCM channel will be opened by the Engine. The audio playback for all types except COMMUNICATION will use OpenMAX AL . COMMUNICATION audio will use QSA instead. Note that the multiple PCM channels will be opened for each types.","title":"Default QNX Configuration "},{"location":"explore/features/system-audio/#linux-configuration-example","text":"Here is a configuration example for Linux platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" }, \"loopback\" : { \"module\" : \"GStreamer\" , \"card\" : \"hw:Loopback,1,0\" , \"shared\" : true } }, \"types\" : { \"LOOPBACK\" : \"loopback\" } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" } } } } } The above example shows how you could provide \"Speaker reference\" into the engine.","title":"Linux Configuration Example"},{"location":"explore/features/system-audio/#specifying-input-and-output-device","text":"The card field specifies the audio input source and audio output sink. For devices using module GStreamer , the card field can be one of the following values: If the card field is an empty string or not specified at all, the input device will be decided by GStreamer autoaudiosrc plugin and the output device will be decided by GStreamer autoaudiosink plugin automatically. If the the card field starts with bin: , the input and output device can be specified with a GStreamer bin description. For example, setting card of an audio input device to bin:udpsrc port=5000 caps=\\\"application/x-rtp,channels=(int)1,format=(string)S16LE,media=(string)audio,payload=(int)96,clock-rate=(int)16000,encoding-name=(string)L16\\\" ! rtpL16depay will receive audio from local UDP port 5000. See Pipeline Description for details. If the card field starts with element: , the input and output device can be specified with a GStreamer element. For example, setting card of an audio output device to element:pulsesink will deliver the output audio to the PulseAudio server. See Plugins for the list of GStreamer plugins. If none of the above matches, the string will be treated as an Advanced Linux Sound Architecture (ALSA) device name. You can use aplay -L or arecord -L to list available audio output and input devices. One practical use of the card field is to specify virtual audio input/output for the following devices: The target device does not have audio input/output hardware. The target device is remotely located. Here is an example to use local microphone and speaker and run C++ sample app on a remote device: Local macOS/Linux device Deliver audio from local microphone to remote UDP port 5000 by running gst-launch-1.0 -v autoaudiosrc ! \"audio/x-raw, format=(string)S16LE, channels=(int)1, layout=(string)interleaved\" ! audioresample ! audio/x-raw, rate=16000 ! audioconvert ! rtpL16pay ! udpsink host=your.remote.device port=5000 . Build a reverse SSH tunnel by running ssh -R 24713:localhost:4713 your.remote.device . Play audio output received from remote device by running pulseaudio --load=module-native-protocol-tcp --exit-idle-time=-1 --daemon . Remote device Receive audio input from UDP port 5000 by specifying card of audio input device to bin:udpsrc port=5000 caps=\\\"application/x-rtp,channels=(int)1,format=(string)S16LE,media=(string)audio,payload=(int)96,clock-rate=(int)16000,encoding-name=(string)L16\\\" ! rtpL16depay . Send audio output to local device by specifying card of audio output device to element:pulsesink and export PULSE_SERVER environment variable to tcp:localhost:24713 before running C++ sample app.","title":"Specifying Input and Output Device"},{"location":"explore/features/system-audio/#playlist-url-support","text":"The System Audio module supports playback of playlist URL from media streaming services (such as TuneIn) based on PlaylistParser provided by AVS Device SDK. The current supported formats include M3U and PLS. Note that only the first playable entry will be played in the current implementation. Choosing a variant based on stream information or continuing playback of the second or later entry is not supported right now. After the user asks Alexa to play on TuneIn, if Alexa acknowledges the request but says TuneIn is not available, the parser displays the following error: 2021-03-02 05:04:25.745 [AVS] E PlaylistParser:doDepthFirstSearch:url=http\\://www.podtrac.com/pts/redirect.mp3/chtbl.com/track/5899E/traffic.megaphone.fm/HSW1953246087.mp3:getHeaderFailed To avoid this error, provide a valid cacert.pem to CURLOPT_CAINFO in the Auto SDK configuration. Download the cacert.pem file from here . \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"/path/to/certs\", \"CURLOPT_CAINFO\": \"/path/to/cacert.pem\" }","title":"Playlist URL Support"},{"location":"explore/features/text-to-speech/","text":"Text-To-Speech (TTS) Module \u00b6 Overview \u00b6 The Text-To-Speech module enables your Alexa Auto SDK client application to synthesize Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. To synthesize speech, this module uses the Text-To-Speech-Provider module. The Auto SDK does not provide any speech-playing APIs. Your application's TTS module integration is responsible for playing the synthesized speech to deliver a unified Alexa experience to the user. Note: This feature may only be used with voice-guided turn-by-turn navigation. Important! The Text-To-Speech module requires the Local Voice Control extension. Configuring the Text-To Speech-Module \u00b6 The Text-To-Speech module does not require Engine configuration. Using the Text-To-Speech AASB Messages \u00b6 Prepare Speech \u00b6 To request speech synthesis from a text or SSML input, your application must publish the PrepareSpeech message . The Engine publishes either the PrepareSpeechCompleted message or PrepareSpeechFailed message to indicate success or failure, respectively. Click to expand or collapse sequence diagram: Prepare Speech Note: The prepareSpeechFailed API contains the reason parameter that specifies the error string for failure. Refer to the TTS provider errors for more information on errors defined by the TTS provider. TThe TTS module defines the REQUEST_TIMED_OUT error that occurs when the TTS provider sends no response, causing the speech request to time out. The timeout value is 1000 milliseconds. Get Capabilities \u00b6 To request the capabilities of the TTS provider being used, your application must publish the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message reply with the capabilities of the TTS provider. Click to expand or collapse sequence diagram: Get Capabilities Integrating the Text-To-Speech Module Into Your Application \u00b6 C++ MessageBroker Integration \u00b6 Use the MessageBroker to subscribe to and publish TextToSpeech AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/TextToSpeech/TextToSpeech/GetCapabilitiesMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechCompletedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechFailedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyTextToSpeechHandler { // Subscribe to messages from the Engine void MyTextToSpeechHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechCompletedMessage ( message ); }, PrepareSpeechCompletedMessage :: topic (), PrepareSpeechCompletedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechFailedMessage ( message ); }, PrepareSpeechFailedMessage :: topic (), PrepareSpeechFailedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCapabilitiesReplyMessage ( message ); }, GetCapabilitiesMessageReply :: topic (), GetCapabilitiesMessageReply :: action ()); } // Handle the PrepareSpeechCompleted message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechCompletedMessage ( const std :: string & message ) { PrepareSpeechCompletedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string streamId = msg . payload . streamId ; std :: string metadata = msg . payload . metadata ; prepareSpeechCompleted ( speechId , streamId , metadata ); } // Handle the PrepareSpeechFailed message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechFailedMessage ( const std :: string & message ) { PrepareSpeechFailedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string reason = msg . payload . reason ; prepareSpeechFailed ( speechId , reason ); } // Handle the GetCapabilities reply message from the Engine void MyTextToSpeechHandler::handleGetCapabilitiesReplyMessage ( const std :: string & message ) { GetCapabilitiesMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string capabilities = msg . payload . capabilities ; // ...Handle capabilities of the TTS provider... } // To prepare speech, publish the PrepareSpeech message to the Engine void MyTextToSpeechHandler::prepareSpeech ( const std :: string & speechId , const std :: string & text , const std :: string & provider , const std :: string & options ) { PrepareSpeechMessage msg ; msg . payload . speechId = speechId ; msg . payload . text = text ; msg . payload . provider = provider ; msg . payload . options = options ; m_messageBroker -> publish ( msg . toString ()); } // To get capabilities, publish the GetCapabilities message to the Engine std :: string MyTextToSpeechHandler::getCapabilities ( const std :: string & requestId , const std :: string & provider ) { GetCapabilitiesMessage msg ; msg . header . id = requestId ; msg . payload . provider = provider ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetCapabilitiesReply message // Return the capabilities from reply message payload } void MyTextToSpeechHandler::prepareSpeechCompleted ( const std :: string & speechId , const std :: string & streamId , const std :: string & metadata ) { // Use MessageBroker openStream API to get the MessageStream std :: shared_ptr < MessageStream > preparedAudio = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // Follow the UX guidelines in order to play the audio stream } // Notification of a failed speech synthesis void TextToSpeechHandler::prepareSpeechFailed ( const std :: string & speechId , const std :: string & reason ) { // Use the speechId to correlate the synthesis request to the result // Access the reason for failure } }; Android Integration \u00b6 The Alexa Auto Client Service (AACS) provides the AACS Text-To-Speech Service to integrate the Auto SDK Text-To-Speech module on Android. See the AACS Text-To-Speech Service documentation for more information.","title":"Text-To-Speech (TTS) Module"},{"location":"explore/features/text-to-speech/#text-to-speech-tts-module","text":"","title":"Text-To-Speech (TTS) Module"},{"location":"explore/features/text-to-speech/#overview","text":"The Text-To-Speech module enables your Alexa Auto SDK client application to synthesize Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. To synthesize speech, this module uses the Text-To-Speech-Provider module. The Auto SDK does not provide any speech-playing APIs. Your application's TTS module integration is responsible for playing the synthesized speech to deliver a unified Alexa experience to the user. Note: This feature may only be used with voice-guided turn-by-turn navigation. Important! The Text-To-Speech module requires the Local Voice Control extension.","title":"Overview"},{"location":"explore/features/text-to-speech/#configuring-the-text-to-speech-module","text":"The Text-To-Speech module does not require Engine configuration.","title":"Configuring the Text-To Speech-Module"},{"location":"explore/features/text-to-speech/#using-the-text-to-speech-aasb-messages","text":"","title":"Using the Text-To-Speech AASB Messages"},{"location":"explore/features/text-to-speech/#prepare-speech","text":"To request speech synthesis from a text or SSML input, your application must publish the PrepareSpeech message . The Engine publishes either the PrepareSpeechCompleted message or PrepareSpeechFailed message to indicate success or failure, respectively. Click to expand or collapse sequence diagram: Prepare Speech Note: The prepareSpeechFailed API contains the reason parameter that specifies the error string for failure. Refer to the TTS provider errors for more information on errors defined by the TTS provider. TThe TTS module defines the REQUEST_TIMED_OUT error that occurs when the TTS provider sends no response, causing the speech request to time out. The timeout value is 1000 milliseconds.","title":"Prepare Speech"},{"location":"explore/features/text-to-speech/#get-capabilities","text":"To request the capabilities of the TTS provider being used, your application must publish the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message reply with the capabilities of the TTS provider. Click to expand or collapse sequence diagram: Get Capabilities","title":"Get Capabilities"},{"location":"explore/features/text-to-speech/#integrating-the-text-to-speech-module-into-your-application","text":"","title":"Integrating the Text-To-Speech Module Into Your Application"},{"location":"explore/features/text-to-speech/#c-messagebroker-integration","text":"Use the MessageBroker to subscribe to and publish TextToSpeech AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/TextToSpeech/TextToSpeech/GetCapabilitiesMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechCompletedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechFailedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyTextToSpeechHandler { // Subscribe to messages from the Engine void MyTextToSpeechHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechCompletedMessage ( message ); }, PrepareSpeechCompletedMessage :: topic (), PrepareSpeechCompletedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechFailedMessage ( message ); }, PrepareSpeechFailedMessage :: topic (), PrepareSpeechFailedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCapabilitiesReplyMessage ( message ); }, GetCapabilitiesMessageReply :: topic (), GetCapabilitiesMessageReply :: action ()); } // Handle the PrepareSpeechCompleted message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechCompletedMessage ( const std :: string & message ) { PrepareSpeechCompletedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string streamId = msg . payload . streamId ; std :: string metadata = msg . payload . metadata ; prepareSpeechCompleted ( speechId , streamId , metadata ); } // Handle the PrepareSpeechFailed message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechFailedMessage ( const std :: string & message ) { PrepareSpeechFailedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string reason = msg . payload . reason ; prepareSpeechFailed ( speechId , reason ); } // Handle the GetCapabilities reply message from the Engine void MyTextToSpeechHandler::handleGetCapabilitiesReplyMessage ( const std :: string & message ) { GetCapabilitiesMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string capabilities = msg . payload . capabilities ; // ...Handle capabilities of the TTS provider... } // To prepare speech, publish the PrepareSpeech message to the Engine void MyTextToSpeechHandler::prepareSpeech ( const std :: string & speechId , const std :: string & text , const std :: string & provider , const std :: string & options ) { PrepareSpeechMessage msg ; msg . payload . speechId = speechId ; msg . payload . text = text ; msg . payload . provider = provider ; msg . payload . options = options ; m_messageBroker -> publish ( msg . toString ()); } // To get capabilities, publish the GetCapabilities message to the Engine std :: string MyTextToSpeechHandler::getCapabilities ( const std :: string & requestId , const std :: string & provider ) { GetCapabilitiesMessage msg ; msg . header . id = requestId ; msg . payload . provider = provider ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetCapabilitiesReply message // Return the capabilities from reply message payload } void MyTextToSpeechHandler::prepareSpeechCompleted ( const std :: string & speechId , const std :: string & streamId , const std :: string & metadata ) { // Use MessageBroker openStream API to get the MessageStream std :: shared_ptr < MessageStream > preparedAudio = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // Follow the UX guidelines in order to play the audio stream } // Notification of a failed speech synthesis void TextToSpeechHandler::prepareSpeechFailed ( const std :: string & speechId , const std :: string & reason ) { // Use the speechId to correlate the synthesis request to the result // Access the reason for failure } };","title":"C++ MessageBroker Integration"},{"location":"explore/features/text-to-speech/#android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS Text-To-Speech Service to integrate the Auto SDK Text-To-Speech module on Android. See the AACS Text-To-Speech Service documentation for more information.","title":"Android Integration"},{"location":"explore/features/text-to-speech-provider/","text":"Text-Speech Provider Module \u00b6 Overview \u00b6 The Text-To-Speech Provider module synthesizes Alexa speech on demand. Auto SDK supports one text-to-speech provider, which uses Alexa's voice as the default voice for speech synthesis. The Text-To-Speech Provider module performs the following functions: Generating speech from a text or SSML document to provide the speech to the TTS module. Providing capabilities based on the properties of the TTS provider, such as available locales. The TTS Provider module follows the existing AVS (Alexa Voice Service) protocol to carry out speech synthesis and requires connection to the Local Voice Control (LVC) service. If the device is disconnected from LVC, speech synthesis fails. Note : The module can synthesize speech only in the current locale as set by the application. Configuring the TTS Provider Module \u00b6 The Text-To-Speech Provider module does not require Engine configuration. Specifying the TTS Provider in AASB Messages \u00b6 In all of the text-to-speech AASB messages that involve the provider parameter, use the string, \"text-to-speech-provider\", to specify the TTS provider. Using TTS Provider Module with Different Input Types \u00b6 How the TTS Provider module synthesizes speech depends on the input type and the requestPayload field in the options parameter of the PrepareSpeech message published to the Engine when request speech synthesis. The requestPayload structure is as follows: { \"requestPayload\" : { \"voiceId\" : {VOICE_IDENTIFIER}, \"locale\" : {LOCALE_STRING} } } Note : You do not need to specify the requestPayload in the options parameter because currently only the default voice (Alexa\u2019s voice) is supported. Therefore, you can leave the options parameter unspecified or supply an empty string for it. The following list explains how the TTS Provider module synthesizes speech depending on the input type and requestPayload : If input is text and requestPayload is empty, the text is synthesized to speech with Alexa's voice and the current locale. If input is text and requestPayload specifies the voice and locale, the text is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is text and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains all the supported tags and requestPayload specifies voice and locale, the SSML document is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is SSML and contains all the supported tags, requestPayload is empty, the SSML document is synthesized to speech with Alexa's voice and current locale. If input is SSML and contains all the supported tags, and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains one or more unsupported tags, speech is synthesized but the unsupported tag is ignored. The text within the tag is synthesized normally. TTS Capability Returned \u00b6 To request the capabilities of the TTS provider being used, your application publishes the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message with the following payload structure: \"text-to-speech-provider\" : { \"voices\" : [ { \"voiceId\": \"Alexa\", \"locales\": [CURRENT_LOCALE] } ] } NOTE : The locale returned is always the current locale because you can load only one locale model at a time, which is the current locale. SSML Examples \u00b6 <speak> ETA <break time=\\\"3s\\\"/> three hours </speak> <speak> Turn right <emphasis level=\\\"strong\\\">in twenty feet</emphasis> </speak> <speak> Turn right on<lang xml:lang=\\\"fr-CA\\\">Moulin Rouge street.</lang> </speak> <speak> <p>Turn left in 500ft.</p> <p>Then turn right.</p> </speak> <speak>Turn left on, <phoneme alphabet=\\\"ipa\\\" ph=\\\"Bo.fort\\\">Beaufort</phoneme></speak> <speak> Turn right onto <phoneme alphabet='nt-sampa' ph='*\\\"stAk|t@n \\\"strit'>Stockton Street</phoneme> </speak> <speak> Your ETA is 5 minutes on <say-as interpret-as=\\\"date\\\" format=\\\"dmy\\\">12-10-2020</say-as>. </speak> <speak> Take a <prosody volume=\\\"-6dB\\\">U turn.</prosody> </speak> <speak> Take the next left onto <sub alias=\\\"John Doe\\\">JD</sub> street </speak> Errors \u00b6 The TTS provider defines its set of error strings or codes. The PrepareSpeechFailed message payload uses the reason parameter to send the error strings to the application. The following list describes the error strings used by the Local TTS provider: LOCALE_NOT_SUPPORTED occurs in any of the following situations: The language model for the current locale is missing. The locale specified in requestPayload is not the current locale. The locale specified is invalid. VOICE_NOT_SUPPORTED occurs when the application specifies in requestPayload an invalid voice or is not Alexa. INTERNAL_ERROR is an internal error that signifies an error when the TTS or TTS Provider module processes a request. PROVIDER_NOT_CONNECTED occurs when the provider is not connected to LVC and a speech synthesis request is made. NOTE : If a speech synthesis request is made during an ongoing Alexa dialog, the speech is synthesized after the current Alexa dialog ends.","title":"Text-Speech Provider Module"},{"location":"explore/features/text-to-speech-provider/#text-speech-provider-module","text":"","title":"Text-Speech Provider Module"},{"location":"explore/features/text-to-speech-provider/#overview","text":"The Text-To-Speech Provider module synthesizes Alexa speech on demand. Auto SDK supports one text-to-speech provider, which uses Alexa's voice as the default voice for speech synthesis. The Text-To-Speech Provider module performs the following functions: Generating speech from a text or SSML document to provide the speech to the TTS module. Providing capabilities based on the properties of the TTS provider, such as available locales. The TTS Provider module follows the existing AVS (Alexa Voice Service) protocol to carry out speech synthesis and requires connection to the Local Voice Control (LVC) service. If the device is disconnected from LVC, speech synthesis fails. Note : The module can synthesize speech only in the current locale as set by the application.","title":"Overview"},{"location":"explore/features/text-to-speech-provider/#configuring-the-tts-provider-module","text":"The Text-To-Speech Provider module does not require Engine configuration.","title":"Configuring the TTS Provider Module"},{"location":"explore/features/text-to-speech-provider/#specifying-the-tts-provider-in-aasb-messages","text":"In all of the text-to-speech AASB messages that involve the provider parameter, use the string, \"text-to-speech-provider\", to specify the TTS provider.","title":"Specifying the TTS Provider in AASB Messages"},{"location":"explore/features/text-to-speech-provider/#using-tts-provider-module-with-different-input-types","text":"How the TTS Provider module synthesizes speech depends on the input type and the requestPayload field in the options parameter of the PrepareSpeech message published to the Engine when request speech synthesis. The requestPayload structure is as follows: { \"requestPayload\" : { \"voiceId\" : {VOICE_IDENTIFIER}, \"locale\" : {LOCALE_STRING} } } Note : You do not need to specify the requestPayload in the options parameter because currently only the default voice (Alexa\u2019s voice) is supported. Therefore, you can leave the options parameter unspecified or supply an empty string for it. The following list explains how the TTS Provider module synthesizes speech depending on the input type and requestPayload : If input is text and requestPayload is empty, the text is synthesized to speech with Alexa's voice and the current locale. If input is text and requestPayload specifies the voice and locale, the text is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is text and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains all the supported tags and requestPayload specifies voice and locale, the SSML document is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is SSML and contains all the supported tags, requestPayload is empty, the SSML document is synthesized to speech with Alexa's voice and current locale. If input is SSML and contains all the supported tags, and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains one or more unsupported tags, speech is synthesized but the unsupported tag is ignored. The text within the tag is synthesized normally.","title":"Using TTS Provider Module with Different Input Types"},{"location":"explore/features/text-to-speech-provider/#tts-capability-returned","text":"To request the capabilities of the TTS provider being used, your application publishes the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message with the following payload structure: \"text-to-speech-provider\" : { \"voices\" : [ { \"voiceId\": \"Alexa\", \"locales\": [CURRENT_LOCALE] } ] } NOTE : The locale returned is always the current locale because you can load only one locale model at a time, which is the current locale.","title":"TTS Capability Returned"},{"location":"explore/features/text-to-speech-provider/#ssml-examples","text":"<speak> ETA <break time=\\\"3s\\\"/> three hours </speak> <speak> Turn right <emphasis level=\\\"strong\\\">in twenty feet</emphasis> </speak> <speak> Turn right on<lang xml:lang=\\\"fr-CA\\\">Moulin Rouge street.</lang> </speak> <speak> <p>Turn left in 500ft.</p> <p>Then turn right.</p> </speak> <speak>Turn left on, <phoneme alphabet=\\\"ipa\\\" ph=\\\"Bo.fort\\\">Beaufort</phoneme></speak> <speak> Turn right onto <phoneme alphabet='nt-sampa' ph='*\\\"stAk|t@n \\\"strit'>Stockton Street</phoneme> </speak> <speak> Your ETA is 5 minutes on <say-as interpret-as=\\\"date\\\" format=\\\"dmy\\\">12-10-2020</say-as>. </speak> <speak> Take a <prosody volume=\\\"-6dB\\\">U turn.</prosody> </speak> <speak> Take the next left onto <sub alias=\\\"John Doe\\\">JD</sub> street </speak>","title":"SSML Examples"},{"location":"explore/features/text-to-speech-provider/#errors","text":"The TTS provider defines its set of error strings or codes. The PrepareSpeechFailed message payload uses the reason parameter to send the error strings to the application. The following list describes the error strings used by the Local TTS provider: LOCALE_NOT_SUPPORTED occurs in any of the following situations: The language model for the current locale is missing. The locale specified in requestPayload is not the current locale. The locale specified is invalid. VOICE_NOT_SUPPORTED occurs when the application specifies in requestPayload an invalid voice or is not Alexa. INTERNAL_ERROR is an internal error that signifies an error when the TTS or TTS Provider module processes a request. PROVIDER_NOT_CONNECTED occurs when the provider is not connected to LVC and a speech synthesis request is made. NOTE : If a speech synthesis request is made during an ongoing Alexa dialog, the speech is synthesized after the current Alexa dialog ends.","title":"Errors"},{"location":"native/","text":"Auto SDK Native C++ Developer Guide \u00b6 Overview \u00b6 This guide outlines how to set up, build, and integrate Auto SDK into your native C++ application. Use this guide if you develop for a head unit running a Linux or QNX operating system. Prerequisites \u00b6 Follow the steps in the general Get Started with Auto SDK guide to set up an Amazon developer account, access to the Auto SDK source code, and understand the core API and features. Read the Build Alexa Auto SDK guide to learn about how the Auto SDK build system works and understand how to build the SDK for your host and target hardware combination. (Optional) Try the sample app \u00b6 Auto SDK provides a C++ sample app that you can run on a Linux, QNX, or macOS machine to try sample utterances that exercise the Auto SDK APIs. See the C++ sample app documentation for more information about building and using the sample app. Build Auto SDK libraries \u00b6 Follow the instructions in Build Alexa Auto SDK to build the Auto SDK for your target platform. The output of your build command will be an archive in the ${AUTO_SDK_HOME}/builder/deploy/ directory. Extract the archive contents to find the Auto SDK libraries and headers. For example, aac-dev-macos_x86_64-release-220111103523/ \u251c\u2500 docs/ \u251c\u2500 include/ \u2502 \u251c\u2500\u2500 AACE \u2502 \u2514\u2500\u2500 AASB \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ \u2514\u2500 aac-buildinfo.txt Link the libraries from lib to your application, and include the headers from include . Manage the Engine lifecycle in your application \u00b6 To use Auto SDK features, your application must instantiate and manage the lifecycle of the Engine. Create the Engine \u00b6 During the launch sequence of your application, create an instance of the Engine using the static function Engine::create() : #include <AACE/Core/Engine.h> std :: shared_ptr < aace :: core :: Engine > engine = aace :: core :: Engine :: create (); A typical application creates the Engine once when the user turns on the vehicle ignition and uses the instance until the user turns off the vehicle ignition. Configure the Engine \u00b6 After creating the Engine instance, configure the Engine with the required Engine configurations for every module that you use. Engine configuration uses serialized JSON strings, but you pass the configurations to the Engine in one or more aace::core::config::EngineConfiguration wrapper objects. Auto SDK provides two options to generate EngineConfiguration objects: Specify your Engine configuration in a JSON file and construct an EngineConfiguration from a path to the file Build the configuration programmatically using one of the configuration factory functions. You can choose either option or a combination of both. I.e., you can generate a single EngineConfiguration object that includes all configuration data for the Engine components you use, or you can break up the configuration data into logical sections and generate multiple EngineConfiguration objects. For example, you might generate one EngineConfiguration object for each module. To configure the Engine, call the Engine::configure() function, passing in the EngineConfiguration object(s): For a single EngineConfiguration object: engine->configure( config ); For multiple EngineConfiguration objects: engine->configure( { xConfig, yConfig, zConfig } ); replacing xConfig , yConfig , zConfig with logical names to identify the EngineConfiguration objects you generated. See the documentation for individual module features to see the format of each module's respective JSON configuration. Note : For one Engine instance, you can call the configure() function only once, and you must call it before you subscribe to AASB messages or start the Engine . Specify configuration in a file \u00b6 Auto SDK provides the ConfigurationFile class that reads the JSON configuration from a specified file path and creates an EngineConfiguration object from the configuration: #include <AACE/Core/EngineConfiguration.h> aace :: core :: config :: ConfigurationFile :: create ( \"</path/to/filename.json>\" ) You can include all the configuration data in a single JSON file to create a single EngineConfiguration object. For example, auto config = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/config/config.json\" ); engine -> configure ( config ); Alternatively, you can break the configuration data into multiple JSON files to create multiple EngineConfiguration objects. For example, auto coreConfig = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/data/core-config.json\" ); auto alexaConfig = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/data/alexa-config.json\" ); auto navigationConfig = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/data/navigation-config.json\" ); engine -> configure ({ coreConfig , alexaConfig , navigationConfig }); Specify configuration programmatically \u00b6 Each Auto SDK module that defines configuration provides a factory class with functions that return EngineConfiguration objects. The values a function puts in the configuration it creates correspond to the function parameters. For example, you can configure the Alexa module's alertsCapabilityAgent settings by using the AlexaConfiguration::createAlertsConfig() function: auto alertsConfig = aace :: alexa :: config :: AlexaConfiguration :: createAlertsConfig ( \"</some/directory/path/for/databases/alerts.db>\" ); Register for AASB Messages \u00b6 After you configure the Engine, get the MessageBroker instance from the Engine instance: std :: shared_ptr < aace :: core :: MessageBroker > messageBroker = engine -> getMessageBroker (); Use MessageBroker to subscribe to any AASB messages that your application will handle. See Understand how to use MessageBroker for further information. Note : For one Engine instance, you must subscribe to messages after configuring the Engine and before starting the Engine . Start the Engine \u00b6 After configuring the Engine and subscribing to AASB messages, start the Engine by calling the Engine::start() function: engine -> start (); Engine start initializes the internal Engine components for each Engine service your application uses. With respect to Alexa, start initiates the connection to Alexa if there is an internet connection and an Alexa access token. Wait to publish AASB messages to the Engine until after start() returns. Your application can start the Engine more than once in its lifetime, if needed, by stopping the Engine and starting it again. However, you cannot start the Engine again after shutting it down. Stop the Engine \u00b6 When your application needs to halt the operations of the Engine, stop the Engine by calling the Engine::stop() function: engine -> stop (); With respect to Alexa, stopping the Engine tears down the Alexa connection. Typically, Engine stop is a cleanup step before Engine shutdown. However, if you stopped the Engine at runtime and need to start it again, calling start() resumes Engine operations. With respect to Alexa, this includes reestablishing the Alexa connection. Shut down the Engine \u00b6 When your application is ready to exit, shut down the Engine by calling the Engine's shutdown() function. engine -> shutdown (); Make sure you also stop the Engine prior to shutting it down. After shutdown completes, you can safely dispose of the pointer to your Engine instance. You cannot use this instance of the Engine again. Understand how to use MessageBroker \u00b6 As outlined in Auto SDK Core API Overview , your application will use MessageBroker to interface with the Engine by exchanging AASB messages. The Message Broker uses AASB messages as serialized JSON strings; however, Auto SDK provides C++ wrapper classes for each message that help with the serialization and de-serialization. The Auto SDK build system generates these wrapper classes as part of the build. For example, if the build output archive file is aac-dev-macos_x86_64-release-220111103523.tgz , the extracted archive contains the AASB messages for each interface in a directory structure like the following example: aac-dev-macos_x86_64-release-220111103523 \u251c\u2500\u2500 aac-buildinfo.txt \u251c\u2500\u2500 bin \u251c\u2500\u2500 docs \u251c\u2500\u2500 include \u2502 \u251c\u2500\u2500 AACE \u2502 \u2514\u2500\u2500 AASB \u2502 \u2514\u2500\u2500 Message \u2502 \u251c\u2500\u2500 Alexa \u2502 \u2502 \u251c\u2500\u2500 ...directory for other interface in Alexa module... \u2502 \u2502 \u2502 \u251c\u2500\u2500 ...message header 1 for this other interface... \u2502 \u2502 \u2502 \u2514\u2500\u2500 ...message header 2 for this other interface... \u2502 \u2502 \u251c\u2500\u2500 SpeechRecognizer \u2502 \u2502 \u2502 \u251c\u2500\u2500 EndOfSpeechDetectedMessage.h \u2502 \u2502 \u2502 \u251c\u2500\u2500 Initiator.h \u2502 \u2502 \u2502 \u251c\u2500\u2500 StartCaptureMessage.h \u2502 \u2502 \u2502 \u251c\u2500\u2500 StopCaptureMessage.h \u2502 \u2502 \u2502 \u2514\u2500\u2500 WakewordDetectedMessage.h \u2502 \u2502 \u2514\u2500\u2500 ...directory for other interface in Alexa module... \u2502 \u251c\u2500\u2500 ...directory for other module... \u2502 \u2502 \u251c\u2500\u2500 ...directory for other interface in this module... \u2502 \u2514\u2500\u2500 ...directory for other module... \u251c\u2500\u2500 lib \u2514\u2500\u2500 share The header file StartCaptureMessage.h , for example, represents the incoming SpeechRecognizer.StartCapture AASB message, and the header contains a class your application can use to build the message in the correct format and then convert it to a string to publish with MessageBroker . Similarly, the WakewordDetectedMessage.h header file contains a class your application can use to easily subscribe to the SpeechRecognizer.WakewordDetectedMessage message and de-serialize the message when you receive it from the Engine. The following example code uses the AASB message wrapper classes for the SpeechRecognizer interface to subscribe to messages from the Engine with SpeechRecognizer topic: #include <AASB/Message/Alexa/SpeechRecognizer/EndOfSpeechDetectedMessage.h> #include <AASB/Message/Alexa/SpeechRecognizer/WakewordDetectedMessage.h> // call this function before starting the Engine void SpeechRecognizerHandler::subscribeToAASBMessages () { messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleEndOfSpeechDetectedMessage ( message ); }, EndOfSpeechDetectedMessage :: topic (), // equivalent to \"SpeechRecognizer\" EndOfSpeechDetectedMessage :: action ()); // equivalent to \"EndOfSpeechDetected\" messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleWakewordDetectedMessage ( message ); }, WakewordDetectedMessage :: topic (), // equivalent to \"SpeechRecognizer\" WakewordDetectedMessage :: action ()); // equivalent to \"WakewordDetected\" } void SpeechRecognizerHandler::handleEndOfSpeechDetectedMessage ( const std :: string & message ) { // Your application defines this handling function. // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message. // Per the AASB message documentation, this message has no payload. // Do something here, and return quickly to avoid blocking MessageBroker's outgoing thread. } void SpeechRecognizerHandler::handleWakewordDetectedMessage ( const std :: string & message ) { // Your application defines this handling function. // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.WakewordDetected message. // You can use the WakewordDetectedMessage class to deserialize the message. // The payload of this message is simple, but other messages may contain more complex payloads. WakewordDetectedMessage msg = json :: parse ( message ); std :: string ww = msg . payload . wakeword ; // This string contains the wake word that the Engine detected // Do something here, and return quickly to avoid blocking MessageBroker's outgoing thread. } For every AASB message interface that you wish to handle, your application will define code like the above example in which you define a function to handle each \"outgoing\" message (or one function to handle all outgoing messages) and subscribe the function to MessageBroker by specifying the topic and action combination that the function will handle. In the implementation of the handling functions, you must return quickly and delegate any time-consuming handling to a worker thread. When you need to publish an \"incoming\" message to the Engine, you can construct the message JSON string directly or, preferably because it's simpler, use the AASB message helper class to construct the message and convert it to a string. Then use MessageBroker to publish the message to the Engine. For example, #include <AASB/Message/Alexa/SpeechRecognizer/Initiator.h> #include <AASB/Message/Alexa/SpeechRecognizer/StartCaptureMessage.h> // call this function when the user tapped the Alexa invocation button to initiate an interaction void SpeechRecognizerHandler::tapToTalk ( Initiator initiator ) { StartCaptureMessage msg ; msg . payload . initiator = Initiator :: TAP_TO_TALK ; m_messageBroker -> publish ( msg . toString ()); } Only publish messages to the Engine after the Engine was started successfully (i.e., after Engine::start() returned true ). Implement features \u00b6 The Auto SDK feature documentation provides detailed documentation for each individual Auto SDK module and explains the Engine configuration and AASB messages you must implement in order to use the features the module provides. Follow the feature documentation as you integrate features into your application. Tip to get started quickly \u00b6 To get your application up and running as quickly as possible if you wish to develop features incrementally, you can start by integrating only the Core , Alexa , CBL , and System Audio modules. In particular, follow these high level guidelines: Implement the Engine lifecycle management described above. Read the documentation for each of these four modules. Provide the required Engine configuration for each of these modules. Integrate the AASB messages for the following interfaces: Authorization Note: CBL completes most of the implementation for you. AudioInput and AudioOutput Note: System Audio completes the implementation for you. PropertyManager Note: You can start by handling only the properties defined by the modules you initially use SpeechRecognizer with TAP_TO_TALK initiation. After you have completed this bare minimum integration, you should be able to start the Engine in your application and invoke Alexa by button press to ask a simple question such as \"What's the weather?\"","title":"Overview"},{"location":"native/#auto-sdk-native-c-developer-guide","text":"","title":"Auto SDK Native C++ Developer Guide"},{"location":"native/#overview","text":"This guide outlines how to set up, build, and integrate Auto SDK into your native C++ application. Use this guide if you develop for a head unit running a Linux or QNX operating system.","title":"Overview"},{"location":"native/#prerequisites","text":"Follow the steps in the general Get Started with Auto SDK guide to set up an Amazon developer account, access to the Auto SDK source code, and understand the core API and features. Read the Build Alexa Auto SDK guide to learn about how the Auto SDK build system works and understand how to build the SDK for your host and target hardware combination.","title":"Prerequisites"},{"location":"native/#optional-try-the-sample-app","text":"Auto SDK provides a C++ sample app that you can run on a Linux, QNX, or macOS machine to try sample utterances that exercise the Auto SDK APIs. See the C++ sample app documentation for more information about building and using the sample app.","title":"(Optional) Try the sample app"},{"location":"native/#build-auto-sdk-libraries","text":"Follow the instructions in Build Alexa Auto SDK to build the Auto SDK for your target platform. The output of your build command will be an archive in the ${AUTO_SDK_HOME}/builder/deploy/ directory. Extract the archive contents to find the Auto SDK libraries and headers. For example, aac-dev-macos_x86_64-release-220111103523/ \u251c\u2500 docs/ \u251c\u2500 include/ \u2502 \u251c\u2500\u2500 AACE \u2502 \u2514\u2500\u2500 AASB \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ \u2514\u2500 aac-buildinfo.txt Link the libraries from lib to your application, and include the headers from include .","title":"Build Auto SDK libraries"},{"location":"native/#manage-the-engine-lifecycle-in-your-application","text":"To use Auto SDK features, your application must instantiate and manage the lifecycle of the Engine.","title":"Manage the Engine lifecycle in your application"},{"location":"native/#create-the-engine","text":"During the launch sequence of your application, create an instance of the Engine using the static function Engine::create() : #include <AACE/Core/Engine.h> std :: shared_ptr < aace :: core :: Engine > engine = aace :: core :: Engine :: create (); A typical application creates the Engine once when the user turns on the vehicle ignition and uses the instance until the user turns off the vehicle ignition.","title":"Create the Engine"},{"location":"native/#configure-the-engine","text":"After creating the Engine instance, configure the Engine with the required Engine configurations for every module that you use. Engine configuration uses serialized JSON strings, but you pass the configurations to the Engine in one or more aace::core::config::EngineConfiguration wrapper objects. Auto SDK provides two options to generate EngineConfiguration objects: Specify your Engine configuration in a JSON file and construct an EngineConfiguration from a path to the file Build the configuration programmatically using one of the configuration factory functions. You can choose either option or a combination of both. I.e., you can generate a single EngineConfiguration object that includes all configuration data for the Engine components you use, or you can break up the configuration data into logical sections and generate multiple EngineConfiguration objects. For example, you might generate one EngineConfiguration object for each module. To configure the Engine, call the Engine::configure() function, passing in the EngineConfiguration object(s): For a single EngineConfiguration object: engine->configure( config ); For multiple EngineConfiguration objects: engine->configure( { xConfig, yConfig, zConfig } ); replacing xConfig , yConfig , zConfig with logical names to identify the EngineConfiguration objects you generated. See the documentation for individual module features to see the format of each module's respective JSON configuration. Note : For one Engine instance, you can call the configure() function only once, and you must call it before you subscribe to AASB messages or start the Engine .","title":"Configure the Engine"},{"location":"native/#specify-configuration-in-a-file","text":"Auto SDK provides the ConfigurationFile class that reads the JSON configuration from a specified file path and creates an EngineConfiguration object from the configuration: #include <AACE/Core/EngineConfiguration.h> aace :: core :: config :: ConfigurationFile :: create ( \"</path/to/filename.json>\" ) You can include all the configuration data in a single JSON file to create a single EngineConfiguration object. For example, auto config = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/config/config.json\" ); engine -> configure ( config ); Alternatively, you can break the configuration data into multiple JSON files to create multiple EngineConfiguration objects. For example, auto coreConfig = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/data/core-config.json\" ); auto alexaConfig = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/data/alexa-config.json\" ); auto navigationConfig = aace :: core :: config :: ConfigurationFile :: create ( \"/opt/AAC/data/navigation-config.json\" ); engine -> configure ({ coreConfig , alexaConfig , navigationConfig });","title":"Specify configuration in a file"},{"location":"native/#specify-configuration-programmatically","text":"Each Auto SDK module that defines configuration provides a factory class with functions that return EngineConfiguration objects. The values a function puts in the configuration it creates correspond to the function parameters. For example, you can configure the Alexa module's alertsCapabilityAgent settings by using the AlexaConfiguration::createAlertsConfig() function: auto alertsConfig = aace :: alexa :: config :: AlexaConfiguration :: createAlertsConfig ( \"</some/directory/path/for/databases/alerts.db>\" );","title":"Specify configuration programmatically"},{"location":"native/#register-for-aasb-messages","text":"After you configure the Engine, get the MessageBroker instance from the Engine instance: std :: shared_ptr < aace :: core :: MessageBroker > messageBroker = engine -> getMessageBroker (); Use MessageBroker to subscribe to any AASB messages that your application will handle. See Understand how to use MessageBroker for further information. Note : For one Engine instance, you must subscribe to messages after configuring the Engine and before starting the Engine .","title":"Register for AASB Messages"},{"location":"native/#start-the-engine","text":"After configuring the Engine and subscribing to AASB messages, start the Engine by calling the Engine::start() function: engine -> start (); Engine start initializes the internal Engine components for each Engine service your application uses. With respect to Alexa, start initiates the connection to Alexa if there is an internet connection and an Alexa access token. Wait to publish AASB messages to the Engine until after start() returns. Your application can start the Engine more than once in its lifetime, if needed, by stopping the Engine and starting it again. However, you cannot start the Engine again after shutting it down.","title":"Start the Engine"},{"location":"native/#stop-the-engine","text":"When your application needs to halt the operations of the Engine, stop the Engine by calling the Engine::stop() function: engine -> stop (); With respect to Alexa, stopping the Engine tears down the Alexa connection. Typically, Engine stop is a cleanup step before Engine shutdown. However, if you stopped the Engine at runtime and need to start it again, calling start() resumes Engine operations. With respect to Alexa, this includes reestablishing the Alexa connection.","title":"Stop the Engine"},{"location":"native/#shut-down-the-engine","text":"When your application is ready to exit, shut down the Engine by calling the Engine's shutdown() function. engine -> shutdown (); Make sure you also stop the Engine prior to shutting it down. After shutdown completes, you can safely dispose of the pointer to your Engine instance. You cannot use this instance of the Engine again.","title":"Shut down the Engine"},{"location":"native/#understand-how-to-use-messagebroker","text":"As outlined in Auto SDK Core API Overview , your application will use MessageBroker to interface with the Engine by exchanging AASB messages. The Message Broker uses AASB messages as serialized JSON strings; however, Auto SDK provides C++ wrapper classes for each message that help with the serialization and de-serialization. The Auto SDK build system generates these wrapper classes as part of the build. For example, if the build output archive file is aac-dev-macos_x86_64-release-220111103523.tgz , the extracted archive contains the AASB messages for each interface in a directory structure like the following example: aac-dev-macos_x86_64-release-220111103523 \u251c\u2500\u2500 aac-buildinfo.txt \u251c\u2500\u2500 bin \u251c\u2500\u2500 docs \u251c\u2500\u2500 include \u2502 \u251c\u2500\u2500 AACE \u2502 \u2514\u2500\u2500 AASB \u2502 \u2514\u2500\u2500 Message \u2502 \u251c\u2500\u2500 Alexa \u2502 \u2502 \u251c\u2500\u2500 ...directory for other interface in Alexa module... \u2502 \u2502 \u2502 \u251c\u2500\u2500 ...message header 1 for this other interface... \u2502 \u2502 \u2502 \u2514\u2500\u2500 ...message header 2 for this other interface... \u2502 \u2502 \u251c\u2500\u2500 SpeechRecognizer \u2502 \u2502 \u2502 \u251c\u2500\u2500 EndOfSpeechDetectedMessage.h \u2502 \u2502 \u2502 \u251c\u2500\u2500 Initiator.h \u2502 \u2502 \u2502 \u251c\u2500\u2500 StartCaptureMessage.h \u2502 \u2502 \u2502 \u251c\u2500\u2500 StopCaptureMessage.h \u2502 \u2502 \u2502 \u2514\u2500\u2500 WakewordDetectedMessage.h \u2502 \u2502 \u2514\u2500\u2500 ...directory for other interface in Alexa module... \u2502 \u251c\u2500\u2500 ...directory for other module... \u2502 \u2502 \u251c\u2500\u2500 ...directory for other interface in this module... \u2502 \u2514\u2500\u2500 ...directory for other module... \u251c\u2500\u2500 lib \u2514\u2500\u2500 share The header file StartCaptureMessage.h , for example, represents the incoming SpeechRecognizer.StartCapture AASB message, and the header contains a class your application can use to build the message in the correct format and then convert it to a string to publish with MessageBroker . Similarly, the WakewordDetectedMessage.h header file contains a class your application can use to easily subscribe to the SpeechRecognizer.WakewordDetectedMessage message and de-serialize the message when you receive it from the Engine. The following example code uses the AASB message wrapper classes for the SpeechRecognizer interface to subscribe to messages from the Engine with SpeechRecognizer topic: #include <AASB/Message/Alexa/SpeechRecognizer/EndOfSpeechDetectedMessage.h> #include <AASB/Message/Alexa/SpeechRecognizer/WakewordDetectedMessage.h> // call this function before starting the Engine void SpeechRecognizerHandler::subscribeToAASBMessages () { messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleEndOfSpeechDetectedMessage ( message ); }, EndOfSpeechDetectedMessage :: topic (), // equivalent to \"SpeechRecognizer\" EndOfSpeechDetectedMessage :: action ()); // equivalent to \"EndOfSpeechDetected\" messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleWakewordDetectedMessage ( message ); }, WakewordDetectedMessage :: topic (), // equivalent to \"SpeechRecognizer\" WakewordDetectedMessage :: action ()); // equivalent to \"WakewordDetected\" } void SpeechRecognizerHandler::handleEndOfSpeechDetectedMessage ( const std :: string & message ) { // Your application defines this handling function. // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message. // Per the AASB message documentation, this message has no payload. // Do something here, and return quickly to avoid blocking MessageBroker's outgoing thread. } void SpeechRecognizerHandler::handleWakewordDetectedMessage ( const std :: string & message ) { // Your application defines this handling function. // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.WakewordDetected message. // You can use the WakewordDetectedMessage class to deserialize the message. // The payload of this message is simple, but other messages may contain more complex payloads. WakewordDetectedMessage msg = json :: parse ( message ); std :: string ww = msg . payload . wakeword ; // This string contains the wake word that the Engine detected // Do something here, and return quickly to avoid blocking MessageBroker's outgoing thread. } For every AASB message interface that you wish to handle, your application will define code like the above example in which you define a function to handle each \"outgoing\" message (or one function to handle all outgoing messages) and subscribe the function to MessageBroker by specifying the topic and action combination that the function will handle. In the implementation of the handling functions, you must return quickly and delegate any time-consuming handling to a worker thread. When you need to publish an \"incoming\" message to the Engine, you can construct the message JSON string directly or, preferably because it's simpler, use the AASB message helper class to construct the message and convert it to a string. Then use MessageBroker to publish the message to the Engine. For example, #include <AASB/Message/Alexa/SpeechRecognizer/Initiator.h> #include <AASB/Message/Alexa/SpeechRecognizer/StartCaptureMessage.h> // call this function when the user tapped the Alexa invocation button to initiate an interaction void SpeechRecognizerHandler::tapToTalk ( Initiator initiator ) { StartCaptureMessage msg ; msg . payload . initiator = Initiator :: TAP_TO_TALK ; m_messageBroker -> publish ( msg . toString ()); } Only publish messages to the Engine after the Engine was started successfully (i.e., after Engine::start() returned true ).","title":"Understand how to use MessageBroker"},{"location":"native/#implement-features","text":"The Auto SDK feature documentation provides detailed documentation for each individual Auto SDK module and explains the Engine configuration and AASB messages you must implement in order to use the features the module provides. Follow the feature documentation as you integrate features into your application.","title":"Implement features"},{"location":"native/#tip-to-get-started-quickly","text":"To get your application up and running as quickly as possible if you wish to develop features incrementally, you can start by integrating only the Core , Alexa , CBL , and System Audio modules. In particular, follow these high level guidelines: Implement the Engine lifecycle management described above. Read the documentation for each of these four modules. Provide the required Engine configuration for each of these modules. Integrate the AASB messages for the following interfaces: Authorization Note: CBL completes most of the implementation for you. AudioInput and AudioOutput Note: System Audio completes the implementation for you. PropertyManager Note: You can start by handling only the properties defined by the modules you initially use SpeechRecognizer with TAP_TO_TALK initiation. After you have completed this bare minimum integration, you should be able to start the Engine in your application and invoke Alexa by button press to ask a simple question such as \"What's the weather?\"","title":"Tip to get started quickly"},{"location":"native/building/","text":"Build Alexa Auto SDK \u00b6 Supported platforms and architectures \u00b6 Auto SDK can be built for the following supported target platforms and hardware architectures: Android 5.1 Lollipop API Level 22 or higher. ARM 64-bit x86 64-bit QNX 7.0 ARM 64-bit x86 64-bit Generic Linux x86 64-bit Poky Linux ARMv7a (+NEON) AArch64 macOS x86 64-bit General build requirements \u00b6 You can build the Alexa Auto SDK natively on a Linux or macOS host, or you can use Docker. For specific information about Docker, see Build in a Docker container . The following list describes the supported host configurations: Operating system: macOS Sierra Ubuntu 18.04 LTS (Bionic) or Ubuntu 20.04 LTS (Focal) Processor: 2.5 GHz Memory: 16 Gb Storage: 1 Gb+ available to use Build dependencies \u00b6 To build Auto SDK, you must install the following dependencies on your host machine: General \u00b6 Python 3.7 Conan 1.45 CMake 3.12 Linux \u00b6 GCC GStreamer (see Install GStreamer ) macOS \u00b6 Xcode Understand the build system \u00b6 Building software for multiple platforms can be complex because specific toolchains might vary depending on the build system and target platform. In general, there are two flavors of builds: native and cross-compiled. In a native build, the build system uses its own toolchain and libraries to build the software, so the compiled software can run on the platform that built it. In cross-compilation, the build system typically uses an installed toolchain to compile the software for a different target platform. It's possible that more than one toolchain is installed on a system, so extra steps are typically needed to cross-compile to those targets. Auto SDK uses Conan , along with other tools and scripts described in this section, to manage the complexities required to implement a complete build system. Conan \u00b6 The Auto SDK build system uses Conan as its underlying package manager and build configuration tool. For every Conan package, there is a recipe that defines the dependencies of the package and specifies how to download and build the package source code. After building a package, Conan copies the binaries and other artifacts into a cache directory so other recipes that depend on that package can use the prebuilt binaries without rebuilding them. When a Conan recipe defines a dependency, Conan finds and builds the dependency as required, taking care of complexities such as transitive requirements, package version conflicts, and managing multiple versions of a package built with different configurations. Before using a package, Conan must export or download the package into the local cache. When a package recipe exists in the same local repository as the source code it builds, as is the case when you download Auto SDK, you must run conan create or conan export before other recipes can build the package. Community servers such as Conan Center host some popular third party libraries, however, so Conan automatically downloads them to the local cache as needed. Auto SDK requires a combination of Conan packages including local recipes for Auto SDK modules and tools, local recipes for third party packages, and third party packages hosted on the Conan Center server. Once Conan copies a package into the local cache, a recipe can build or consume the package based on the specified build configuration. Conan will build a new package version if the package version is required and missing from the cache. For example, if you build Auto SDK for Linux, Conan will build all of the required packages for the specified Linux target. If you then build for an Android target, Conan will rebuild all of the required packages for the Android target and cache both the Linux and Android versions. In addition to target platform, any option or setting that you specify when building a recipe affects the package version. Auto SDK modules \u00b6 Auto SDK includes a base Conan recipe class that all Auto SDK modules extend. This is defined in conan/recipes/aac-sdk-tools , and must be exported before other modules since it is required by each module's recipe definition. The base recipe defines common build options, and relies on specific conventions in the module's directory structure to find source files and headers, and to generate other artifacts that are needed at build time. A simple Conan recipe is required for each module to override abstract values in the base class (such as the module name), and to define any module specific dependencies or options that are required. A module can also define it's own CMake files, unique configuration, or even custom build steps as needed. For each module, the base recipe defines common options that are used to specify which components are included in the library. The default values provided in the base recipe should be used in most cases when you are building release libraries for production. For some cases, however, you may want to enabled features such as with_sensitive_logs or with_unit_tests , to add additional information when debugging issues with the libraries. To find out which options are defined for a specific module, you can use the conan inspect command to display information about any Conan recipe. This command will display all of options and default values for a recipe, including any options that are inherited from the base module recipe. See the Specify build settings and options section in this guide, for more information. Applications integrate with Auto SDK using the MessageBroker API by publishing and subscribing to specific message topics and actions (see Understand the Auto SDK API ). Most modules provide interfaces that require these messages to be defined, in which case they will include one or more message definition files in the aasb/messages directory of the module. The model created by the message definitions are used when building Auto SDK to generate message headers that are required to build the module, and are also used to create documentation for each message interface. Third party dependencies \u00b6 Auto SDK has dependencies on several third party packages (libraries and build tools for example), which may themselves have dependencies on other packages. In general, managing these types of build requirements can be very complex for a large project. Conan helps by providing community hosted recipes for many common packages, as well as by allowing developers to create there own package recipes. It is important to understand that some of the packages used by Auto SDK are pulled from the Conan Center remote server, while others are defined locally in the conan/recipes directory of Auto SDK. Local recipes are typically required when the package does not already exist on Conan Center, or there are specific patches or changes to the recipe that are needed for Auto SDK. Builder Tool \u00b6 The Builder Tool is a script that can be used to build Auto SDK libraries for supported platforms. It improves the build process by wrapping underlying Conan commands and options with a simple command line interface. Although it is possible to use Conan by itself to build Auto SDK\u2014see Build with Conan directly \u2014it is recommended to use the Builder Tool for common build tasks. Alexa Auto Client Service \u00b6 Alexa Auto Client Service (AACS) is an Android service library that simplifies the process of integrating Auto SDK on Android-based devices. AACS has a dependency on Auto SDK native Android libraries, but can be built independently using standard Android development tools. For more information about building AACS, see the Android developer documentation . Build with Builder Tool \u00b6 The Builder Tool script, build.py is located in the builder directory of the SDK. It wraps underlying Conan commands, and simplifies building libraries for Auto SDK modules on supported platforms. Individual modules, components, and dependencies in the SDK are described as packages in the builder. Each package has a corresponding Conan recipe that is used to build and deploy the package to the cache located in the builder's home directory. An archive containing all of the specified build artifacts is created from the cache, and written to the deploy directory of the builder, after the build has completed. This section describes the most common commands used to build Auto SDK. For a complete reference to the Builder Tool command line interface, see Builder Tool command reference . Auto SDK supports native builds for Ubuntu Linux (x86_64) and MacOS, and building for each platform follows the same steps. After cloning the Auto SDK git repository on your system, the following examples should be run with alexa-auto-sdk as the working directory. The following command will build all of the modules that are included in the Auto SDK repository, along with any dependencies that are required for the target platform: $ ./builder/build.py When you run the build command, the builder tool will export and configure any new build artifacts, such as package recipes or configuration files, that are discovered in the search path. The first time you run (or after cleaning the build cache), you'll see several log messages indicating that the build recipes are being exported to the local cache: [ BUILDER ] INFO: Python version: 3 .7.3 [ BUILDER ] INFO: Cleaning cached builder data [ BUILDER ] INFO: Builder home: ../aac-sdk/builder/.builder [ BUILDER ] INFO: Conan home: ../aac-sdk/builder/.builder/.conan [ BUILDER ] INFO: Gradle home: ../aac-sdk/builder/.builder/.gradle [ BUILDER ] INFO: Configuring Conan... [ BUILDER ] INFO: Installing Conan configuration: ../aac-sdk/conan/config [ BUILDER ] INFO: Exporting recipe: aac-sdk-tools [ BUILDER ] INFO: Exporting recipe: aac-module-core [ BUILDER ] INFO: Exporting recipe: aac-module-alexa [ BUILDER ] INFO: Exporting recipe: aac-module-cbl [ BUILDER ] INFO: Exporting recipe: android-sdk-tools [ BUILDER ] INFO: Exporting recipe: avs-device-sdk ... The builder keeps track of which recipes have already been added to the cache, so that the next time you run the build command only new recipes will be exported. It is possible, however, to tell the builder to force re-exporting a recipe (using the -f or --force option), and build it if necessary. The following command will force all Auto SDK module recipes to be re-exported: $ ./builder/build.py -f \"aac-module-*\" To explicitly force one or more recipes to be exported, you can specify the name of the module (or explicit package name) that you want. The following example will force the builder to re-export and build only the alexa and cbl modules. $ ./builder/build.py -f alexa cbl Each time the builder is run, it will also attempt to re-configure Conan settings by initializing the Conan configuration and installing any config files found in the search path. This happens every time because it is possible, using Docker for example, to re-use the Conan home path when building with a different build system configuration. This step ensures that the Conan configuration will match the build system currently being used. In the case that you want to skip the configuration step for some reason (maybe you have overridden configuration settings in the Conan home manually), you can tell the builder to skip the configuration step using the --skip-config option: $ ./builder/build.py --skip-config Specify the build target \u00b6 Auto SDK can be cross-compiled for supported target systems by specifying the platform and architecture with the build command. Android and QNX targets can be built on either Linux or macOS, and Poky must be built using Linux. For information about specific build target requirements, see the Platform-specific build information section of this guide. To set the target platform using the Builder Tool, specify the --platform,-p <platform> option when doing a build: $ ./builder/build.py -p android You can also set the target architecture by specifying the --arch,-a <architecture> option: $ ./builder/build.py -p android -a x86_64 The following table defines the supported platforms and architectures. platform arch android armv8, x86_64 qnx armv8, x86_64 poky armv8, armv7hf, x86_64, x86 Specify which modules to build \u00b6 If you are using a subset of modules in Auto SDK, you can specify which modules to build on the command line using the -m or --modules option followed by a list of modules names. Dependent modules and libraries will be included transitively when specifying which modules to build. The following example will build the core , alexa , and cbl modules, and package them into the output archive: $ ./builder/build.py -m core alexa cbl You can verify which modules were specified in the build by looking at the [requires] section or pkg_modules option value in the aac-buildinfo.txt file: [requires] aac-module-alexa/dev aac-module-cbl/dev aac-module-core/dev [options] ... pkg_modules=aac-module-core/dev,aac-module-alexa/dev,aac-module-cbl/dev You could also build the same modules by specifying the following on the command line: $ ./builder/build.py -m cbl This works because the cbl module depends on the alexa module, which depends on the core module, so even though they are not specified on the command line, core and alexa are transitively included. The aac-buildinfo.txt file will only show the cbl module under the [requires] section, however, the full list of included dependencies can be found under the [full_requires] section in the build info: [full_requires] aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 aac-module-cbl/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-core/dev:fe4587e72f3350cdb9dab53b293dfee0d5575a0a ... Clean build artifacts \u00b6 Conan caches binaries and artifacts for each package after it is built, so they can be used as dependencies by other packages without having to be re-built each time. If you make changes to the source code in the SDK, however, you must either explicitly force the builder to re-export and build the package (using the --force,-f <pattern> option of the builder), or remove the package entirely from the cache. To remove packages from the cache using the Builder Tool, you can use the clean command: $ ./builder/build.py clean <pattern> You must specify the package name or regex-style pattern to clean. For example, to remove all of the packages from the cache, you can use the following command: $ ./builder/build.py clean \"*\" To remove a specific module, you can either specify the package name or just the module's name: $ ./builder/build.py clean alexa Since the convention used by Auto SDK is to specify the module's package name as aac-module-<name> , you can also use the full package name as part of the pattern. One way to remove all Auto SDK modules from the cache would be to use the following command: $ ./builder/build.py clean \"aac-module-*\" If a package has been removed from the cache, the Builder Tool will automatically detect that it needs to be re-exported and built the next time you do a build, and it is not necessary to specify the package using the --force option. Build debug libraries \u00b6 Building debug libraries for Auto SDK can be specified by using the --debug or -g option when doing a build: $ ./builder/build.py -g When this option is used, debug libraries for all of the Auto SDK modules and dependencies will be built if required, and exported to the build archive. If you want more specific control over which debug libraries to use, you can specify the build_type option as a Conan setting instead, using the --conan-setting,-s <name>=<value> build option. For example, to use debug libraries only for Auto SDK modules, you can use the following build command: $ ./builder/build.py -s \"aac-module-*\" :build_type = Debug This is a less common use case, however, that requires you to be familiar with some of the underlying Conan build architecture. To learn more about some of the Conan specific options for building Auto SDK, see the Build with Conan directly section of this guide. Locate the build output \u00b6 When you run the builder tool, all of the shared libraries and dependencies will be saved in an archive file in the builder/deploy directory by default. The name of the archive file is displayed in the console when the build is completed: [ BUILDER ] INFO: Created output archive: ../aac-dev-macos_x86_64-release-210706140415.tgz The default name of the archive indicates the following information that is used to build the SDK: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz Sometimes it is helpful to tag a build with an identifier, for example, if you want to indicate a build was made for a specific purpose. If you want to add an additional identifier to the archive name, you can use --name option when running the build tool: $ ./builder/build.py --name test ... [ BUILDER ] INFO: Created output archive: ../aac-dev-test-macos_x86_64-release-210706142403.tgz It is also possible to completely override the output file name and path by specifying the -o or --output option on the command line: $ ./builder/build.py --output /mypath/custom-output.tgz ... [ BUILDER ] INFO: Created output archive: /mypath/custom-output.tgz If you don't want the builder to generate an output archive at all, you can specify the --no-output option on the command line. This is helpful if you just want to re-build one or more module, for example, to run unit tests or inspect the package libraries: $ ./builder/build.py --no-output Archive contents \u00b6 The output archive created by the Builder Tool includes all of the build artifacts from the modules and dependencies specified by the build command. You can extract the archive with the following command (the exact filename will be slightly different for your build): $ tar -xvzf builder/deploy/aac-dev-linux_x86_64-release.tgz After you can extract the contents of the archive, there should be a directory with contents similar to the following file structure: aac-dev-linux_x86_64-release/ \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ \u2514\u2500 aac-buildinfo.txt You can get additional information about the archive contents from a description file in the archive named aac-buildinfo.txt . The build description file can be used to identify which modules, settings, and options were used to generate the libraries by the build. The following is an example of the information found in the build description file: [settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [requires] aac-module-aasb/dev aac-module-address-book/dev aac-module-alexa/dev aac-module-car-control/dev aac-module-cbl/dev aac-module-connectivity/dev aac-module-core/dev aac-module-messaging/dev aac-module-navigation/dev aac-module-phone-control/dev aac-module-text-to-speech/dev [options] aac_version=dev with_sensitive_logs=False pkg_modules=aac-module-aasb/dev,aac-module-address-book/dev,aac-module-alexa/dev,... with_aasb=False [full_settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [full_requires] aac-module-aasb/dev:4990d7e4c95bbcae311c6d13cb0e71a09ecd2f43 aac-module-address-book/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 ... Build with Conan directly \u00b6 Conan can be used directly to build Auto SDK components and other package dependencies, or to use Auto SDK libraries in other Conan recipes. It's helpful to have a good general understanding of how Conan works first, and also to understand the basic Auto SDK build system. The examples in this section should be run with aac-sdk as the working directory. Export Conan recipes \u00b6 The following script will find all of the Conan recipes in Auto SDK and export them to the local cache. Package binaries won't actually be built until they are required by another recipe during a build operation, or explicitly built by running the conan create command. This is a convenience script and is not required if you want to export or create packages individually. $ ./conan/setup.py If you want to export a single package individually, you can run the conan export command. For example, to export the alexa module to the local cache: $ conan export modules/alexa It is important to understand that exporting a module using the conan export command does not automatically find and export any of the dependent packages specified in the recipe. Attempting to build the alexa module would fail, unless all of the requirements can be resolved in the local cache. Running the conan/setup.py script is usually the safest option to ensure all required packages are copied to the cache, however, exporting a package individually can save time after you make changes, if you have previously exported all of the packages. Build modules \u00b6 In most cases it shouldn't be necessary to manually build Auto SDK modules, since Conan can build missing dependencies when required by another recipe. It is possible, however, to create/build a package independently using Conan if needed. The following example shows how to create the Alexa module package from the command line: $ conan create modules/alexa --build missing The conan create command tells conan to create a new binary package from a recipe file and install it in the local cache. In the example above, modules/alexa refers to the parent directory in Auto SDK ( aac-sdk/modules/alexa ), where the conanfile.py recipe is located for the Alexa module. By specifying the --build missing option, Conan will automatically build dependencies where a binary package is missing for the specified build configuration. If the dependency has already been created it will not be built again. Using the --build flag without any additional options will force all of the dependencies to be rebuilt, even if the binary for the specified configuration already exists. Specify build settings and options \u00b6 When you build a Conan package, you can specify settings and options that result in different binaries when the source code is built. Conan settings are project-wide configurations, such as os , compiler , build_type , and arch . These settings should be applied to each package when selecting the correct binary. Most of the time, settings will be applied based on the selected (or default) profile. To view or modify a profile, you can use the conan profile command. To show the default profile values, you can enter the following command: $ conan profile show default Configuration for profile default: [ settings ] os = Macos os_build = Macos arch = x86_64 arch_build = x86_64 compiler = apple-clang compiler.version = 11 .0 compiler.libcxx = libc++ build_type = Release [ options ] [ build_requires ] [ env ] You usually don't need to change settings specified in the profile, but if needed, you can override any setting value when running a Conan command. For example, to build a debug version of the alexa module, you can add -s build_type=Debug to the conan create command: $ conan create modules/alexa -b missing -s build_type = Debug Individual packages can also define options which are specific to it's own build requirements. One common option that most packages define is shared , which is used to build either the static or dynamic library. Options can also be used to specify conditional features which should be included in the build, for example, libcurl defines an option called with_nghttp2 to specify that the build should include support for http2 . Inspect package recipes \u00b6 To see which options a recipe has defined, you can use the conan inspect command: $ conan inspect modules/alexa/conanfile.py name: aac-module-alexa version: dev url: https://github.com/alexa/alexa-auto-sdk homepage: None license: Apache-2.0 author: None description: Auto SDK module: alexa topics: None generators: cmake exports: None exports_sources: * short_paths: False apply_env: True build_policy: None revision_mode: hash settings: ( 'os' , 'compiler' , 'build_type' , 'arch' ) options: message_version: ANY shared: [ True, False ] with_aasb: [ True, False ] with_address_sanitizer: [ True, False ] with_android_libs: [ True, False ] with_coverage_tests: [ True, False ] with_docs: [ True, False ] with_engine: [ True, False ] with_jni: [ True, False ] with_latency_logs: [ True, False ] with_messages: [ True, False ] with_platform: [ True, False ] with_sensitive_logs: [ True, False ] with_unit_tests: [ True, False ] default_options: message_version: 4 .0 shared: True with_aasb: True with_address_sanitizer: False with_android_libs: True with_coverage_tests: False with_docs: True with_engine: True with_jni: True with_latency_logs: False with_messages: True with_platform: True with_sensitive_logs: False with_unit_tests: False deprecated: None This command shows different attributes of the package, including its options and the default values for each option specified in default_options . To override a default option when building a package, you can add -o [option]=[value] . If you want to override an option for a specific package, then you can specify the package name as well, -o [pkg]:[option]=[value] . For example, to build and run unit tests for the alexa module, you can add -o with_unit_tests=True to the conan create command: $ conan create modules/alexa -b missing -o with_unit_tests = True Remove packages from the cache \u00b6 Packages can be removed from the local cache if needed by using the conan remove command. For example, the following command can be used to remove the alexa module from the cache: $ conan remove aac-module-alexa -f The -f option is used to remove the package without confirmation. To remove all Auto SDK modules from the cache, you can specify the following pattern aac-module-* in place of a package name, or specify * to remove all packages: $ conan remove \"aac-module-*\" -f $ conan remove \"*\" Note: when specifying a wildcard in the package name, you must surround the pattern with quotes. Use Auto SDK in other recipes \u00b6 If you have your own project that uses Conan, to build an application or library for example, you can include Auto SDK packages in the requirements section of your Conan recipe. The following example shows how you can include Auto SDK modules that are built on the same development machine, in a conanfile.txt recipe: [requires] aac-module-core/dev aac-module-alexa/dev aac-module-cbl/dev aac-module-system-audio/dev ... When you build your package, as long as the Auto SDK packages have been exported to the local cache, Conan will include the specified modules when building your project. It is important to note the convention used by Auto SDK, where all module packages are named aac-module-<module_name> , and the default package version when building locally will be dev unless overridden at build time. You can add Auto SDK modules as a requirement to conanfile.py recipes as well, by specifying them using the requires attribute in the recipe: class ConanRecipe ( ConanFile ): requires = [ \"aac-module-core/dev\" , \"aac-module-alexa\" , \"aac-module-cbl/dev\" , \"aac-module-system-audio/dev\" ] ... Platform-specific build information \u00b6 Android \u00b6 Android can be cross-compiled on either MacOS or Linux, using the NDK toolchain build requirement specified in the aac-android profile. To build Android compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the android platform. $ ./builder/build.py -p android By default the android configuration used to build the SDK is defined in the aac-android Conan profile: [settings] os=Android os.api_level=26 arch=armv8 build_type=Release compiler=clang compiler.libcxx=libc++ compiler.version=8 [build_requires] android-sdk-tools/4.0@aac-sdk/stable You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p android --arch = x86_64 The first time you build Auto SDK for Android, the Android SDK must be downloaded and installed. This is handled by the android-sdk-tools recipe in Auto SDK when you build, however, several license agreements must be manually accepted before any of the Android tools can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:b and --profile:build,-pr:b options as part of the build command. In this case for Android, you would specify aac-android as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the x86_64 version of the Android libraries you can specify -s:h arch=x86_64 as an option: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing -s:h arch = x86_64 Ubuntu \u00b6 Building Auto SDK for Linux on Ubuntu requires installing some additional dependencies, such as GStreamer if you are using the system-audio module. Install GStreamer \u00b6 The system-audio module uses GStreamer to implement the core audio interfaces, and must be installed prior to building. The following command will install the dependencies required to build with GStreamer: $ apt install -y \\ pkg-config libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \\ libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base \\ gstreamer1.0-plugins-good gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc \\ gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl \\ gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio Update the default Conan profile \u00b6 You might run into an issue on Ubuntu where Conan does not detect the default libstdc++11 setting properly, so it is recommended to check this when setting up your host environment. You can run the following command to update the default Conan profile to use the libstdc++11 compiler option: $ conan profile new default --detect $ conan profile update settings.compiler.libcxx = libstdc++11 default Poky \u00b6 Poky can be cross compiled on Linux using the host Poky SDK toolchain. To build Poky compatible binaries with the Builder Tool, simple use the --platform or -p option to specify the poky platform. $ ./builder/build.py -p poky By default the poky configuration used to build the Auto SDK is defined in the aac-poky Conan profile: [settings] compiler.version=8.2 arch=armv7hf build_type=Release os=Linux compiler.libcxx=libstdc++11 [build_requires] poky-sdk/2.6.1 You can override default target architecture to build either the armv7hf , or armv8 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p poky --arch = armv8 The first time you build Auto SDK for Poky, the Poky SDK must be downloaded and installed. This is handled by the poky-sdk recipe in Auto SDK when you build, however, several license agreements must be manually accepted before the Poky SDK can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:h and --profile:build,-pr:b options as part of the build command. In this case for Poky, you would specify aac-poky as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-poky -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the armv8 version of the Poky libraries you can specify -s:h arch=armv8 as an option: $ conan create modules/alexa -pr:h aac-poky -pr:h default -b missing -s:h arch = armv8 QNX \u00b6 QNX can be cross compiled on Linux or MacOS using the host QNX SDP tools. To build QNX, you must install the QNX 7.0 SDP on your host as a prerequisite. To build QNX compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the qnx platform: $ ./builder/build.py -p qnx By default the QNX configuration used to build the Alexa Auto SDK is defined in the aac-qnx Conan profile: [settings] os=Neutrino os.version=7.0 arch=armv8 compiler=qcc compiler.version=5.4 compiler.libcxx=cxx compiler.cppstd=None [build_requires] qnx-cross-compiling/7.0.0 [options] [env] You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p qnx --arch = x86_64 The Conan recipe assumes that the QNX SDP is installed in your home director: ~/qnx700 , but you can override this by setting the qnx7sdp_path option using the --conan-option or -o argument on the command line: $ ./builder/build.py -p qnx -o qnx7-sdp:qnx7sdp_path = /path/to/qnx7sdp macOS \u00b6 macOS can be used as a build host for cross-compiled Android and QNX targets, as well and target for native development and testing. Windows \u00b6 Windows is not currently supported as a build host or target. Build in a Docker container \u00b6 You can use Docker for native Linux builds, or any cross-compiler target that is supported with Linux, as long as the Docker container has the required build dependencies installed. For convenience, you can use the aac-ubuntu-bionic or aac-ubuntu-focal containers provided in the conan/docker directory of the SDK. The following commands should be run with aac-sdk as the working directory. Create the aac-ubuntu-bionic docker image: $ docker build -t aac/ubuntu-bionic conan/docker/aac-ubuntu-bionic Build Auto SDK using the Builder Tool: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py\" The option -v$(pwd):/home/conan/aac-sdk specifies that we want to mount the current directory on the host machine (which should be the Auto SDK root), to /home/conan/aac-sdk in the Docker container file system. After starting the container, you will be able to build Auto SDK using Conan with the same commands used on your host machine. When the build is complete, the output archive file will be saved to the mounted aac-sdk/builder/deploy directory of your host machine. If you inspect aac-buildinfo.txt in the archive, you should see that the libraries were built for os=Linux, arch=x86_64 : [settings] arch=x86_64 build_type=Release compiler=gcc compiler.libcxx=libstdc++11 compiler.version=7 os=Linux Optimize build performance \u00b6 When you build Auto SDK using a Docker container it can take much longer to build than it would natively on your host computer. This is because the Builder Tool home directory is specified as aac-sdk/builder by default, which is a directory on the host file system. File operations in general are much slower when running on a mounted volume, so this will impact the build performance. One option is to specify a different home directory on the container's volume when running the build command instead. This will greatly improve the build time, however, you should be aware that when you remove the container the cached build artifacts may be lost. The Builder Tool will still write the output archive to aac-sdk/builder/deploy on the mounted volume by default, even if the home directory is changed. The following example shows how you can set the home directory using the --home option, when doing a build using Docker: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py --home /home/conan\"","title":"Build Alexa Auto SDK"},{"location":"native/building/#build-alexa-auto-sdk","text":"","title":"Build Alexa Auto SDK"},{"location":"native/building/#supported-platforms-and-architectures","text":"Auto SDK can be built for the following supported target platforms and hardware architectures: Android 5.1 Lollipop API Level 22 or higher. ARM 64-bit x86 64-bit QNX 7.0 ARM 64-bit x86 64-bit Generic Linux x86 64-bit Poky Linux ARMv7a (+NEON) AArch64 macOS x86 64-bit","title":"Supported platforms and architectures"},{"location":"native/building/#general-build-requirements","text":"You can build the Alexa Auto SDK natively on a Linux or macOS host, or you can use Docker. For specific information about Docker, see Build in a Docker container . The following list describes the supported host configurations: Operating system: macOS Sierra Ubuntu 18.04 LTS (Bionic) or Ubuntu 20.04 LTS (Focal) Processor: 2.5 GHz Memory: 16 Gb Storage: 1 Gb+ available to use","title":"General build requirements"},{"location":"native/building/#build-dependencies","text":"To build Auto SDK, you must install the following dependencies on your host machine:","title":"Build dependencies"},{"location":"native/building/#general","text":"Python 3.7 Conan 1.45 CMake 3.12","title":"General"},{"location":"native/building/#linux","text":"GCC GStreamer (see Install GStreamer )","title":"Linux"},{"location":"native/building/#macos","text":"Xcode","title":"macOS"},{"location":"native/building/#understand-the-build-system","text":"Building software for multiple platforms can be complex because specific toolchains might vary depending on the build system and target platform. In general, there are two flavors of builds: native and cross-compiled. In a native build, the build system uses its own toolchain and libraries to build the software, so the compiled software can run on the platform that built it. In cross-compilation, the build system typically uses an installed toolchain to compile the software for a different target platform. It's possible that more than one toolchain is installed on a system, so extra steps are typically needed to cross-compile to those targets. Auto SDK uses Conan , along with other tools and scripts described in this section, to manage the complexities required to implement a complete build system.","title":"Understand the build system"},{"location":"native/building/#conan","text":"The Auto SDK build system uses Conan as its underlying package manager and build configuration tool. For every Conan package, there is a recipe that defines the dependencies of the package and specifies how to download and build the package source code. After building a package, Conan copies the binaries and other artifacts into a cache directory so other recipes that depend on that package can use the prebuilt binaries without rebuilding them. When a Conan recipe defines a dependency, Conan finds and builds the dependency as required, taking care of complexities such as transitive requirements, package version conflicts, and managing multiple versions of a package built with different configurations. Before using a package, Conan must export or download the package into the local cache. When a package recipe exists in the same local repository as the source code it builds, as is the case when you download Auto SDK, you must run conan create or conan export before other recipes can build the package. Community servers such as Conan Center host some popular third party libraries, however, so Conan automatically downloads them to the local cache as needed. Auto SDK requires a combination of Conan packages including local recipes for Auto SDK modules and tools, local recipes for third party packages, and third party packages hosted on the Conan Center server. Once Conan copies a package into the local cache, a recipe can build or consume the package based on the specified build configuration. Conan will build a new package version if the package version is required and missing from the cache. For example, if you build Auto SDK for Linux, Conan will build all of the required packages for the specified Linux target. If you then build for an Android target, Conan will rebuild all of the required packages for the Android target and cache both the Linux and Android versions. In addition to target platform, any option or setting that you specify when building a recipe affects the package version.","title":"Conan"},{"location":"native/building/#auto-sdk-modules","text":"Auto SDK includes a base Conan recipe class that all Auto SDK modules extend. This is defined in conan/recipes/aac-sdk-tools , and must be exported before other modules since it is required by each module's recipe definition. The base recipe defines common build options, and relies on specific conventions in the module's directory structure to find source files and headers, and to generate other artifacts that are needed at build time. A simple Conan recipe is required for each module to override abstract values in the base class (such as the module name), and to define any module specific dependencies or options that are required. A module can also define it's own CMake files, unique configuration, or even custom build steps as needed. For each module, the base recipe defines common options that are used to specify which components are included in the library. The default values provided in the base recipe should be used in most cases when you are building release libraries for production. For some cases, however, you may want to enabled features such as with_sensitive_logs or with_unit_tests , to add additional information when debugging issues with the libraries. To find out which options are defined for a specific module, you can use the conan inspect command to display information about any Conan recipe. This command will display all of options and default values for a recipe, including any options that are inherited from the base module recipe. See the Specify build settings and options section in this guide, for more information. Applications integrate with Auto SDK using the MessageBroker API by publishing and subscribing to specific message topics and actions (see Understand the Auto SDK API ). Most modules provide interfaces that require these messages to be defined, in which case they will include one or more message definition files in the aasb/messages directory of the module. The model created by the message definitions are used when building Auto SDK to generate message headers that are required to build the module, and are also used to create documentation for each message interface.","title":"Auto SDK modules"},{"location":"native/building/#third-party-dependencies","text":"Auto SDK has dependencies on several third party packages (libraries and build tools for example), which may themselves have dependencies on other packages. In general, managing these types of build requirements can be very complex for a large project. Conan helps by providing community hosted recipes for many common packages, as well as by allowing developers to create there own package recipes. It is important to understand that some of the packages used by Auto SDK are pulled from the Conan Center remote server, while others are defined locally in the conan/recipes directory of Auto SDK. Local recipes are typically required when the package does not already exist on Conan Center, or there are specific patches or changes to the recipe that are needed for Auto SDK.","title":"Third party dependencies"},{"location":"native/building/#builder-tool","text":"The Builder Tool is a script that can be used to build Auto SDK libraries for supported platforms. It improves the build process by wrapping underlying Conan commands and options with a simple command line interface. Although it is possible to use Conan by itself to build Auto SDK\u2014see Build with Conan directly \u2014it is recommended to use the Builder Tool for common build tasks.","title":"Builder Tool"},{"location":"native/building/#alexa-auto-client-service","text":"Alexa Auto Client Service (AACS) is an Android service library that simplifies the process of integrating Auto SDK on Android-based devices. AACS has a dependency on Auto SDK native Android libraries, but can be built independently using standard Android development tools. For more information about building AACS, see the Android developer documentation .","title":"Alexa Auto Client Service"},{"location":"native/building/#build-with-builder-tool","text":"The Builder Tool script, build.py is located in the builder directory of the SDK. It wraps underlying Conan commands, and simplifies building libraries for Auto SDK modules on supported platforms. Individual modules, components, and dependencies in the SDK are described as packages in the builder. Each package has a corresponding Conan recipe that is used to build and deploy the package to the cache located in the builder's home directory. An archive containing all of the specified build artifacts is created from the cache, and written to the deploy directory of the builder, after the build has completed. This section describes the most common commands used to build Auto SDK. For a complete reference to the Builder Tool command line interface, see Builder Tool command reference . Auto SDK supports native builds for Ubuntu Linux (x86_64) and MacOS, and building for each platform follows the same steps. After cloning the Auto SDK git repository on your system, the following examples should be run with alexa-auto-sdk as the working directory. The following command will build all of the modules that are included in the Auto SDK repository, along with any dependencies that are required for the target platform: $ ./builder/build.py When you run the build command, the builder tool will export and configure any new build artifacts, such as package recipes or configuration files, that are discovered in the search path. The first time you run (or after cleaning the build cache), you'll see several log messages indicating that the build recipes are being exported to the local cache: [ BUILDER ] INFO: Python version: 3 .7.3 [ BUILDER ] INFO: Cleaning cached builder data [ BUILDER ] INFO: Builder home: ../aac-sdk/builder/.builder [ BUILDER ] INFO: Conan home: ../aac-sdk/builder/.builder/.conan [ BUILDER ] INFO: Gradle home: ../aac-sdk/builder/.builder/.gradle [ BUILDER ] INFO: Configuring Conan... [ BUILDER ] INFO: Installing Conan configuration: ../aac-sdk/conan/config [ BUILDER ] INFO: Exporting recipe: aac-sdk-tools [ BUILDER ] INFO: Exporting recipe: aac-module-core [ BUILDER ] INFO: Exporting recipe: aac-module-alexa [ BUILDER ] INFO: Exporting recipe: aac-module-cbl [ BUILDER ] INFO: Exporting recipe: android-sdk-tools [ BUILDER ] INFO: Exporting recipe: avs-device-sdk ... The builder keeps track of which recipes have already been added to the cache, so that the next time you run the build command only new recipes will be exported. It is possible, however, to tell the builder to force re-exporting a recipe (using the -f or --force option), and build it if necessary. The following command will force all Auto SDK module recipes to be re-exported: $ ./builder/build.py -f \"aac-module-*\" To explicitly force one or more recipes to be exported, you can specify the name of the module (or explicit package name) that you want. The following example will force the builder to re-export and build only the alexa and cbl modules. $ ./builder/build.py -f alexa cbl Each time the builder is run, it will also attempt to re-configure Conan settings by initializing the Conan configuration and installing any config files found in the search path. This happens every time because it is possible, using Docker for example, to re-use the Conan home path when building with a different build system configuration. This step ensures that the Conan configuration will match the build system currently being used. In the case that you want to skip the configuration step for some reason (maybe you have overridden configuration settings in the Conan home manually), you can tell the builder to skip the configuration step using the --skip-config option: $ ./builder/build.py --skip-config","title":"Build with Builder Tool"},{"location":"native/building/#specify-the-build-target","text":"Auto SDK can be cross-compiled for supported target systems by specifying the platform and architecture with the build command. Android and QNX targets can be built on either Linux or macOS, and Poky must be built using Linux. For information about specific build target requirements, see the Platform-specific build information section of this guide. To set the target platform using the Builder Tool, specify the --platform,-p <platform> option when doing a build: $ ./builder/build.py -p android You can also set the target architecture by specifying the --arch,-a <architecture> option: $ ./builder/build.py -p android -a x86_64 The following table defines the supported platforms and architectures. platform arch android armv8, x86_64 qnx armv8, x86_64 poky armv8, armv7hf, x86_64, x86","title":"Specify the build target"},{"location":"native/building/#specify-which-modules-to-build","text":"If you are using a subset of modules in Auto SDK, you can specify which modules to build on the command line using the -m or --modules option followed by a list of modules names. Dependent modules and libraries will be included transitively when specifying which modules to build. The following example will build the core , alexa , and cbl modules, and package them into the output archive: $ ./builder/build.py -m core alexa cbl You can verify which modules were specified in the build by looking at the [requires] section or pkg_modules option value in the aac-buildinfo.txt file: [requires] aac-module-alexa/dev aac-module-cbl/dev aac-module-core/dev [options] ... pkg_modules=aac-module-core/dev,aac-module-alexa/dev,aac-module-cbl/dev You could also build the same modules by specifying the following on the command line: $ ./builder/build.py -m cbl This works because the cbl module depends on the alexa module, which depends on the core module, so even though they are not specified on the command line, core and alexa are transitively included. The aac-buildinfo.txt file will only show the cbl module under the [requires] section, however, the full list of included dependencies can be found under the [full_requires] section in the build info: [full_requires] aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 aac-module-cbl/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-core/dev:fe4587e72f3350cdb9dab53b293dfee0d5575a0a ...","title":"Specify which modules to build"},{"location":"native/building/#clean-build-artifacts","text":"Conan caches binaries and artifacts for each package after it is built, so they can be used as dependencies by other packages without having to be re-built each time. If you make changes to the source code in the SDK, however, you must either explicitly force the builder to re-export and build the package (using the --force,-f <pattern> option of the builder), or remove the package entirely from the cache. To remove packages from the cache using the Builder Tool, you can use the clean command: $ ./builder/build.py clean <pattern> You must specify the package name or regex-style pattern to clean. For example, to remove all of the packages from the cache, you can use the following command: $ ./builder/build.py clean \"*\" To remove a specific module, you can either specify the package name or just the module's name: $ ./builder/build.py clean alexa Since the convention used by Auto SDK is to specify the module's package name as aac-module-<name> , you can also use the full package name as part of the pattern. One way to remove all Auto SDK modules from the cache would be to use the following command: $ ./builder/build.py clean \"aac-module-*\" If a package has been removed from the cache, the Builder Tool will automatically detect that it needs to be re-exported and built the next time you do a build, and it is not necessary to specify the package using the --force option.","title":"Clean build artifacts"},{"location":"native/building/#build-debug-libraries","text":"Building debug libraries for Auto SDK can be specified by using the --debug or -g option when doing a build: $ ./builder/build.py -g When this option is used, debug libraries for all of the Auto SDK modules and dependencies will be built if required, and exported to the build archive. If you want more specific control over which debug libraries to use, you can specify the build_type option as a Conan setting instead, using the --conan-setting,-s <name>=<value> build option. For example, to use debug libraries only for Auto SDK modules, you can use the following build command: $ ./builder/build.py -s \"aac-module-*\" :build_type = Debug This is a less common use case, however, that requires you to be familiar with some of the underlying Conan build architecture. To learn more about some of the Conan specific options for building Auto SDK, see the Build with Conan directly section of this guide.","title":"Build debug libraries"},{"location":"native/building/#locate-the-build-output","text":"When you run the builder tool, all of the shared libraries and dependencies will be saved in an archive file in the builder/deploy directory by default. The name of the archive file is displayed in the console when the build is completed: [ BUILDER ] INFO: Created output archive: ../aac-dev-macos_x86_64-release-210706140415.tgz The default name of the archive indicates the following information that is used to build the SDK: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz Sometimes it is helpful to tag a build with an identifier, for example, if you want to indicate a build was made for a specific purpose. If you want to add an additional identifier to the archive name, you can use --name option when running the build tool: $ ./builder/build.py --name test ... [ BUILDER ] INFO: Created output archive: ../aac-dev-test-macos_x86_64-release-210706142403.tgz It is also possible to completely override the output file name and path by specifying the -o or --output option on the command line: $ ./builder/build.py --output /mypath/custom-output.tgz ... [ BUILDER ] INFO: Created output archive: /mypath/custom-output.tgz If you don't want the builder to generate an output archive at all, you can specify the --no-output option on the command line. This is helpful if you just want to re-build one or more module, for example, to run unit tests or inspect the package libraries: $ ./builder/build.py --no-output","title":"Locate the build output"},{"location":"native/building/#archive-contents","text":"The output archive created by the Builder Tool includes all of the build artifacts from the modules and dependencies specified by the build command. You can extract the archive with the following command (the exact filename will be slightly different for your build): $ tar -xvzf builder/deploy/aac-dev-linux_x86_64-release.tgz After you can extract the contents of the archive, there should be a directory with contents similar to the following file structure: aac-dev-linux_x86_64-release/ \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ \u2514\u2500 aac-buildinfo.txt You can get additional information about the archive contents from a description file in the archive named aac-buildinfo.txt . The build description file can be used to identify which modules, settings, and options were used to generate the libraries by the build. The following is an example of the information found in the build description file: [settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [requires] aac-module-aasb/dev aac-module-address-book/dev aac-module-alexa/dev aac-module-car-control/dev aac-module-cbl/dev aac-module-connectivity/dev aac-module-core/dev aac-module-messaging/dev aac-module-navigation/dev aac-module-phone-control/dev aac-module-text-to-speech/dev [options] aac_version=dev with_sensitive_logs=False pkg_modules=aac-module-aasb/dev,aac-module-address-book/dev,aac-module-alexa/dev,... with_aasb=False [full_settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [full_requires] aac-module-aasb/dev:4990d7e4c95bbcae311c6d13cb0e71a09ecd2f43 aac-module-address-book/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 ...","title":"Archive contents"},{"location":"native/building/#build-with-conan-directly","text":"Conan can be used directly to build Auto SDK components and other package dependencies, or to use Auto SDK libraries in other Conan recipes. It's helpful to have a good general understanding of how Conan works first, and also to understand the basic Auto SDK build system. The examples in this section should be run with aac-sdk as the working directory.","title":"Build with Conan directly"},{"location":"native/building/#export-conan-recipes","text":"The following script will find all of the Conan recipes in Auto SDK and export them to the local cache. Package binaries won't actually be built until they are required by another recipe during a build operation, or explicitly built by running the conan create command. This is a convenience script and is not required if you want to export or create packages individually. $ ./conan/setup.py If you want to export a single package individually, you can run the conan export command. For example, to export the alexa module to the local cache: $ conan export modules/alexa It is important to understand that exporting a module using the conan export command does not automatically find and export any of the dependent packages specified in the recipe. Attempting to build the alexa module would fail, unless all of the requirements can be resolved in the local cache. Running the conan/setup.py script is usually the safest option to ensure all required packages are copied to the cache, however, exporting a package individually can save time after you make changes, if you have previously exported all of the packages.","title":"Export Conan recipes"},{"location":"native/building/#build-modules","text":"In most cases it shouldn't be necessary to manually build Auto SDK modules, since Conan can build missing dependencies when required by another recipe. It is possible, however, to create/build a package independently using Conan if needed. The following example shows how to create the Alexa module package from the command line: $ conan create modules/alexa --build missing The conan create command tells conan to create a new binary package from a recipe file and install it in the local cache. In the example above, modules/alexa refers to the parent directory in Auto SDK ( aac-sdk/modules/alexa ), where the conanfile.py recipe is located for the Alexa module. By specifying the --build missing option, Conan will automatically build dependencies where a binary package is missing for the specified build configuration. If the dependency has already been created it will not be built again. Using the --build flag without any additional options will force all of the dependencies to be rebuilt, even if the binary for the specified configuration already exists.","title":"Build modules"},{"location":"native/building/#specify-build-settings-and-options","text":"When you build a Conan package, you can specify settings and options that result in different binaries when the source code is built. Conan settings are project-wide configurations, such as os , compiler , build_type , and arch . These settings should be applied to each package when selecting the correct binary. Most of the time, settings will be applied based on the selected (or default) profile. To view or modify a profile, you can use the conan profile command. To show the default profile values, you can enter the following command: $ conan profile show default Configuration for profile default: [ settings ] os = Macos os_build = Macos arch = x86_64 arch_build = x86_64 compiler = apple-clang compiler.version = 11 .0 compiler.libcxx = libc++ build_type = Release [ options ] [ build_requires ] [ env ] You usually don't need to change settings specified in the profile, but if needed, you can override any setting value when running a Conan command. For example, to build a debug version of the alexa module, you can add -s build_type=Debug to the conan create command: $ conan create modules/alexa -b missing -s build_type = Debug Individual packages can also define options which are specific to it's own build requirements. One common option that most packages define is shared , which is used to build either the static or dynamic library. Options can also be used to specify conditional features which should be included in the build, for example, libcurl defines an option called with_nghttp2 to specify that the build should include support for http2 .","title":"Specify build settings and options"},{"location":"native/building/#inspect-package-recipes","text":"To see which options a recipe has defined, you can use the conan inspect command: $ conan inspect modules/alexa/conanfile.py name: aac-module-alexa version: dev url: https://github.com/alexa/alexa-auto-sdk homepage: None license: Apache-2.0 author: None description: Auto SDK module: alexa topics: None generators: cmake exports: None exports_sources: * short_paths: False apply_env: True build_policy: None revision_mode: hash settings: ( 'os' , 'compiler' , 'build_type' , 'arch' ) options: message_version: ANY shared: [ True, False ] with_aasb: [ True, False ] with_address_sanitizer: [ True, False ] with_android_libs: [ True, False ] with_coverage_tests: [ True, False ] with_docs: [ True, False ] with_engine: [ True, False ] with_jni: [ True, False ] with_latency_logs: [ True, False ] with_messages: [ True, False ] with_platform: [ True, False ] with_sensitive_logs: [ True, False ] with_unit_tests: [ True, False ] default_options: message_version: 4 .0 shared: True with_aasb: True with_address_sanitizer: False with_android_libs: True with_coverage_tests: False with_docs: True with_engine: True with_jni: True with_latency_logs: False with_messages: True with_platform: True with_sensitive_logs: False with_unit_tests: False deprecated: None This command shows different attributes of the package, including its options and the default values for each option specified in default_options . To override a default option when building a package, you can add -o [option]=[value] . If you want to override an option for a specific package, then you can specify the package name as well, -o [pkg]:[option]=[value] . For example, to build and run unit tests for the alexa module, you can add -o with_unit_tests=True to the conan create command: $ conan create modules/alexa -b missing -o with_unit_tests = True","title":"Inspect package recipes"},{"location":"native/building/#remove-packages-from-the-cache","text":"Packages can be removed from the local cache if needed by using the conan remove command. For example, the following command can be used to remove the alexa module from the cache: $ conan remove aac-module-alexa -f The -f option is used to remove the package without confirmation. To remove all Auto SDK modules from the cache, you can specify the following pattern aac-module-* in place of a package name, or specify * to remove all packages: $ conan remove \"aac-module-*\" -f $ conan remove \"*\" Note: when specifying a wildcard in the package name, you must surround the pattern with quotes.","title":"Remove packages from the cache"},{"location":"native/building/#use-auto-sdk-in-other-recipes","text":"If you have your own project that uses Conan, to build an application or library for example, you can include Auto SDK packages in the requirements section of your Conan recipe. The following example shows how you can include Auto SDK modules that are built on the same development machine, in a conanfile.txt recipe: [requires] aac-module-core/dev aac-module-alexa/dev aac-module-cbl/dev aac-module-system-audio/dev ... When you build your package, as long as the Auto SDK packages have been exported to the local cache, Conan will include the specified modules when building your project. It is important to note the convention used by Auto SDK, where all module packages are named aac-module-<module_name> , and the default package version when building locally will be dev unless overridden at build time. You can add Auto SDK modules as a requirement to conanfile.py recipes as well, by specifying them using the requires attribute in the recipe: class ConanRecipe ( ConanFile ): requires = [ \"aac-module-core/dev\" , \"aac-module-alexa\" , \"aac-module-cbl/dev\" , \"aac-module-system-audio/dev\" ] ...","title":"Use Auto SDK in other recipes"},{"location":"native/building/#platform-specific-build-information","text":"","title":"Platform-specific build information"},{"location":"native/building/#android","text":"Android can be cross-compiled on either MacOS or Linux, using the NDK toolchain build requirement specified in the aac-android profile. To build Android compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the android platform. $ ./builder/build.py -p android By default the android configuration used to build the SDK is defined in the aac-android Conan profile: [settings] os=Android os.api_level=26 arch=armv8 build_type=Release compiler=clang compiler.libcxx=libc++ compiler.version=8 [build_requires] android-sdk-tools/4.0@aac-sdk/stable You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p android --arch = x86_64 The first time you build Auto SDK for Android, the Android SDK must be downloaded and installed. This is handled by the android-sdk-tools recipe in Auto SDK when you build, however, several license agreements must be manually accepted before any of the Android tools can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:b and --profile:build,-pr:b options as part of the build command. In this case for Android, you would specify aac-android as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the x86_64 version of the Android libraries you can specify -s:h arch=x86_64 as an option: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing -s:h arch = x86_64","title":"Android"},{"location":"native/building/#ubuntu","text":"Building Auto SDK for Linux on Ubuntu requires installing some additional dependencies, such as GStreamer if you are using the system-audio module.","title":"Ubuntu"},{"location":"native/building/#install-gstreamer","text":"The system-audio module uses GStreamer to implement the core audio interfaces, and must be installed prior to building. The following command will install the dependencies required to build with GStreamer: $ apt install -y \\ pkg-config libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \\ libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base \\ gstreamer1.0-plugins-good gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc \\ gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl \\ gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio","title":"Install GStreamer"},{"location":"native/building/#update-the-default-conan-profile","text":"You might run into an issue on Ubuntu where Conan does not detect the default libstdc++11 setting properly, so it is recommended to check this when setting up your host environment. You can run the following command to update the default Conan profile to use the libstdc++11 compiler option: $ conan profile new default --detect $ conan profile update settings.compiler.libcxx = libstdc++11 default","title":"Update the default Conan profile"},{"location":"native/building/#poky","text":"Poky can be cross compiled on Linux using the host Poky SDK toolchain. To build Poky compatible binaries with the Builder Tool, simple use the --platform or -p option to specify the poky platform. $ ./builder/build.py -p poky By default the poky configuration used to build the Auto SDK is defined in the aac-poky Conan profile: [settings] compiler.version=8.2 arch=armv7hf build_type=Release os=Linux compiler.libcxx=libstdc++11 [build_requires] poky-sdk/2.6.1 You can override default target architecture to build either the armv7hf , or armv8 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p poky --arch = armv8 The first time you build Auto SDK for Poky, the Poky SDK must be downloaded and installed. This is handled by the poky-sdk recipe in Auto SDK when you build, however, several license agreements must be manually accepted before the Poky SDK can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:h and --profile:build,-pr:b options as part of the build command. In this case for Poky, you would specify aac-poky as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-poky -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the armv8 version of the Poky libraries you can specify -s:h arch=armv8 as an option: $ conan create modules/alexa -pr:h aac-poky -pr:h default -b missing -s:h arch = armv8","title":"Poky"},{"location":"native/building/#qnx","text":"QNX can be cross compiled on Linux or MacOS using the host QNX SDP tools. To build QNX, you must install the QNX 7.0 SDP on your host as a prerequisite. To build QNX compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the qnx platform: $ ./builder/build.py -p qnx By default the QNX configuration used to build the Alexa Auto SDK is defined in the aac-qnx Conan profile: [settings] os=Neutrino os.version=7.0 arch=armv8 compiler=qcc compiler.version=5.4 compiler.libcxx=cxx compiler.cppstd=None [build_requires] qnx-cross-compiling/7.0.0 [options] [env] You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p qnx --arch = x86_64 The Conan recipe assumes that the QNX SDP is installed in your home director: ~/qnx700 , but you can override this by setting the qnx7sdp_path option using the --conan-option or -o argument on the command line: $ ./builder/build.py -p qnx -o qnx7-sdp:qnx7sdp_path = /path/to/qnx7sdp","title":"QNX"},{"location":"native/building/#macos_1","text":"macOS can be used as a build host for cross-compiled Android and QNX targets, as well and target for native development and testing.","title":"macOS"},{"location":"native/building/#windows","text":"Windows is not currently supported as a build host or target.","title":"Windows"},{"location":"native/building/#build-in-a-docker-container","text":"You can use Docker for native Linux builds, or any cross-compiler target that is supported with Linux, as long as the Docker container has the required build dependencies installed. For convenience, you can use the aac-ubuntu-bionic or aac-ubuntu-focal containers provided in the conan/docker directory of the SDK. The following commands should be run with aac-sdk as the working directory. Create the aac-ubuntu-bionic docker image: $ docker build -t aac/ubuntu-bionic conan/docker/aac-ubuntu-bionic Build Auto SDK using the Builder Tool: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py\" The option -v$(pwd):/home/conan/aac-sdk specifies that we want to mount the current directory on the host machine (which should be the Auto SDK root), to /home/conan/aac-sdk in the Docker container file system. After starting the container, you will be able to build Auto SDK using Conan with the same commands used on your host machine. When the build is complete, the output archive file will be saved to the mounted aac-sdk/builder/deploy directory of your host machine. If you inspect aac-buildinfo.txt in the archive, you should see that the libraries were built for os=Linux, arch=x86_64 : [settings] arch=x86_64 build_type=Release compiler=gcc compiler.libcxx=libstdc++11 compiler.version=7 os=Linux","title":"Build in a Docker container"},{"location":"native/building/#optimize-build-performance","text":"When you build Auto SDK using a Docker container it can take much longer to build than it would natively on your host computer. This is because the Builder Tool home directory is specified as aac-sdk/builder by default, which is a directory on the host file system. File operations in general are much slower when running on a mounted volume, so this will impact the build performance. One option is to specify a different home directory on the container's volume when running the build command instead. This will greatly improve the build time, however, you should be aware that when you remove the container the cached build artifacts may be lost. The Builder Tool will still write the output archive to aac-sdk/builder/deploy on the mounted volume by default, even if the home directory is changed. The following example shows how you can set the home directory using the --home option, when doing a build using Docker: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py --home /home/conan\"","title":"Optimize build performance"},{"location":"native/api/","text":"C++ API Reference \u00b6 AASB Message Reference \u00b6 See the AASB Message Reference for detailed information about each AASB message interface. C++ Class Reference \u00b6 See the C++ Class Reference for detailed information about the C++ API including the Engine , MessageBroker , and configuration factory classes.","title":"C++ API Reference"},{"location":"native/api/#c-api-reference","text":"","title":"C++ API Reference"},{"location":"native/api/#aasb-message-reference","text":"See the AASB Message Reference for detailed information about each AASB message interface.","title":"AASB Message Reference"},{"location":"native/api/#c-class-reference","text":"See the C++ Class Reference for detailed information about the C++ API including the Engine , MessageBroker , and configuration factory classes.","title":"C++ Class Reference"},{"location":"native/sample-app/","text":"Alexa Auto SDK C++ Sample App \u00b6 Overview \u00b6 The purpose of the C++ Sample App is to provide useful example code to help you integrate your implementation with the Alexa Auto SDK. The C++ Sample App provides an example of creating and configuring an instance of the Engine, and using the MessageBroker API to subscribe to messages from the Engine. It also provides examples of handling audio and stream based interfaces with the MessageStream API, and replying to messages from the Engine. The C++ Sample App also includes detailed logs for interactions with the Alexa Auto SDK, as well as UI elements relevant to the implementation. Prerequisites \u00b6 Amazon developer account \u00b6 To use the C++ Sample App, you need an Amazon Developer account. Register product and security profile \u00b6 After creating an Amazon developer account, you'll need to register a product and create a security profile on the AVS developer portal. When you follow the instructions to fill in the product information : Use your own custom information, taking note of the Product ID , as this information is required to confingure the Sample App. Be sure to select Automotive from the Product category pull-down. When you follow the instructions to set up your security profile , generate a Client ID and take note of it, as this information is required to configure the Sample App. Optional device capabilities \u00b6 In order to use certain optional Alexa Auto SDK functionality (for example, AmazonLite Wake Word, Alexa Communications, Local Voice Control (LVC), and Device Client Metrics (DCM)) with the Sample App, your product must be placed on the allow list by Amazon. Copy the product's Amazon ID from the Developer Console and follow the directions on the Need Help? page. Note: Most of the commands that follow are meant to be run from this alexa-auto-sdk directory. Build and Run the Sample App \u00b6 Before you build and run the Sample App, it is recommended that you first review and understand how to build Auto SDK . The Sample App can be built by using the Auto SDK Builder Tool, or by using Conan to build the Auto SDK and Sample App packages directly. Each option is described in more detail in this section. Build using Builder Tool \u00b6 The C++ Sample App can be built using the Auto SDK Builder Tool by specifying the --with-sampleapp or --sampleapp option when doing a build. The following examples should be run with alexa-auto-sdk as the working directory. To build Auto SDK and Sample App with all modules included: $ ./builder/build.py --with-sampleapp The build archive is created in the builder/deploy directory, and will include the Sample App binary, along with all of the required libs and configuration files needed to run the application. The name of the archive will depend on your build settings, but in general will match the following pattern: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz You can extract the contents of the build archive to any location on your target device, with the following command: $ tar -xvzf <archive>.tgz After extracting the contents, the directory structure should look something like the following: aac-dev-linux_x86_64-release/ \u251c\u2500 bin/ | \u2514\u2500 SampleApp \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ | \u251c\u2500 sampleapp/ | | \u251c\u2500 certs/ | | \u251c\u2500 config/ | | | \u2514\u2500 config.json | | \u251c\u2500 inputs/ | | \u251c\u2500 menu/ | | | \u2514\u2500 menu.json | | \u2514\u2500 sampledata/ | \u2514\u2500 ... \u2514\u2500 aac-buildinfo.txt Run the Sample App \u00b6 Before running the Sample App, you are required to configure the settings defined in the share/sampleapp/config/config.json file, including setting up your unique client ID and product information. This is described in more detail in the Configure the Sample App section of this document. Once the configuration changes have been made, you can run the Sample App from the root directory of the extracted archive using the following command: $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c share/sampleapp/config/config.json -m share/sampleapp/menu/menu.json Build using Conan \u00b6 The Auto SDK C++ Sample App can be configured using the provided Conan recipe, and then built with CMake. The Conan recipe requires packages that are defined as part of Auto SDK, which must first be installed into the local cache (see Build Alexa Auto SDK for instructions about how to install Auto SDK Conan packages). If you are specifying any additional dependencies, such as extra modules for Auto SDK, those packages must also be installed in the Conan cache before configuring the Sample App. If the required dependencies are already installed, the following commands can be used to quickly configure, build and run the Sample App. # export auto sdk conan dependencies $ python conan/setup.py # configure the sample app and install it in a build directory $ conan install samples/cpp -if = build-sampleapp -b missing # build the sample app in the build directory $ conan build samples/cpp -bf = build-sampleapp # run the sample app from the build directory $ cd build-sampleapp $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c ./config/config.json -m ./menu/menu.json Note: These examples assume your working directory is set to the root alexa-auto-sdk directory. Specify build options \u00b6 You can use the following command line options with the Conan install command. The options are defined in the Conan recipe: aac_modules - Specify default Auto SDK modules to build with the Sample App. This is a comma seperated list of modules that must be installed in the Conan local cache before building. If this option is not overridden, the default value will be core, alexa, cbl, system-audio . extra_modules - Specify additional modules to build with the Sample App. This is a comma separated list of modules that must be installed in the Conan local cache before building. This is a useful option if you want to specify modules to build in addition to the default modules, rather than replacing the default modules entirely. You can specify the options above using -o when running the Conan command. For example, to specify additional modules that are included when building the Sample App, you can us the following option: $ conan install samples/cpp -if = build-sampleapp -b missing \\ -o extra_modules = \"navigation,phone-control\" Specify environment variables for configuration values \u00b6 For convenience, a config file template has been included for the core Auto SDK modules with well-known tokens (e.g. CLIENT_ID , PRODUCT_ID ) for various configuration values. You can set environment variables for these tokens; when building the Sample App, they will be replaced in the configuration file. For example you can set an environment variable when running conan install like this: $ CLIENT_ID = xxxx \\ PRODUCT_ID = xxxx \\ conan install ... Configure the Sample App \u00b6 You can pass one or more configuration files to the Sample App using the --config <config-file-path> flag. When you build additional modules with the sample app, you may need to pass module-specific configuration. Please refer to the README file within each module to get this configuration information. For convenience, a config file template has been included for the core Auto SDK modules. You must customize this template with values specific to your implementation. You can either edit the configuration file manually or specify environment variables that can be used to override the configuration values when building the Sample App with Conan, see how to specify environment variables for configuration values . To change the config file manually, follow these steps: Edit the config file template and save it. Replace the ${YOUR_CLIENT_ID} , ${YOUR_PRODUCT_ID} , and ${YOUR_DEVICE_SERIAL_NUMBER} placeholders with your values as follows: Replace ${YOUR_CLIENT_ID} with the Client ID, which you can find in your device's Security Profile under the Other devices and platforms tab. Replace ${YOUR_PRODUCT_ID} with the Product ID, which you can find under the Products tab on the AVS Developer Console. (It is different from the Amazon ID.) Replace ${YOUR_DEVICE_SERIAL_NUMBER} with an arbitrary value that must not contain spaces and must be unique. Note: The Client ID and Product ID must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . Replace the ${DATA_PATH} and ${CERTS_PATH} with paths to your database and certificates, respectively. You must ensure that the directories exist and have write permissions. Note: The Auto SDK engine will fail to start if the database directory path does not exist or does not have write permissions. Modify the vehicle information ( aace.vehicle ) to match your vehicle specifics. Use the Sample App \u00b6 Authenticate with AVS using Code-Based Linking (CBL) \u00b6 Every request to AVS requires an Login with Amazon (LWA) access token. Code-Based Linking (CBL) is the recommended method to acquire access tokens and is demonstrated by the C++ Sample App. After the Sample App launches, you will see the Main Menu. Follow these steps to authorize your device with AVS using CBL. Start the CBL authorization \u00b6 Press A , the Sample App displays the below message: ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Start CBL Authorization [ esc ] Go back Press 1 to start the CBL authorization. The Sample App displays messages, including a code and a URL in a format similar to the following: ########################### 123456 ############################################ url: http://www.amazon.com/us/code ############################################ Note: You may have to scroll up to see the code and URL. Open a browser and navigate to the URL displayed in the Sample App. In the browser, enter the code displayed in the Sample App. Click Continue and follow the instructions in the browser to complete the authentication. Cancel the authorization \u00b6 After you start the authorization, the Authorization menu displays option [1] for you to cancel the authorization that is in progress. Press 1 to cancel the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Cancel CBL Authorization [ esc ] Go back Log out of the CBL authorization \u00b6 After the device is registered successfully, the Sample App displays option [1] in the Authorization menu for you to log out of CBL authorization. Press 1 to log out from the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Logout CBL Authorization [ esc ] Go back Multimedia support for QNX \u00b6 The C++ Sample App supports the BlackBerry QNX Multimedia Suite for live audio input and output on QNX platforms. Note: The SHOUTcast/lcecast streaming format is not supported. See the System Audio module documentation for details about configuring audio input and output on QNX platforms. AudioFile menu \u00b6 The C++ Sample App provides an AudioFile menu to send pre-recorded utterances. Responses are saved as MP3 audio files within the current directory where the app was run. Refer to the C++ Sample App Menu System documentation for information on how to extend the AudioFile menu with custom audio files. However, this menu is only available if there is no default audio provider specified during the build. By default the Auto SDK Builder will build the C++ Sample App with the System Audio configuration defined in the config-system-audio.json file. Note: The AudioFile menu appears on platforms that do not provide built-in audio support (such as platforms that are under development). On platforms that provide built-in audio support, the AudioFile menu does not appear. Handle unknown locations for navigation use-cases \u00b6 Your platform implementation should handle cases where a GPS location cannot be obtained by returning the UNDEFINED value provided by the Auto SDK. In these cases, the Auto SDK does not report the location in the context, and your platform implementation should return a localization object initialized with UNDEFINED values for latitude and longitude ((latitude,longitude) = ( UNDEFINED , UNDEFINED )) in the context object of every SpeechRecognizer event. Enable SiriusXM as a local media source \u00b6 The Sample App does not configure SiriusXM as a local media source by default. If you need the SiriusXM local media source, you must enable and build it. To do this, add the following line to the list of local media sources in the Application.cpp class then rebuild the Sample App: { aace::alexa::LocalMediaSource::Source::SIRIUS_XM, nullptr } Note: When SiriusXM is present as a local media source, the cloud defaults to local SiriusXM only and blocks any use of the cloud SiriusXM service even if the local implementation/service is unavailable or not enabled. Troubleshooting \u00b6 When interacting with Alexa, if the Dialog State goes from LISTENING immediately to IDLE , you might not be logged in. Try logging into your account via CBL by tapping A from the Main Menu. Note: For security reasons, authentication is not persisted if you quit the Sample App. Upon relaunch, you must re-authenticate via CBL. Restarting the app using the menu system, however, preserves authentication. If the device serial number is not unique, the authentication state bounces between PENDING and CONNECTED states: Auth state changed: REFRESHED ( NO_ERROR ) Connection status changed: PENDING ( ACL_CLIENT_REQUEST ) Connection status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) ... To resolve this, edit the samples/cpp/assets/config.json file and choose a unique serial number.","title":"Alexa Auto SDK C++ Sample App"},{"location":"native/sample-app/#alexa-auto-sdk-c-sample-app","text":"","title":"Alexa Auto SDK C++ Sample App"},{"location":"native/sample-app/#overview","text":"The purpose of the C++ Sample App is to provide useful example code to help you integrate your implementation with the Alexa Auto SDK. The C++ Sample App provides an example of creating and configuring an instance of the Engine, and using the MessageBroker API to subscribe to messages from the Engine. It also provides examples of handling audio and stream based interfaces with the MessageStream API, and replying to messages from the Engine. The C++ Sample App also includes detailed logs for interactions with the Alexa Auto SDK, as well as UI elements relevant to the implementation.","title":"Overview"},{"location":"native/sample-app/#prerequisites","text":"","title":"Prerequisites"},{"location":"native/sample-app/#amazon-developer-account","text":"To use the C++ Sample App, you need an Amazon Developer account.","title":"Amazon developer account"},{"location":"native/sample-app/#register-product-and-security-profile","text":"After creating an Amazon developer account, you'll need to register a product and create a security profile on the AVS developer portal. When you follow the instructions to fill in the product information : Use your own custom information, taking note of the Product ID , as this information is required to confingure the Sample App. Be sure to select Automotive from the Product category pull-down. When you follow the instructions to set up your security profile , generate a Client ID and take note of it, as this information is required to configure the Sample App.","title":"Register product and security profile"},{"location":"native/sample-app/#optional-device-capabilities","text":"In order to use certain optional Alexa Auto SDK functionality (for example, AmazonLite Wake Word, Alexa Communications, Local Voice Control (LVC), and Device Client Metrics (DCM)) with the Sample App, your product must be placed on the allow list by Amazon. Copy the product's Amazon ID from the Developer Console and follow the directions on the Need Help? page. Note: Most of the commands that follow are meant to be run from this alexa-auto-sdk directory.","title":"Optional device capabilities"},{"location":"native/sample-app/#build-and-run-the-sample-app","text":"Before you build and run the Sample App, it is recommended that you first review and understand how to build Auto SDK . The Sample App can be built by using the Auto SDK Builder Tool, or by using Conan to build the Auto SDK and Sample App packages directly. Each option is described in more detail in this section.","title":"Build and Run the Sample App"},{"location":"native/sample-app/#build-using-builder-tool","text":"The C++ Sample App can be built using the Auto SDK Builder Tool by specifying the --with-sampleapp or --sampleapp option when doing a build. The following examples should be run with alexa-auto-sdk as the working directory. To build Auto SDK and Sample App with all modules included: $ ./builder/build.py --with-sampleapp The build archive is created in the builder/deploy directory, and will include the Sample App binary, along with all of the required libs and configuration files needed to run the application. The name of the archive will depend on your build settings, but in general will match the following pattern: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz You can extract the contents of the build archive to any location on your target device, with the following command: $ tar -xvzf <archive>.tgz After extracting the contents, the directory structure should look something like the following: aac-dev-linux_x86_64-release/ \u251c\u2500 bin/ | \u2514\u2500 SampleApp \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ | \u251c\u2500 sampleapp/ | | \u251c\u2500 certs/ | | \u251c\u2500 config/ | | | \u2514\u2500 config.json | | \u251c\u2500 inputs/ | | \u251c\u2500 menu/ | | | \u2514\u2500 menu.json | | \u2514\u2500 sampledata/ | \u2514\u2500 ... \u2514\u2500 aac-buildinfo.txt","title":"Build using Builder Tool"},{"location":"native/sample-app/#run-the-sample-app","text":"Before running the Sample App, you are required to configure the settings defined in the share/sampleapp/config/config.json file, including setting up your unique client ID and product information. This is described in more detail in the Configure the Sample App section of this document. Once the configuration changes have been made, you can run the Sample App from the root directory of the extracted archive using the following command: $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c share/sampleapp/config/config.json -m share/sampleapp/menu/menu.json","title":"Run the Sample App"},{"location":"native/sample-app/#build-using-conan","text":"The Auto SDK C++ Sample App can be configured using the provided Conan recipe, and then built with CMake. The Conan recipe requires packages that are defined as part of Auto SDK, which must first be installed into the local cache (see Build Alexa Auto SDK for instructions about how to install Auto SDK Conan packages). If you are specifying any additional dependencies, such as extra modules for Auto SDK, those packages must also be installed in the Conan cache before configuring the Sample App. If the required dependencies are already installed, the following commands can be used to quickly configure, build and run the Sample App. # export auto sdk conan dependencies $ python conan/setup.py # configure the sample app and install it in a build directory $ conan install samples/cpp -if = build-sampleapp -b missing # build the sample app in the build directory $ conan build samples/cpp -bf = build-sampleapp # run the sample app from the build directory $ cd build-sampleapp $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c ./config/config.json -m ./menu/menu.json Note: These examples assume your working directory is set to the root alexa-auto-sdk directory.","title":"Build using Conan"},{"location":"native/sample-app/#specify-build-options","text":"You can use the following command line options with the Conan install command. The options are defined in the Conan recipe: aac_modules - Specify default Auto SDK modules to build with the Sample App. This is a comma seperated list of modules that must be installed in the Conan local cache before building. If this option is not overridden, the default value will be core, alexa, cbl, system-audio . extra_modules - Specify additional modules to build with the Sample App. This is a comma separated list of modules that must be installed in the Conan local cache before building. This is a useful option if you want to specify modules to build in addition to the default modules, rather than replacing the default modules entirely. You can specify the options above using -o when running the Conan command. For example, to specify additional modules that are included when building the Sample App, you can us the following option: $ conan install samples/cpp -if = build-sampleapp -b missing \\ -o extra_modules = \"navigation,phone-control\"","title":"Specify build options"},{"location":"native/sample-app/#specify-environment-variables-for-configuration-values","text":"For convenience, a config file template has been included for the core Auto SDK modules with well-known tokens (e.g. CLIENT_ID , PRODUCT_ID ) for various configuration values. You can set environment variables for these tokens; when building the Sample App, they will be replaced in the configuration file. For example you can set an environment variable when running conan install like this: $ CLIENT_ID = xxxx \\ PRODUCT_ID = xxxx \\ conan install ...","title":"Specify environment variables for configuration values"},{"location":"native/sample-app/#configure-the-sample-app","text":"You can pass one or more configuration files to the Sample App using the --config <config-file-path> flag. When you build additional modules with the sample app, you may need to pass module-specific configuration. Please refer to the README file within each module to get this configuration information. For convenience, a config file template has been included for the core Auto SDK modules. You must customize this template with values specific to your implementation. You can either edit the configuration file manually or specify environment variables that can be used to override the configuration values when building the Sample App with Conan, see how to specify environment variables for configuration values . To change the config file manually, follow these steps: Edit the config file template and save it. Replace the ${YOUR_CLIENT_ID} , ${YOUR_PRODUCT_ID} , and ${YOUR_DEVICE_SERIAL_NUMBER} placeholders with your values as follows: Replace ${YOUR_CLIENT_ID} with the Client ID, which you can find in your device's Security Profile under the Other devices and platforms tab. Replace ${YOUR_PRODUCT_ID} with the Product ID, which you can find under the Products tab on the AVS Developer Console. (It is different from the Amazon ID.) Replace ${YOUR_DEVICE_SERIAL_NUMBER} with an arbitrary value that must not contain spaces and must be unique. Note: The Client ID and Product ID must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . Replace the ${DATA_PATH} and ${CERTS_PATH} with paths to your database and certificates, respectively. You must ensure that the directories exist and have write permissions. Note: The Auto SDK engine will fail to start if the database directory path does not exist or does not have write permissions. Modify the vehicle information ( aace.vehicle ) to match your vehicle specifics.","title":"Configure the Sample App"},{"location":"native/sample-app/#use-the-sample-app","text":"","title":"Use the Sample App"},{"location":"native/sample-app/#authenticate-with-avs-using-code-based-linking-cbl","text":"Every request to AVS requires an Login with Amazon (LWA) access token. Code-Based Linking (CBL) is the recommended method to acquire access tokens and is demonstrated by the C++ Sample App. After the Sample App launches, you will see the Main Menu. Follow these steps to authorize your device with AVS using CBL.","title":"Authenticate with AVS using Code-Based Linking (CBL)"},{"location":"native/sample-app/#start-the-cbl-authorization","text":"Press A , the Sample App displays the below message: ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Start CBL Authorization [ esc ] Go back Press 1 to start the CBL authorization. The Sample App displays messages, including a code and a URL in a format similar to the following: ########################### 123456 ############################################ url: http://www.amazon.com/us/code ############################################ Note: You may have to scroll up to see the code and URL. Open a browser and navigate to the URL displayed in the Sample App. In the browser, enter the code displayed in the Sample App. Click Continue and follow the instructions in the browser to complete the authentication.","title":"Start the CBL authorization"},{"location":"native/sample-app/#cancel-the-authorization","text":"After you start the authorization, the Authorization menu displays option [1] for you to cancel the authorization that is in progress. Press 1 to cancel the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Cancel CBL Authorization [ esc ] Go back","title":"Cancel the authorization"},{"location":"native/sample-app/#log-out-of-the-cbl-authorization","text":"After the device is registered successfully, the Sample App displays option [1] in the Authorization menu for you to log out of CBL authorization. Press 1 to log out from the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Logout CBL Authorization [ esc ] Go back","title":"Log out of the CBL authorization"},{"location":"native/sample-app/#multimedia-support-for-qnx","text":"The C++ Sample App supports the BlackBerry QNX Multimedia Suite for live audio input and output on QNX platforms. Note: The SHOUTcast/lcecast streaming format is not supported. See the System Audio module documentation for details about configuring audio input and output on QNX platforms.","title":"Multimedia support for QNX"},{"location":"native/sample-app/#audiofile-menu","text":"The C++ Sample App provides an AudioFile menu to send pre-recorded utterances. Responses are saved as MP3 audio files within the current directory where the app was run. Refer to the C++ Sample App Menu System documentation for information on how to extend the AudioFile menu with custom audio files. However, this menu is only available if there is no default audio provider specified during the build. By default the Auto SDK Builder will build the C++ Sample App with the System Audio configuration defined in the config-system-audio.json file. Note: The AudioFile menu appears on platforms that do not provide built-in audio support (such as platforms that are under development). On platforms that provide built-in audio support, the AudioFile menu does not appear.","title":"AudioFile menu"},{"location":"native/sample-app/#handle-unknown-locations-for-navigation-use-cases","text":"Your platform implementation should handle cases where a GPS location cannot be obtained by returning the UNDEFINED value provided by the Auto SDK. In these cases, the Auto SDK does not report the location in the context, and your platform implementation should return a localization object initialized with UNDEFINED values for latitude and longitude ((latitude,longitude) = ( UNDEFINED , UNDEFINED )) in the context object of every SpeechRecognizer event.","title":"Handle unknown locations for navigation use-cases"},{"location":"native/sample-app/#enable-siriusxm-as-a-local-media-source","text":"The Sample App does not configure SiriusXM as a local media source by default. If you need the SiriusXM local media source, you must enable and build it. To do this, add the following line to the list of local media sources in the Application.cpp class then rebuild the Sample App: { aace::alexa::LocalMediaSource::Source::SIRIUS_XM, nullptr } Note: When SiriusXM is present as a local media source, the cloud defaults to local SiriusXM only and blocks any use of the cloud SiriusXM service even if the local implementation/service is unavailable or not enabled.","title":"Enable SiriusXM as a local media source"},{"location":"native/sample-app/#troubleshooting","text":"When interacting with Alexa, if the Dialog State goes from LISTENING immediately to IDLE , you might not be logged in. Try logging into your account via CBL by tapping A from the Main Menu. Note: For security reasons, authentication is not persisted if you quit the Sample App. Upon relaunch, you must re-authenticate via CBL. Restarting the app using the menu system, however, preserves authentication. If the device serial number is not unique, the authentication state bounces between PENDING and CONNECTED states: Auth state changed: REFRESHED ( NO_ERROR ) Connection status changed: PENDING ( ACL_CLIENT_REQUEST ) Connection status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) ... To resolve this, edit the samples/cpp/assets/config.json file and choose a unique serial number.","title":"Troubleshooting"},{"location":"releases/","text":"Auto SDK Release Notes \u00b6 Change log \u00b6 Learn about the latest Auto SDK features, enhancements, resolved issues, and known issues in the Auto SDK change log. >> Change log Migration guide \u00b6 Keep your Auto SDK version up-to-date with help from the Auto SDK migration guide, which describes changes you'll need to make when upgrading your application to the latest Auto SDK version. >> Migration guide","title":"Auto SDK Release Notes"},{"location":"releases/#auto-sdk-release-notes","text":"","title":"Auto SDK Release Notes"},{"location":"releases/#change-log","text":"Learn about the latest Auto SDK features, enhancements, resolved issues, and known issues in the Auto SDK change log. >> Change log","title":"Change log"},{"location":"releases/#migration-guide","text":"Keep your Auto SDK version up-to-date with help from the Auto SDK migration guide, which describes changes you'll need to make when upgrading your application to the latest Auto SDK version. >> Migration guide","title":"Migration guide"},{"location":"releases/changelog/","text":"Change Log \u00b6 v4.1.1 released on 2022-08-08 \u00b6 Enhancements \u00b6 Improved Auto SDK AACS Sample App Setup and Settings UX. Updated APL renderer app component, as well as dependent APL Viewhost Android libraries (AARs). It is highly recommended you update to release 4.1.1 for APL integrations. Note: All Auto SDK 4.1 extensions are compatible with 4.1.1. Resolved Issues \u00b6 Improved the settings menu by expanding the clickable area of settings, and added missing descriptions for menu items. Fixed a race condition in which updating the Alexa language setting, and then navigating away from the menu page could crash the application without switching the language. Fixed an issue in which the Alexa comms permission screen did not render properly. Improved the margin alignment issue in the setup screens. Known Issues \u00b6 General The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try Communications If the user asks Alexa to redial the last called number when their phone is not connected to the head unit, Alexa is silent rather than prompting the user to connect their phone. Entertainment When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song. When using the LVC extension, if the application publishes the MediaPlaybackRequestor.RequestMediaPlayback AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the RequestMediaPlayback message. There is no AASB message to indicate to Alexa that the user switched the media player UI on the head unit from an Alexa-integrated local media source, such as FM radio, to Alexa cloud-based music service provider. The only way to switch the audio context between the two player types is through voice interaction explicitly requesting a particular player. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. Local Voice Control In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize follow up requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. AACS sample app * Sometimes the sample app will display an error page during sign-in if the user launched the app with the launcher icon. The recommended workaround is to set Alexa as the default assistant in the settings menu to guarantee AACS initializes properly before sign in. * APL Card is prematurely closed if there is music playing in the background and APL command SpeakItem or SpeakList is executed. * The voice interaction UI does not match the automotive UX guidelines for touching the screen during the interaction. The UX guidelines state that the interaction should continue if the user taps or scrolls, but the sample app cancels the interaction when the user taps or scrolls. * The volume Alexa uses to read a shopping list is louder than the volume set for other Alexa responses. * When the device has internet disconnected and the user sets the system language to a language not supported by Alexa, the sample app does not always display the language selection screen automatically. * When the user revokes Alexa permission to use the microphone and then re-enables the permission, Alexa does not respond to utterances until the user restarts the app. * If an alert is going off while Alexa is speaking, the timer audio cancels the Alexa speech. timer is going off while Alexa is speaking, the timer audio cancels the Alexa speech. C++ sample app The sample app may fail to handle synchronous-style AASB messages within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected. v4.1.0 released on 2022-05-27 \u00b6 Enhancements \u00b6 Auto SDK Added support to display a smart home dashboard using voice requests such as \u201cAlexa, show me my smart home dashboard\u201d. The user can use the dashboard to monitor and control the states of their smart home devices such as lights, plugs, switches, and thermostats. The smart home dashboard is powered by APL and updates to reflect the vehicle\u2019s settings for day and night mode, custom themes, and driving state. Added the Feature Discovery interface, enabling users to learn about Alexa features by providing an API for your application to retrieve and display suggested utterances dynamically. For more information, see the Feature Discovery documentation . Deprecated the Local Voice Control (LVC) APK in favor of a new LVC AACS App Component that integrates LVC directly into AACS. See the Local Voice Control extension documentation for more information. Enhanced LVC offline local search to support voice-based search and navigation to cheap gas stations and electric vehicle charging stations for en-US locale. Enhanced LVC offline navigation feature to show/navigate to previous destinations, show alternate route, route-based ETA, and add/remove waypoints to POI, user favorites, and address for en-US locale. Updated Alexa to disallow Alexa Presentation Language (APL), directives from skills that are not explicitly certified as safe for automotive. Certified skills may render APL, and uncertified skills fall back to experiences with TemplateRuntime (if supported) or voice-only. Updated the aace.vehicle.info configuration to include two additional optional fields, engineType and rseEmbeddedFireTvs. See the Core module documentation for additional information. Updated the Auto SDK Builder Tool to use a custom Python interpreter /usr/bin/env python3 rather than the previously hardcoded /usr/bin/python3 Updated the Auto SDK Builder Tool to use the additional compiler and linker flags that enable exploit mitigation techniques, including safe stack, stack canary, fortifying source, and RELRO. Updated the following dependency versions: Android NDK r21e Curl 7.81.0 SQLite 3.37.2 The Auto SDK build system was updated to support QNX 7.0 and QNX 7.1 SDP cross-compilation. Added the option libcurl:openssl_version to the Auto SDK build system recipes to specify the OpenSSL version. Enhanced Auto SDK logs to display thread ID and uses different colors per log level. Added support to build Auto SDK using a custom toolchain. See the Build Alexa Auto SDK documentation for more information. AACS Sample App for Android Automotive OS Added an Alexa app icon that allows users to launch the AACS sample app directly from the app launcher instead of the system settings menu. Added Things-to-try in setting menu that displays a list of utterances for user to try out in different domains. Enhanced the Navigation app component that provides a plugin framework for 3P navigation provider. See Alexa Auto Navigation app-component for details. Interruption Behavior - Push-to-talk (PTT) now interrupts while Alexa is speaking/thinking, and cancels when Alexa is listening. Barge-in sounds now play, in the previous version the new dialog would start silently. Alexa setup flow is now interrupted if the vehicle is in motion, and setup flow is resumed when the vehicle returns to the parked state. Implemented a BACK button that returns the user to the previous activity when pressed. Enhanced the contacts sharing consent UI to display the consent screen when a new phone is paired and to persist consent for subsequent pairings. Previously, the consent UI only displayed as part of the setup flow. Enhanced the communications screen UI to display all paired phones instead of only connected phones. This enables the user to enable or disable contacts from a paired phone at any time. Added a short \"exit\" animation to the voice chrome UI that displays on transitions from Speaking to Idle or Listening to Idle. Added support for handling Alexa's Language selection mismatch between system and Alexa supported languages during first-time user experience (FTUE) and subsequent language changes. Resolved Issues \u00b6 Auto SDK Fixed an issue in which the CBL module did not check the network connection status when attempting to refresh an access token. If there was no network connection when the refresh was attempted, the token would not refresh immediately when connection was restored. Fixed an issue in which the \u201cAlexa, stop\u201d utterance did not stop music playback when audio ducking is enabled. Fixed periodic Engine shutdown crashes in ContextManager , ExternalMediaPlayer , and AACS. Fixed an issue in which the Navigation module inserted an invalid error code in the payload of the ShowAlternativeRoutesFailed event. Additionally added the NOT_NAVIGATING error code to the Navigation AASB interface. See the Navigation module documentation for info about which error codes to use. Fixed issues that could cause the Engine to hang indefinitely at shutdown. Fixed an issue in the Local Navigation module of the LVC extension that could cause Engine restart to fail after a previous Engine stop. Fixed an issue in which applications had to manually include header files from the Nlohmann - JSON for Modern C++ library (https://github.com/nlohmann/json) because the Auto SDK build did not export them Fixed an issue in which offline local search and navigation for POIs was not working. Fixed an issue in which the C++ sample app crashed during launch on the Poky Linux 32-bit platform. AACS Sample App Fixed the language selection screen in the AACS sample app when the Preview Mode feature is enabled. Fixed an issue in which the AACS sample app did not play alarms when the device is offline. Fixed an issue in which the display card for a second weather utterance closed too soon. Fixed an issue which the AACS sample app did not reset the contact permissions when switching accounts Fixed an issue in which the AACS sample app stopped music playback when the user tapped the screen showing a display card. Fixed an issue in which AACS did not play the Alexa confirmation speech when the user creates a notification while music is playing. Known Issues \u00b6 General The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try Communications If the user asks Alexa to redial the last called number when their phone is not connected to the head unit, Alexa is silent rather than prompting the user to connect their phone. Entertainment When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song. When using the LVC extension, if the application publishes the MediaPlaybackRequestor.RequestMediaPlayback AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the RequestMediaPlayback message. There is no AASB message to indicate to Alexa that the user switched the media player UI on the head unit from an Alexa-integrated local media source, such as FM radio, to Alexa cloud-based music service provider. The only way to switch the audio context between the two player types is through voice interaction explicitly requesting a particular player. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. Local Voice Control In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize follow up requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. C++ sample app The sample app may fail to handle synchronous-style AASB messages within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected. AACS sample app Sometimes the sample app will display an error page during sign-in if the user launched the app with the launcher icon. The recommended workaround is to set Alexa as the default assistant in the settings menu to guarantee AACS initializes properly before sign in. APL Card is prematurely closed if there is music playing in the background and APL command SpeakItem or SpeakList is executed. The voice interaction UI does not match the automotive UX guidelines for touching the screen during the interaction. The UX guidelines state that the interaction should continue if the user taps or scrolls, but the sample app cancels the interaction when the user taps or scrolls. The volume Alexa uses to read a shopping list is louder than the volume set for other Alexa responses. When the device has internet disconnected and the user sets the system language to a language not supported by Alexa, the sample app does not always display the language selection screen automatically. When the user revokes Alexa permission to use the microphone and then re-enables the permission, Alexa does not respond to utterances until the user restarts the app. If an alert is going off while Alexa is speaking, the timer audio cancels the Alexa speech. timer is going off while Alexa is speaking, the timer audio cancels the Alexa speech. v4.0.0 released on 2021-12-15 \u00b6 Enhancements \u00b6 Deprecated the C++ and Java platform interfaces in favor of an asynchronous message-based API. Auto SDK client applications use the new MessageBroker to publish and subscribe to Alexa Auto Services Bridge (AASB) messages. The C++ sample app is refactored to use the new API to provide a reference implementation for Linux platforms. The Alexa Auto Client Service (AACS) sample app provides the reference implementation for Android platforms. See the Auto SDK Migration Guide for help migrating your application to use the new API. Enhanced the Auto SDK build system with the Conan package manager. The new build system introduces modular builds, better dependency management, and simpler build artifacts. The Auto SDK build system includes the Auto SDK Builder Tool script, which wraps the Conan build commands with a simple interface similar to the previous version of Auto SDK Builder. See the Build Alexa Auto SDK documentation for details about the build system and the migration guide for help migrating your build to the new version of Builder Tool. Extended the features of Alexa Presentation Language (APL) support for automotive. The APL module provides messages to report vehicle properties such as the display theme, driving state, and ambient light conditions. The property settings affect how APL documents render on screen; for example, some APL content is automatically hidden when the vehicle starts moving, and the display contrast updates with the day or night mode setting. Auto SDK 4.0 supports APL 1.9. For more information about the Auto SDK APL interface, see the APL module documentation. Added the CustomDomain interface, which establishes a bidirectional communication channel between your Auto SDK client application and your custom cloud skill. CustomDomain includes messages for exchanging directives, events, and context between the vehicle and your skill, achieving a fully customizable experience. For more information about the Auto SDK CustomDomain interface, See the Custom Domain module documentation. Added the MediaPlaybackRequestor interface, which enables Alexa to play the user\u2019s favorite media content as soon as they start their vehicle. MediaPlaybackRequestor simplifies content selection for the user by removing the need for the user to use buttons or voice commands to resume the Alexa media content that was playing when they stopped the vehicle. For more information about the Auto SDK MediaPlaybackRequestor interface, See the Alexa module documentation. Extended the AudioOutput interface and added configuration to allow ducking Alexa media. Your application can use this feature for enhanced control of Alexa content audio focus according to your platform requirements. For more information about audio ducking, see the Core module documentation. Updated the Auto SDK to use AVS Device SDK Version 1.25.0. For information about this version of AVS Device SDK, see the AVS Device SDK release notes. Added LVC support for Alexa Custom Assistant specialized handoffs. You can configure the default fallback and self-introduction prompts for your custom assistant while offline. For more information, see the Alexa Custom Assistant extension documentation. Integrated the Auto SDK Conan build system enhancements to AACS and the AACS sample app. You can use a single Gradle command to build AACS and the AACS sample app without using the Auto SDK Builder Tool directly. For build instructions, see the AACS documentation . Added the following enhancements to the AACS sample app: Additional languages\u2014 The AACS sample app supports the following languages: US English ( en-US ), Australian English ( en-AU ), Canadian English ( en-CA ), Indian English ( en-IN ), British English ( en-GB ), German (d e-DE ), Spanish ( es-ES ), Mexican Spanish ( es-MX ), US Spanish ( es-US ), French ( fr-FR ), Canadian French ( fr-CA ), Hindi ( hi-IN ), Italian ( it-IT ), Japanese ( ja-JP ), and Brazilian Portuguese ( pr-BR ). The sample app language setting matches the device\u2019s system language setting and syncs the with Alexa as long as the setting is in the supported language list. If Alexa does not support the system language, the sample app GUI defaults to en-US and presents a list of languages for the user to choose from. Once the user selects the language override, the system language does not sync with the sample app again until the user logs out or disables Alexa. Network error prompts\u2014 You can configure the sample app to provide feedback to the user when Alexa cannot respond due internet connection issues. The feedback is a voice prompt or an error screen depending on the user action. Alexa app assets\u2014 The sample app can show Alexa logos (assets) on the setup screen and display cards instead of showing placeholder assets. Comms UI improvements\u2014 Updated the contacts uploading logic in the Comms UI AACS app component to ensure the sample app only uploads the contacts for the primary phone. Updated the AACS Telephony library to get the outgoing phone account using the Android standard API getDefaultOutgoingPhoneAccount . AACS Telephony no longer sends an account query intent when receiving the PhoneCallController.Dial message from the Auto SDK Engine. Added a new intent com.amazon.aacstelephony.bluetooth.connectionCheckCompleted , which AACS Telephony service broadcasts when it finishes the initial bluetooth connection check. Updated the alexa-auto-lwa-auth app component to use the Authorization Auto SDK interface for CBL authorization. Other changes \u00b6 Removed support for the Android 32-bit ARM architecture (i.e., armeabi-v7a ). Moved several source code directories within the aac-sdk root directory to support the enhanced build system. Removed aac-sdk/platforms/android/ . The deprecated Java platform interfaces and JNI are in their respective modules. For example, the Alexa module Java interfaces and JNI are moved from aac-sdk/platforms/android/modules/alexa/ to aac-sdk/modules/alexa/android/ Removed aac-sdk/extensions/aasb/ because using AASB messages with MessageBroker is the primary Auto SDK API. AASB code for each module is in the respective module directory. For example, the AASB code for the Alexa module is in aac-sdk/modules/alexa/aasb/ . Note that the AASB message headers to include in your application are not in this directory since they are generated as part of the Auto SDK build output. Moved aac-sdk/extensions/system-audio/ to aac-sdk/modules/system-audio/ Moved aac-sdk/extensions/bluetooth/ to aac-sdk/modules/bluetooth/ Moved aac-sdk/extensions/loopback-detector/ to aac-sdk/modules/loopback-detector/ Moved aac-sdk/platforms/android/alexa-auto-client-service/ to aac-sdk/aacs/android/ Moved aac-sdk/platforms/android/alexa-auto-client-service/app-components/ to aac-sdk/aacs/android/app-components/ Moved aac-sdk/samples/android-aacs-sample-app/ to aac-sdk/aacs/android/sample-app/ Moved aac-sdk/platforms/android/alexa-auto-client-service /commonutils/ , /ipc/ , and /constants/ to aac-sdk/aacs/android/common/ Moved AACS media player files to a directory audioOutput within aac-sdk/platforms/android/alexa-auto-client-service/service/ Moved the Media App Command and Control Android library from aac-sdk/platforms/android/maccandroid/ to aac-sdk/aacs/android/service/modules/maccandroid/ In the LVC extension, the LocalSearchProvider AASB messages now have topic LocalNavigation . For example, the existing message LocalSearchProvider.SearchRequest in 3.3 is LocalNavigation.SearchRequest in 4.0. The next major release version of Auto SDK will change the topic back to LocalSearchProvider . Deprecated the option to build AACS as an APK. Starting from Auto SDK 4.0, you can only build AACS as an AAR. Removed the Android sample app based on the Java platform interfaces. The AACS sample app demonstrates using Auto SDK on Android. Updated AASB configuration fields used for AACS. See the migration guide for details. Resolved issues \u00b6 Fixed an issue preventing the generic DEFAULT type LocalMediaSource from working in offline mode with LVC. Fixed a race condition in SpeechRecognizer in which enabling wake word detection immediately after calling startCapture() resulted in a missing call to stopAudioInput() when wake word detection was later disabled. Fixed a deadlock that could occur in an application that uses the deprecated AuthProvider interface and starts, stops, and restarts the Engine in quick succession. Fixed an issue in which Spotify playback commands were delayed on QNX. Fixed an issue in which the Engine added malformed PhoneCallController context to PhoneCallController events sent to Alexa. Fixed an issue in which AACS did not acquire audio focus prior to playing Alexa speech. Known issues \u00b6 General If you do not specify the deviceSettings.locales field of the Alexa module configuration, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not automatically declare support for default locale combinations if you assign an empty value to the locales field. The Engine does not persist the aace.alexa.wakewordEnabled Engine property setting across device reboots. Your application has to persist the setting and set the property again at each Engine start. AACS implements persisting this property and hence does not have this issue. If your Linux platform does not use AVX2 instructions, the Amazonlite wake word library initialization causes an illegal instruction error. When using LVC and stopping the Engine, the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your application should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED . The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. When the user requests to view their list of timers on an APL-enabled application, they cannot use an utterance such as \u201cAlexa, scroll up\u201d to scroll through the list shown on the APL card. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. On the Poky Linux 32-bit platform, the C++ sample app shuts down with an error on launch. In offline mode with LVC, you might not see the AlexaClient.DialogStateChanged THINKING state transition if the user invokes Alexa with hold-to-talk and your application provides the audio input data in one large chunk. In offline mode with LVC, Alexa gets stuck in the THINKING state and does not respond after changing the locale setting. The state recovers after a few minutes. The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the Engine attempts the refresh, it might take up to a minute to refresh the token after the internet connection is restored. Some Core module messages published by the Engine do not have a corresponding message for the application to report a handling failure. For example, if the user invokes Alexa by tap-to-talk, and the application cannot handle the AudioInput.StartAudioInput message, the Engine assumes the application handled the message properly and will provide audio data. As a result, the Engine state and application state might become out of sync. The affected messages are the following: AudioInput : StartAudioInput AudioOutput : SetPosition VolumeChanged MutedStateChanged Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications Alexa does not understand DTMF utterances that include letters. For example, \"press A\" and \"dial 3*#B\" do not result in the correct DTMF directives. The user might experience unexpected results by trying to dial or place calls in the following ways: Using utterances that include \u201cdouble\u201d, \u201ctriple\u201d, \u201chundred\u201d, or \u201cthousand.\u201d For example, calling a number such as 1-800-xxx-xxxx by saying \u201cAlexa call one eight double oh ...\u201d Pressing special characters such has \u201c#\u201d or \u201c*\u201d by saying \"Alexa press * #.\" The user cannot accept or reject incoming Alexa-to-Alexa calls by voice while playing a skill with extended multi-turn dialogs, such as Jeopardy or Skyrim. Entertainment If the user requests Alexa to read notifications while music is playing, they might hear the music play for a split second between the end of one notification and the start of the next. When an external media player authorization is in progress during Engine shutdown, a rare race condition might cause the Engine to crash. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. When using the System Audio module, Audible and Amazon music might not play correctly on i.MX8 boards. Local search and navigation In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize followup requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. AACS If you do not use the default audio output implementation (i.e., your application handles AudioOutput AASB messages), your application will not receive the AudioOutput.Stop message if Alexa media is playing when AACS shuts down. As a workaround, your application can listen to AASB.StopService or adopt AACSPinger to listen to the STOPPED state of AACS and stop the media accordingly. AACS Sample App The AACS Sample App does not show the language selection screen when the app is built with Preview Mode. The AACS Sample App only shows the language selection screen if there is a language mismatch with the system language setting at the first app launch. v3.3.0 released on 2021-09-30 \u00b6 Enhancements \u00b6 Added the DeviceUsage platform interface to provide the Alexa application network usage data to the Auto SDK Engine. The Auto SDK Engine emits this data as a metric to Amazon if Auto SDK is built with the Device Client Metrics extension. For more information, see the Core module documentation Extended the features of the Local Navigation module for the Local Voice Control (LVC) extension. The LocalSearchProvider platform interface now enables you to provide customers with offline navigation to street addresses, cities, and neighborhoods in addition to the existing support for local search and navigation to points of interest. See the Local Navigation module README for information about integrating the features. Note: There are updates to the LocalSearchProvider APIs. See the Auto SDK Migration Guide for details. Added a new generic DEFAULT media source to the list of sources supported by the LocalMediaSource platform interface. The DEFAULT source can be used for voice playback control of any arbitrary media sources on the infotainment system outside of deep-linked MACC applications using the ExternalMediaAdapter interface and existing sources supported by name through the LocalMediaSource interface. For details about integrating a default media source, see the Alexa module documentation . Added offline LVC support for tuning to station names on terrestrial radio and SiriusXM. E.g., \u201cPlay CNN on Sirius XM\u201d and \u201cPlay KISS FM\u201d. This feature is already available in online mode. Enhancements for AACS: Added an app component called alexa-auto-carcontrol that deeply integrates Auto SDK car control features into the Android Automotive OS. For more information about AACS deep integration to Car Control, please refer to this README . Added an enhancement in which AACS can automatically sync Alexa\u2019s timezone and locale properties with the device system settings when you set the syncSystemPropertyChange field to true in your AACS configuration file. If you set the field to false or omit it, you still have flexibility to change the properties in your own implementation. Enhancements for AACS Sample App: Added a location sharing consent screen in Alexa setup and settings wherein the user has the option to enable or disable location sharing. Added support for rendering for TemplateRuntime display cards for the weather domain. Added support for rendering Amazon Presentation Language (APL) documents. Added media player transport control improvements. For example, shuffle and loop transport controls are added, and disabled transport controls are displayed. Added support for setup and setting menu specific to the Alexa Custom Assistant extension. Resolved Issues \u00b6 Android 11 requires the attribute android:foregroundServiceType to be defined in services that require permissions such as microphone and location. This is added to the AACS Android Manifest file. Also, the compileSdkVersion and targetSdkVersion to are updated to 30 in build.gradle . Added a UserIdentity value in AACS AuthStatus when the user finishes CBL login. Made the 'stateOrRegion' field optional in the AACS StartNavigation directive JSON parser. Implemented the AASB SetUserProfile message in the CBL module to ensure the user email and username will be sent to the client application after user login when enableUserProfile is set to true. Fixed an issue that blocked a valid transition from the THINKING to LISTENING AlexaClient dialog states. Updated the PhoneCallControllerCapabilityAgent to include context in PhoneCallController events per the PhoneCallController API specification. Fixed a memory leak observed during Engine shutdown in the Local Voice Control extension. Fixed a rare deadlock issue during Engine stop and start when using the AuthProvider interface. Fixed an issue in which the Engine erroneously allowed 3,000 coordinates in the \"shapes\" array of navigation state queried via Navigation::getNavigationState() . The limit is updated to 100 coordinates. Known Issues \u00b6 General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. The automotive HMI guidelines for display cards state that actionable display cards should be dismissed automatically after 30 seconds, and non-actionable display cards should be dismissed automatically after 8 seconds. This guideline is not descriptive enough since it does not clarify what is actionable and non-actionable content. The UX team is working on correcting the guideline to specify specific template types. The current automatic dismissal time for all Template Runtime display cards is 8 seconds. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. The generic DEFAULT LocalMediaSource type is not supported offline with LVC. If user gives a generic playback control request like \"Alexa, play\" when the Alexa application is operating in the offline mode with LVC, Alexa responds \"Sorry, something went wrong\". Other named players like USB work as expected in the offline mode. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. Local Search and Navigation When using LVC in offline mode, after requesting a list of POIs (e.g., \"find Starbucks nearby\"), Alexa does not recognize utterances like \"select the first one\" and does not display or read detailed information about the requested selection. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) If you are not using the default audio output implementation (i.e. your application handles AudioOutput AASB messages) and even though you are playing the Alexa pushed media content, Stop message would not be sent from AACS when AACS shuts down. e.g. If you are playing an audio stream for AmazonMusic, if AACS is stopped, AASB AudioOutput.Stop message would not be received. As a result, the media playing from your application would not be stopped. This issue will be fixed in the next release. As a workaround, your application can listen to AASB.StopService message or adopt AACSPinger to listen to the STOPPED state of AACS and stop the media accordingly. v3.2.1 released on 2021-08-06 \u00b6 Note: All Auto SDK 3.2 extensions are compatible with 3.2.1. Enhancements \u00b6 Added additional APIs to the Connectivity module, which enable the voice up-sell conversation between the user and Alexa to activate a trial data plan or a paid subscription plan. Your implementation should call AlexaConnectivity::sendConnectivityEvent() to notify the Engine of the data plan type. To respond, the Engine calls AlexaConnectivity::connectivityEventResponse() . Added the configuration field aace.addressBook.cleanAllAddressBooksAtStart to Engine configuration. This field specifies whether to automatically delete address books each time the Engine starts. Resolved Issues \u00b6 Fixed an issue in which wake words cannot be detected correctly when using the SpeechRecognizer::startCapture() API with an external wake word engine. Known Issues \u00b6 General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) v3.2.0 released on 2021-05-19 \u00b6 Enhancements \u00b6 Added the DeviceSetup platform interface that handles events and directives related to device setup during or after an out-of-the-box experience (OOBE). After the user login, Alexa is informed that device setup is complete and starts the on-boarding experience, for example, by starting a short first-time conversation. For more information, see the Alexa module documentation . Added support in the Connectivity module to provide the network identifier from the vehicle to Alexa, which enables automakers to offer full connectivity plans to customers. For connectivity status, the module supports sending the version of the terms and conditions through a field called termsVersion . Also, the termsStatus field accepts DEFERRED , which means Alexa can remind users to respond to the terms and conditions at a later time. Added the Mobile Authorization extension, which enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone, instead of opening a web browser and entering a code. Added the Bluetooth extension, which allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Added the Geolocation extension, which provides geolocation consent support. The user can grant consent to location sharing with Alexa from your application. Added the locationServiceAccessChanged(LocationServiceAccess access) API in the LocationProvider interface, which allows the Engine not to query the device location when the location service access is turned off on the device. Added the APL Render module, which enables APL rendering capabilities in an Android application. Note: This module is for you to experiment with APL document rendering on an automotive device. Do not use the module to render APL documents in a production vehicle. Added support in the Address Book module for a phonetic field. The phonetic field is required for resolving the name of a contact or navigation favorite if the name uses Kanji characters in Japanese. Updated the Docker container for the Auto SDK builder script to use OpenSSL 1.1.1k by default. Added an environment variable for you to change the OpenSSL version, if desired. For information about the OpenSSL version, see the Builder README. Updated the Auto SDK to use AVS Device SDK Version 1.22.0. For information about the AVS Device SDK, see the AVS Device SDK Release Notes . Enhancements for AACS: Added AACS instrumentation, which enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. For information about AACS instrumentation, see the AACS documentation. Added an app component called alexa-auto-telephony , which enables you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. Added an app component called alexa-auto-contacts to enable AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information. Added the AACS AAR, which you can include in your application. The timeout for AASB synchronous messages is now configurable. For information about configuring the timeout, see the AACS documentation. Enhancements for AACS Sample App: Added support for new features in the AACS Sample App. For example, it includes a menu for the user to select a language if the in-vehicle infotainment (IVI) language is not supported by Alexa, and it supports authorization with Preview Mode. Added support for the Alexa Custom Assistant extension to the Alexa Auto Client Service (AACS) Sample App. The sample app demonstrates how an application can use AACS with this extension. With app components included with the sample app, you can develop an application that handles assistant handoff and displays custom animation for your custom assistant. Note: In order to use the Alexa Custom Assistant extension with the AACS Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Enhancements for metrics uploading: The Auto SDK emits only registration metrics before user login is complete. Other metrics are emitted after user login. The Device Client Metrics (DCM) extension supports uploading more metrics from the vehicle than in previous versions. The DCM extension supports anonymizing all Auto SDK metrics. Enhancements for car control: Added prompt improvements. Alexa can provide a recommendation or ask for clarification after receiving an invalid or ambiguous user request. Suppose a user request targets the wrong mode, setting, or value for an appliance, such as \"Alexa, set fan speed to 100\", Alexa responds, \"Sorry, you can only set the fan between 1 and 10\". When the target in a user request is ambiguous, Alexa prompts for more information to determine the exact meaning of the request. For example, when a user says, \"Turn on fan\" (when the fan's default zone is not set), Alexa responds, \"For the driver, the passenger, or the rear?\" This feature is supported online and offline. Improved asset management for car control, which enables Alexa to accept utterances only a few seconds after the user logs in. Previously, the user had to wait up to 20 seconds for Alexa to accept utterances. Improved the Auto SDK Voice Chrome extension to allow the height and width of the linear voice chrome to be controlled by the parent layout. Previously, the dimensions were fixed. Resolved Issues \u00b6 Disabled APL by default in AACS to make sure utterances like \"tell me a joke\" work correctly without handling APL. If your platform wants to implement APL, see the AACS Configuration README to enable it. An SMS message can be sent to an Alexa contact correctly. A user request to send an SMS message to an Alexa contact no longer results in an Alexa-to-Alexa message. For car control, there is no longer a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). After the AmazonLite Wake Word locale model is switched from the default (en-US) to another locale model (e.g., de-DE), the newly selected locale remains in effect after the user quits and then restarts the application. Numeric weather IDs are passed to AVS for the TemplateRunTime API, making it easier for you to display weather icons that are consistent with your user interface. After the user disconnects the phone, if the user tries to use Alexa to make a call, Alexa responds correctly by reminding the user to connect the phone. Previously, Alexa tried to dial the number. After the user pauses on Spotify and presses \u201cPlay\u201d to resume, the player starts correctly from the point where the player stops. Previously the player skipped ahead, resuming from an incorrect place. AutoVoiceChromeController and StateChangeAnimationScheduler of the Voice Chrome extension are thread-safe now, preventing the Alexa app from crashing in different scenarios (e.g. when changing to the previous music track). Fixed a race condition in AuthorizationManager during the Engine shutdown. Known Issues \u00b6 General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) v3.1.0 released on 2020-12-15 \u00b6 Enhancements \u00b6 Added the Authorization platform interface that replaces the CBL platform interface and the AuthProvider platform interface. For information about how the Alexa Auto SDK Engine handles authorization with the Authorization platform interface, see the Core module documentation . Note: Logging out from CBL or Auth Provider authorization clears the databases that store user data, such as alerts and settings. For example, when the user logs out, pending alerts in the database are cleared to ensure that the next user who logs in does not receive the alerts. In addition, upon logout, the locale setting is reset to the default value in the Engine configuration. Therefore, if the current device locale is different from the default locale, you must set the locale before starting an authorization flow. Added the Text-To-Speech module that exposes the platform interface for requesting synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. Added the Text-To-Speech Provider module that synthesizes the Alexa speech. The Text-to-Speech provider requires Auto SDK to be built with the Local Voice Control extension. For information about these modules, see the Text-To-Speech module documentation and Text-To-Speech Provider documentation . Note: This feature may only be used with voice-guided turn-by-turn navigation. Added the Connectivity module that creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. For information about the Connectivity module, see the Connectivity documentation . Added the Local Navigation module for the Local Voice Control (LVC) extension. This module enables you to provide customers with offline search and navigation to points of interest (POI) by leveraging the POI data of an onboard navigation provider. The POIs include categories, chains, and entities. The Local Voice Control (LVC) extension is required for the Local Navigation module. Note: Offline search with the Local Navigation module is only supported in the en-US locale. Added the Alexa Auto Client Service (AACS) sample app that demonstrates how an application uses AACS. The Auto SDK includes the app components used by the AACS sample app, which you can also use when developing an application that communicates with AACS. For information about the AACS sample app, see the AACS sample app documentation Added support for Digital Audio Broadcasting (DAB) radio. For more information about the DAB local media source, see the Alexa module documentation . Enhancements for AACS: Enhanced the file sharing protocol of AACS by using Android's FileProvider. This enhancement grants AACS permission to access files within your AACS client application, which are required by configuration fields for the Auto SDK. Added support for the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. For information about how AACS uses FileProvider and ContentProvider , see the AACS documentation. Added support for a ping broadcast to check the AACS connection state. For more information about how to use ping , see the AACS documentation. Added support for caching AASB message intent targets based on AASB Action. This enables you to define an intent filter with a subset of the possible actions for an AASB topic. For more information on specifying intent targets, see the AACS documentation. Added support for Text-to-Speech Service, which allows Android applications to interact with Android TTS APIs to convert text to speech. For information about the Text-to-Speech Service, see the AACS TTS app component documentation . Resolved Issues \u00b6 On Android, the Engine returns the correct value ( UNDEFINED ) for requests to LocationProvider.getLocation() when the device does not have access to location. Previously the Engine populated the user geolocation with a default value when Location.UNDEFINED was returned in LocationProvider.getLocation() . In the AACS commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime could only parse the payload field of the AASB RenderPlayerInfo message payload. Now it can parse the overall AASB payload. Notifications sound plays correctly. Previously, the sound did not play as expected due to improper channel configuration. The CBL module code request flow correctly applies the locale setting to the Login With Amazon (LWA) code request. Previously, the URL returned by LWA was always in the en-US locale. If you log out and log in, the client-side Do Not Disturb (DND) state is synchronized with Alexa. Known Issues \u00b6 General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However, \u2018send message\u2019 instead of \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) AACS enables APL by default, but it does not have a default implementation for APL. AACS expects the client application to handle the messages or directives from the Engine. If APL is not handled on the client side, utterances that trigger APL capabilities, such as \"tell me a joke,\" fail. To disable APL, add the lines below to the AACS configuration file. \"aasb.apl\": { \"APL\": { \"enabled\" : false } } Additional Changes \u00b6 Starting with v3.1.0, the Local Voice Control (LVC) extension is no longer supported on ARM32 platforms. v3.0.0 released on 2020-10-09 \u00b6 Enhancements \u00b6 Added Alexa Auto Client Service (AACS), which enables OEMs of Android-based devices to simplify the process of integrating the Auto SDK. For more information about AACS, see the AACS documentation . Added support for removing local media sources at runtime, such as a USB drive or a Bluetooth device. Previously, if a user removed a USB drive and then requested to play music from the USB drive, the Auto SDK would attempt to play and not return an appropriate error message. This feature is enabled with an existing field in the LocalMediaSource platform interface state. For information about the platform interface state, see the Alexa module documentation. Resolved Issues \u00b6 On QNX, when a portion of music on Spotify is skipped, either by the user saying, \"Skip forward,\" or by the user skipping to a different song, the volume is no longer reset to the default level. A user barging in when music is playing no longer hears an Alexa response to the barge-in request. Previously, this issue happened if the System Audio extension was used. When streaming music from Alexa, the user can switch to a local media source by using one utterance, such as \"Alexa, play radio.\" Previously, Alexa would not switch to the local media source after the first utterance. The user needed to issue the request again before Alexa could play from the local media source. Known Issues \u00b6 General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) In the commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime can only parse the payload field of the AASB RenderPlayerInfo message payload. The payload field of RenderPlayerInfo is the inner payload of the nested payload structure. When using TemplateRuntime.parseRenderInfo(String json) , provide it with the embedded JSON as a string of the string value whose key is payload in the RenderPlayerInfo message\u2019s payload instead of the overall AASB payload. Additional Changes \u00b6 Starting with Auto SDK v3.0, we no longer support the Automotive Grade Linux (AGL) Alexa Voice agent in the Auto SDK. If you intend to use the AGL Alexa Voice Agent, continue using Auto SDK v2.3.0, which is the last version that provides AGL support. v2.3.0 released on 2020-07-31 \u00b6 Enhancements \u00b6 Added a new Messaging module that provides support for Short Message Service (SMS) to allow a user to send, reply to, and read messages through Alexa. Added support for zones to car control for online-only devices so the customer can target endpoints by location (e.g., \u201cset the front fan to 7\u201d). This feature was supported only with the Local Voice Control (LVC) extension, and endpoints belonged to exactly one zone. The features for online-only and LVC devices are at parity and now include assigning an endpoint to multiple zones and setting a default zone. Endpoints in the default zone take higher priority than endpoints not in the default zone when no zone is specified in an utterance. Added support for \u201csemantics\u201d for car control to enable \u201copen\u201d, \u201cclose\u201d, \u201craise\u201d, and \u201clower\u201d utterances to control endpoints. Added a method to the 'AlexaClient' platform interface to stop foreground-focused Alexa activity on the device (e.g., locally canceling ongoing TTS when the user selects a list item or presses a cancel button). Added support for Dynamic Language Switching. Previously, Alexa could only understand and respond in one language at a time. Now Alexa supports two languages at once and automatically detects the user's spoken language and responds in the same language as the utterance. The supported locale pairs are the following: [ \"en-US\", \"es-US\" ] [ \"es-US\", \"en-US\" ] [ \"en-IN\", \"hi-IN\" ] [ \"hi-IN\", \"en-IN\" ] [ \"en-CA\", \"fr-CA\" ] [ \"fr-CA\", \"en-CA\" ] Note: Dynamic Language Switching works online only. For hybrid systems using the LVC extension, offline Alexa understands and responds in the language of the primary locale. * Updated radio tuning increments for \u201cAM_RADIO\u201d and \u201cFM_RADIO\u201d Local Media Source types to support the en_IN locale. * Alexa Voice Agent now supports AGL Itchy Icefish v9.0.2. * Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binary. Resolved Issues \u00b6 Fixed an issue in which navigation road regulation and maneuver events resulted in \u201cINVALID_REQUEST_EXCEPTION\" or \"INTERNAL_SERVICE_EXCEPTION\" error logs. Fixed several failing car control utterances including those for offline AC controls and those using the words \u201cmy\u201d or \u201clights.\u201d Fixed an issue in External Media Player that caused the \u201cNEXT\u201d play control request to be issued twice for ExternalMediaAdapter (e.g., MACC) and LocalMediaSource platform interface handlers. Fixed an issue in which the Engine did not stop music playback after user logout. Fixed an issue that caused Spotify to play at an increased and unsteady rate on QNX. Fixed an issue with the --use-mbedtls build option that caused a crash in the Android sample app at startup. Fixed an issue in the Engine metrics implementation in which regular expression matching with a large number of data points caused a crash. Fixed an issue in MACC in which players removed while the Engine was running (such as by the uninstallation of a linked MACC-compliant app) could not be rediscovered properly and used again, even if the player was restored (such as by the reinstallation of the app and user login). Previously, the rediscovery logic left insufficient time to process the player removal event before trying to discover players again, resulting in a loop. Now the rediscovery step runs at 5-minute intervals. Fixed an issue with the Engine's SQLite local storage database in which concurrent access to the database caused a crash. Fixed various memory leaks and intermittent crashes caused by race conditions at Engine shutdown. Fixed an issue on Android API 25 in which a large number of emitted logs could cause a crash due to a JNI local reference table overflow. Fixed an issue in which you experienced unexpected results if the local timezone of your device differed from the timezone configured through the Alexa companion app. Known Issues \u00b6 General A user barging in when music is playing sometimes hears the Alexa response to the barge-in request and the music at the same time if System Audio extension is used. If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The user must enunciate \u201cline-in\u201d in utterances targeting the \u201cLINE_IN\u201d Local Media Source type in order for Alexa to recognize the intent. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. On QNX, when a portion of music on Spotify is skipped, either by the user saying \"Skip forward\" or by the user skipping to a different song, the volume is reset to the default level. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. v2.2.1 released on 2020-05-29 \u00b6 Enhancements \u00b6 Added enhancements to the maccandroid module to allow SupportedOperations to be overridden to support custom actions. Enhanced the TemplateRuntime platform interface to support focus and audio player metadata in renderTemplate and renderPlayerInfo methods. This is a backward compatible change, see the migration guide for details. SpeakerManager is now a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\". Resolved Issues \u00b6 Fixed issues in the maccandroid module to a) rediscover media apps after getting the app removed callback, and b) change the behavior to only report unauthorized when the user specifically asks to play a media app. On the QNX platform, prevent unnecessary flushing for audio output. Known Issues \u00b6 On the Android Sample App, media playback gets into \"No Content Playing\" state where all GUI playback control breaks, when pressing next after force closing an external media app. Playback controls in the C++ Sample App Playback Controller Menu are static text items and do not change visual state (e.g. add/remove, hilite, select) based on audio player metadata. v2.2.0 released on 2020-04-15 \u00b6 Enhancements \u00b6 Added a Car Control module to support online-only car control use cases without the optional Local Voice Control (LVC) extension. The Car Control module provides the car control functionality introduced in Auto SDK 2.0.0 but does not require the LVC extension. Made various enhancements to the External Media Player (EMP) Adapter to improve EMP behavior and facilitate implementation of Alexa audio focus. Introduced the Property Manager, a new platform interface that allows you to set and retrieve Engine property values and be notified of property value changes. Added support for setting the timezone of a vehicle. The PropertyManager interface supports a new a \"TIMEZONE\" property setting. Added support for specifying a custom volume range for voice interactions in implementations that use the optional Local Voice Control (LVC) extension. Separated the LVC language models into independent APKs rather than providing them directly in the LVC APK as was done in previous releases. One language model APK is provided for each supported locale (currently en-US, en-CA, and fr-CA). Resolved Issues \u00b6 Fixed an issue where the CBL state did not change to stopped when you cancelled login with CBL::cancel() . Fixed an issue where volume adjustments were lost when pausing and resuming music. Fixed an External Media Player (EMP) Engine implementation that caused an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession. Fixed an issue where the Engine might hang during shutdown if it was shut down while TTS was being played or read. Fixed an issue where Auto SDK initialization failed at startup when applications using the optional LVC extension didn't register a NetworkInfoProvider platform interface. Fixed an issue where building the Auto SDK with sensitive logging enabled was not working as expected. Added alerts error enums ( DELETED and SCHEDULED_FOR_LATER ) to the Alerts platform interface. With the exception of road regulation and maneuver events, the Alexa cloud no longer returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to navigation events sent by the Auto SDK. Alexa now prompts or notifies the clients and rejects the ping packet when the user deregisters from the companion app. Known Issues \u00b6 General If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". Auto SDK v2.2.0 adds support for setting the timezone of the vehicle, which allows your device to synchronize with the timezone set in the Alexa companion app; however, the Auto SDK currently does not receive a SetTimeZone directive when the timezone is changed from the companion app. Navigation The Alexa cloud currently returns an INTERNAL_SERVICE_EXCEPTION in response to any navigation road regulation or maneuver event sent by the Auto SDK (triggered by an utterance such as \"which lane should I take\", for example). You may see a harmless error/exception in the logs. Car Control Certain car control utterances return errors. Problematic utterances include natural versions of certain test utterances (for example, \u201cturn on the light\u201c instead of \u201cplease turn on the light in the car\u201d); utterances that include the words \u201clights\u201d or \u201cmy\u201d; and utterances to control the defroster or defogger that use \u201cput on\u201d or \u201cset on\u201d rather than \u201cturn on\u201d or \u201cswitch on\u201d. Setting the air conditioner using range controller control capabilities (for example \u201cset the air conditioner to 65\u201d or \u201cset the air conditioner to low\u201d) is not currently supported. In offline mode, the utterances \"turn ac on\u201d, \u201cturn off ac\u201d, \u201cturn ac off\u201d, and \u201cturn up ac\" return errors. Communications When using LVC in online mode, users can redial a call when the phone connection state has been switched to OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. Entertainment A user playing any skill with extended multi-turn dialogues (such as Jeopardy or Skyrim) cannot accept or reject incoming Alexa-to-Alexa calls using voice. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d Authentication The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. v2.1.0 released on 2019-12-19: \u00b6 Enhancements \u00b6 Added Navigation enhancements to support the following features: Add a waypoint - Enables users to search and add waypoints to their current route along the way or start a new route with a given set of waypoints. Cancel a waypoint - Enables users to cancel a waypoint with voice. Show/Navigate to previous destinations - Enables users to view previous destinations and navigate to any of their previous destinations.. Turn and Lane Guidance - Enables users to ask Alexa for details about their next navigation instruction. Control Display - Enables users to interact with their onscreen map applications. Note: The Navigation enhancements are not backward-compatible with previous versions of the Auto SDK. The startNavigation() method supersedes the setDestination() method, and many new methods have been implemented. See the Auto SDK Migration Guide for details. Added support for Alexa Presentation Language (APL) rendering to present visual information and manage user interactions with Alexa. Note: In order to use APL rendering with the Android Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Added support for the Alexa DoNotDisturb (DND) interface, which allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . Note: Alexa does not notify the user of the DND state. Added a System Audio extension to provide the default audio capturing and playback functionality for various platforms, including audio input/output on QNX platforms. The Alexa Auto SDK Builder automatically includes the System Audio extension when you build the Auto SDK. Added local media sources (LMS) and hybrid car control support to the Automotive Grade Linux (AGL) Alexa Voice Agent. Added onAuthFailure() to the AuthProvider platform interface and an AUTHORIZATION_EXPIRED argument to the cblStateChanged() method of the CBL platform interface to expose 403 unauthorized request exceptions from Alexa Voice Service (AVS). These may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. Added support for call display information change notifications (caller ID) to the optional Alexa Communication extension. Resolved Issues \u00b6 Fixed an issue where contact uploading failed for contacts without addresses. Fixed an issue where if the user rejected an incoming Alexa-to-Alexa call via voice, ringtones did not sound for subsequent incoming calls until the user either answered an incoming call via voice or made an outbound call. Fixed an issue that required you to assign unique entry IDs to contacts and navigation favorites to ensure that the ID space used for contacts and navigation favorites did not collide. Fixed an issue where multiple automotive devices using the same account at the same time could access contacts from phones paired across those devices. Fixed an issue where uttering \"stop\" when a timer sounded during an Alexa-to-Alexa call ended the call, not the timer. Added enhancements to the maccandroid module (Spotify) to simplify the MACCPlayer handler implementation. Rediscovery now occurs automatically, and the authorization TTS error events no longer occur repeatedly. Known Issues \u00b6 The Alexa cloud currently returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to any navigation event sent by the Auto SDK. You may see a harmless error/exception in the logs. The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If the user deregisters from the companion app, Alexa does not prompt or notify the clients and does not reject the ping packet. If you log out and log in, the Do Not Disturb (DND) state is not synchronized with Alexa. When you cancel login with CBL::cancel() , the CBL state does not change to stopped. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or* using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. The Engine may sometimes stop abruptly on shutdown due to a race condition. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d A user playing Jeopardy or Skyrim cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". When pausing and resuming music, volume adjustments are lost. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession. v2.0.0 released on 2019-09-10: \u00b6 Enhancements \u00b6 Added offline enhancements to improve offline car control support and add support for: offline car control enhancements - to support generic controls that represent what can be controlled in a vehicle; for example: interior lighting, fans, temperature zone (driver and passenger), vent position, defroster, air conditioner, and recirculation. > Note : The car control enhancements are not backward compatible with previous versions of car control. The configuration and platform interface have changed. offline entertainment - to support tuning to a specific frequency or SiriusXM channel, tuning to radio presets, switching between car audio sources (bluetooth, radio, satellite radio, CD player, etc.), and controlling local audio sources (pause, shuffle, loop, etc.) offline communications - to support uploading contacts, calling a number or a contact, answering, declining, redialing, or ending a call, and dialing digits during a call offline navigation - to support navigating to favorite locations and canceling navigation Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets. Added online navigation enhancements to support navigating to favorite locations and answering ETA and time to destination questions. Introduced the Address Book module , which includes a common platform interface that you can implement to either upload user data to the Alexa cloud or allow the local communications and navigation capabilities to access user data for offline use cases (supported by the optional Local Voice Control (LVC) module). The Address Book module supersedes the Contacts Uploader module, which supports only phone contacts and only online use cases. Introduced a new core Audio service and API to implement audio input and output providers, and deprecated the existing MediaPlayer and Speaker platform interfaces in the Alexa module. This redesign simplifies integration with platform-specific audio capabilities and enables implementation of new, advanced audio features. NOTE: The new core Audio service and APIs are not backward compatible with previous versions of the Alexa Auto SDK (prior to version 2.0.0). Added a library to support the Device Client Metrics (DCM) extension for additional platforms such as Linux and QNX in addition to Android, which was supported in release 1.5. This library is required to upload metrics and vehicle information to the Amazon cloud. Added support for Voice Chrome for Android , an extension available through your Solutions Architect or Partner Manager that provides a Voice Chrome library for the Android platform. This library allows you to display voice chrome animations of different Alexa states to the user on screen. Added an integrated wake word enhancement to ignore Alexa waking itself up . In order to implement this enhancement, you must provide audio loopback via the platform or application. Added local pause handling to the PlaybackController to allow non-voice interactions to pause media playback from the AudioPlayer source immediately, without waiting for a response from the cloud. Added Geolocation support to the Navigation module. Geolocation support enables location-based services (which are used to answer questions such as \u201cwhere am I\u201d or \u201cwhat\u2019s the weather\u201d) to use the location information provided by the platform. Note: In order to make use of this functionality, you must register the Navigation platform interface for Geolocation support. * Enhanced the builder scripts to simplify the build process by removing unnecessary options and including the default components for different targets. For details see the Builder documentation. * Refactored the Java Native Interface (JNI) code used for Android platform interfaces for more modular deployment. In place of a single AAR including all Auto SDK native libraries, the Alexa Auto SDK now generates multiple AARs (one per module). See the builder documentation and the Android Sample App documentation for details. Resolved Issues \u00b6 Fixed an issue where music streaming from online music service providers continued to play when the user switched to a local media source. Fixed an issue where an MACC app (Spotify) could automatically play after the first utterance. Fixed a race condition in the Navigation module that occasionally caused Cancel Navigation to fail. Fixed broken links in the documentation. Known Issues \u00b6 Calling numbers such as 1800xxxxxxx using utterances such as \"Alexa call one eight double oh...\" may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore, when requesting Alexa to call or press digits, we recommend that your client application ignore special characters, dots, and non-numeric characters if not relevant to the context. The Engine may crash during shutdown due to a race condition in the Local Media Source Engine implementation. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. In online mode, Alexa does not recognize the utterance \"Switch to line in.\" A user interacting with multiturn skills such as Jeopardy cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the user rejects an incoming Alexa-to-Alexa call via voice, ringtones do not sound for subsequent incoming calls until the user either answers an incoming call via the VUI or makes an outbound call. If you change your Car Control configuration or custom assets during development after Local Voice Control (LVC) was previously running, you should stop your application and LVC, change the configuration or custom assets, uninstall and reinstall LVC, and relaunch your application to ensure the changes are applied. To ensure that the ID space used for contacts and navigation favorites does not collide, you must assign unique entryId s to contacts and navigation data. If you use the same entryId , re-uploading contacts may cause navigation favorites to become unavailable to Alexa, and re-uploading navigation favorites may cause contacts to become unavailable. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\" Alexa uses different audio channels, such as dialog (user utterance or TTS) and content (music), and shuffles between them to respond to user requests. As a result of this shuffling, content (such as music playback) that gets paused to accommodate higher priority channels may regain foreground audio focus and resume content in bursts between the outputs of higher priority channels (such as Alexa TTS or ongoing alerts). To avoid this, platforms should maintain the audio focus for a few extra milliseconds. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.6.3 released on 2019-12-02: \u00b6 Enhancements \u00b6 This release is for bug fixes only. There are no new features or enhancements. Resolved Issues \u00b6 Fixed a race condition that could cause follow-ons to a TTS request (for example asking for movies nearby) not to play while Alexa is speaking or playing something. Known Issues \u00b6 All known issues from v1.6.0. v1.6.2 released on 2019-10-11: \u00b6 Enhancements \u00b6 Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets. Resolved Issues \u00b6 n/a Known Issues \u00b6 All known issues from v1.6.0. v1.6.1 released on 2019-06-21: \u00b6 Enhancements \u00b6 This release of Alexa Auto SDK includes updates for music certification. Resolved Issues \u00b6 Resolved issues are limited to music certification updates: Added fixes from AVS Device SDK v1.12.1 for music certification. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Documentation updates. Known Issues \u00b6 All known issues from v1.6.0. v1.6.0 released on 2019-05-16: \u00b6 Enhancements \u00b6 General availability for Linux target platforms, including: Linux x86-64, Linux ARM 64 (armv8a), and Linux ARM 32 (armv7a). Alexa Auto SDK v1.6.0 enhances the C++ Sample App by improving the reference implementation for Linux platforms. See the C++ sample app documentation for details. Resolved Issues \u00b6 Fixed an issue where Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. Made changes to External Media Player events to send the service id and agent details, which are now mandated by the Alexa Music service. If you are using previous versions with Local Media Source switching or third-party app with MACC, you should upgrade to Alexa Auto SDK v1.6.0 to continue using the corresponding functionality. Known Issues \u00b6 If the local timezone of the device differs from the timezone that was configured through the Alexa companion app, you may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\u201d If you play your notifications while music is playing, you will hear the music for a split second between the end of one notification and the start of the next. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.5.0 released on 2019-03-06: \u00b6 Enhancements \u00b6 Added a C++ sample application to demonstrate use cases that the Alexa Auto SDK supports. For details, see the C++ sample app documentation. Released the code for the AGL Alexa Voice Agent, a binding for Automotive Grade Linux powered by Alexa Auto SDK v1.5. The software is shipped as a standard AGL binding that exposes an API for speech recognition using the Alexa Voice Service. Please refer to the AGL Alexa Voice Agent documentation for instructions to build, install, and test the binding on an R-Car M3 board. Added support for runtime selection of the AmazonLite wake word locale. The AmazonLite locale will automatically switch when the AVS locale is switched. Added support for optionally logging and uploading Alexa Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and UPL between the request and Alexa\u2019s response. Please contact your SA or Partner Manager for details or to request this package for Android. Added support for an optional platform interface EqualizerController . The Equalizer Controller enables Alexa voice control of device audio equalizer settings by making gain adjustments to three frequency bands (\u201cBASS\u201d, \u201cMIDRANGE\u201d, and/or \u201cTREBLE\u201d). Added an optional Code-Based Linking (CBL) authorization implementation in the Engine. With the new cbl module, the Engine handles acquiring access tokens. A CBL platform implementation should be registered with the Engine in place of an AuthProvider implementation to use this method for authorization. Improved the usage and deployment of the Local Voice Control extension on Android. Please contact your SA or Partner Manager for more information. Updated the vehicle information configuration API to include a vehicle identifier. An aace.vehicle.info.vehicleIdentifier property of vehicle configuration is now available through the existing VehicleConfiguration . Resolved Issues \u00b6 Fixed an issue where barging in while many unprocessed Speak directives are queued could cause SpeechSynthesizer to become unresponsive or crash Added an EXPECTING state to the AlexaClient DialogState to accommodate multi-turn for hold-to-talk interactions. When more user input is required during an interaction, tap-to-talk interactions will transition directly from EXPECTING to LISTENING whereas hold-to-talk will remain in the EXPECTING state until listening is manually triggered. Fixed an issue where the Android Sample App could get stuck in a loop of INVALID_REQUEST_EXCEPTION errors being thrown repeatedly after MACCAndroidClient reported an error. Note: To fix this, the C++ ExternalMediaAdapter::getState method signature changed to allow the implementation to say whether the state it provides is valid. This change is not backward compatible. Fixed an issue where the Android Sample App created a syslog sink and logged VERBOSE in release builds. Note: As part of the fix, the default Engine logger sink id changed from console to default . Existing calls to LoggerConfiguration::createLoggerRuleConfig with sink id \"console\" should be changed to sink id \"default\" . Known Issues \u00b6 The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.4.0 released on 2018-12-17: \u00b6 Enhancements \u00b6 The Alexa Auto SDK now supports the Local Voice Control extension. The Local Voice Control extension enhances the Alexa Auto experience by providing voice-based car controls whether connected to the internet or not. In this release, the Local Voice Control extension will provision access only to the car\u2019s climate control. Note : This extension is available on request - Please contact your Amazon Solutions Architect (SA) or Partner Manager for more information. Resolved Issues \u00b6 No resolved issues. Known Issues \u00b6 The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.3.1 released on 2019-06-21: \u00b6 Enhancements \u00b6 This release of Alexa Auto SDK includes updates for music certification. Resolved Issues \u00b6 Resolved issues are limited to music certification updates: Migrated to AVS Device SDK v1.12.1 for music certification. As part of the migration there is a new dependency on openssl . Developers using their own build system may need to make changes in order to accommodate this new dependency when linking AVS Device SDK. Fixed ExternalMediaPlayerAdapter getState() failure that triggered INVALID_REQUEST_EXCEPTION/Bad Request exceptions. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Updated the Android Sample App log view implementation for improved stability and performance. Bug fixes and documentation updates: Additional test in AuthProviderEngineImpl::doShutdown() to avoid null pointer exception. Fixed an issue with SQLiteStorage::removeKey() where the DELETE FROM statement repeated the FROM . Fixed a race condition in AudioChannelEngineImpl::setSource() with back to back TTS. Internal calls to AudioChannelEngineImpl::executePlaybackFinished() now save the player offset. Internal calls to AudioPlayerEngineImpl::removeObserver() now remove an AudioPlayerObserverInterface observer instance instead of adding it. Use static_cast<unsigned char> for upper/lower character conversions. The platform interfaces have not changed, however the following C++ and Android enums are updated: * The enum class DialogState inserts the EXPECTING enum constant. * The enum class ConnectionChangedReason inserts NONE , SUCCESS , and UNRECOVERABLE_ERROR enum constants. Known Issues \u00b6 All known issues from v1.3.0. v1.3.0 released on 2018-11-20: \u00b6 Enhancements \u00b6 Android 8 and ARM v8a platform support. Making calls to contacts from a locally-paired mobile phone as long as the Alexa Auto SDK has a valid auth token. For details, see the Contact Uploader documentation . Redial, answer, terminate, and decline calls using voice. End users can also send dual-tone multi-frequency (DTMF) via voice to interact with Interactive Voice Responders (IVRs). For details, see the Phone Control documentation . Switching to local media sources, generic controls and deep linking into 3rd party media applications compatible with the Amazon Media App Command and Control (MACC) specification using the External Media Player Interface 1.1. This allows customers to switch between a CD player, AM/FM player, and auxiliary input that is MACC-compliant. For details, see the Alexa documentation . Enhancement for 3rd party wake word engine to enable cloud based verification. Provides a way to override Template Runtime display card timeout values for RenderTemplate and RenderPlayerInfo by updating the templateRuntimeCapabilityAgent Engine configuration values. Resolved Issues \u00b6 No resolved issues. Known Issues \u00b6 The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.2.0 released on 2018-10-15: \u00b6 Enhancements \u00b6 Additional information related to the presentation of alerts is now available. The extended interface now includes Alert token, type, rendering time, and label if applicable when an alert is set and notification when an alert is deleted. In the Navigation platform interface, SetDestination now provides business hours and contact information for a returned location when available. Resolved Issues \u00b6 If a location is not available, the location state is set to unavailable . Previously it was treated as (0,0) , which was a valid value for longitude and latitude. Fixed an issue related to stopping an alert where there could be up to a 10 second delay before the alert completely stopped. Fixed issue where the TemplateRuntime platform interface could not be registered before AudioPlayer . Known Issues \u00b6 There are no known issues in this release. v1.1.1 released on 2018-09-10: \u00b6 Enhancements \u00b6 This release is for bug fixes only. There are no new features or enhancements. Resolved Issues \u00b6 Updated a dependency build recipe to skip the checksum verification to allow for document changes in the current tag. Known Issues \u00b6 There are no known issues in this release. v1.1.0 released on 2018-08-31: \u00b6 Enhancements \u00b6 Added support for choosing one of multiple network adaptors before starting the Engine. Added support for the latest Amazon Wakeword Engine. Added custom volume control support for infotainment system's native input volume range. The range that comes down to the device will be 0 to 100. Added support for encoding the utterance in OPUS format with the Amazon Wakeword Engine as well as PTT. Our builder pulls the libopus source code as a part of build process. Added Locale API to return the list of Alexa-supported locales. Updated Vehicle Information API to capture the microphone details. Added support for routines, music alarms, timers and alarms volume management, and deleting all timers and alarms. Added support for TemplateRuntime Interface 1.1, which provides visual playback control for Alexa-enabled products with TemplateRuntime Interface support. This includes upgrades to PlaybackController Interface 1.1 and TemplateRuntime Interface 1.1. Note : The older button-press APIs ( playButtonPressed() , nextButtonPressed() , etc.) have been deprecated in favor of the new generic buttonPressed(PlaybackButtonType) . Updated the builder script to confirm compliance with open source component licenses. Resolved Issues \u00b6 There are no resolved issues in this release. Known Issues \u00b6 There are no known issues in this release. v1.0.2 released on 2018-08-08: \u00b6 Enhancements \u00b6 This release is only for documentation updates. There are no new features or enhancements. Resolved Issues \u00b6 Only name change updates were made to the documentation. There are no resolved issues in this release. Known Issues \u00b6 There are no known issues in this release. v1.0.1 released on 2018-07-31: \u00b6 Enhancements \u00b6 This release is for bug fixes only. There are no new features or enhancements. Resolved Issues \u00b6 The Engine now reconnects to Alexa when the NetworkInfoProvider updates the network status. All shared memory objects are now freed when the Engine object is disposed. We fixed a media playback state issue in the Engine that caused an unexpected pause and resume for a media stream that was already stopped. We added AudioPlayer::playerActivityChanged to the Android APIs. Updated the AuthError enumeration with additional error types. Removed deprecated createAuthConfig() configuration method. Fixed issue in the JNI where trying to create a UTF-8 string with invalid characters caused a crash, seen when sensitive logging is enabled. Improved JNI thread handling. Enabled capability registration for phone call control. We fixed an issue where the Android platform build failed on the initial attempt when using clean code. Known Issues \u00b6 There are no known issues in this release. v1.0.0 released on 2018-06-29: \u00b6 Enhancements \u00b6 Alexa Auto SDK now supports two Navigation directives. SetDestination CancelNavigation Added support for phone control APIs. The PhoneCallController platform interface supports the Dial directive with three events: CallActivated CallTerminated CallFailed Support for Amazon Wake Word Engine (WWE) Known Issues \u00b6 The Engine doesn't immediately reconnect to AVS when the NetworkInfoProvider updates network status. Some shared memory objects are not freed when the Engine object is disposed. Sample App issues are documented in the Sample App README . v1.0.0 Beta released on 2018-04-29: \u00b6 Enhancements \u00b6 The following enhancements were added to the Alexa Auto SDK since the last Alpha release (binary). SetDestination() API added to the Navigation module Android Sample Application updated with a number of features such as rendering of Display Cards (Shopping List, Coffee Shops Nearby, etc), handling of the SetDestination() API, Notifications, LWA (Login with Amazon) Known Issues \u00b6 SDK: While the SDK does build against Android API22 and above and runs successfully on Android O devices, our current testing shows a native-code linking error when actually running on API22 devices. Android Sample App: M3U and PLS based stream URLs are not parsed before sent to the Android Mediaplayer. Affects live streams typically coming from TuneIn and IHeartRadio services Media playback can take a long time to start sometimes for iHeartRadio and TuneIn The Android Alexa Auto SDK Sample App was developed on an Android tablet with 2048 x 1536 resolution screen size. It can run on smaller devices, but some of the display cards may not display correctly During Playing Media in the Sample App we see the following messages (none of these will cause any issues): E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=streamFormat E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=progressReportDelayInMilliseconds E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=expectedPreviousToken E/AAC:aace.alexa.AudioChannelEngineImpl:validateSource:reason=invalidSource E/AAC:aace.alexa.AudioChannelEngineImpl:pause:reason=invalidSource,expectedState=X On App startup we see the following messages (none of these will cause any issues): E/AVS:SQLiteAlertStorage:openFailed::File specified does not exist.:file path=/data/user/0/com.amazon.sampleapp/cache/appdata/alerts.sqlite Several minor documentation issues that will be addressed in the GA release","title":"Changelog"},{"location":"releases/changelog/#change-log","text":"","title":"Change Log"},{"location":"releases/changelog/#v411-released-on-2022-08-08","text":"","title":"v4.1.1 released on 2022-08-08"},{"location":"releases/changelog/#enhancements","text":"Improved Auto SDK AACS Sample App Setup and Settings UX. Updated APL renderer app component, as well as dependent APL Viewhost Android libraries (AARs). It is highly recommended you update to release 4.1.1 for APL integrations. Note: All Auto SDK 4.1 extensions are compatible with 4.1.1.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues","text":"Improved the settings menu by expanding the clickable area of settings, and added missing descriptions for menu items. Fixed a race condition in which updating the Alexa language setting, and then navigating away from the menu page could crash the application without switching the language. Fixed an issue in which the Alexa comms permission screen did not render properly. Improved the margin alignment issue in the setup screens.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues","text":"General The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try Communications If the user asks Alexa to redial the last called number when their phone is not connected to the head unit, Alexa is silent rather than prompting the user to connect their phone. Entertainment When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song. When using the LVC extension, if the application publishes the MediaPlaybackRequestor.RequestMediaPlayback AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the RequestMediaPlayback message. There is no AASB message to indicate to Alexa that the user switched the media player UI on the head unit from an Alexa-integrated local media source, such as FM radio, to Alexa cloud-based music service provider. The only way to switch the audio context between the two player types is through voice interaction explicitly requesting a particular player. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. Local Voice Control In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize follow up requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. AACS sample app * Sometimes the sample app will display an error page during sign-in if the user launched the app with the launcher icon. The recommended workaround is to set Alexa as the default assistant in the settings menu to guarantee AACS initializes properly before sign in. * APL Card is prematurely closed if there is music playing in the background and APL command SpeakItem or SpeakList is executed. * The voice interaction UI does not match the automotive UX guidelines for touching the screen during the interaction. The UX guidelines state that the interaction should continue if the user taps or scrolls, but the sample app cancels the interaction when the user taps or scrolls. * The volume Alexa uses to read a shopping list is louder than the volume set for other Alexa responses. * When the device has internet disconnected and the user sets the system language to a language not supported by Alexa, the sample app does not always display the language selection screen automatically. * When the user revokes Alexa permission to use the microphone and then re-enables the permission, Alexa does not respond to utterances until the user restarts the app. * If an alert is going off while Alexa is speaking, the timer audio cancels the Alexa speech. timer is going off while Alexa is speaking, the timer audio cancels the Alexa speech. C++ sample app The sample app may fail to handle synchronous-style AASB messages within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected.","title":"Known Issues"},{"location":"releases/changelog/#v410-released-on-2022-05-27","text":"","title":"v4.1.0 released on 2022-05-27"},{"location":"releases/changelog/#enhancements_1","text":"Auto SDK Added support to display a smart home dashboard using voice requests such as \u201cAlexa, show me my smart home dashboard\u201d. The user can use the dashboard to monitor and control the states of their smart home devices such as lights, plugs, switches, and thermostats. The smart home dashboard is powered by APL and updates to reflect the vehicle\u2019s settings for day and night mode, custom themes, and driving state. Added the Feature Discovery interface, enabling users to learn about Alexa features by providing an API for your application to retrieve and display suggested utterances dynamically. For more information, see the Feature Discovery documentation . Deprecated the Local Voice Control (LVC) APK in favor of a new LVC AACS App Component that integrates LVC directly into AACS. See the Local Voice Control extension documentation for more information. Enhanced LVC offline local search to support voice-based search and navigation to cheap gas stations and electric vehicle charging stations for en-US locale. Enhanced LVC offline navigation feature to show/navigate to previous destinations, show alternate route, route-based ETA, and add/remove waypoints to POI, user favorites, and address for en-US locale. Updated Alexa to disallow Alexa Presentation Language (APL), directives from skills that are not explicitly certified as safe for automotive. Certified skills may render APL, and uncertified skills fall back to experiences with TemplateRuntime (if supported) or voice-only. Updated the aace.vehicle.info configuration to include two additional optional fields, engineType and rseEmbeddedFireTvs. See the Core module documentation for additional information. Updated the Auto SDK Builder Tool to use a custom Python interpreter /usr/bin/env python3 rather than the previously hardcoded /usr/bin/python3 Updated the Auto SDK Builder Tool to use the additional compiler and linker flags that enable exploit mitigation techniques, including safe stack, stack canary, fortifying source, and RELRO. Updated the following dependency versions: Android NDK r21e Curl 7.81.0 SQLite 3.37.2 The Auto SDK build system was updated to support QNX 7.0 and QNX 7.1 SDP cross-compilation. Added the option libcurl:openssl_version to the Auto SDK build system recipes to specify the OpenSSL version. Enhanced Auto SDK logs to display thread ID and uses different colors per log level. Added support to build Auto SDK using a custom toolchain. See the Build Alexa Auto SDK documentation for more information. AACS Sample App for Android Automotive OS Added an Alexa app icon that allows users to launch the AACS sample app directly from the app launcher instead of the system settings menu. Added Things-to-try in setting menu that displays a list of utterances for user to try out in different domains. Enhanced the Navigation app component that provides a plugin framework for 3P navigation provider. See Alexa Auto Navigation app-component for details. Interruption Behavior - Push-to-talk (PTT) now interrupts while Alexa is speaking/thinking, and cancels when Alexa is listening. Barge-in sounds now play, in the previous version the new dialog would start silently. Alexa setup flow is now interrupted if the vehicle is in motion, and setup flow is resumed when the vehicle returns to the parked state. Implemented a BACK button that returns the user to the previous activity when pressed. Enhanced the contacts sharing consent UI to display the consent screen when a new phone is paired and to persist consent for subsequent pairings. Previously, the consent UI only displayed as part of the setup flow. Enhanced the communications screen UI to display all paired phones instead of only connected phones. This enables the user to enable or disable contacts from a paired phone at any time. Added a short \"exit\" animation to the voice chrome UI that displays on transitions from Speaking to Idle or Listening to Idle. Added support for handling Alexa's Language selection mismatch between system and Alexa supported languages during first-time user experience (FTUE) and subsequent language changes.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_1","text":"Auto SDK Fixed an issue in which the CBL module did not check the network connection status when attempting to refresh an access token. If there was no network connection when the refresh was attempted, the token would not refresh immediately when connection was restored. Fixed an issue in which the \u201cAlexa, stop\u201d utterance did not stop music playback when audio ducking is enabled. Fixed periodic Engine shutdown crashes in ContextManager , ExternalMediaPlayer , and AACS. Fixed an issue in which the Navigation module inserted an invalid error code in the payload of the ShowAlternativeRoutesFailed event. Additionally added the NOT_NAVIGATING error code to the Navigation AASB interface. See the Navigation module documentation for info about which error codes to use. Fixed issues that could cause the Engine to hang indefinitely at shutdown. Fixed an issue in the Local Navigation module of the LVC extension that could cause Engine restart to fail after a previous Engine stop. Fixed an issue in which applications had to manually include header files from the Nlohmann - JSON for Modern C++ library (https://github.com/nlohmann/json) because the Auto SDK build did not export them Fixed an issue in which offline local search and navigation for POIs was not working. Fixed an issue in which the C++ sample app crashed during launch on the Poky Linux 32-bit platform. AACS Sample App Fixed the language selection screen in the AACS sample app when the Preview Mode feature is enabled. Fixed an issue in which the AACS sample app did not play alarms when the device is offline. Fixed an issue in which the display card for a second weather utterance closed too soon. Fixed an issue which the AACS sample app did not reset the contact permissions when switching accounts Fixed an issue in which the AACS sample app stopped music playback when the user tapped the screen showing a display card. Fixed an issue in which AACS did not play the Alexa confirmation speech when the user creates a notification while music is playing.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_1","text":"General The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try Communications If the user asks Alexa to redial the last called number when their phone is not connected to the head unit, Alexa is silent rather than prompting the user to connect their phone. Entertainment When music is playing, repeatedly pressing the \u201cnext\u201d button to advance in the playlist restarts the current song. When using the LVC extension, if the application publishes the MediaPlaybackRequestor.RequestMediaPlayback AASB message before the Auto SDK Engine connects to Alexa cloud, media playback will not automatically resume as expected. The workaround is to wait for the connection to Alexa cloud to complete before publishing the RequestMediaPlayback message. There is no AASB message to indicate to Alexa that the user switched the media player UI on the head unit from an Alexa-integrated local media source, such as FM radio, to Alexa cloud-based music service provider. The only way to switch the audio context between the two player types is through voice interaction explicitly requesting a particular player. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. Local Voice Control In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize follow up requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. C++ sample app The sample app may fail to handle synchronous-style AASB messages within the required timeout to construct device context for Alexa. As a result, some utterances may not work as expected. AACS sample app Sometimes the sample app will display an error page during sign-in if the user launched the app with the launcher icon. The recommended workaround is to set Alexa as the default assistant in the settings menu to guarantee AACS initializes properly before sign in. APL Card is prematurely closed if there is music playing in the background and APL command SpeakItem or SpeakList is executed. The voice interaction UI does not match the automotive UX guidelines for touching the screen during the interaction. The UX guidelines state that the interaction should continue if the user taps or scrolls, but the sample app cancels the interaction when the user taps or scrolls. The volume Alexa uses to read a shopping list is louder than the volume set for other Alexa responses. When the device has internet disconnected and the user sets the system language to a language not supported by Alexa, the sample app does not always display the language selection screen automatically. When the user revokes Alexa permission to use the microphone and then re-enables the permission, Alexa does not respond to utterances until the user restarts the app. If an alert is going off while Alexa is speaking, the timer audio cancels the Alexa speech. timer is going off while Alexa is speaking, the timer audio cancels the Alexa speech.","title":"Known Issues"},{"location":"releases/changelog/#v400-released-on-2021-12-15","text":"","title":"v4.0.0 released on 2021-12-15"},{"location":"releases/changelog/#enhancements_2","text":"Deprecated the C++ and Java platform interfaces in favor of an asynchronous message-based API. Auto SDK client applications use the new MessageBroker to publish and subscribe to Alexa Auto Services Bridge (AASB) messages. The C++ sample app is refactored to use the new API to provide a reference implementation for Linux platforms. The Alexa Auto Client Service (AACS) sample app provides the reference implementation for Android platforms. See the Auto SDK Migration Guide for help migrating your application to use the new API. Enhanced the Auto SDK build system with the Conan package manager. The new build system introduces modular builds, better dependency management, and simpler build artifacts. The Auto SDK build system includes the Auto SDK Builder Tool script, which wraps the Conan build commands with a simple interface similar to the previous version of Auto SDK Builder. See the Build Alexa Auto SDK documentation for details about the build system and the migration guide for help migrating your build to the new version of Builder Tool. Extended the features of Alexa Presentation Language (APL) support for automotive. The APL module provides messages to report vehicle properties such as the display theme, driving state, and ambient light conditions. The property settings affect how APL documents render on screen; for example, some APL content is automatically hidden when the vehicle starts moving, and the display contrast updates with the day or night mode setting. Auto SDK 4.0 supports APL 1.9. For more information about the Auto SDK APL interface, see the APL module documentation. Added the CustomDomain interface, which establishes a bidirectional communication channel between your Auto SDK client application and your custom cloud skill. CustomDomain includes messages for exchanging directives, events, and context between the vehicle and your skill, achieving a fully customizable experience. For more information about the Auto SDK CustomDomain interface, See the Custom Domain module documentation. Added the MediaPlaybackRequestor interface, which enables Alexa to play the user\u2019s favorite media content as soon as they start their vehicle. MediaPlaybackRequestor simplifies content selection for the user by removing the need for the user to use buttons or voice commands to resume the Alexa media content that was playing when they stopped the vehicle. For more information about the Auto SDK MediaPlaybackRequestor interface, See the Alexa module documentation. Extended the AudioOutput interface and added configuration to allow ducking Alexa media. Your application can use this feature for enhanced control of Alexa content audio focus according to your platform requirements. For more information about audio ducking, see the Core module documentation. Updated the Auto SDK to use AVS Device SDK Version 1.25.0. For information about this version of AVS Device SDK, see the AVS Device SDK release notes. Added LVC support for Alexa Custom Assistant specialized handoffs. You can configure the default fallback and self-introduction prompts for your custom assistant while offline. For more information, see the Alexa Custom Assistant extension documentation. Integrated the Auto SDK Conan build system enhancements to AACS and the AACS sample app. You can use a single Gradle command to build AACS and the AACS sample app without using the Auto SDK Builder Tool directly. For build instructions, see the AACS documentation . Added the following enhancements to the AACS sample app: Additional languages\u2014 The AACS sample app supports the following languages: US English ( en-US ), Australian English ( en-AU ), Canadian English ( en-CA ), Indian English ( en-IN ), British English ( en-GB ), German (d e-DE ), Spanish ( es-ES ), Mexican Spanish ( es-MX ), US Spanish ( es-US ), French ( fr-FR ), Canadian French ( fr-CA ), Hindi ( hi-IN ), Italian ( it-IT ), Japanese ( ja-JP ), and Brazilian Portuguese ( pr-BR ). The sample app language setting matches the device\u2019s system language setting and syncs the with Alexa as long as the setting is in the supported language list. If Alexa does not support the system language, the sample app GUI defaults to en-US and presents a list of languages for the user to choose from. Once the user selects the language override, the system language does not sync with the sample app again until the user logs out or disables Alexa. Network error prompts\u2014 You can configure the sample app to provide feedback to the user when Alexa cannot respond due internet connection issues. The feedback is a voice prompt or an error screen depending on the user action. Alexa app assets\u2014 The sample app can show Alexa logos (assets) on the setup screen and display cards instead of showing placeholder assets. Comms UI improvements\u2014 Updated the contacts uploading logic in the Comms UI AACS app component to ensure the sample app only uploads the contacts for the primary phone. Updated the AACS Telephony library to get the outgoing phone account using the Android standard API getDefaultOutgoingPhoneAccount . AACS Telephony no longer sends an account query intent when receiving the PhoneCallController.Dial message from the Auto SDK Engine. Added a new intent com.amazon.aacstelephony.bluetooth.connectionCheckCompleted , which AACS Telephony service broadcasts when it finishes the initial bluetooth connection check. Updated the alexa-auto-lwa-auth app component to use the Authorization Auto SDK interface for CBL authorization.","title":"Enhancements"},{"location":"releases/changelog/#other-changes","text":"Removed support for the Android 32-bit ARM architecture (i.e., armeabi-v7a ). Moved several source code directories within the aac-sdk root directory to support the enhanced build system. Removed aac-sdk/platforms/android/ . The deprecated Java platform interfaces and JNI are in their respective modules. For example, the Alexa module Java interfaces and JNI are moved from aac-sdk/platforms/android/modules/alexa/ to aac-sdk/modules/alexa/android/ Removed aac-sdk/extensions/aasb/ because using AASB messages with MessageBroker is the primary Auto SDK API. AASB code for each module is in the respective module directory. For example, the AASB code for the Alexa module is in aac-sdk/modules/alexa/aasb/ . Note that the AASB message headers to include in your application are not in this directory since they are generated as part of the Auto SDK build output. Moved aac-sdk/extensions/system-audio/ to aac-sdk/modules/system-audio/ Moved aac-sdk/extensions/bluetooth/ to aac-sdk/modules/bluetooth/ Moved aac-sdk/extensions/loopback-detector/ to aac-sdk/modules/loopback-detector/ Moved aac-sdk/platforms/android/alexa-auto-client-service/ to aac-sdk/aacs/android/ Moved aac-sdk/platforms/android/alexa-auto-client-service/app-components/ to aac-sdk/aacs/android/app-components/ Moved aac-sdk/samples/android-aacs-sample-app/ to aac-sdk/aacs/android/sample-app/ Moved aac-sdk/platforms/android/alexa-auto-client-service /commonutils/ , /ipc/ , and /constants/ to aac-sdk/aacs/android/common/ Moved AACS media player files to a directory audioOutput within aac-sdk/platforms/android/alexa-auto-client-service/service/ Moved the Media App Command and Control Android library from aac-sdk/platforms/android/maccandroid/ to aac-sdk/aacs/android/service/modules/maccandroid/ In the LVC extension, the LocalSearchProvider AASB messages now have topic LocalNavigation . For example, the existing message LocalSearchProvider.SearchRequest in 3.3 is LocalNavigation.SearchRequest in 4.0. The next major release version of Auto SDK will change the topic back to LocalSearchProvider . Deprecated the option to build AACS as an APK. Starting from Auto SDK 4.0, you can only build AACS as an AAR. Removed the Android sample app based on the Java platform interfaces. The AACS sample app demonstrates using Auto SDK on Android. Updated AASB configuration fields used for AACS. See the migration guide for details.","title":"Other changes"},{"location":"releases/changelog/#resolved-issues_2","text":"Fixed an issue preventing the generic DEFAULT type LocalMediaSource from working in offline mode with LVC. Fixed a race condition in SpeechRecognizer in which enabling wake word detection immediately after calling startCapture() resulted in a missing call to stopAudioInput() when wake word detection was later disabled. Fixed a deadlock that could occur in an application that uses the deprecated AuthProvider interface and starts, stops, and restarts the Engine in quick succession. Fixed an issue in which Spotify playback commands were delayed on QNX. Fixed an issue in which the Engine added malformed PhoneCallController context to PhoneCallController events sent to Alexa. Fixed an issue in which AACS did not acquire audio focus prior to playing Alexa speech.","title":"Resolved issues"},{"location":"releases/changelog/#known-issues_2","text":"General If you do not specify the deviceSettings.locales field of the Alexa module configuration, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not automatically declare support for default locale combinations if you assign an empty value to the locales field. The Engine does not persist the aace.alexa.wakewordEnabled Engine property setting across device reboots. Your application has to persist the setting and set the property again at each Engine start. AACS implements persisting this property and hence does not have this issue. If your Linux platform does not use AVX2 instructions, the Amazonlite wake word library initialization causes an illegal instruction error. When using LVC and stopping the Engine, the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your application should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED . The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. When the user requests to view their list of timers on an APL-enabled application, they cannot use an utterance such as \u201cAlexa, scroll up\u201d to scroll through the list shown on the APL card. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. On the Poky Linux 32-bit platform, the C++ sample app shuts down with an error on launch. In offline mode with LVC, you might not see the AlexaClient.DialogStateChanged THINKING state transition if the user invokes Alexa with hold-to-talk and your application provides the audio input data in one large chunk. In offline mode with LVC, Alexa gets stuck in the THINKING state and does not respond after changing the locale setting. The state recovers after a few minutes. The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the Engine attempts the refresh, it might take up to a minute to refresh the token after the internet connection is restored. Some Core module messages published by the Engine do not have a corresponding message for the application to report a handling failure. For example, if the user invokes Alexa by tap-to-talk, and the application cannot handle the AudioInput.StartAudioInput message, the Engine assumes the application handled the message properly and will provide audio data. As a result, the Engine state and application state might become out of sync. The affected messages are the following: AudioInput : StartAudioInput AudioOutput : SetPosition VolumeChanged MutedStateChanged Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications Alexa does not understand DTMF utterances that include letters. For example, \"press A\" and \"dial 3*#B\" do not result in the correct DTMF directives. The user might experience unexpected results by trying to dial or place calls in the following ways: Using utterances that include \u201cdouble\u201d, \u201ctriple\u201d, \u201chundred\u201d, or \u201cthousand.\u201d For example, calling a number such as 1-800-xxx-xxxx by saying \u201cAlexa call one eight double oh ...\u201d Pressing special characters such has \u201c#\u201d or \u201c*\u201d by saying \"Alexa press * #.\" The user cannot accept or reject incoming Alexa-to-Alexa calls by voice while playing a skill with extended multi-turn dialogs, such as Jeopardy or Skyrim. Entertainment If the user requests Alexa to read notifications while music is playing, they might hear the music play for a split second between the end of one notification and the start of the next. When an external media player authorization is in progress during Engine shutdown, a rare race condition might cause the Engine to crash. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. When using the System Audio module, Audible and Amazon music might not play correctly on i.MX8 boards. Local search and navigation In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize followup requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. AACS If you do not use the default audio output implementation (i.e., your application handles AudioOutput AASB messages), your application will not receive the AudioOutput.Stop message if Alexa media is playing when AACS shuts down. As a workaround, your application can listen to AASB.StopService or adopt AACSPinger to listen to the STOPPED state of AACS and stop the media accordingly. AACS Sample App The AACS Sample App does not show the language selection screen when the app is built with Preview Mode. The AACS Sample App only shows the language selection screen if there is a language mismatch with the system language setting at the first app launch.","title":"Known issues"},{"location":"releases/changelog/#v330-released-on-2021-09-30","text":"","title":"v3.3.0 released on 2021-09-30"},{"location":"releases/changelog/#enhancements_3","text":"Added the DeviceUsage platform interface to provide the Alexa application network usage data to the Auto SDK Engine. The Auto SDK Engine emits this data as a metric to Amazon if Auto SDK is built with the Device Client Metrics extension. For more information, see the Core module documentation Extended the features of the Local Navigation module for the Local Voice Control (LVC) extension. The LocalSearchProvider platform interface now enables you to provide customers with offline navigation to street addresses, cities, and neighborhoods in addition to the existing support for local search and navigation to points of interest. See the Local Navigation module README for information about integrating the features. Note: There are updates to the LocalSearchProvider APIs. See the Auto SDK Migration Guide for details. Added a new generic DEFAULT media source to the list of sources supported by the LocalMediaSource platform interface. The DEFAULT source can be used for voice playback control of any arbitrary media sources on the infotainment system outside of deep-linked MACC applications using the ExternalMediaAdapter interface and existing sources supported by name through the LocalMediaSource interface. For details about integrating a default media source, see the Alexa module documentation . Added offline LVC support for tuning to station names on terrestrial radio and SiriusXM. E.g., \u201cPlay CNN on Sirius XM\u201d and \u201cPlay KISS FM\u201d. This feature is already available in online mode. Enhancements for AACS: Added an app component called alexa-auto-carcontrol that deeply integrates Auto SDK car control features into the Android Automotive OS. For more information about AACS deep integration to Car Control, please refer to this README . Added an enhancement in which AACS can automatically sync Alexa\u2019s timezone and locale properties with the device system settings when you set the syncSystemPropertyChange field to true in your AACS configuration file. If you set the field to false or omit it, you still have flexibility to change the properties in your own implementation. Enhancements for AACS Sample App: Added a location sharing consent screen in Alexa setup and settings wherein the user has the option to enable or disable location sharing. Added support for rendering for TemplateRuntime display cards for the weather domain. Added support for rendering Amazon Presentation Language (APL) documents. Added media player transport control improvements. For example, shuffle and loop transport controls are added, and disabled transport controls are displayed. Added support for setup and setting menu specific to the Alexa Custom Assistant extension.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_3","text":"Android 11 requires the attribute android:foregroundServiceType to be defined in services that require permissions such as microphone and location. This is added to the AACS Android Manifest file. Also, the compileSdkVersion and targetSdkVersion to are updated to 30 in build.gradle . Added a UserIdentity value in AACS AuthStatus when the user finishes CBL login. Made the 'stateOrRegion' field optional in the AACS StartNavigation directive JSON parser. Implemented the AASB SetUserProfile message in the CBL module to ensure the user email and username will be sent to the client application after user login when enableUserProfile is set to true. Fixed an issue that blocked a valid transition from the THINKING to LISTENING AlexaClient dialog states. Updated the PhoneCallControllerCapabilityAgent to include context in PhoneCallController events per the PhoneCallController API specification. Fixed a memory leak observed during Engine shutdown in the Local Voice Control extension. Fixed a rare deadlock issue during Engine stop and start when using the AuthProvider interface. Fixed an issue in which the Engine erroneously allowed 3,000 coordinates in the \"shapes\" array of navigation state queried via Navigation::getNavigationState() . The limit is updated to 100 coordinates.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_3","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. The automotive HMI guidelines for display cards state that actionable display cards should be dismissed automatically after 30 seconds, and non-actionable display cards should be dismissed automatically after 8 seconds. This guideline is not descriptive enough since it does not clarify what is actionable and non-actionable content. The UX team is working on correcting the guideline to specify specific template types. The current automatic dismissal time for all Template Runtime display cards is 8 seconds. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. The generic DEFAULT LocalMediaSource type is not supported offline with LVC. If user gives a generic playback control request like \"Alexa, play\" when the Alexa application is operating in the offline mode with LVC, Alexa responds \"Sorry, something went wrong\". Other named players like USB work as expected in the offline mode. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. Local Search and Navigation When using LVC in offline mode, after requesting a list of POIs (e.g., \"find Starbucks nearby\"), Alexa does not recognize utterances like \"select the first one\" and does not display or read detailed information about the requested selection. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) If you are not using the default audio output implementation (i.e. your application handles AudioOutput AASB messages) and even though you are playing the Alexa pushed media content, Stop message would not be sent from AACS when AACS shuts down. e.g. If you are playing an audio stream for AmazonMusic, if AACS is stopped, AASB AudioOutput.Stop message would not be received. As a result, the media playing from your application would not be stopped. This issue will be fixed in the next release. As a workaround, your application can listen to AASB.StopService message or adopt AACSPinger to listen to the STOPPED state of AACS and stop the media accordingly.","title":"Known Issues"},{"location":"releases/changelog/#v321-released-on-2021-08-06","text":"Note: All Auto SDK 3.2 extensions are compatible with 3.2.1.","title":"v3.2.1 released on 2021-08-06"},{"location":"releases/changelog/#enhancements_4","text":"Added additional APIs to the Connectivity module, which enable the voice up-sell conversation between the user and Alexa to activate a trial data plan or a paid subscription plan. Your implementation should call AlexaConnectivity::sendConnectivityEvent() to notify the Engine of the data plan type. To respond, the Engine calls AlexaConnectivity::connectivityEventResponse() . Added the configuration field aace.addressBook.cleanAllAddressBooksAtStart to Engine configuration. This field specifies whether to automatically delete address books each time the Engine starts.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_4","text":"Fixed an issue in which wake words cannot be detected correctly when using the SpeechRecognizer::startCapture() API with an external wake word engine.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_4","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state)","title":"Known Issues"},{"location":"releases/changelog/#v320-released-on-2021-05-19","text":"","title":"v3.2.0 released on 2021-05-19"},{"location":"releases/changelog/#enhancements_5","text":"Added the DeviceSetup platform interface that handles events and directives related to device setup during or after an out-of-the-box experience (OOBE). After the user login, Alexa is informed that device setup is complete and starts the on-boarding experience, for example, by starting a short first-time conversation. For more information, see the Alexa module documentation . Added support in the Connectivity module to provide the network identifier from the vehicle to Alexa, which enables automakers to offer full connectivity plans to customers. For connectivity status, the module supports sending the version of the terms and conditions through a field called termsVersion . Also, the termsStatus field accepts DEFERRED , which means Alexa can remind users to respond to the terms and conditions at a later time. Added the Mobile Authorization extension, which enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone, instead of opening a web browser and entering a code. Added the Bluetooth extension, which allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Added the Geolocation extension, which provides geolocation consent support. The user can grant consent to location sharing with Alexa from your application. Added the locationServiceAccessChanged(LocationServiceAccess access) API in the LocationProvider interface, which allows the Engine not to query the device location when the location service access is turned off on the device. Added the APL Render module, which enables APL rendering capabilities in an Android application. Note: This module is for you to experiment with APL document rendering on an automotive device. Do not use the module to render APL documents in a production vehicle. Added support in the Address Book module for a phonetic field. The phonetic field is required for resolving the name of a contact or navigation favorite if the name uses Kanji characters in Japanese. Updated the Docker container for the Auto SDK builder script to use OpenSSL 1.1.1k by default. Added an environment variable for you to change the OpenSSL version, if desired. For information about the OpenSSL version, see the Builder README. Updated the Auto SDK to use AVS Device SDK Version 1.22.0. For information about the AVS Device SDK, see the AVS Device SDK Release Notes . Enhancements for AACS: Added AACS instrumentation, which enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. For information about AACS instrumentation, see the AACS documentation. Added an app component called alexa-auto-telephony , which enables you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. Added an app component called alexa-auto-contacts to enable AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information. Added the AACS AAR, which you can include in your application. The timeout for AASB synchronous messages is now configurable. For information about configuring the timeout, see the AACS documentation. Enhancements for AACS Sample App: Added support for new features in the AACS Sample App. For example, it includes a menu for the user to select a language if the in-vehicle infotainment (IVI) language is not supported by Alexa, and it supports authorization with Preview Mode. Added support for the Alexa Custom Assistant extension to the Alexa Auto Client Service (AACS) Sample App. The sample app demonstrates how an application can use AACS with this extension. With app components included with the sample app, you can develop an application that handles assistant handoff and displays custom animation for your custom assistant. Note: In order to use the Alexa Custom Assistant extension with the AACS Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Enhancements for metrics uploading: The Auto SDK emits only registration metrics before user login is complete. Other metrics are emitted after user login. The Device Client Metrics (DCM) extension supports uploading more metrics from the vehicle than in previous versions. The DCM extension supports anonymizing all Auto SDK metrics. Enhancements for car control: Added prompt improvements. Alexa can provide a recommendation or ask for clarification after receiving an invalid or ambiguous user request. Suppose a user request targets the wrong mode, setting, or value for an appliance, such as \"Alexa, set fan speed to 100\", Alexa responds, \"Sorry, you can only set the fan between 1 and 10\". When the target in a user request is ambiguous, Alexa prompts for more information to determine the exact meaning of the request. For example, when a user says, \"Turn on fan\" (when the fan's default zone is not set), Alexa responds, \"For the driver, the passenger, or the rear?\" This feature is supported online and offline. Improved asset management for car control, which enables Alexa to accept utterances only a few seconds after the user logs in. Previously, the user had to wait up to 20 seconds for Alexa to accept utterances. Improved the Auto SDK Voice Chrome extension to allow the height and width of the linear voice chrome to be controlled by the parent layout. Previously, the dimensions were fixed.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_5","text":"Disabled APL by default in AACS to make sure utterances like \"tell me a joke\" work correctly without handling APL. If your platform wants to implement APL, see the AACS Configuration README to enable it. An SMS message can be sent to an Alexa contact correctly. A user request to send an SMS message to an Alexa contact no longer results in an Alexa-to-Alexa message. For car control, there is no longer a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). After the AmazonLite Wake Word locale model is switched from the default (en-US) to another locale model (e.g., de-DE), the newly selected locale remains in effect after the user quits and then restarts the application. Numeric weather IDs are passed to AVS for the TemplateRunTime API, making it easier for you to display weather icons that are consistent with your user interface. After the user disconnects the phone, if the user tries to use Alexa to make a call, Alexa responds correctly by reminding the user to connect the phone. Previously, Alexa tried to dial the number. After the user pauses on Spotify and presses \u201cPlay\u201d to resume, the player starts correctly from the point where the player stops. Previously the player skipped ahead, resuming from an incorrect place. AutoVoiceChromeController and StateChangeAnimationScheduler of the Voice Chrome extension are thread-safe now, preventing the Alexa app from crashing in different scenarios (e.g. when changing to the previous music track). Fixed a race condition in AuthorizationManager during the Engine shutdown.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_5","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state)","title":"Known Issues"},{"location":"releases/changelog/#v310-released-on-2020-12-15","text":"","title":"v3.1.0 released on 2020-12-15"},{"location":"releases/changelog/#enhancements_6","text":"Added the Authorization platform interface that replaces the CBL platform interface and the AuthProvider platform interface. For information about how the Alexa Auto SDK Engine handles authorization with the Authorization platform interface, see the Core module documentation . Note: Logging out from CBL or Auth Provider authorization clears the databases that store user data, such as alerts and settings. For example, when the user logs out, pending alerts in the database are cleared to ensure that the next user who logs in does not receive the alerts. In addition, upon logout, the locale setting is reset to the default value in the Engine configuration. Therefore, if the current device locale is different from the default locale, you must set the locale before starting an authorization flow. Added the Text-To-Speech module that exposes the platform interface for requesting synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. Added the Text-To-Speech Provider module that synthesizes the Alexa speech. The Text-to-Speech provider requires Auto SDK to be built with the Local Voice Control extension. For information about these modules, see the Text-To-Speech module documentation and Text-To-Speech Provider documentation . Note: This feature may only be used with voice-guided turn-by-turn navigation. Added the Connectivity module that creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. For information about the Connectivity module, see the Connectivity documentation . Added the Local Navigation module for the Local Voice Control (LVC) extension. This module enables you to provide customers with offline search and navigation to points of interest (POI) by leveraging the POI data of an onboard navigation provider. The POIs include categories, chains, and entities. The Local Voice Control (LVC) extension is required for the Local Navigation module. Note: Offline search with the Local Navigation module is only supported in the en-US locale. Added the Alexa Auto Client Service (AACS) sample app that demonstrates how an application uses AACS. The Auto SDK includes the app components used by the AACS sample app, which you can also use when developing an application that communicates with AACS. For information about the AACS sample app, see the AACS sample app documentation Added support for Digital Audio Broadcasting (DAB) radio. For more information about the DAB local media source, see the Alexa module documentation . Enhancements for AACS: Enhanced the file sharing protocol of AACS by using Android's FileProvider. This enhancement grants AACS permission to access files within your AACS client application, which are required by configuration fields for the Auto SDK. Added support for the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. For information about how AACS uses FileProvider and ContentProvider , see the AACS documentation. Added support for a ping broadcast to check the AACS connection state. For more information about how to use ping , see the AACS documentation. Added support for caching AASB message intent targets based on AASB Action. This enables you to define an intent filter with a subset of the possible actions for an AASB topic. For more information on specifying intent targets, see the AACS documentation. Added support for Text-to-Speech Service, which allows Android applications to interact with Android TTS APIs to convert text to speech. For information about the Text-to-Speech Service, see the AACS TTS app component documentation .","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_6","text":"On Android, the Engine returns the correct value ( UNDEFINED ) for requests to LocationProvider.getLocation() when the device does not have access to location. Previously the Engine populated the user geolocation with a default value when Location.UNDEFINED was returned in LocationProvider.getLocation() . In the AACS commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime could only parse the payload field of the AASB RenderPlayerInfo message payload. Now it can parse the overall AASB payload. Notifications sound plays correctly. Previously, the sound did not play as expected due to improper channel configuration. The CBL module code request flow correctly applies the locale setting to the Login With Amazon (LWA) code request. Previously, the URL returned by LWA was always in the en-US locale. If you log out and log in, the client-side Do Not Disturb (DND) state is synchronized with Alexa.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_6","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However, \u2018send message\u2019 instead of \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) AACS enables APL by default, but it does not have a default implementation for APL. AACS expects the client application to handle the messages or directives from the Engine. If APL is not handled on the client side, utterances that trigger APL capabilities, such as \"tell me a joke,\" fail. To disable APL, add the lines below to the AACS configuration file. \"aasb.apl\": { \"APL\": { \"enabled\" : false } }","title":"Known Issues"},{"location":"releases/changelog/#additional-changes","text":"Starting with v3.1.0, the Local Voice Control (LVC) extension is no longer supported on ARM32 platforms.","title":"Additional Changes"},{"location":"releases/changelog/#v300-released-on-2020-10-09","text":"","title":"v3.0.0 released on 2020-10-09"},{"location":"releases/changelog/#enhancements_7","text":"Added Alexa Auto Client Service (AACS), which enables OEMs of Android-based devices to simplify the process of integrating the Auto SDK. For more information about AACS, see the AACS documentation . Added support for removing local media sources at runtime, such as a USB drive or a Bluetooth device. Previously, if a user removed a USB drive and then requested to play music from the USB drive, the Auto SDK would attempt to play and not return an appropriate error message. This feature is enabled with an existing field in the LocalMediaSource platform interface state. For information about the platform interface state, see the Alexa module documentation.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_7","text":"On QNX, when a portion of music on Spotify is skipped, either by the user saying, \"Skip forward,\" or by the user skipping to a different song, the volume is no longer reset to the default level. A user barging in when music is playing no longer hears an Alexa response to the barge-in request. Previously, this issue happened if the System Audio extension was used. When streaming music from Alexa, the user can switch to a local media source by using one utterance, such as \"Alexa, play radio.\" Previously, Alexa would not switch to the local media source after the first utterance. The user needed to issue the request again before Alexa could play from the local media source.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_7","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) In the commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime can only parse the payload field of the AASB RenderPlayerInfo message payload. The payload field of RenderPlayerInfo is the inner payload of the nested payload structure. When using TemplateRuntime.parseRenderInfo(String json) , provide it with the embedded JSON as a string of the string value whose key is payload in the RenderPlayerInfo message\u2019s payload instead of the overall AASB payload.","title":"Known Issues"},{"location":"releases/changelog/#additional-changes_1","text":"Starting with Auto SDK v3.0, we no longer support the Automotive Grade Linux (AGL) Alexa Voice agent in the Auto SDK. If you intend to use the AGL Alexa Voice Agent, continue using Auto SDK v2.3.0, which is the last version that provides AGL support.","title":"Additional Changes"},{"location":"releases/changelog/#v230-released-on-2020-07-31","text":"","title":"v2.3.0 released on 2020-07-31"},{"location":"releases/changelog/#enhancements_8","text":"Added a new Messaging module that provides support for Short Message Service (SMS) to allow a user to send, reply to, and read messages through Alexa. Added support for zones to car control for online-only devices so the customer can target endpoints by location (e.g., \u201cset the front fan to 7\u201d). This feature was supported only with the Local Voice Control (LVC) extension, and endpoints belonged to exactly one zone. The features for online-only and LVC devices are at parity and now include assigning an endpoint to multiple zones and setting a default zone. Endpoints in the default zone take higher priority than endpoints not in the default zone when no zone is specified in an utterance. Added support for \u201csemantics\u201d for car control to enable \u201copen\u201d, \u201cclose\u201d, \u201craise\u201d, and \u201clower\u201d utterances to control endpoints. Added a method to the 'AlexaClient' platform interface to stop foreground-focused Alexa activity on the device (e.g., locally canceling ongoing TTS when the user selects a list item or presses a cancel button). Added support for Dynamic Language Switching. Previously, Alexa could only understand and respond in one language at a time. Now Alexa supports two languages at once and automatically detects the user's spoken language and responds in the same language as the utterance. The supported locale pairs are the following: [ \"en-US\", \"es-US\" ] [ \"es-US\", \"en-US\" ] [ \"en-IN\", \"hi-IN\" ] [ \"hi-IN\", \"en-IN\" ] [ \"en-CA\", \"fr-CA\" ] [ \"fr-CA\", \"en-CA\" ] Note: Dynamic Language Switching works online only. For hybrid systems using the LVC extension, offline Alexa understands and responds in the language of the primary locale. * Updated radio tuning increments for \u201cAM_RADIO\u201d and \u201cFM_RADIO\u201d Local Media Source types to support the en_IN locale. * Alexa Voice Agent now supports AGL Itchy Icefish v9.0.2. * Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binary.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_8","text":"Fixed an issue in which navigation road regulation and maneuver events resulted in \u201cINVALID_REQUEST_EXCEPTION\" or \"INTERNAL_SERVICE_EXCEPTION\" error logs. Fixed several failing car control utterances including those for offline AC controls and those using the words \u201cmy\u201d or \u201clights.\u201d Fixed an issue in External Media Player that caused the \u201cNEXT\u201d play control request to be issued twice for ExternalMediaAdapter (e.g., MACC) and LocalMediaSource platform interface handlers. Fixed an issue in which the Engine did not stop music playback after user logout. Fixed an issue that caused Spotify to play at an increased and unsteady rate on QNX. Fixed an issue with the --use-mbedtls build option that caused a crash in the Android sample app at startup. Fixed an issue in the Engine metrics implementation in which regular expression matching with a large number of data points caused a crash. Fixed an issue in MACC in which players removed while the Engine was running (such as by the uninstallation of a linked MACC-compliant app) could not be rediscovered properly and used again, even if the player was restored (such as by the reinstallation of the app and user login). Previously, the rediscovery logic left insufficient time to process the player removal event before trying to discover players again, resulting in a loop. Now the rediscovery step runs at 5-minute intervals. Fixed an issue with the Engine's SQLite local storage database in which concurrent access to the database caused a crash. Fixed various memory leaks and intermittent crashes caused by race conditions at Engine shutdown. Fixed an issue on Android API 25 in which a large number of emitted logs could cause a crash due to a JNI local reference table overflow. Fixed an issue in which you experienced unexpected results if the local timezone of your device differed from the timezone configured through the Alexa companion app.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_8","text":"General A user barging in when music is playing sometimes hears the Alexa response to the barge-in request and the music at the same time if System Audio extension is used. If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The user must enunciate \u201cline-in\u201d in utterances targeting the \u201cLINE_IN\u201d Local Media Source type in order for Alexa to recognize the intent. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. On QNX, when a portion of music on Spotify is skipped, either by the user saying \"Skip forward\" or by the user skipping to a different song, the volume is reset to the default level. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.","title":"Known Issues"},{"location":"releases/changelog/#v221-released-on-2020-05-29","text":"","title":"v2.2.1 released on 2020-05-29"},{"location":"releases/changelog/#enhancements_9","text":"Added enhancements to the maccandroid module to allow SupportedOperations to be overridden to support custom actions. Enhanced the TemplateRuntime platform interface to support focus and audio player metadata in renderTemplate and renderPlayerInfo methods. This is a backward compatible change, see the migration guide for details. SpeakerManager is now a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\".","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_9","text":"Fixed issues in the maccandroid module to a) rediscover media apps after getting the app removed callback, and b) change the behavior to only report unauthorized when the user specifically asks to play a media app. On the QNX platform, prevent unnecessary flushing for audio output.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_9","text":"On the Android Sample App, media playback gets into \"No Content Playing\" state where all GUI playback control breaks, when pressing next after force closing an external media app. Playback controls in the C++ Sample App Playback Controller Menu are static text items and do not change visual state (e.g. add/remove, hilite, select) based on audio player metadata.","title":"Known Issues"},{"location":"releases/changelog/#v220-released-on-2020-04-15","text":"","title":"v2.2.0 released on 2020-04-15"},{"location":"releases/changelog/#enhancements_10","text":"Added a Car Control module to support online-only car control use cases without the optional Local Voice Control (LVC) extension. The Car Control module provides the car control functionality introduced in Auto SDK 2.0.0 but does not require the LVC extension. Made various enhancements to the External Media Player (EMP) Adapter to improve EMP behavior and facilitate implementation of Alexa audio focus. Introduced the Property Manager, a new platform interface that allows you to set and retrieve Engine property values and be notified of property value changes. Added support for setting the timezone of a vehicle. The PropertyManager interface supports a new a \"TIMEZONE\" property setting. Added support for specifying a custom volume range for voice interactions in implementations that use the optional Local Voice Control (LVC) extension. Separated the LVC language models into independent APKs rather than providing them directly in the LVC APK as was done in previous releases. One language model APK is provided for each supported locale (currently en-US, en-CA, and fr-CA).","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_10","text":"Fixed an issue where the CBL state did not change to stopped when you cancelled login with CBL::cancel() . Fixed an issue where volume adjustments were lost when pausing and resuming music. Fixed an External Media Player (EMP) Engine implementation that caused an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession. Fixed an issue where the Engine might hang during shutdown if it was shut down while TTS was being played or read. Fixed an issue where Auto SDK initialization failed at startup when applications using the optional LVC extension didn't register a NetworkInfoProvider platform interface. Fixed an issue where building the Auto SDK with sensitive logging enabled was not working as expected. Added alerts error enums ( DELETED and SCHEDULED_FOR_LATER ) to the Alerts platform interface. With the exception of road regulation and maneuver events, the Alexa cloud no longer returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to navigation events sent by the Auto SDK. Alexa now prompts or notifies the clients and rejects the ping packet when the user deregisters from the companion app.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_10","text":"General If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". Auto SDK v2.2.0 adds support for setting the timezone of the vehicle, which allows your device to synchronize with the timezone set in the Alexa companion app; however, the Auto SDK currently does not receive a SetTimeZone directive when the timezone is changed from the companion app. Navigation The Alexa cloud currently returns an INTERNAL_SERVICE_EXCEPTION in response to any navigation road regulation or maneuver event sent by the Auto SDK (triggered by an utterance such as \"which lane should I take\", for example). You may see a harmless error/exception in the logs. Car Control Certain car control utterances return errors. Problematic utterances include natural versions of certain test utterances (for example, \u201cturn on the light\u201c instead of \u201cplease turn on the light in the car\u201d); utterances that include the words \u201clights\u201d or \u201cmy\u201d; and utterances to control the defroster or defogger that use \u201cput on\u201d or \u201cset on\u201d rather than \u201cturn on\u201d or \u201cswitch on\u201d. Setting the air conditioner using range controller control capabilities (for example \u201cset the air conditioner to 65\u201d or \u201cset the air conditioner to low\u201d) is not currently supported. In offline mode, the utterances \"turn ac on\u201d, \u201cturn off ac\u201d, \u201cturn ac off\u201d, and \u201cturn up ac\" return errors. Communications When using LVC in online mode, users can redial a call when the phone connection state has been switched to OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. Entertainment A user playing any skill with extended multi-turn dialogues (such as Jeopardy or Skyrim) cannot accept or reject incoming Alexa-to-Alexa calls using voice. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d Authentication The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.","title":"Known Issues"},{"location":"releases/changelog/#v210-released-on-2019-12-19","text":"","title":"v2.1.0 released on 2019-12-19:"},{"location":"releases/changelog/#enhancements_11","text":"Added Navigation enhancements to support the following features: Add a waypoint - Enables users to search and add waypoints to their current route along the way or start a new route with a given set of waypoints. Cancel a waypoint - Enables users to cancel a waypoint with voice. Show/Navigate to previous destinations - Enables users to view previous destinations and navigate to any of their previous destinations.. Turn and Lane Guidance - Enables users to ask Alexa for details about their next navigation instruction. Control Display - Enables users to interact with their onscreen map applications. Note: The Navigation enhancements are not backward-compatible with previous versions of the Auto SDK. The startNavigation() method supersedes the setDestination() method, and many new methods have been implemented. See the Auto SDK Migration Guide for details. Added support for Alexa Presentation Language (APL) rendering to present visual information and manage user interactions with Alexa. Note: In order to use APL rendering with the Android Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Added support for the Alexa DoNotDisturb (DND) interface, which allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . Note: Alexa does not notify the user of the DND state. Added a System Audio extension to provide the default audio capturing and playback functionality for various platforms, including audio input/output on QNX platforms. The Alexa Auto SDK Builder automatically includes the System Audio extension when you build the Auto SDK. Added local media sources (LMS) and hybrid car control support to the Automotive Grade Linux (AGL) Alexa Voice Agent. Added onAuthFailure() to the AuthProvider platform interface and an AUTHORIZATION_EXPIRED argument to the cblStateChanged() method of the CBL platform interface to expose 403 unauthorized request exceptions from Alexa Voice Service (AVS). These may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. Added support for call display information change notifications (caller ID) to the optional Alexa Communication extension.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_11","text":"Fixed an issue where contact uploading failed for contacts without addresses. Fixed an issue where if the user rejected an incoming Alexa-to-Alexa call via voice, ringtones did not sound for subsequent incoming calls until the user either answered an incoming call via voice or made an outbound call. Fixed an issue that required you to assign unique entry IDs to contacts and navigation favorites to ensure that the ID space used for contacts and navigation favorites did not collide. Fixed an issue where multiple automotive devices using the same account at the same time could access contacts from phones paired across those devices. Fixed an issue where uttering \"stop\" when a timer sounded during an Alexa-to-Alexa call ended the call, not the timer. Added enhancements to the maccandroid module (Spotify) to simplify the MACCPlayer handler implementation. Rediscovery now occurs automatically, and the authorization TTS error events no longer occur repeatedly.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_11","text":"The Alexa cloud currently returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to any navigation event sent by the Auto SDK. You may see a harmless error/exception in the logs. The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If the user deregisters from the companion app, Alexa does not prompt or notify the clients and does not reject the ping packet. If you log out and log in, the Do Not Disturb (DND) state is not synchronized with Alexa. When you cancel login with CBL::cancel() , the CBL state does not change to stopped. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or* using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. The Engine may sometimes stop abruptly on shutdown due to a race condition. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d A user playing Jeopardy or Skyrim cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". When pausing and resuming music, volume adjustments are lost. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession.","title":"Known Issues"},{"location":"releases/changelog/#v200-released-on-2019-09-10","text":"","title":"v2.0.0 released on 2019-09-10:"},{"location":"releases/changelog/#enhancements_12","text":"Added offline enhancements to improve offline car control support and add support for: offline car control enhancements - to support generic controls that represent what can be controlled in a vehicle; for example: interior lighting, fans, temperature zone (driver and passenger), vent position, defroster, air conditioner, and recirculation. > Note : The car control enhancements are not backward compatible with previous versions of car control. The configuration and platform interface have changed. offline entertainment - to support tuning to a specific frequency or SiriusXM channel, tuning to radio presets, switching between car audio sources (bluetooth, radio, satellite radio, CD player, etc.), and controlling local audio sources (pause, shuffle, loop, etc.) offline communications - to support uploading contacts, calling a number or a contact, answering, declining, redialing, or ending a call, and dialing digits during a call offline navigation - to support navigating to favorite locations and canceling navigation Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets. Added online navigation enhancements to support navigating to favorite locations and answering ETA and time to destination questions. Introduced the Address Book module , which includes a common platform interface that you can implement to either upload user data to the Alexa cloud or allow the local communications and navigation capabilities to access user data for offline use cases (supported by the optional Local Voice Control (LVC) module). The Address Book module supersedes the Contacts Uploader module, which supports only phone contacts and only online use cases. Introduced a new core Audio service and API to implement audio input and output providers, and deprecated the existing MediaPlayer and Speaker platform interfaces in the Alexa module. This redesign simplifies integration with platform-specific audio capabilities and enables implementation of new, advanced audio features. NOTE: The new core Audio service and APIs are not backward compatible with previous versions of the Alexa Auto SDK (prior to version 2.0.0). Added a library to support the Device Client Metrics (DCM) extension for additional platforms such as Linux and QNX in addition to Android, which was supported in release 1.5. This library is required to upload metrics and vehicle information to the Amazon cloud. Added support for Voice Chrome for Android , an extension available through your Solutions Architect or Partner Manager that provides a Voice Chrome library for the Android platform. This library allows you to display voice chrome animations of different Alexa states to the user on screen. Added an integrated wake word enhancement to ignore Alexa waking itself up . In order to implement this enhancement, you must provide audio loopback via the platform or application. Added local pause handling to the PlaybackController to allow non-voice interactions to pause media playback from the AudioPlayer source immediately, without waiting for a response from the cloud. Added Geolocation support to the Navigation module. Geolocation support enables location-based services (which are used to answer questions such as \u201cwhere am I\u201d or \u201cwhat\u2019s the weather\u201d) to use the location information provided by the platform. Note: In order to make use of this functionality, you must register the Navigation platform interface for Geolocation support. * Enhanced the builder scripts to simplify the build process by removing unnecessary options and including the default components for different targets. For details see the Builder documentation. * Refactored the Java Native Interface (JNI) code used for Android platform interfaces for more modular deployment. In place of a single AAR including all Auto SDK native libraries, the Alexa Auto SDK now generates multiple AARs (one per module). See the builder documentation and the Android Sample App documentation for details.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_12","text":"Fixed an issue where music streaming from online music service providers continued to play when the user switched to a local media source. Fixed an issue where an MACC app (Spotify) could automatically play after the first utterance. Fixed a race condition in the Navigation module that occasionally caused Cancel Navigation to fail. Fixed broken links in the documentation.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_12","text":"Calling numbers such as 1800xxxxxxx using utterances such as \"Alexa call one eight double oh...\" may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore, when requesting Alexa to call or press digits, we recommend that your client application ignore special characters, dots, and non-numeric characters if not relevant to the context. The Engine may crash during shutdown due to a race condition in the Local Media Source Engine implementation. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. In online mode, Alexa does not recognize the utterance \"Switch to line in.\" A user interacting with multiturn skills such as Jeopardy cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the user rejects an incoming Alexa-to-Alexa call via voice, ringtones do not sound for subsequent incoming calls until the user either answers an incoming call via the VUI or makes an outbound call. If you change your Car Control configuration or custom assets during development after Local Voice Control (LVC) was previously running, you should stop your application and LVC, change the configuration or custom assets, uninstall and reinstall LVC, and relaunch your application to ensure the changes are applied. To ensure that the ID space used for contacts and navigation favorites does not collide, you must assign unique entryId s to contacts and navigation data. If you use the same entryId , re-uploading contacts may cause navigation favorites to become unavailable to Alexa, and re-uploading navigation favorites may cause contacts to become unavailable. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\" Alexa uses different audio channels, such as dialog (user utterance or TTS) and content (music), and shuffles between them to respond to user requests. As a result of this shuffling, content (such as music playback) that gets paused to accommodate higher priority channels may regain foreground audio focus and resume content in bursts between the outputs of higher priority channels (such as Alexa TTS or ongoing alerts). To avoid this, platforms should maintain the audio focus for a few extra milliseconds. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"releases/changelog/#v163-released-on-2019-12-02","text":"","title":"v1.6.3 released on 2019-12-02:"},{"location":"releases/changelog/#enhancements_13","text":"This release is for bug fixes only. There are no new features or enhancements.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_13","text":"Fixed a race condition that could cause follow-ons to a TTS request (for example asking for movies nearby) not to play while Alexa is speaking or playing something.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_13","text":"All known issues from v1.6.0.","title":"Known Issues"},{"location":"releases/changelog/#v162-released-on-2019-10-11","text":"","title":"v1.6.2 released on 2019-10-11:"},{"location":"releases/changelog/#enhancements_14","text":"Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_14","text":"n/a","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_14","text":"All known issues from v1.6.0.","title":"Known Issues"},{"location":"releases/changelog/#v161-released-on-2019-06-21","text":"","title":"v1.6.1 released on 2019-06-21:"},{"location":"releases/changelog/#enhancements_15","text":"This release of Alexa Auto SDK includes updates for music certification.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_15","text":"Resolved issues are limited to music certification updates: Added fixes from AVS Device SDK v1.12.1 for music certification. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Documentation updates.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_15","text":"All known issues from v1.6.0.","title":"Known Issues"},{"location":"releases/changelog/#v160-released-on-2019-05-16","text":"","title":"v1.6.0 released on 2019-05-16:"},{"location":"releases/changelog/#enhancements_16","text":"General availability for Linux target platforms, including: Linux x86-64, Linux ARM 64 (armv8a), and Linux ARM 32 (armv7a). Alexa Auto SDK v1.6.0 enhances the C++ Sample App by improving the reference implementation for Linux platforms. See the C++ sample app documentation for details.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_16","text":"Fixed an issue where Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. Made changes to External Media Player events to send the service id and agent details, which are now mandated by the Alexa Music service. If you are using previous versions with Local Media Source switching or third-party app with MACC, you should upgrade to Alexa Auto SDK v1.6.0 to continue using the corresponding functionality.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_16","text":"If the local timezone of the device differs from the timezone that was configured through the Alexa companion app, you may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\u201d If you play your notifications while music is playing, you will hear the music for a split second between the end of one notification and the start of the next. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"releases/changelog/#v150-released-on-2019-03-06","text":"","title":"v1.5.0 released on 2019-03-06:"},{"location":"releases/changelog/#enhancements_17","text":"Added a C++ sample application to demonstrate use cases that the Alexa Auto SDK supports. For details, see the C++ sample app documentation. Released the code for the AGL Alexa Voice Agent, a binding for Automotive Grade Linux powered by Alexa Auto SDK v1.5. The software is shipped as a standard AGL binding that exposes an API for speech recognition using the Alexa Voice Service. Please refer to the AGL Alexa Voice Agent documentation for instructions to build, install, and test the binding on an R-Car M3 board. Added support for runtime selection of the AmazonLite wake word locale. The AmazonLite locale will automatically switch when the AVS locale is switched. Added support for optionally logging and uploading Alexa Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and UPL between the request and Alexa\u2019s response. Please contact your SA or Partner Manager for details or to request this package for Android. Added support for an optional platform interface EqualizerController . The Equalizer Controller enables Alexa voice control of device audio equalizer settings by making gain adjustments to three frequency bands (\u201cBASS\u201d, \u201cMIDRANGE\u201d, and/or \u201cTREBLE\u201d). Added an optional Code-Based Linking (CBL) authorization implementation in the Engine. With the new cbl module, the Engine handles acquiring access tokens. A CBL platform implementation should be registered with the Engine in place of an AuthProvider implementation to use this method for authorization. Improved the usage and deployment of the Local Voice Control extension on Android. Please contact your SA or Partner Manager for more information. Updated the vehicle information configuration API to include a vehicle identifier. An aace.vehicle.info.vehicleIdentifier property of vehicle configuration is now available through the existing VehicleConfiguration .","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_17","text":"Fixed an issue where barging in while many unprocessed Speak directives are queued could cause SpeechSynthesizer to become unresponsive or crash Added an EXPECTING state to the AlexaClient DialogState to accommodate multi-turn for hold-to-talk interactions. When more user input is required during an interaction, tap-to-talk interactions will transition directly from EXPECTING to LISTENING whereas hold-to-talk will remain in the EXPECTING state until listening is manually triggered. Fixed an issue where the Android Sample App could get stuck in a loop of INVALID_REQUEST_EXCEPTION errors being thrown repeatedly after MACCAndroidClient reported an error. Note: To fix this, the C++ ExternalMediaAdapter::getState method signature changed to allow the implementation to say whether the state it provides is valid. This change is not backward compatible. Fixed an issue where the Android Sample App created a syslog sink and logged VERBOSE in release builds. Note: As part of the fix, the default Engine logger sink id changed from console to default . Existing calls to LoggerConfiguration::createLoggerRuleConfig with sink id \"console\" should be changed to sink id \"default\" .","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_17","text":"The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"releases/changelog/#v140-released-on-2018-12-17","text":"","title":"v1.4.0 released on 2018-12-17:"},{"location":"releases/changelog/#enhancements_18","text":"The Alexa Auto SDK now supports the Local Voice Control extension. The Local Voice Control extension enhances the Alexa Auto experience by providing voice-based car controls whether connected to the internet or not. In this release, the Local Voice Control extension will provision access only to the car\u2019s climate control. Note : This extension is available on request - Please contact your Amazon Solutions Architect (SA) or Partner Manager for more information.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_18","text":"No resolved issues.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_18","text":"The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"releases/changelog/#v131-released-on-2019-06-21","text":"","title":"v1.3.1 released on 2019-06-21:"},{"location":"releases/changelog/#enhancements_19","text":"This release of Alexa Auto SDK includes updates for music certification.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_19","text":"Resolved issues are limited to music certification updates: Migrated to AVS Device SDK v1.12.1 for music certification. As part of the migration there is a new dependency on openssl . Developers using their own build system may need to make changes in order to accommodate this new dependency when linking AVS Device SDK. Fixed ExternalMediaPlayerAdapter getState() failure that triggered INVALID_REQUEST_EXCEPTION/Bad Request exceptions. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Updated the Android Sample App log view implementation for improved stability and performance. Bug fixes and documentation updates: Additional test in AuthProviderEngineImpl::doShutdown() to avoid null pointer exception. Fixed an issue with SQLiteStorage::removeKey() where the DELETE FROM statement repeated the FROM . Fixed a race condition in AudioChannelEngineImpl::setSource() with back to back TTS. Internal calls to AudioChannelEngineImpl::executePlaybackFinished() now save the player offset. Internal calls to AudioPlayerEngineImpl::removeObserver() now remove an AudioPlayerObserverInterface observer instance instead of adding it. Use static_cast<unsigned char> for upper/lower character conversions. The platform interfaces have not changed, however the following C++ and Android enums are updated: * The enum class DialogState inserts the EXPECTING enum constant. * The enum class ConnectionChangedReason inserts NONE , SUCCESS , and UNRECOVERABLE_ERROR enum constants.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_19","text":"All known issues from v1.3.0.","title":"Known Issues"},{"location":"releases/changelog/#v130-released-on-2018-11-20","text":"","title":"v1.3.0 released on 2018-11-20:"},{"location":"releases/changelog/#enhancements_20","text":"Android 8 and ARM v8a platform support. Making calls to contacts from a locally-paired mobile phone as long as the Alexa Auto SDK has a valid auth token. For details, see the Contact Uploader documentation . Redial, answer, terminate, and decline calls using voice. End users can also send dual-tone multi-frequency (DTMF) via voice to interact with Interactive Voice Responders (IVRs). For details, see the Phone Control documentation . Switching to local media sources, generic controls and deep linking into 3rd party media applications compatible with the Amazon Media App Command and Control (MACC) specification using the External Media Player Interface 1.1. This allows customers to switch between a CD player, AM/FM player, and auxiliary input that is MACC-compliant. For details, see the Alexa documentation . Enhancement for 3rd party wake word engine to enable cloud based verification. Provides a way to override Template Runtime display card timeout values for RenderTemplate and RenderPlayerInfo by updating the templateRuntimeCapabilityAgent Engine configuration values.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_20","text":"No resolved issues.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_20","text":"The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"releases/changelog/#v120-released-on-2018-10-15","text":"","title":"v1.2.0 released on 2018-10-15:"},{"location":"releases/changelog/#enhancements_21","text":"Additional information related to the presentation of alerts is now available. The extended interface now includes Alert token, type, rendering time, and label if applicable when an alert is set and notification when an alert is deleted. In the Navigation platform interface, SetDestination now provides business hours and contact information for a returned location when available.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_21","text":"If a location is not available, the location state is set to unavailable . Previously it was treated as (0,0) , which was a valid value for longitude and latitude. Fixed an issue related to stopping an alert where there could be up to a 10 second delay before the alert completely stopped. Fixed issue where the TemplateRuntime platform interface could not be registered before AudioPlayer .","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_21","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"releases/changelog/#v111-released-on-2018-09-10","text":"","title":"v1.1.1 released on 2018-09-10:"},{"location":"releases/changelog/#enhancements_22","text":"This release is for bug fixes only. There are no new features or enhancements.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_22","text":"Updated a dependency build recipe to skip the checksum verification to allow for document changes in the current tag.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_22","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"releases/changelog/#v110-released-on-2018-08-31","text":"","title":"v1.1.0 released on 2018-08-31:"},{"location":"releases/changelog/#enhancements_23","text":"Added support for choosing one of multiple network adaptors before starting the Engine. Added support for the latest Amazon Wakeword Engine. Added custom volume control support for infotainment system's native input volume range. The range that comes down to the device will be 0 to 100. Added support for encoding the utterance in OPUS format with the Amazon Wakeword Engine as well as PTT. Our builder pulls the libopus source code as a part of build process. Added Locale API to return the list of Alexa-supported locales. Updated Vehicle Information API to capture the microphone details. Added support for routines, music alarms, timers and alarms volume management, and deleting all timers and alarms. Added support for TemplateRuntime Interface 1.1, which provides visual playback control for Alexa-enabled products with TemplateRuntime Interface support. This includes upgrades to PlaybackController Interface 1.1 and TemplateRuntime Interface 1.1. Note : The older button-press APIs ( playButtonPressed() , nextButtonPressed() , etc.) have been deprecated in favor of the new generic buttonPressed(PlaybackButtonType) . Updated the builder script to confirm compliance with open source component licenses.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_23","text":"There are no resolved issues in this release.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_23","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"releases/changelog/#v102-released-on-2018-08-08","text":"","title":"v1.0.2 released on 2018-08-08:"},{"location":"releases/changelog/#enhancements_24","text":"This release is only for documentation updates. There are no new features or enhancements.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_24","text":"Only name change updates were made to the documentation. There are no resolved issues in this release.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_24","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"releases/changelog/#v101-released-on-2018-07-31","text":"","title":"v1.0.1 released on 2018-07-31:"},{"location":"releases/changelog/#enhancements_25","text":"This release is for bug fixes only. There are no new features or enhancements.","title":"Enhancements"},{"location":"releases/changelog/#resolved-issues_25","text":"The Engine now reconnects to Alexa when the NetworkInfoProvider updates the network status. All shared memory objects are now freed when the Engine object is disposed. We fixed a media playback state issue in the Engine that caused an unexpected pause and resume for a media stream that was already stopped. We added AudioPlayer::playerActivityChanged to the Android APIs. Updated the AuthError enumeration with additional error types. Removed deprecated createAuthConfig() configuration method. Fixed issue in the JNI where trying to create a UTF-8 string with invalid characters caused a crash, seen when sensitive logging is enabled. Improved JNI thread handling. Enabled capability registration for phone call control. We fixed an issue where the Android platform build failed on the initial attempt when using clean code.","title":"Resolved Issues"},{"location":"releases/changelog/#known-issues_25","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"releases/changelog/#v100-released-on-2018-06-29","text":"","title":"v1.0.0 released on 2018-06-29:"},{"location":"releases/changelog/#enhancements_26","text":"Alexa Auto SDK now supports two Navigation directives. SetDestination CancelNavigation Added support for phone control APIs. The PhoneCallController platform interface supports the Dial directive with three events: CallActivated CallTerminated CallFailed Support for Amazon Wake Word Engine (WWE)","title":"Enhancements"},{"location":"releases/changelog/#known-issues_26","text":"The Engine doesn't immediately reconnect to AVS when the NetworkInfoProvider updates network status. Some shared memory objects are not freed when the Engine object is disposed. Sample App issues are documented in the Sample App README .","title":"Known Issues"},{"location":"releases/changelog/#v100-beta-released-on-2018-04-29","text":"","title":"v1.0.0 Beta released on 2018-04-29:"},{"location":"releases/changelog/#enhancements_27","text":"The following enhancements were added to the Alexa Auto SDK since the last Alpha release (binary). SetDestination() API added to the Navigation module Android Sample Application updated with a number of features such as rendering of Display Cards (Shopping List, Coffee Shops Nearby, etc), handling of the SetDestination() API, Notifications, LWA (Login with Amazon)","title":"Enhancements"},{"location":"releases/changelog/#known-issues_27","text":"SDK: While the SDK does build against Android API22 and above and runs successfully on Android O devices, our current testing shows a native-code linking error when actually running on API22 devices. Android Sample App: M3U and PLS based stream URLs are not parsed before sent to the Android Mediaplayer. Affects live streams typically coming from TuneIn and IHeartRadio services Media playback can take a long time to start sometimes for iHeartRadio and TuneIn The Android Alexa Auto SDK Sample App was developed on an Android tablet with 2048 x 1536 resolution screen size. It can run on smaller devices, but some of the display cards may not display correctly During Playing Media in the Sample App we see the following messages (none of these will cause any issues): E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=streamFormat E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=progressReportDelayInMilliseconds E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=expectedPreviousToken E/AAC:aace.alexa.AudioChannelEngineImpl:validateSource:reason=invalidSource E/AAC:aace.alexa.AudioChannelEngineImpl:pause:reason=invalidSource,expectedState=X On App startup we see the following messages (none of these will cause any issues): E/AVS:SQLiteAlertStorage:openFailed::File specified does not exist.:file path=/data/user/0/com.amazon.sampleapp/cache/appdata/alerts.sqlite Several minor documentation issues that will be addressed in the GA release","title":"Known Issues"},{"location":"releases/migrate-to-messagebroker/","text":"Migrate to the MessageBroker API \u00b6 Overview \u00b6 Auto SDK 4.0 introduces a new MessageBroker API for applications to subscribe to and publish AASB messages. This API replaces the existing platform interfaces that developers use to integrate platform-specific functionality such as audio, location, and Alexa capabilities. MessageBroker also replaces the deprecated AASB interface used in previous Auto SDK versions. Developers integrating with Auto SDK for the first time should only use the MessageBroker API. Developers who upgrade to Auto SDK 4.0 (and plan to continue to upgrade beyond 4.0), should migrate their existing applications as soon as possible. The next major release of Auto SDK will remove the platform interface API without maintaining backward compatibility with older versions of the SDK. Application architecture \u00b6 In most cases, the interface changes in Auto SDK do not require modifying the architecture of the existing Auto SDK client application. The following diagram shows an application with a typical architecture based on Auto SDK 3.3 next to the same application using the Auto SDK 4.0 MessageBroker API: In the example above, the key difference is that rather than creating handlers that extend platform interfaces, the new implementation uses a loosely coupled MessageBroker API to subscribe to and publish messages. It is straightforward to adapt the existing application handlers to MessageBroker by using a simple adapter pattern that does not require completely redesigning the application. Migrating existing platform interface handlers \u00b6 The following diagram highlights the core differences between using the old platform interfaces and the new MessageBroker API. The left side shows the steps for creating the Engine and handlers and invoking interface methods in Auto SDK 3.3. The right side shows the equivalent steps using the MessageBroker API required for Auto SDK 4.0. Even though the MessageBroker API provides flexibility for how to design an application, it may be easier to adapt an existing implementation rather than redesigning it. The following example demonstrates how to modify a DoNotDisturb platform interface handler to use MessageBroker. Example implementation of a DoNotDisturb handler in Auto SDK 3.3: In Auto SDK 3.3, the DoNotDisturb platform interface has the following methods: /** * Handle setting of DND directive. * * @param [in] doNotDisturb setting state */ virtual void setDoNotDisturb ( const bool doNotDisturb ) = 0 ; /** * Notifies the Engine of a platform request to set the DND State * * @param [in] doNotDisturb setting state * @return true if successful, false if change was rejected */ bool doNotDisturbChanged ( const bool doNotDisturb ); The implementation overrides the setDoNotDisturb() platform interface method to provide application-specific behavior (in this case, logging a message to the console) and calls the Engine interface method doNotDisturbChanged to request a change to the DoNotDisturb setting. #include <AACE/Alexa/DoNotDisturb.h> class DoNotDisturbHandler : public DoNotDisturb { public : DoNotDisturbHandler () = default ; void setDoNotDisturb ( bool doNotDisturb ) override ; void notifyDoNotDisturbSettingChange ( bool doNotDisturb ); }; void DoNotDisturbHandler::setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler::notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by calling // the Engine interface method implemented in the DoNotDisturb base class doNotDisturbChanged ( bool doNotDisturb ); } Example implementation of a DoNotDisturb handler in Auto SDK 4.0: In Auto SDK 4.0 the SetDoNotDisturbMessage and the DoNotDisturbChangedMessage replace setDoNotDisturb the doNotDisturbChanged methods, respectively. The following example shows the same core logic in the handler, but it uses the MessageBroker API instead of extending a platform interface. #include <AASB/Message/Alexa/DoNotDisturb/SetDoNotDisturbMessage.h> #include <AASB/Message/Alexa/DoNotDisturb/DoNotDisturbChangedMessage.h> #include <AACE/Core/MessageBroker.h> class DoNotDisturbHandler { public : DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void setDoNotDisturb ( bool doNotDisturb ); void doNotDisturbChanged ( bool doNotDisturb ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; DoNotDisturbHandler :: DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to the \"SetDoNotDisturb\" message m_messageBroker -> subscribe ( [ = ]( const std :: string & msg ) { SetDoNotDisturbMessage _msg = json :: parse ( msg ); setDoNotDisturb ( _msg . payload . doNotDisturb ); }, SetDoNotDisturbMessage :: topic (), SetDoNotDisturbMessage :: action ()); } void DoNotDisturbHandler :: setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler :: notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by publishing // a \"DoNotDisturbChanged\" message DoNotDisturbChangedMessage _msg ; _msg . payload . doNotDisturb = doNotDisturb ; m_messageBroker -> publish ( _msg . toString ()); // publish is fire and forget } A reference to the MessageBroker is required. This can be accessed from the Engine object and provided when creating the DoNotDisturbHandler instance in the main application code: auto handler = std :: make_shared < DoNotDisturbHandler > ( engine -> getMessageBroker ()); Handling audio and stream based interfaces \u00b6 Auto SDK 4.0 replaces audio stream platform interfaces AudioInput and AudioOutput with the MessageBroker's MessageStream API and corresponding AASB messages with \"AudioInput\" and \"AudioOutput\" topics. When the application receives a message that requires it to read from or write to a stream, the message payload includes a stream ID. The application uses the stream ID to \u201copen\u201d the stream for I/O. Developers with existing handlers for media players or microphone, for example, should migrate their handlers to use the new MessageBroker and MessageStream API. Note In previous versions of Auto SDK, the Engine \"opened\" audio channels through the AudioInputProvider and AudioOutputProvider platform interfaces prior to requesting audio input or output through the AudioInput and AudioOutput platform interface instances representing each channel. In Auto SDK 4.0, there is no AASB message equivalent of AudioInputProvider or AudioOutputProvider . When the Engine needs audio input from a particular channel, it sends the AudioInput.StartAudioInput message with the channel type specified in the payload. Similarly, when the Engine needs to play audio for a particular channel, it sends the AudioOutput.Prepare message with the channel type specified in the payload. The following example demonstrates how the application would open an input stream after receiving the StartAudioInput message, and write data to the stream until a StopAudioInput message is received: #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); // open the stream for writing auto streamId = _msg . payload . streamId ; auto stream = messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); startAudioInput ( streamId , stream ) }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; stopAudioInput ( streamId ); }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } A MessageStream can be read-only, write-only, or support both read and write operations. It is required to specify the operation mode when opening the stream using the MessageStream::Mode enumeration. If the MessageBroker cannot open a stream for the specified operation, the openStream() call will fail and return a null object. Handling synchronous-style messages \u00b6 Most AASB messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special reply message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message. Replying to messages from the Engine \u00b6 In most cases in which a message requires a reply, the Engine will block sending other messages until it receives the reply (or until a timeout occurs), so it is important to send the reply message right away. The following example demonstrates how to subscribe to the GetLocation message from the LocationProvider interface and send a reply back to the Engine: #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> // subscribe to GetLocation message m_messageBroker -> subscribe ([ = ]( const std :: string & msg ) { GetLocationMessageReply _reply ; // set the reply message \"replyToId\" to the id of the // original message: _reply . header . messageDescription . replyToId = _msg . header . id ; // populate the reply message payload data _reply . payload . location . latitude = m_latitude ; _reply . payload . location . longitude = m_longitude ; // publish ther reply m_messageBroker -> publish ( _reply . toString ()); }, GetLocationMessage :: topic (), GetLocationMessage :: action ()); Receiving reply messages from the Engine \u00b6 For some messages published by the application, the Engine may send a reply back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The \"replyToId\" in the reply message will contain the message ID for which the reply is sent. The following example demonstrates how subscribe to GetPropertyReply message from the Engine. m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); // Publish GetPropertyMessage void publishGetProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // Engine sends the GetProperty message reply with the requested property // The \"replyToId\" in the reply message will contain the ID of this published message } void handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); // Get the property value from the reply and handle in the implementation const std :: string & propertyValue = msg . payload . value } Migrating existing AASB platform interface handler implementation \u00b6 Auto SDK 3.3 supports AASB as an optional extension and platform interface. Developers using the AASB platform interface need to migrate the AASB platform interface handler to use the new MessageBroker API instead. This can be accomplished by following a similar pattern as described in the sections above; however, use MessageBroker to subscribe to ALL messages in order to provide the same functionality as the existing AASB platform interface. class AASBHandler { public : AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void messageReceived ( const std :: string & message ); // engine interface implementation void publish ( const std :: string & message ); std :: shared_ptr < MessageStream > openStream ( const std :: string & streamId , MessageStream :: Mode mode ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; AASBHandler :: AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to ALL messages and bind to the messageReceived() function // since it has the same method signature as the message handler m_messageBroker -> subscribe ( std :: bind ( & AASBHandler :: messageReceived , this , std :: placeholders :: _1 ) ); } void AASBHandler :: messageReceived ( const std :: string & message ){ // application logic for handling AASB messages std :: cout << message << std :: endl ; } void AASBHandler :: publish ( const std :: string & message ){ // invoke the MessageBroker publish method m_messageBroker -> publish ( message ); } std :: shared_ptr < MessageStream > AASBHandler :: openStream ( const std :: string & streamId , MessageStream :: Mode mode ){ // invoke the MessageBroker openStream method return m_messageBroker -> openStream ( mode ); } Hybrid or incremental migration \u00b6 Although Amazon recommends migrating the entire application to MessageBroker when upgrading to Auto SDK 4.0, it is possible to use a hybrid implementation of platform interface handlers and MessageBroker until Auto SDK removes the platform interface API. New interfaces added in Auto SDK 4.0 are enabled to use the MessageBroker API by default. The following diagram illustrates the architecture for a hybrid application:","title":"Migrate to the MessageBroker API"},{"location":"releases/migrate-to-messagebroker/#migrate-to-the-messagebroker-api","text":"","title":"Migrate to the MessageBroker API"},{"location":"releases/migrate-to-messagebroker/#overview","text":"Auto SDK 4.0 introduces a new MessageBroker API for applications to subscribe to and publish AASB messages. This API replaces the existing platform interfaces that developers use to integrate platform-specific functionality such as audio, location, and Alexa capabilities. MessageBroker also replaces the deprecated AASB interface used in previous Auto SDK versions. Developers integrating with Auto SDK for the first time should only use the MessageBroker API. Developers who upgrade to Auto SDK 4.0 (and plan to continue to upgrade beyond 4.0), should migrate their existing applications as soon as possible. The next major release of Auto SDK will remove the platform interface API without maintaining backward compatibility with older versions of the SDK.","title":"Overview"},{"location":"releases/migrate-to-messagebroker/#application-architecture","text":"In most cases, the interface changes in Auto SDK do not require modifying the architecture of the existing Auto SDK client application. The following diagram shows an application with a typical architecture based on Auto SDK 3.3 next to the same application using the Auto SDK 4.0 MessageBroker API: In the example above, the key difference is that rather than creating handlers that extend platform interfaces, the new implementation uses a loosely coupled MessageBroker API to subscribe to and publish messages. It is straightforward to adapt the existing application handlers to MessageBroker by using a simple adapter pattern that does not require completely redesigning the application.","title":"Application architecture"},{"location":"releases/migrate-to-messagebroker/#migrating-existing-platform-interface-handlers","text":"The following diagram highlights the core differences between using the old platform interfaces and the new MessageBroker API. The left side shows the steps for creating the Engine and handlers and invoking interface methods in Auto SDK 3.3. The right side shows the equivalent steps using the MessageBroker API required for Auto SDK 4.0. Even though the MessageBroker API provides flexibility for how to design an application, it may be easier to adapt an existing implementation rather than redesigning it. The following example demonstrates how to modify a DoNotDisturb platform interface handler to use MessageBroker. Example implementation of a DoNotDisturb handler in Auto SDK 3.3: In Auto SDK 3.3, the DoNotDisturb platform interface has the following methods: /** * Handle setting of DND directive. * * @param [in] doNotDisturb setting state */ virtual void setDoNotDisturb ( const bool doNotDisturb ) = 0 ; /** * Notifies the Engine of a platform request to set the DND State * * @param [in] doNotDisturb setting state * @return true if successful, false if change was rejected */ bool doNotDisturbChanged ( const bool doNotDisturb ); The implementation overrides the setDoNotDisturb() platform interface method to provide application-specific behavior (in this case, logging a message to the console) and calls the Engine interface method doNotDisturbChanged to request a change to the DoNotDisturb setting. #include <AACE/Alexa/DoNotDisturb.h> class DoNotDisturbHandler : public DoNotDisturb { public : DoNotDisturbHandler () = default ; void setDoNotDisturb ( bool doNotDisturb ) override ; void notifyDoNotDisturbSettingChange ( bool doNotDisturb ); }; void DoNotDisturbHandler::setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler::notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by calling // the Engine interface method implemented in the DoNotDisturb base class doNotDisturbChanged ( bool doNotDisturb ); } Example implementation of a DoNotDisturb handler in Auto SDK 4.0: In Auto SDK 4.0 the SetDoNotDisturbMessage and the DoNotDisturbChangedMessage replace setDoNotDisturb the doNotDisturbChanged methods, respectively. The following example shows the same core logic in the handler, but it uses the MessageBroker API instead of extending a platform interface. #include <AASB/Message/Alexa/DoNotDisturb/SetDoNotDisturbMessage.h> #include <AASB/Message/Alexa/DoNotDisturb/DoNotDisturbChangedMessage.h> #include <AACE/Core/MessageBroker.h> class DoNotDisturbHandler { public : DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void setDoNotDisturb ( bool doNotDisturb ); void doNotDisturbChanged ( bool doNotDisturb ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; DoNotDisturbHandler :: DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to the \"SetDoNotDisturb\" message m_messageBroker -> subscribe ( [ = ]( const std :: string & msg ) { SetDoNotDisturbMessage _msg = json :: parse ( msg ); setDoNotDisturb ( _msg . payload . doNotDisturb ); }, SetDoNotDisturbMessage :: topic (), SetDoNotDisturbMessage :: action ()); } void DoNotDisturbHandler :: setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler :: notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by publishing // a \"DoNotDisturbChanged\" message DoNotDisturbChangedMessage _msg ; _msg . payload . doNotDisturb = doNotDisturb ; m_messageBroker -> publish ( _msg . toString ()); // publish is fire and forget } A reference to the MessageBroker is required. This can be accessed from the Engine object and provided when creating the DoNotDisturbHandler instance in the main application code: auto handler = std :: make_shared < DoNotDisturbHandler > ( engine -> getMessageBroker ());","title":"Migrating existing platform interface handlers"},{"location":"releases/migrate-to-messagebroker/#handling-audio-and-stream-based-interfaces","text":"Auto SDK 4.0 replaces audio stream platform interfaces AudioInput and AudioOutput with the MessageBroker's MessageStream API and corresponding AASB messages with \"AudioInput\" and \"AudioOutput\" topics. When the application receives a message that requires it to read from or write to a stream, the message payload includes a stream ID. The application uses the stream ID to \u201copen\u201d the stream for I/O. Developers with existing handlers for media players or microphone, for example, should migrate their handlers to use the new MessageBroker and MessageStream API. Note In previous versions of Auto SDK, the Engine \"opened\" audio channels through the AudioInputProvider and AudioOutputProvider platform interfaces prior to requesting audio input or output through the AudioInput and AudioOutput platform interface instances representing each channel. In Auto SDK 4.0, there is no AASB message equivalent of AudioInputProvider or AudioOutputProvider . When the Engine needs audio input from a particular channel, it sends the AudioInput.StartAudioInput message with the channel type specified in the payload. Similarly, when the Engine needs to play audio for a particular channel, it sends the AudioOutput.Prepare message with the channel type specified in the payload. The following example demonstrates how the application would open an input stream after receiving the StartAudioInput message, and write data to the stream until a StopAudioInput message is received: #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); // open the stream for writing auto streamId = _msg . payload . streamId ; auto stream = messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); startAudioInput ( streamId , stream ) }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; stopAudioInput ( streamId ); }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } A MessageStream can be read-only, write-only, or support both read and write operations. It is required to specify the operation mode when opening the stream using the MessageStream::Mode enumeration. If the MessageBroker cannot open a stream for the specified operation, the openStream() call will fail and return a null object.","title":"Handling audio and stream based interfaces"},{"location":"releases/migrate-to-messagebroker/#handling-synchronous-style-messages","text":"Most AASB messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special reply message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message.","title":"Handling synchronous-style messages"},{"location":"releases/migrate-to-messagebroker/#replying-to-messages-from-the-engine","text":"In most cases in which a message requires a reply, the Engine will block sending other messages until it receives the reply (or until a timeout occurs), so it is important to send the reply message right away. The following example demonstrates how to subscribe to the GetLocation message from the LocationProvider interface and send a reply back to the Engine: #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> // subscribe to GetLocation message m_messageBroker -> subscribe ([ = ]( const std :: string & msg ) { GetLocationMessageReply _reply ; // set the reply message \"replyToId\" to the id of the // original message: _reply . header . messageDescription . replyToId = _msg . header . id ; // populate the reply message payload data _reply . payload . location . latitude = m_latitude ; _reply . payload . location . longitude = m_longitude ; // publish ther reply m_messageBroker -> publish ( _reply . toString ()); }, GetLocationMessage :: topic (), GetLocationMessage :: action ());","title":"Replying to messages from the Engine"},{"location":"releases/migrate-to-messagebroker/#receiving-reply-messages-from-the-engine","text":"For some messages published by the application, the Engine may send a reply back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The \"replyToId\" in the reply message will contain the message ID for which the reply is sent. The following example demonstrates how subscribe to GetPropertyReply message from the Engine. m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); // Publish GetPropertyMessage void publishGetProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // Engine sends the GetProperty message reply with the requested property // The \"replyToId\" in the reply message will contain the ID of this published message } void handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); // Get the property value from the reply and handle in the implementation const std :: string & propertyValue = msg . payload . value }","title":"Receiving reply messages from the Engine"},{"location":"releases/migrate-to-messagebroker/#migrating-existing-aasb-platform-interface-handler-implementation","text":"Auto SDK 3.3 supports AASB as an optional extension and platform interface. Developers using the AASB platform interface need to migrate the AASB platform interface handler to use the new MessageBroker API instead. This can be accomplished by following a similar pattern as described in the sections above; however, use MessageBroker to subscribe to ALL messages in order to provide the same functionality as the existing AASB platform interface. class AASBHandler { public : AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void messageReceived ( const std :: string & message ); // engine interface implementation void publish ( const std :: string & message ); std :: shared_ptr < MessageStream > openStream ( const std :: string & streamId , MessageStream :: Mode mode ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; AASBHandler :: AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to ALL messages and bind to the messageReceived() function // since it has the same method signature as the message handler m_messageBroker -> subscribe ( std :: bind ( & AASBHandler :: messageReceived , this , std :: placeholders :: _1 ) ); } void AASBHandler :: messageReceived ( const std :: string & message ){ // application logic for handling AASB messages std :: cout << message << std :: endl ; } void AASBHandler :: publish ( const std :: string & message ){ // invoke the MessageBroker publish method m_messageBroker -> publish ( message ); } std :: shared_ptr < MessageStream > AASBHandler :: openStream ( const std :: string & streamId , MessageStream :: Mode mode ){ // invoke the MessageBroker openStream method return m_messageBroker -> openStream ( mode ); }","title":"Migrating existing AASB platform interface handler implementation"},{"location":"releases/migrate-to-messagebroker/#hybrid-or-incremental-migration","text":"Although Amazon recommends migrating the entire application to MessageBroker when upgrading to Auto SDK 4.0, it is possible to use a hybrid implementation of platform interface handlers and MessageBroker until Auto SDK removes the platform interface API. New interfaces added in Auto SDK 4.0 are enabled to use the MessageBroker API by default. The following diagram illustrates the architecture for a hybrid application:","title":"Hybrid or incremental migration"},{"location":"releases/migration/","text":"Auto SDK Migration Guide \u00b6 Overview \u00b6 This guide highlights the changes in each Auto SDK version that require your application to update to maintain compatibility. The guide outlines the changes with step-by-step recommendations to help you stay up-to-date with the latest Auto SDK version. Each section describes an increment of one release, so if you skip intermediate versions when you upgrade, ensure you follow the steps in each section from your current version to the latest version. Backward compatibility \u00b6 Auto SDK remains backward compatible across minor version updates; however, to continually improve, Auto SDK sometimes deprecates APIs, configuration fields, and build options in a minor version. The changes this guide outlines in minor version upgrade sections are intended to highlight deprecations and help you stop using deprecated features as soon as possible to prepare for their removal in the next major version. Although rare, if Auto SDK makes an exception to the backward compatibility tenants in a minor version, this guide explicitly calls out the change. Migrating from Auto SDK v4.0.0 to v4.1.0 \u00b6 This section provides the information you need to migrate from Auto SDK v4.0.0 to Auto SDK v4.1.0 ShowAlternativeRoutesSucceeded savings amount must be float \u00b6 The field alternateRoute.savings.amount in the Navigation.ShowAlternativeRoutesSucceeded AASB message (and corresponding deprecated platform interface API Navigation::showAlternativeRoutesSucceeded ) is a float, but Auto SDK versions 4.0 and earlier incorrectly allowed passing a string for this value. Auto SDK 4.1 fixes the issue, so you must update your code to use a float if your code is also incorrectly using a string. LVC App Components replace LVC APK on Android Platform \u00b6 AACS LVC App Components replace the LVC APK on Android. Auto SDK no longer releases the LVC APK, and the previous LVC APK does not work with 4.1 AACS. The LVC App Components are Android libraries (AARs) that run LVC in the same application as AACS, and the AACS sample app integrates them by default. If your Alexa client application uses the Java platform interfaces (deprecated in 4.0), you are required to update your application to use AACS before integrating with LVC App Components. See Migrate to the MessageBroker API and the AACS documentation for information about migrating your application. If your Alexa client application is AACS-based already and has LVC functionality, the previous implementation based on AIDL interfaces and the LVC APK no longer applies. Specifically, ILVCClient and ILVCService are removed. Remove your implementation of ILVCClient and the binding to the LVC service. Instead, by default, no additional implementation is needed with AACS in 4.1 because AACS starts and configures LVC. You do not need to specify android:sharedUserId previously required for inter-application UDS IPC. For more details about integrating the LVC App Components, see the documentation in the Local Voice Control extension on the Amazon developer portal. Migrating from Auto SDK v3.3.0 to v4.0.0 \u00b6 This section provides the information you need to migrate from Auto SDK v3.3.0 to Auto SDK v4.0.0 Platform Interfaces are deprecated \u00b6 The C++ and Java platform interfaces are deprecated in favor of Alexa Auto Services Bridge (AASB). Auto SDK 4.0 replaces the platform interfaces with a new MessageBroker API for subscribing to and publishing AASB messages. See Migrate to the MessageBroker API for information and instructions to migrate your application. AASB configuration for AACS is updated \u00b6 In Auto SDK version 3.3, your application using AACS was required to configure the AASB version with the following aacs.aasb object in your AACS configuration file: \"aacs.aasb\" : { \"version\": \"3.3\" } Remove this configuration from your 4.0 AACS configuration file. Additionally, the optional defaultMessageTimeout and autoEnableInterfaces configuration fields are moved from the aasb object to the messageBroker object, so you must update your AACS configuration file if you use these fields. For example, if your AACS configuration file includes this block: { \"aacs.aasb\": { \"autoEnableInterfaces\": false, \"defaultMessageTimeout\": 1000 } } change it to this: { \"aacs.messageBroker\": { \"autoEnableInterfaces\": false, \"defaultMessageTimeout\": 1000 } } Migrating from Auto SDK v3.2.1 to v3.3.0 \u00b6 This section provides the information you need to migrate from Auto SDK v3.2.1 to Auto SDK v3.3.0 Local Media Source and Global Preset Enhancements \u00b6 GlobalPreset is deprecated \u00b6 The GlobalPreset platform interface is deprecated because its feature set is supported by the new DEFAULT LocalMediaSource type. To preserve functionality for utterances targeting generic presets like \"Alexa, play preset 1\", implement and register a LocalMediaSource handler of Source::DEFAULT type. The user utterances that cause the Engine to invoke GlobalPreset::setGlobalPreset() will cause the Engine to invoke LocalMediaSource::play() with ContentSelector::PRESET instead. The GlobalPreset platform interface will be removed in a future version of Auto SDK. Additional LocalMediaSource playerEvent calls are needed \u00b6 Previous Auto SDK documentation stated that you must call LocalMediaSource::playerEvent() to report events \"PlaybackStated\" and \"PlaybackStopped\" only. Please update your implementation to call playerEvent() with states \"PlaybackSessionStarted\" and \"PlaybackSessionEnded\" as well. See the Alexa module documentation for information about when to report these events. setFocus is deprecated \u00b6 The API LocalMediaSource::setFocus() is deprecated because its functionality is equivalent to calling LocalMediaSource::playerEvent() with event name \"PlaybackSessionStarted\" when a player is brought into focus or \"PlaybackSessionEnded\" when a player is removed from focus. Please replace your calls to setFocus(true) and setFocus(false) with calls to playerEvent(\"PlaybackSessionStarted\") and playerEvent(\"PlaybackSessionEnded\") , respectively. setFocus will be removed in a future version of Auto SDK. Reporting playback session ID is needed \u00b6 The Alexa cloud requires ExternalMediaPlayer events and context for a particular player to include the playback session ID of a player's active session. To support this, the LocalMediaSource::play() function signature is updated to include a parameter for session ID for an Alexa-initiated session, which you must use when reporting player events for the player. The playerEvent and playerError signatures are also updated to include session ID. You must generate your own session ID when the playback is initiated by the user without Alexa. See the Alexa module documentation for more details about the sessionId . The versions of APIs without the session ID will be removed in a future version of Auto SDK. Migrating the Local Navigation Module APIs \u00b6 The local search features of the Local Voice Control Extension's Local Navigation module are extended to support offline navigation to addresses, cities, and neighborhoods. To support the new feature set, the existing APIs are updated to a more general name. The changes are backward compatible, but the old APIs are deprecated and will be removed in a future version. Use the following steps to assist the migration to the new APIs: LocalSearchProvider Platform Interface Changes \u00b6 We have deprecated the functions poiSearchRequest , poiLookupRequest , poiSearchResponse , and poiLookupResponse in favor of searchRequest , lookupRequest , searchResponse , and lookupResponse , respectively. Override LocalSearchProvider::searchRequest() instead of LocalSearchProvider::poiSearchRequest() . Override LocalSearchProvider::lookupRequest() instead of LocalSearchProvider::poiLookupRequest() . Call LocalSearchProvider::searchResponse() instead of LocalSearchProvider::poiSearchResponse() . Call LocalSearchProvider::lookupResponse() instead of LocalSearchProvider::poiLookupResponse() . We have also deprecated the AASB messages PoiSearchRequestMessage , PoiLookupRequestMessage , PoiSearchResponseMessage , and PoiLookupResponseMessage in favor of SearchRequestMessage , LookupRequestMessage , SearchResponseMessage , and LookupResponseMessage , respectively. Subscribe to SearchRequestMessage instead of PoiSearchRequestMessage . Subscribe to LookupRequestMessage instead of PoiLookupRequestMessage . Publish to SearchResponseMessage instead of PoiSearchResponseMessage . Publish to LookupResponseMessage instead of PoiLookupResponseMessage . The JSON schemas of search and response are still the same. Note: Do not use/implement a mix of the old APIs and the new APIs Local Navigation Module Engine Configuration Changes \u00b6 The aace.localNavigation.localSearch configuration keys navigationPOISocketPath and poiEERSocketPath are renamed to navigationLocalSearchSocketPath and localSearchEERSocketPath , respectively. For example, if your configuration was this { \"aace.localNavigation\": { \"localSearch\": { \"navigationPOISocketPath\": \"/opt/LVC/data/poi-er-service/poi_navigation.socket\", \"poiEERSocketPath\": \"/opt/LVC/data/poi-er-service/poi_eer.socket\" } } } change it to this { \"aace.localNavigation\": { \"localSearch\": { \"navigationLocalSearchSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_navigation.socket\", \"localSearchEERSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_eer.socket\" } } } If you are using the LocalNavigationConfiguration::createLocalSearchConfig() factory function to generate the configuration, your usage does not have to change because the signature is the same and implementation of this function generates the new JSON. Note: the socket paths in the Linux default sample configuration file are updated, so if you use different values, ensure you update your LVC app configuration accordingly LVC APK Configuration Changes \u00b6 If you use LVC on Android, update the configuration returned by your implementation of the interface ILVCClient.getConfiguration() . The paths NavigationPOISocketDir and POIEERSocketDir have been deprecated in favor of NavigationLocalSearchSocketDir and LocalSearchEERSocketDir , respectively. The socket names NavigationPOISocketName and POIEERSocketName have been deprecated in favor of NavigationLocalSearchSocketName and LocalSearchEERSocketName , respectively. LVC Linux App Configuration Changes \u00b6 The LVC configuration file lvc-config.json installed at /opt/LVC/config by the installation script LVC.sh has no changes to its JSON configuration schema since Auto SDK 3.2. However, the socket directories and names used by default in this file are updated to use more general names. Migrating from Auto SDK v3.1.0 to v3.2.0 \u00b6 This section provides the information you need to migrate from Auto SDK v3.1.0 to Auto SDK 3.2.0. All information about 3.2.0 is also applicable to 3.2.1. Using the Alexa Communication Extension \u00b6 The Alexa Comms library in Auto SDK v3.2.0 uses Device Client Metrics (DCM) instead of AWS IoT for uploading metrics. Therefore, remove the iotCertificateDirPath , iotHostAddress , and deviceTypeId fields from the communication configuration file. For information about the configuration file format, see the Alexa Communication extension documentation. If you build the Alexa Comms module configuration using the programmatic factory function AlexaCommsConfiguration::createCommsConfig() (C++) or AlexaCommsConfiguration.createCommsConfig() (Java), remove the parameters that are no longer present in the signature. Using the Device Client Metrics (DCM) Extension \u00b6 The Device Client Metrics extension in Auto SDK v3.2.0 requires a field called metricsTag to be defined in the DCM configuration. The value of metricsTag is used for generating a unique identifier for anonymous registration metrics. Note: You must not use the vehicle identification number (VIN) or device serial number (DSN) as metricsTag . For information about how to use this field, see the Device Client Metric extension documentation. If you build the DCM module configuration using the programmatic factory function DCMConfiguration::createDCMConfig() (C++) or DCMConfiguration.createDCMConfig() (Java), add the metricsTag parameter as instructed in the API documentation. Migrating from Auto SDK v3.0.0 to v3.1.0 \u00b6 This section provides the information you need to migrate from Auto SDK v3.0.0 to Auto SDK v3.1.0. Migrating to the Authorization Platform Interface \u00b6 Auto SDK v3.1.0 introduces the Authorization module that provides a single platform interface to manage different types of authorizations supported by the Engine. This single platform interface works with the Engine services that carry out the actual authorization process or flow. For more information about how authorization works, see the Core module documentation. This section provides the information you need for migrating to the Authorization platform interface from the CBL or AuthProvider platform interface, which are deprecated in v3.1.0 Migrating from the CBL Platform Interface To migrate from the CBL platform interface to the Authorization platform interface, follow the instructions in the CBL module documentation, which describes the Authorization APIs for CBL authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the CBL platform interface, as shown in the following table: CBL Authorization Description ERROR UNKNOWN_ERROR Unknown error occurs during the authorization flow. TIMEOUT TIMEOUT Request for the the CBL code from LWA times out. CODE_PAIR_EXPIRED CODE_PAIR_EXPIRED The code pair obtained has expired. AUTHORIZATION_EXPIRED AUTHORIZATION_EXPIRED Refresh token is expired or revoked. START_AUTHORIZATION_FAILED Authorization fails to start. LOGOUT_FAILED Logout fails. Migrating from the AuthProvider Platform Interface To migrate from the AuthProvider platform interface to the Authorization platform interface, follow the instructions in the Alexa module documentation, which describes the Authorization APIs for Auth Provider authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the AuthProvider platform interface, as shown in the following table: AuthProvider Authorization Description authFailure AUTH_FAILURE Invalid or expired access token was provided. NOT PRESENT UNKNOWN_ERROR Unknown error occurs during the authorization flow. NOT PRESENT START_AUTHORIZATION_FAILED Authorization fails to start. NOT PRESENT LOGOUT_FAILED Logout fails. Deprecated Features Removed in Auto SDK v3.0.0 \u00b6 The following asset IDs for Car Control have been removed: \"Alexa.Automotive.DeviceName.DriverSeat\", \"Alexa.Automotive.DeviceName.LeftSeat\", \"Alexa.Automotive.DeviceName.PassengerSeat\", \"Alexa.Automotive.DeviceName.RightSeat\". The createControl() method has been removed. Use createEndpoint() instead. Support for the \"isMemberOf\" relationship for endpoint definition has been removed. You must list member endpoints in a zone definition. Implicit zone definitions have been removed. The following TemplateRuntime methods have been removed: The renderTemplate(const std::string& payload) method has been removed. Use renderTemplate(const std::string& payload, FocusState focusState) instead. The renderPlayerInfo(const std::string& payload) method has been removed. Use renderPlayerInfo(const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState) instead. In the Alexa module, AlexaProperties::SUPPORTED_LOCALES has been removed. For Alexa to recognize the locale setting, specify one of these values: de-DE, en-AU, en-CA, en-GB, en-IN, en-US, es-ES, es-MX, es-US, fr-CA, fr-FR, hi-IN, it-IT, ja-JP, pt-BR. Engine::setProperty() and Engine::getProperty() have been removed. Use PropertyManager::setProperty() and PropertyManager::getProperty() instead. For details about the Property Manager platform interface, see the Core module documentation. The SpeechRecognizer::enableWakeWordDetection() , SpeechRecognizer::disableWakeWordDetection() , and SpeechRecognizer::isWakewordDetectionEnabled() methods have been removed. The Contact Uploader module has been removed. Use the Address Book module instead. Using the Address Book Module \u00b6 Address Book module enables the user to upload contacts from the phone that is paired with the car or the navigation favorites from the car head unit to Alexa cloud. For more information about how this module works, see the Address Book module documentation. Both the Android and C++ sample apps demonstrate the use of the AddressBook platform interface. See the sample app source code for specific implementation details. The following Address Book API descriptions help you transition from the Contact Uploader module to the Address Book module: addAddressBook bool addAddressBook(const std::string& addressBookSourceId, const std::string& name, AddressBookType type); Use addAddressBook instead of ContactUploader::addContactsBegin . In addition, addAddressBook requires you to specify the source id to identify the address book, the friendly name of the address book, and the type of address book. removeAddressBook bool removeAddressBook(const std::string& addressBookSourceId); Use removeAddressBook instead of ContactUploader:: removeUploadedContacts . You must specify the id of the address book to be removed. getEntries bool getEntries( const std::string& addressBookSourceId, std::weak_ptr<IAddressBookEntriesFactory> factory) When using the Address Book module, the Engine pulls the address book contents from the platform implementation. You must upload the address book contents through the factory class, IAddressBookEntriesFactory , for the specified address book source id. Migrating from Auto SDK v2.2.1 to v2.3.0 \u00b6 This section outlines the changes you will need to make to migrate from Auto SDK v2.2.1 to Auto SDK v2.3. Car Control Enhancements and Breaking Changes \u00b6 Read the updated Car Control module documentation to get a complete understanding of all supported features and the current format of the \"aace.carControl\" configuration schema. Read the updated API documentation for the CarControlConfiguration builder class if you construct your configuration programmatically. The changes to the \"aace.carControl\" configuration for v2.3 are backward-compatible, meaning your previous configuration (regardless of whether it was file-based or built programmatically with the CarControlConfiguration class) will still compile and produce a valid configuration to input to Auto SDK. However, several updates are recommended to ensure expected behavior, even if you do not want new features. 1. Zones configuration schema update \u00b6 Prior to v2.3, to assign an endpoint to exactly one zone, you would specify an \"isMemberOf\" relationship in the definition of the endpoint and specify no information about endpoints in the zone definition. { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ], \"relationships\": { \"isMemberOf\": { \"zoneId\": \"zone.all\" } } } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] } } In 2.3, the \"isMemberOf\" relationship is removed from endpoint definitions so that endpoints need not belong to zones and the zone definition can be the source of truth for all its member endpoints. The zone definition now includes a list of member endpoints: { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ] } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] }, \"members\" : [ { \"endpointId\": \"all.fan\" }, ... ] } You should update your configuration accordingly. The Auto SDK Engine translates the old format to the new format internally, but this will be deprecated in later versions. When updating to the new format, you must not combine usage of the \"isMemberOf\" format with the \"members\" list format. Fully migrate all definitions in your configuration. 2. Deprecated implicit creation of zone definitions \u00b6 If you construct your configuration programmatically with the CarControlConfiguration builder class, your implementation prior to v2.3 might not have explicitly specified definitions for the set of zones considered \"official\", but you still used them in your endpoint configurations anyway. The builder class added these definitions to the \"aace.carControl\" configuration automatically without requiring you to call CarControlConfiguration::createZone() . In v2.3, CarControlConfiguration still includes this logic for the old \"official\" zones, but it does not implicitly create any new zones, and it is recommended to define every zone you use by calling CarControlConfiguration::createZone() . Implicit zone definitions will be removed in a later version. 3. New default zone feature \u00b6 Specifying a \"default\" zone ID is an optional new feature, but it is highly recommended that you use it. See the Car Control module documentation for details about why this feature is important. 4. Deprecated \"DriverSeat\" and related assets in favor of zones \u00b6 Prior to v2.3, the default automotive catalog of assets introduced several asset IDs so that online-only systems could mock zones support for heaters on seat endpoints. The asset IDs are the following: Alexa.Automotive.DeviceName.DriverSeat , Alexa.Automotive.DeviceName.LeftSeat , Alexa.Automotive.DeviceName.PassengerSeat , Alexa.Automotive.DeviceName.RightSeat . Now that the cloud supports zones, you must stop using these asset IDs and properly model the endpoints using zones so that Alexa resolves user utterance intents as expected. These assets will be removed in a later version of Auto SDK. See the Car Control module documentation for sample configuration. 5. New default assets \u00b6 The Car Control module is updated to include many new assets in the default automotive catalog to support a wider range of utterances. If you previously defined custom assets to support any of the features introduced to the v2.3 assets, it is recommended that you use the new default assets instead of your previous custom ones. See the Car Control module documentation for details about assets. 6. Reset your account when changing from 2.2 to 2.3 configuration \u00b6 It is a known issue that you cannot delete any previously configured endpoint IDs associated with your customer account in the cloud. When upgrading your configuration from v2.2 to v2.3, contact your SA or Partner Manager for help to reset your account's endpoint database in the cloud. This is especially important if you are updating to use new features. It is also recommended that your v2.3 configuration follows the configuration sample of supported features shown in the Car Control module documentation. Refer to this document for reference. Language Model Packaging \u00b6 Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binaries. If you use the Local Voice Control extension, you must install the language models to successfully migrate to v2.3.0. Download the language model tar files. Installation instructions are provided in the Local Voice Control extension. Android \u00b6 Gradle \u00b6 The gradle plugin has been updated to v3.6.2. This requires gradle v5.6.4 or above in order to build the Auto SDK for Android targets. Sample App \u00b6 The Android sample app supports overriding the client configuration by pushing a file named app_config.json to the /sdcard folder on the device. If the /sdcard/app_config.json file existed on the device before you migrate to v2.3.0, the file overrides the client configuration included in the v2.3.0 Android sample app APK. Clang Formatting \u00b6 Auto SDK code has been formatted with clang-format version 9.0.0. This may lead to merge conflicts if changes have been made to v2.2.1 source code files and you migrate to v2.3. Migrating from Auto SDK v2.2 to v2.2.1 \u00b6 This section outlines the changes you will need to make to migrate from Auto SDK v2.2 to Auto SDK v2.2.1. TemplateRuntime Enhancements \u00b6 Auto SDK v2.2.1 introduces additional TemplateRuntime platform interface features that you can integrate in your application to enrich the user's experience with Now Playing cards for AudioPlayer and ExternalMediaPlayer implementations. Now Playing cards are a form of display cards \u2014 visual aids that complement the Alexa voice experience \u2014 that contain media metadata, player controls and album art delivered in the TemplateRuntime RenderPlayerInfo directive. Migration is only required to support the new features, but is highly recommended for the following reasons: AudioPlayer and TemplateRuntime are now decoupled. The following TemplateRuntime methods are now deprecated: The renderTemplate( const std::string& payload ) method is deprecated. Use renderTemplate( const std::string& payload, FocusState focusState ) instead. The renderPlayerInfo( const std::string& payload ) method is deprecated. Use renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) instead. renderTemplate \u00b6 Method renderTemplate( const std::string& payload, FocusState focusState ) The new renderTemplate method provides visual metadata associated with a user request to Alexa. The platform implementation should parse the template metadata and render a display card for the user. Parameters payload Renderable template metadata in structured JSON format focusState The FocusState of the channel used by TemplateRuntime interface FOREGROUND Represents the highest focus a Channel can have BACKGROUND Represents the intermediate level focus a Channel can have renderPlayerInfo \u00b6 Method renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) The new renderPlayerInfo method provides visual metadata associated with a user request to Alexa for audio playback. The platform implementation should parse the player info metadata and render a display card for the user. The audioPlayerState and offset are useful for implementing the progress bar in the display card. It is assumed that the client is responsible for progressing the progress bar when the AudioPlayer is in PLAYING state. Parameters payload Renderable player info metadata in structured JSON format audioPlayerState The state of the AudioPlayer IDLE Audio playback has not yet begun PLAYING Audio is currently playing STOPPED Audio playback is stopped, either from a stop directive or playback error PAUSED Audio playback is paused BUFFER_UNDERRUN Audio playback is stalled because a buffer underrun has occurred FINISHED Audio playback is finished offset The offset in millisecond of the media that AudioPlayer is handling focusState The FocusState of the channel used by TemplateRuntime interface FOREGROUND Represents the highest focus a Channel can have BACKGROUND Represents the intermediate level focus a Channel can have Sample Apps \u00b6 The Android Sample App demonstrates the new features in TemplateRuntimeHandler.java in GUI form. Refer to sample app source code and Alexa Voice Service documentation for specific implementation details. The C++ Sample App simply demonstrates the new features by printing audioPlayerState , offset , and focusState to the console in the TemplateRuntimeHandler::renderPlayerInfo() method of TemplateRuntimeHandler.cpp . Migrating from Auto SDK v2.1 to v2.2 \u00b6 This section outlines the changes you will need to make to migrate from Auto SDK v2.1 to Auto SDK v2.2. Implementing the Property Manager Interface \u00b6 Auto SDK v2.2 introduces the Property Manager, a component that maintains runtime properties by storing property values and listeners and delegating the setProperty() and getProperty() calls from your application to the respective Engine services. The Engine invokes the PropertyManager platform interface method propertyChanged() to notify your application about property value changes originating internally. The property values may be set by Auto SDK modules that define constants (for example FIRMWARE_VERSION and LOCALE ), or they may be initiated from the Alexa Voice Service (AVS), such as when the user changes the TIMEZONE setting in the Alexa Companion App. PropertyManager::setProperty() and PropertyManager::getProperty() replace deprecated Engine::setProperty() and Engine::getProperty() . For details about the Property Manager platform interface, see Core module documentation. Car Control Changes \u00b6 This section documents the changes you will need to make to migrate your Car Control implementation to Auto SDK v2.2. New Asset ID Prefix \u00b6 The asset ID prefix for default assets has been changed from \"Alexa.\" to \"Alexa.Automotive.\" . This change requires a code or configuration change only if your existing car control implementation uses the CarControlConfiguration configuration builder with the literal strings of asset IDs. If your existing car control implementation uses the predefined constants in CarControlAssets.h or CarControlAssets.java , then no change is required. Specifying the Path to Custom Car Control Assets \u00b6 If your implementation using the Local Voice Control (LVC) extension uses custom assets for car control, you must specify the path to the custom assets in both the aace.carControl Auto SDK car control configuration and the LVC configuration, not just the LVC configuration as in Auto SDK v2.0. For C++ implementations: The default LVC configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the assets.customAssetsPath field in the Auto SDK car control configuration, or provide a path to an assets file with equivalent content. For Android implementations: The file at the path you provide in the assets.customAssetsPath field of the Auto SDK car control configuration must be the same as the custom assets file you configure for your ILVCClient using the LVC APK. Car Control Config Builder Asset Methods \u00b6 Two new CarControlConfiguration methods are now implemented in the Engine: CarControlConfiguration::addCustomAssetsPath() CarControlConfiguration::addDefaultAssetsPath() Note: These methods were also present in Auto SDK v2.1; however they didn't function as designed. They have been updated to function correctly in Auto SDK v2.2. This implementation populates the \"aace.carControl\" configuration object with the \"assets.customAssetsPath\" and \"assets.defaultAssetsPath\" nodes. Migrating from Auto SDK v2.0 to v2.1 \u00b6 This section outlines the changes you will need to make to migrate from Auto SDK v2.0 to Auto SDK v2.1. Build Changes \u00b6 The following build changes have been introduced in Auto SDK v2.1: The builder script usage has changed for Linux targets. All Linux targets now use the same platform name ( linux ), and -t <target> is mandatory. For example, to build for a Linux native target, use: builder/build.sh linux -t native to build for Linux native, pokyarm, and pokyarm64 targets, use: builder/build.sh linux -t native,pokyarm,pokyarm64 See the Builder documentation for details about supported platforms and targets. For QNX targets, you must cross-compile with the QNX multimedia software for the system audio extension (which is built by default for QNX targets). This requires a QNX Multimedia Suite license. See the System Audio extension documentation for details. Engine Configuration File Updates \u00b6 The AVS Device SDK portion of the Auto SDK Engine configuration (the aace.alexa.avsDeviceSDK node) has been updated. See the config.json.in file for details. The \"deviceInfo\" node includes two new elements: \"manufacturerName\" and \"description\" . A path to the capabilities database is now required. Use the \"capabilitiesDelegate\" element to specify this path. The \"settings\" element has changed to \"deviceSettings\" , and it includes these changes: The default locale setting has been moved from \"defaultAVSClientSettings/locale\" to \"defaultLocale\" . \"deviceSettings\" now requires a \"defaultTimezone\" . Navigation Enhancements \u00b6 Auto SDK v2.1 introduces additional navigation features that you can integrate in your application to enrich the user's experience: add/cancel a waypoint, show/navigate to a previous destination, turn and lane guidance, and map display control. Implementing these enhancements required deprecating the setDestination() interface in favor of the startNavigation() interface and adding several additional interfaces. To migrate from Auto SDK v2.0 to Auto SDK v2.1, you must update your platform implementation to use the startNavigation() method instead of the setDestination() method, modify the payload for the getNavigationState() method, and implement the new navigation methods. This guide takes you through these steps. See the Navigation module documentation for additional information and resources. What's New \u00b6 The following abstract methods have been added to the Navigation platform interface: startNavigation() showPreviousWaypoints() navigateToPreviousWaypoint() showAlternativeRoutes() controlDisplay() announceManeuver() announceRoadRegulation() The following methods have been added as well: navigationEvent() navigationError() showAlternativeRoutesSucceeded() The following method has been removed from the Navigation module: setDestination() The following method now returns a different payload: getNavigationState() Implementing the New Navigation Features \u00b6 To implement the new navigation features, follow these steps: STEP 1: Replace the setDestination() method with the startNavigation() method. The payload meaning of startNavigation() is different than that of deprecated setDestination() . setDestination() corresponded to adding a destination to the navigation system context. startNavigation() , on the other hand, corresponds to using the route information provided in the payload to start navigation, with one or more waypoints. In response to startNavigation() , your implementation should also call either the navigationEvent() method or the navigationError() method. Java (Android) - click to expand or collapse // NavigationHandler.java @Override *public void *startNavigation( String payload ) { ... // success navigationEvent( EventName.NAVIGATION_STARTED ); ... // failure navigationError( ErrorType.NAVIGATION_START_FAILED, ErrorCode.INTERNAL_SERVICE_ERROR, \"\" ); C++ - click to expand or collapse // NavigationHandler.cpp void NavigationHandler::startNavigation(const std::string& payload ) { ... // success navigationEvent( aace::navigation::NavigationEngineInterface::EventName::NAVIGATION_STARTED ); ... // failure navigationError( aace::navigation::NavigationEngineInterface::ErrorType::NAVIGATION_START_FAILED, aace::navigation::NavigationEngineInterface::ErrorCode::INTERNAL_SERVICE_ERROR, \"\" ); STEP 2: Modify the payload for the getNavigationState() method. The functionality of the getNavigationState() and cancelNavigationState() methods is unchanged from Auto SDK v2.0, but the getNavigationState() payload has changed. The NavigationState context has been updated to contain more information than in Auto SDK v2.0. The address field has been updated from a string to the following object: ... \"address\": { \"addressLine1\": \"{{STRING}}\", //Address line 1 \"addressLine2\": \"{{STRING}}\", //Address line 2 \"addressLine3\": \"{{STRING}}\", //Address line 3 \"city\": \"{{STRING}}\", //City \"districtOrCounty\": \"{{STRING}}\", //district or county \"stateOrRegion\": \"{{STRING}}\", //state or region \"countryCode\": \"{{STRING}}\", //3 letter country code \"postalCode\": \"{{STRING}}\", //postal code }, ... The name field has been added to the waypoint payload: \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks Here is an example of a full NavigationState context payload - click to expand or collapse ..., { \"header\": { \"namespace\": \"Navigation\", \"name\": \"NavigationState\" }, \"payload\": { \"state\": \"{{STRING}}\", //NAVIGATING or NOT_NAVIGATING \"waypoints\": [ { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //City ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", //state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", //postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], }, { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //city ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", // state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", // postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], \"pointOfInterest\": { \"id\": \"{{STRING}}\", //POI lookup Id vended from Alexa \"hoursOfOperation\": [ { \"dayOfWeek\": \"{{STRING}}\", \"hours\": [ { \"open\": \"{{STRING}}\", // ISO-8601 time with timezone format \"close\": \"{{STRING}}\" // ISO-8601 time with timezone format } ], \"type\": \"{{STRING}}\" // Can be: OPEN_DURING_HOURS, OPEN_24_HOURS, etc. } ], \"phoneNumber\": \"{{STRING}}\" } }, ... ], \"shapes\": [ [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], ... ] } } ..., STEP 3: Implement the new navigation abstract methods. The new navigation methods are all called in response to navigation-based user utterances such as \u201cshow my previous route\u201d or \u201cwhat\u2019s the speed limit here?\u201d. At a minimum, your implementation should report a navigationError() to inform the user when the navigation system does not support that information. Note: The navigationEvent() , showAlternativeRoutesSucceeded() and navigationError() methods have been implemented in the Auto SDK but are not yet implemented on the cloud side. Sending the events will not affect navigation functionality, but the Alexa cloud will return an INVALID_REQUEST_EXCEPTION or INVALID_SERVICE_EXCEPTION until these events are implemented on the cloud side. Java (Android) - click to expand or collapse @Override public void showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, ErrorCode.NOT_SUPPORTED, *\"\"** *); } ... @Override public void navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( ErrorType.PREVIOUS_NAVIGATION_START_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void showAlternativeRoutes( AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void controlDisplay ( ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( ErrorType.ROUTE_OVERVIEW_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( ErrorType.TURN_GUIDANCE_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceRoadRegulation( RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( ErrorType.SPEED_LIMIT_REGULATION_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } C++ - click to expand or collapse void NavigationHandler::showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( aace::navigation::Navigation::ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\"* *); } ... void NavigationHandler::navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( aace::navigation::Navigation::ErrorType.PREVIOUS_NAVIGATION_START_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::showAlternativeRoutes( aace::navigation::Navigation::AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( aace::navigation::Navigation::ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::controlDisplay ( aace::navigation::Navigation::ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( aace::navigation::Navigation::ErrorType.ROUTE_OVERVIEW_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( aace::navigation::Navigation::ErrorType.TURN_GUIDANCE_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceRoadRegulation( aace::navigation::Navigation::RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( aace::navigation::Navigation::ErrorType.SPEED_LIMIT_REGULATION_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } New TemplateRuntime Interface Version \u00b6 The Auto SDK now implements version 1.2 of the TemplateRuntime interface to handle display card templates. If you support TemplateRuntime in your implementation, you must update your implementation to support the new card types. The TemplateRuntime interface remains the same, but the LocalSearchListTemplate1 template has been deprecated in favor of the new LocalSearchListTemplate2 template. In addition, two new templates ( TrafficDetailsTemplate and LocalSearchDetailTemplate1 ), are now supported. The TrafficDetailsTemplate includes commute information to favorite destinations such as home or work. The LocalSearchDetailTemplate1 template includes information about specific locations or information in response to users asking for details about locations presented in the LocalSearchListTemplate2 template. For details about the TemplateRuntime interface, see the Alexa Voice Service (AVS) documentation . For details about implementing TemplateRuntime in your Auto SDK implementation, see the Alexa module documentation. Car Control Source File Relocation \u00b6 The Car Control module platform interface files and documentation are now located in aac-sdk/modules/car-control for C++ and aac-sdk/platforms/android/modules/car-control for Android, rather than in the Local Voice Control (LVC) extension directory structure. Note: In addition, if you use custom assets for car control in an implementation with the optional Local Voice Control (LVC) extension, you must specify the path to the custom assets in both the Auto SDK car control configuration and the LVC configuration, not just the LVC configuration. For details, see Car Control module documentation. Code-Based-Linking (CBL) Handler in the Sample Apps \u00b6 Both of the Auto SDK Sample Apps now include the Code-Based Linking (CBL) handler implementation (in favor of the AuthProvider handler implementation ) to handle obtaining access tokens from Login with Amazon (LWA). Changing from the AuthProvider handler to the CBL handler is not a required change, but we recommend that you use the Auto SDK CBL interface for ease of implementation. For details about the CBL handler, please see the CBL module documentation. If you want to continue using the AuthProvider interface, we recommend that you implement the new onAuthFailure() method that exposes 403 \"unauthorized request\" exceptions from Alexa Voice Service (AVS). This method may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. In the Sample Apps, you can override the interface and unset your login credentials as if the user had done so with your GUI interface: Java (Android) - click to expand or collapse @Override public void authFailure( String token ) { // handle user de-authorize scenario C++ - click to expand or collapse void AuthProviderHandler::authFailure( const std::string& token ) { // handle user de-authorize scenario","title":"Migration Guide"},{"location":"releases/migration/#auto-sdk-migration-guide","text":"","title":"Auto SDK Migration Guide"},{"location":"releases/migration/#overview","text":"This guide highlights the changes in each Auto SDK version that require your application to update to maintain compatibility. The guide outlines the changes with step-by-step recommendations to help you stay up-to-date with the latest Auto SDK version. Each section describes an increment of one release, so if you skip intermediate versions when you upgrade, ensure you follow the steps in each section from your current version to the latest version.","title":"Overview"},{"location":"releases/migration/#backward-compatibility","text":"Auto SDK remains backward compatible across minor version updates; however, to continually improve, Auto SDK sometimes deprecates APIs, configuration fields, and build options in a minor version. The changes this guide outlines in minor version upgrade sections are intended to highlight deprecations and help you stop using deprecated features as soon as possible to prepare for their removal in the next major version. Although rare, if Auto SDK makes an exception to the backward compatibility tenants in a minor version, this guide explicitly calls out the change.","title":"Backward compatibility"},{"location":"releases/migration/#migrating-from-auto-sdk-v400-to-v410","text":"This section provides the information you need to migrate from Auto SDK v4.0.0 to Auto SDK v4.1.0","title":"Migrating from Auto SDK v4.0.0 to v4.1.0"},{"location":"releases/migration/#showalternativeroutessucceeded-savings-amount-must-be-float","text":"The field alternateRoute.savings.amount in the Navigation.ShowAlternativeRoutesSucceeded AASB message (and corresponding deprecated platform interface API Navigation::showAlternativeRoutesSucceeded ) is a float, but Auto SDK versions 4.0 and earlier incorrectly allowed passing a string for this value. Auto SDK 4.1 fixes the issue, so you must update your code to use a float if your code is also incorrectly using a string.","title":"ShowAlternativeRoutesSucceeded savings amount must be float"},{"location":"releases/migration/#lvc-app-components-replace-lvc-apk-on-android-platform","text":"AACS LVC App Components replace the LVC APK on Android. Auto SDK no longer releases the LVC APK, and the previous LVC APK does not work with 4.1 AACS. The LVC App Components are Android libraries (AARs) that run LVC in the same application as AACS, and the AACS sample app integrates them by default. If your Alexa client application uses the Java platform interfaces (deprecated in 4.0), you are required to update your application to use AACS before integrating with LVC App Components. See Migrate to the MessageBroker API and the AACS documentation for information about migrating your application. If your Alexa client application is AACS-based already and has LVC functionality, the previous implementation based on AIDL interfaces and the LVC APK no longer applies. Specifically, ILVCClient and ILVCService are removed. Remove your implementation of ILVCClient and the binding to the LVC service. Instead, by default, no additional implementation is needed with AACS in 4.1 because AACS starts and configures LVC. You do not need to specify android:sharedUserId previously required for inter-application UDS IPC. For more details about integrating the LVC App Components, see the documentation in the Local Voice Control extension on the Amazon developer portal.","title":"LVC App Components replace LVC APK on Android Platform"},{"location":"releases/migration/#migrating-from-auto-sdk-v330-to-v400","text":"This section provides the information you need to migrate from Auto SDK v3.3.0 to Auto SDK v4.0.0","title":"Migrating from Auto SDK v3.3.0 to v4.0.0"},{"location":"releases/migration/#platform-interfaces-are-deprecated","text":"The C++ and Java platform interfaces are deprecated in favor of Alexa Auto Services Bridge (AASB). Auto SDK 4.0 replaces the platform interfaces with a new MessageBroker API for subscribing to and publishing AASB messages. See Migrate to the MessageBroker API for information and instructions to migrate your application.","title":"Platform Interfaces are deprecated"},{"location":"releases/migration/#aasb-configuration-for-aacs-is-updated","text":"In Auto SDK version 3.3, your application using AACS was required to configure the AASB version with the following aacs.aasb object in your AACS configuration file: \"aacs.aasb\" : { \"version\": \"3.3\" } Remove this configuration from your 4.0 AACS configuration file. Additionally, the optional defaultMessageTimeout and autoEnableInterfaces configuration fields are moved from the aasb object to the messageBroker object, so you must update your AACS configuration file if you use these fields. For example, if your AACS configuration file includes this block: { \"aacs.aasb\": { \"autoEnableInterfaces\": false, \"defaultMessageTimeout\": 1000 } } change it to this: { \"aacs.messageBroker\": { \"autoEnableInterfaces\": false, \"defaultMessageTimeout\": 1000 } }","title":"AASB configuration for AACS is updated"},{"location":"releases/migration/#migrating-from-auto-sdk-v321-to-v330","text":"This section provides the information you need to migrate from Auto SDK v3.2.1 to Auto SDK v3.3.0","title":"Migrating from Auto SDK v3.2.1 to v3.3.0"},{"location":"releases/migration/#local-media-source-and-global-preset-enhancements","text":"","title":"Local Media Source and Global Preset Enhancements"},{"location":"releases/migration/#globalpreset-is-deprecated","text":"The GlobalPreset platform interface is deprecated because its feature set is supported by the new DEFAULT LocalMediaSource type. To preserve functionality for utterances targeting generic presets like \"Alexa, play preset 1\", implement and register a LocalMediaSource handler of Source::DEFAULT type. The user utterances that cause the Engine to invoke GlobalPreset::setGlobalPreset() will cause the Engine to invoke LocalMediaSource::play() with ContentSelector::PRESET instead. The GlobalPreset platform interface will be removed in a future version of Auto SDK.","title":"GlobalPreset is deprecated"},{"location":"releases/migration/#additional-localmediasource-playerevent-calls-are-needed","text":"Previous Auto SDK documentation stated that you must call LocalMediaSource::playerEvent() to report events \"PlaybackStated\" and \"PlaybackStopped\" only. Please update your implementation to call playerEvent() with states \"PlaybackSessionStarted\" and \"PlaybackSessionEnded\" as well. See the Alexa module documentation for information about when to report these events.","title":"Additional LocalMediaSource playerEvent calls are needed"},{"location":"releases/migration/#setfocus-is-deprecated","text":"The API LocalMediaSource::setFocus() is deprecated because its functionality is equivalent to calling LocalMediaSource::playerEvent() with event name \"PlaybackSessionStarted\" when a player is brought into focus or \"PlaybackSessionEnded\" when a player is removed from focus. Please replace your calls to setFocus(true) and setFocus(false) with calls to playerEvent(\"PlaybackSessionStarted\") and playerEvent(\"PlaybackSessionEnded\") , respectively. setFocus will be removed in a future version of Auto SDK.","title":"setFocus is deprecated"},{"location":"releases/migration/#reporting-playback-session-id-is-needed","text":"The Alexa cloud requires ExternalMediaPlayer events and context for a particular player to include the playback session ID of a player's active session. To support this, the LocalMediaSource::play() function signature is updated to include a parameter for session ID for an Alexa-initiated session, which you must use when reporting player events for the player. The playerEvent and playerError signatures are also updated to include session ID. You must generate your own session ID when the playback is initiated by the user without Alexa. See the Alexa module documentation for more details about the sessionId . The versions of APIs without the session ID will be removed in a future version of Auto SDK.","title":"Reporting playback session ID is needed"},{"location":"releases/migration/#migrating-the-local-navigation-module-apis","text":"The local search features of the Local Voice Control Extension's Local Navigation module are extended to support offline navigation to addresses, cities, and neighborhoods. To support the new feature set, the existing APIs are updated to a more general name. The changes are backward compatible, but the old APIs are deprecated and will be removed in a future version. Use the following steps to assist the migration to the new APIs:","title":"Migrating the Local Navigation Module APIs"},{"location":"releases/migration/#localsearchprovider-platform-interface-changes","text":"We have deprecated the functions poiSearchRequest , poiLookupRequest , poiSearchResponse , and poiLookupResponse in favor of searchRequest , lookupRequest , searchResponse , and lookupResponse , respectively. Override LocalSearchProvider::searchRequest() instead of LocalSearchProvider::poiSearchRequest() . Override LocalSearchProvider::lookupRequest() instead of LocalSearchProvider::poiLookupRequest() . Call LocalSearchProvider::searchResponse() instead of LocalSearchProvider::poiSearchResponse() . Call LocalSearchProvider::lookupResponse() instead of LocalSearchProvider::poiLookupResponse() . We have also deprecated the AASB messages PoiSearchRequestMessage , PoiLookupRequestMessage , PoiSearchResponseMessage , and PoiLookupResponseMessage in favor of SearchRequestMessage , LookupRequestMessage , SearchResponseMessage , and LookupResponseMessage , respectively. Subscribe to SearchRequestMessage instead of PoiSearchRequestMessage . Subscribe to LookupRequestMessage instead of PoiLookupRequestMessage . Publish to SearchResponseMessage instead of PoiSearchResponseMessage . Publish to LookupResponseMessage instead of PoiLookupResponseMessage . The JSON schemas of search and response are still the same. Note: Do not use/implement a mix of the old APIs and the new APIs","title":"LocalSearchProvider Platform Interface Changes"},{"location":"releases/migration/#local-navigation-module-engine-configuration-changes","text":"The aace.localNavigation.localSearch configuration keys navigationPOISocketPath and poiEERSocketPath are renamed to navigationLocalSearchSocketPath and localSearchEERSocketPath , respectively. For example, if your configuration was this { \"aace.localNavigation\": { \"localSearch\": { \"navigationPOISocketPath\": \"/opt/LVC/data/poi-er-service/poi_navigation.socket\", \"poiEERSocketPath\": \"/opt/LVC/data/poi-er-service/poi_eer.socket\" } } } change it to this { \"aace.localNavigation\": { \"localSearch\": { \"navigationLocalSearchSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_navigation.socket\", \"localSearchEERSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_eer.socket\" } } } If you are using the LocalNavigationConfiguration::createLocalSearchConfig() factory function to generate the configuration, your usage does not have to change because the signature is the same and implementation of this function generates the new JSON. Note: the socket paths in the Linux default sample configuration file are updated, so if you use different values, ensure you update your LVC app configuration accordingly","title":"Local Navigation Module Engine Configuration Changes"},{"location":"releases/migration/#lvc-apk-configuration-changes","text":"If you use LVC on Android, update the configuration returned by your implementation of the interface ILVCClient.getConfiguration() . The paths NavigationPOISocketDir and POIEERSocketDir have been deprecated in favor of NavigationLocalSearchSocketDir and LocalSearchEERSocketDir , respectively. The socket names NavigationPOISocketName and POIEERSocketName have been deprecated in favor of NavigationLocalSearchSocketName and LocalSearchEERSocketName , respectively.","title":"LVC APK Configuration Changes"},{"location":"releases/migration/#lvc-linux-app-configuration-changes","text":"The LVC configuration file lvc-config.json installed at /opt/LVC/config by the installation script LVC.sh has no changes to its JSON configuration schema since Auto SDK 3.2. However, the socket directories and names used by default in this file are updated to use more general names.","title":"LVC Linux App Configuration Changes"},{"location":"releases/migration/#migrating-from-auto-sdk-v310-to-v320","text":"This section provides the information you need to migrate from Auto SDK v3.1.0 to Auto SDK 3.2.0. All information about 3.2.0 is also applicable to 3.2.1.","title":"Migrating from Auto SDK v3.1.0 to v3.2.0"},{"location":"releases/migration/#using-the-alexa-communication-extension","text":"The Alexa Comms library in Auto SDK v3.2.0 uses Device Client Metrics (DCM) instead of AWS IoT for uploading metrics. Therefore, remove the iotCertificateDirPath , iotHostAddress , and deviceTypeId fields from the communication configuration file. For information about the configuration file format, see the Alexa Communication extension documentation. If you build the Alexa Comms module configuration using the programmatic factory function AlexaCommsConfiguration::createCommsConfig() (C++) or AlexaCommsConfiguration.createCommsConfig() (Java), remove the parameters that are no longer present in the signature.","title":"Using the Alexa Communication Extension"},{"location":"releases/migration/#using-the-device-client-metrics-dcm-extension","text":"The Device Client Metrics extension in Auto SDK v3.2.0 requires a field called metricsTag to be defined in the DCM configuration. The value of metricsTag is used for generating a unique identifier for anonymous registration metrics. Note: You must not use the vehicle identification number (VIN) or device serial number (DSN) as metricsTag . For information about how to use this field, see the Device Client Metric extension documentation. If you build the DCM module configuration using the programmatic factory function DCMConfiguration::createDCMConfig() (C++) or DCMConfiguration.createDCMConfig() (Java), add the metricsTag parameter as instructed in the API documentation.","title":"Using the Device Client Metrics (DCM) Extension"},{"location":"releases/migration/#migrating-from-auto-sdk-v300-to-v310","text":"This section provides the information you need to migrate from Auto SDK v3.0.0 to Auto SDK v3.1.0.","title":"Migrating from Auto SDK v3.0.0 to v3.1.0"},{"location":"releases/migration/#migrating-to-the-authorization-platform-interface","text":"Auto SDK v3.1.0 introduces the Authorization module that provides a single platform interface to manage different types of authorizations supported by the Engine. This single platform interface works with the Engine services that carry out the actual authorization process or flow. For more information about how authorization works, see the Core module documentation. This section provides the information you need for migrating to the Authorization platform interface from the CBL or AuthProvider platform interface, which are deprecated in v3.1.0 Migrating from the CBL Platform Interface To migrate from the CBL platform interface to the Authorization platform interface, follow the instructions in the CBL module documentation, which describes the Authorization APIs for CBL authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the CBL platform interface, as shown in the following table: CBL Authorization Description ERROR UNKNOWN_ERROR Unknown error occurs during the authorization flow. TIMEOUT TIMEOUT Request for the the CBL code from LWA times out. CODE_PAIR_EXPIRED CODE_PAIR_EXPIRED The code pair obtained has expired. AUTHORIZATION_EXPIRED AUTHORIZATION_EXPIRED Refresh token is expired or revoked. START_AUTHORIZATION_FAILED Authorization fails to start. LOGOUT_FAILED Logout fails. Migrating from the AuthProvider Platform Interface To migrate from the AuthProvider platform interface to the Authorization platform interface, follow the instructions in the Alexa module documentation, which describes the Authorization APIs for Auth Provider authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the AuthProvider platform interface, as shown in the following table: AuthProvider Authorization Description authFailure AUTH_FAILURE Invalid or expired access token was provided. NOT PRESENT UNKNOWN_ERROR Unknown error occurs during the authorization flow. NOT PRESENT START_AUTHORIZATION_FAILED Authorization fails to start. NOT PRESENT LOGOUT_FAILED Logout fails.","title":"Migrating to the Authorization Platform Interface"},{"location":"releases/migration/#deprecated-features-removed-in-auto-sdk-v300","text":"The following asset IDs for Car Control have been removed: \"Alexa.Automotive.DeviceName.DriverSeat\", \"Alexa.Automotive.DeviceName.LeftSeat\", \"Alexa.Automotive.DeviceName.PassengerSeat\", \"Alexa.Automotive.DeviceName.RightSeat\". The createControl() method has been removed. Use createEndpoint() instead. Support for the \"isMemberOf\" relationship for endpoint definition has been removed. You must list member endpoints in a zone definition. Implicit zone definitions have been removed. The following TemplateRuntime methods have been removed: The renderTemplate(const std::string& payload) method has been removed. Use renderTemplate(const std::string& payload, FocusState focusState) instead. The renderPlayerInfo(const std::string& payload) method has been removed. Use renderPlayerInfo(const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState) instead. In the Alexa module, AlexaProperties::SUPPORTED_LOCALES has been removed. For Alexa to recognize the locale setting, specify one of these values: de-DE, en-AU, en-CA, en-GB, en-IN, en-US, es-ES, es-MX, es-US, fr-CA, fr-FR, hi-IN, it-IT, ja-JP, pt-BR. Engine::setProperty() and Engine::getProperty() have been removed. Use PropertyManager::setProperty() and PropertyManager::getProperty() instead. For details about the Property Manager platform interface, see the Core module documentation. The SpeechRecognizer::enableWakeWordDetection() , SpeechRecognizer::disableWakeWordDetection() , and SpeechRecognizer::isWakewordDetectionEnabled() methods have been removed. The Contact Uploader module has been removed. Use the Address Book module instead.","title":"Deprecated Features Removed in Auto SDK v3.0.0"},{"location":"releases/migration/#using-the-address-book-module","text":"Address Book module enables the user to upload contacts from the phone that is paired with the car or the navigation favorites from the car head unit to Alexa cloud. For more information about how this module works, see the Address Book module documentation. Both the Android and C++ sample apps demonstrate the use of the AddressBook platform interface. See the sample app source code for specific implementation details. The following Address Book API descriptions help you transition from the Contact Uploader module to the Address Book module: addAddressBook bool addAddressBook(const std::string& addressBookSourceId, const std::string& name, AddressBookType type); Use addAddressBook instead of ContactUploader::addContactsBegin . In addition, addAddressBook requires you to specify the source id to identify the address book, the friendly name of the address book, and the type of address book. removeAddressBook bool removeAddressBook(const std::string& addressBookSourceId); Use removeAddressBook instead of ContactUploader:: removeUploadedContacts . You must specify the id of the address book to be removed. getEntries bool getEntries( const std::string& addressBookSourceId, std::weak_ptr<IAddressBookEntriesFactory> factory) When using the Address Book module, the Engine pulls the address book contents from the platform implementation. You must upload the address book contents through the factory class, IAddressBookEntriesFactory , for the specified address book source id.","title":"Using the Address Book Module"},{"location":"releases/migration/#migrating-from-auto-sdk-v221-to-v230","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.2.1 to Auto SDK v2.3.","title":"Migrating from Auto SDK v2.2.1 to v2.3.0"},{"location":"releases/migration/#car-control-enhancements-and-breaking-changes","text":"Read the updated Car Control module documentation to get a complete understanding of all supported features and the current format of the \"aace.carControl\" configuration schema. Read the updated API documentation for the CarControlConfiguration builder class if you construct your configuration programmatically. The changes to the \"aace.carControl\" configuration for v2.3 are backward-compatible, meaning your previous configuration (regardless of whether it was file-based or built programmatically with the CarControlConfiguration class) will still compile and produce a valid configuration to input to Auto SDK. However, several updates are recommended to ensure expected behavior, even if you do not want new features.","title":"Car Control Enhancements and Breaking Changes"},{"location":"releases/migration/#1-zones-configuration-schema-update","text":"Prior to v2.3, to assign an endpoint to exactly one zone, you would specify an \"isMemberOf\" relationship in the definition of the endpoint and specify no information about endpoints in the zone definition. { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ], \"relationships\": { \"isMemberOf\": { \"zoneId\": \"zone.all\" } } } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] } } In 2.3, the \"isMemberOf\" relationship is removed from endpoint definitions so that endpoints need not belong to zones and the zone definition can be the source of truth for all its member endpoints. The zone definition now includes a list of member endpoints: { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ] } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] }, \"members\" : [ { \"endpointId\": \"all.fan\" }, ... ] } You should update your configuration accordingly. The Auto SDK Engine translates the old format to the new format internally, but this will be deprecated in later versions. When updating to the new format, you must not combine usage of the \"isMemberOf\" format with the \"members\" list format. Fully migrate all definitions in your configuration.","title":"1. Zones configuration schema update"},{"location":"releases/migration/#2-deprecated-implicit-creation-of-zone-definitions","text":"If you construct your configuration programmatically with the CarControlConfiguration builder class, your implementation prior to v2.3 might not have explicitly specified definitions for the set of zones considered \"official\", but you still used them in your endpoint configurations anyway. The builder class added these definitions to the \"aace.carControl\" configuration automatically without requiring you to call CarControlConfiguration::createZone() . In v2.3, CarControlConfiguration still includes this logic for the old \"official\" zones, but it does not implicitly create any new zones, and it is recommended to define every zone you use by calling CarControlConfiguration::createZone() . Implicit zone definitions will be removed in a later version.","title":"2. Deprecated implicit creation of zone definitions"},{"location":"releases/migration/#3-new-default-zone-feature","text":"Specifying a \"default\" zone ID is an optional new feature, but it is highly recommended that you use it. See the Car Control module documentation for details about why this feature is important.","title":"3. New default zone feature"},{"location":"releases/migration/#4-deprecated-driverseat-and-related-assets-in-favor-of-zones","text":"Prior to v2.3, the default automotive catalog of assets introduced several asset IDs so that online-only systems could mock zones support for heaters on seat endpoints. The asset IDs are the following: Alexa.Automotive.DeviceName.DriverSeat , Alexa.Automotive.DeviceName.LeftSeat , Alexa.Automotive.DeviceName.PassengerSeat , Alexa.Automotive.DeviceName.RightSeat . Now that the cloud supports zones, you must stop using these asset IDs and properly model the endpoints using zones so that Alexa resolves user utterance intents as expected. These assets will be removed in a later version of Auto SDK. See the Car Control module documentation for sample configuration.","title":"4. Deprecated \"DriverSeat\" and related assets in favor of zones"},{"location":"releases/migration/#5-new-default-assets","text":"The Car Control module is updated to include many new assets in the default automotive catalog to support a wider range of utterances. If you previously defined custom assets to support any of the features introduced to the v2.3 assets, it is recommended that you use the new default assets instead of your previous custom ones. See the Car Control module documentation for details about assets.","title":"5. New default assets"},{"location":"releases/migration/#6-reset-your-account-when-changing-from-22-to-23-configuration","text":"It is a known issue that you cannot delete any previously configured endpoint IDs associated with your customer account in the cloud. When upgrading your configuration from v2.2 to v2.3, contact your SA or Partner Manager for help to reset your account's endpoint database in the cloud. This is especially important if you are updating to use new features. It is also recommended that your v2.3 configuration follows the configuration sample of supported features shown in the Car Control module documentation. Refer to this document for reference.","title":"6. Reset your account when changing from 2.2 to 2.3 configuration"},{"location":"releases/migration/#language-model-packaging","text":"Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binaries. If you use the Local Voice Control extension, you must install the language models to successfully migrate to v2.3.0. Download the language model tar files. Installation instructions are provided in the Local Voice Control extension.","title":"Language Model Packaging"},{"location":"releases/migration/#android","text":"","title":"Android"},{"location":"releases/migration/#gradle","text":"The gradle plugin has been updated to v3.6.2. This requires gradle v5.6.4 or above in order to build the Auto SDK for Android targets.","title":"Gradle"},{"location":"releases/migration/#sample-app","text":"The Android sample app supports overriding the client configuration by pushing a file named app_config.json to the /sdcard folder on the device. If the /sdcard/app_config.json file existed on the device before you migrate to v2.3.0, the file overrides the client configuration included in the v2.3.0 Android sample app APK.","title":"Sample App"},{"location":"releases/migration/#clang-formatting","text":"Auto SDK code has been formatted with clang-format version 9.0.0. This may lead to merge conflicts if changes have been made to v2.2.1 source code files and you migrate to v2.3.","title":"Clang Formatting"},{"location":"releases/migration/#migrating-from-auto-sdk-v22-to-v221","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.2 to Auto SDK v2.2.1.","title":"Migrating from Auto SDK v2.2 to v2.2.1"},{"location":"releases/migration/#templateruntime-enhancements","text":"Auto SDK v2.2.1 introduces additional TemplateRuntime platform interface features that you can integrate in your application to enrich the user's experience with Now Playing cards for AudioPlayer and ExternalMediaPlayer implementations. Now Playing cards are a form of display cards \u2014 visual aids that complement the Alexa voice experience \u2014 that contain media metadata, player controls and album art delivered in the TemplateRuntime RenderPlayerInfo directive. Migration is only required to support the new features, but is highly recommended for the following reasons: AudioPlayer and TemplateRuntime are now decoupled. The following TemplateRuntime methods are now deprecated: The renderTemplate( const std::string& payload ) method is deprecated. Use renderTemplate( const std::string& payload, FocusState focusState ) instead. The renderPlayerInfo( const std::string& payload ) method is deprecated. Use renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) instead.","title":"TemplateRuntime Enhancements"},{"location":"releases/migration/#rendertemplate","text":"Method renderTemplate( const std::string& payload, FocusState focusState ) The new renderTemplate method provides visual metadata associated with a user request to Alexa. The platform implementation should parse the template metadata and render a display card for the user. Parameters payload Renderable template metadata in structured JSON format focusState The FocusState of the channel used by TemplateRuntime interface FOREGROUND Represents the highest focus a Channel can have BACKGROUND Represents the intermediate level focus a Channel can have","title":"renderTemplate"},{"location":"releases/migration/#renderplayerinfo","text":"Method renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) The new renderPlayerInfo method provides visual metadata associated with a user request to Alexa for audio playback. The platform implementation should parse the player info metadata and render a display card for the user. The audioPlayerState and offset are useful for implementing the progress bar in the display card. It is assumed that the client is responsible for progressing the progress bar when the AudioPlayer is in PLAYING state. Parameters payload Renderable player info metadata in structured JSON format audioPlayerState The state of the AudioPlayer IDLE Audio playback has not yet begun PLAYING Audio is currently playing STOPPED Audio playback is stopped, either from a stop directive or playback error PAUSED Audio playback is paused BUFFER_UNDERRUN Audio playback is stalled because a buffer underrun has occurred FINISHED Audio playback is finished offset The offset in millisecond of the media that AudioPlayer is handling focusState The FocusState of the channel used by TemplateRuntime interface FOREGROUND Represents the highest focus a Channel can have BACKGROUND Represents the intermediate level focus a Channel can have","title":"renderPlayerInfo"},{"location":"releases/migration/#sample-apps","text":"The Android Sample App demonstrates the new features in TemplateRuntimeHandler.java in GUI form. Refer to sample app source code and Alexa Voice Service documentation for specific implementation details. The C++ Sample App simply demonstrates the new features by printing audioPlayerState , offset , and focusState to the console in the TemplateRuntimeHandler::renderPlayerInfo() method of TemplateRuntimeHandler.cpp .","title":"Sample Apps"},{"location":"releases/migration/#migrating-from-auto-sdk-v21-to-v22","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.1 to Auto SDK v2.2.","title":"Migrating from Auto SDK v2.1 to v2.2"},{"location":"releases/migration/#implementing-the-property-manager-interface","text":"Auto SDK v2.2 introduces the Property Manager, a component that maintains runtime properties by storing property values and listeners and delegating the setProperty() and getProperty() calls from your application to the respective Engine services. The Engine invokes the PropertyManager platform interface method propertyChanged() to notify your application about property value changes originating internally. The property values may be set by Auto SDK modules that define constants (for example FIRMWARE_VERSION and LOCALE ), or they may be initiated from the Alexa Voice Service (AVS), such as when the user changes the TIMEZONE setting in the Alexa Companion App. PropertyManager::setProperty() and PropertyManager::getProperty() replace deprecated Engine::setProperty() and Engine::getProperty() . For details about the Property Manager platform interface, see Core module documentation.","title":"Implementing the Property Manager Interface"},{"location":"releases/migration/#car-control-changes","text":"This section documents the changes you will need to make to migrate your Car Control implementation to Auto SDK v2.2.","title":"Car Control Changes"},{"location":"releases/migration/#new-asset-id-prefix","text":"The asset ID prefix for default assets has been changed from \"Alexa.\" to \"Alexa.Automotive.\" . This change requires a code or configuration change only if your existing car control implementation uses the CarControlConfiguration configuration builder with the literal strings of asset IDs. If your existing car control implementation uses the predefined constants in CarControlAssets.h or CarControlAssets.java , then no change is required.","title":"New Asset ID Prefix"},{"location":"releases/migration/#specifying-the-path-to-custom-car-control-assets","text":"If your implementation using the Local Voice Control (LVC) extension uses custom assets for car control, you must specify the path to the custom assets in both the aace.carControl Auto SDK car control configuration and the LVC configuration, not just the LVC configuration as in Auto SDK v2.0. For C++ implementations: The default LVC configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the assets.customAssetsPath field in the Auto SDK car control configuration, or provide a path to an assets file with equivalent content. For Android implementations: The file at the path you provide in the assets.customAssetsPath field of the Auto SDK car control configuration must be the same as the custom assets file you configure for your ILVCClient using the LVC APK.","title":"Specifying the Path to Custom Car Control Assets"},{"location":"releases/migration/#car-control-config-builder-asset-methods","text":"Two new CarControlConfiguration methods are now implemented in the Engine: CarControlConfiguration::addCustomAssetsPath() CarControlConfiguration::addDefaultAssetsPath() Note: These methods were also present in Auto SDK v2.1; however they didn't function as designed. They have been updated to function correctly in Auto SDK v2.2. This implementation populates the \"aace.carControl\" configuration object with the \"assets.customAssetsPath\" and \"assets.defaultAssetsPath\" nodes.","title":"Car Control Config Builder Asset Methods"},{"location":"releases/migration/#migrating-from-auto-sdk-v20-to-v21","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.0 to Auto SDK v2.1.","title":"Migrating from Auto SDK v2.0 to v2.1"},{"location":"releases/migration/#build-changes","text":"The following build changes have been introduced in Auto SDK v2.1: The builder script usage has changed for Linux targets. All Linux targets now use the same platform name ( linux ), and -t <target> is mandatory. For example, to build for a Linux native target, use: builder/build.sh linux -t native to build for Linux native, pokyarm, and pokyarm64 targets, use: builder/build.sh linux -t native,pokyarm,pokyarm64 See the Builder documentation for details about supported platforms and targets. For QNX targets, you must cross-compile with the QNX multimedia software for the system audio extension (which is built by default for QNX targets). This requires a QNX Multimedia Suite license. See the System Audio extension documentation for details.","title":"Build Changes"},{"location":"releases/migration/#engine-configuration-file-updates","text":"The AVS Device SDK portion of the Auto SDK Engine configuration (the aace.alexa.avsDeviceSDK node) has been updated. See the config.json.in file for details. The \"deviceInfo\" node includes two new elements: \"manufacturerName\" and \"description\" . A path to the capabilities database is now required. Use the \"capabilitiesDelegate\" element to specify this path. The \"settings\" element has changed to \"deviceSettings\" , and it includes these changes: The default locale setting has been moved from \"defaultAVSClientSettings/locale\" to \"defaultLocale\" . \"deviceSettings\" now requires a \"defaultTimezone\" .","title":"Engine Configuration File Updates"},{"location":"releases/migration/#navigation-enhancements","text":"Auto SDK v2.1 introduces additional navigation features that you can integrate in your application to enrich the user's experience: add/cancel a waypoint, show/navigate to a previous destination, turn and lane guidance, and map display control. Implementing these enhancements required deprecating the setDestination() interface in favor of the startNavigation() interface and adding several additional interfaces. To migrate from Auto SDK v2.0 to Auto SDK v2.1, you must update your platform implementation to use the startNavigation() method instead of the setDestination() method, modify the payload for the getNavigationState() method, and implement the new navigation methods. This guide takes you through these steps. See the Navigation module documentation for additional information and resources.","title":"Navigation Enhancements"},{"location":"releases/migration/#whats-new","text":"The following abstract methods have been added to the Navigation platform interface: startNavigation() showPreviousWaypoints() navigateToPreviousWaypoint() showAlternativeRoutes() controlDisplay() announceManeuver() announceRoadRegulation() The following methods have been added as well: navigationEvent() navigationError() showAlternativeRoutesSucceeded() The following method has been removed from the Navigation module: setDestination() The following method now returns a different payload: getNavigationState()","title":"What's New"},{"location":"releases/migration/#implementing-the-new-navigation-features","text":"To implement the new navigation features, follow these steps: STEP 1: Replace the setDestination() method with the startNavigation() method. The payload meaning of startNavigation() is different than that of deprecated setDestination() . setDestination() corresponded to adding a destination to the navigation system context. startNavigation() , on the other hand, corresponds to using the route information provided in the payload to start navigation, with one or more waypoints. In response to startNavigation() , your implementation should also call either the navigationEvent() method or the navigationError() method. Java (Android) - click to expand or collapse // NavigationHandler.java @Override *public void *startNavigation( String payload ) { ... // success navigationEvent( EventName.NAVIGATION_STARTED ); ... // failure navigationError( ErrorType.NAVIGATION_START_FAILED, ErrorCode.INTERNAL_SERVICE_ERROR, \"\" ); C++ - click to expand or collapse // NavigationHandler.cpp void NavigationHandler::startNavigation(const std::string& payload ) { ... // success navigationEvent( aace::navigation::NavigationEngineInterface::EventName::NAVIGATION_STARTED ); ... // failure navigationError( aace::navigation::NavigationEngineInterface::ErrorType::NAVIGATION_START_FAILED, aace::navigation::NavigationEngineInterface::ErrorCode::INTERNAL_SERVICE_ERROR, \"\" ); STEP 2: Modify the payload for the getNavigationState() method. The functionality of the getNavigationState() and cancelNavigationState() methods is unchanged from Auto SDK v2.0, but the getNavigationState() payload has changed. The NavigationState context has been updated to contain more information than in Auto SDK v2.0. The address field has been updated from a string to the following object: ... \"address\": { \"addressLine1\": \"{{STRING}}\", //Address line 1 \"addressLine2\": \"{{STRING}}\", //Address line 2 \"addressLine3\": \"{{STRING}}\", //Address line 3 \"city\": \"{{STRING}}\", //City \"districtOrCounty\": \"{{STRING}}\", //district or county \"stateOrRegion\": \"{{STRING}}\", //state or region \"countryCode\": \"{{STRING}}\", //3 letter country code \"postalCode\": \"{{STRING}}\", //postal code }, ... The name field has been added to the waypoint payload: \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks Here is an example of a full NavigationState context payload - click to expand or collapse ..., { \"header\": { \"namespace\": \"Navigation\", \"name\": \"NavigationState\" }, \"payload\": { \"state\": \"{{STRING}}\", //NAVIGATING or NOT_NAVIGATING \"waypoints\": [ { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //City ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", //state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", //postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], }, { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //city ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", // state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", // postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], \"pointOfInterest\": { \"id\": \"{{STRING}}\", //POI lookup Id vended from Alexa \"hoursOfOperation\": [ { \"dayOfWeek\": \"{{STRING}}\", \"hours\": [ { \"open\": \"{{STRING}}\", // ISO-8601 time with timezone format \"close\": \"{{STRING}}\" // ISO-8601 time with timezone format } ], \"type\": \"{{STRING}}\" // Can be: OPEN_DURING_HOURS, OPEN_24_HOURS, etc. } ], \"phoneNumber\": \"{{STRING}}\" } }, ... ], \"shapes\": [ [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], ... ] } } ..., STEP 3: Implement the new navigation abstract methods. The new navigation methods are all called in response to navigation-based user utterances such as \u201cshow my previous route\u201d or \u201cwhat\u2019s the speed limit here?\u201d. At a minimum, your implementation should report a navigationError() to inform the user when the navigation system does not support that information. Note: The navigationEvent() , showAlternativeRoutesSucceeded() and navigationError() methods have been implemented in the Auto SDK but are not yet implemented on the cloud side. Sending the events will not affect navigation functionality, but the Alexa cloud will return an INVALID_REQUEST_EXCEPTION or INVALID_SERVICE_EXCEPTION until these events are implemented on the cloud side. Java (Android) - click to expand or collapse @Override public void showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, ErrorCode.NOT_SUPPORTED, *\"\"** *); } ... @Override public void navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( ErrorType.PREVIOUS_NAVIGATION_START_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void showAlternativeRoutes( AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void controlDisplay ( ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( ErrorType.ROUTE_OVERVIEW_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( ErrorType.TURN_GUIDANCE_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceRoadRegulation( RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( ErrorType.SPEED_LIMIT_REGULATION_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } C++ - click to expand or collapse void NavigationHandler::showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( aace::navigation::Navigation::ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\"* *); } ... void NavigationHandler::navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( aace::navigation::Navigation::ErrorType.PREVIOUS_NAVIGATION_START_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::showAlternativeRoutes( aace::navigation::Navigation::AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( aace::navigation::Navigation::ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::controlDisplay ( aace::navigation::Navigation::ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( aace::navigation::Navigation::ErrorType.ROUTE_OVERVIEW_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( aace::navigation::Navigation::ErrorType.TURN_GUIDANCE_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceRoadRegulation( aace::navigation::Navigation::RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( aace::navigation::Navigation::ErrorType.SPEED_LIMIT_REGULATION_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); }","title":"Implementing the New Navigation Features"},{"location":"releases/migration/#new-templateruntime-interface-version","text":"The Auto SDK now implements version 1.2 of the TemplateRuntime interface to handle display card templates. If you support TemplateRuntime in your implementation, you must update your implementation to support the new card types. The TemplateRuntime interface remains the same, but the LocalSearchListTemplate1 template has been deprecated in favor of the new LocalSearchListTemplate2 template. In addition, two new templates ( TrafficDetailsTemplate and LocalSearchDetailTemplate1 ), are now supported. The TrafficDetailsTemplate includes commute information to favorite destinations such as home or work. The LocalSearchDetailTemplate1 template includes information about specific locations or information in response to users asking for details about locations presented in the LocalSearchListTemplate2 template. For details about the TemplateRuntime interface, see the Alexa Voice Service (AVS) documentation . For details about implementing TemplateRuntime in your Auto SDK implementation, see the Alexa module documentation.","title":"New TemplateRuntime Interface Version"},{"location":"releases/migration/#car-control-source-file-relocation","text":"The Car Control module platform interface files and documentation are now located in aac-sdk/modules/car-control for C++ and aac-sdk/platforms/android/modules/car-control for Android, rather than in the Local Voice Control (LVC) extension directory structure. Note: In addition, if you use custom assets for car control in an implementation with the optional Local Voice Control (LVC) extension, you must specify the path to the custom assets in both the Auto SDK car control configuration and the LVC configuration, not just the LVC configuration. For details, see Car Control module documentation.","title":"Car Control Source File Relocation"},{"location":"releases/migration/#code-based-linking-cbl-handler-in-the-sample-apps","text":"Both of the Auto SDK Sample Apps now include the Code-Based Linking (CBL) handler implementation (in favor of the AuthProvider handler implementation ) to handle obtaining access tokens from Login with Amazon (LWA). Changing from the AuthProvider handler to the CBL handler is not a required change, but we recommend that you use the Auto SDK CBL interface for ease of implementation. For details about the CBL handler, please see the CBL module documentation. If you want to continue using the AuthProvider interface, we recommend that you implement the new onAuthFailure() method that exposes 403 \"unauthorized request\" exceptions from Alexa Voice Service (AVS). This method may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. In the Sample Apps, you can override the interface and unset your login credentials as if the user had done so with your GUI interface: Java (Android) - click to expand or collapse @Override public void authFailure( String token ) { // handle user de-authorize scenario C++ - click to expand or collapse void AuthProviderHandler::authFailure( const std::string& token ) { // handle user de-authorize scenario","title":"Code-Based-Linking (CBL) Handler in the Sample Apps"}]}